repo,old_env,new_env,old_code,new_code
numpy/numpy,v1.24.2,v1.24.3,"[' hypothesis.settings.register_profile(\n', '     name=""np.test() profile"",\n', '     deadline=None, print_blob=True, database=None, derandomize=True,\n', '+    suppress_health_check=list(hypothesis.HealthCheck),\n', ' )\n', ' # Note that the default profile is chosen based on the presence \n', ' # of pytest.ini, but can be overridden by passing the \n']","[' hypothesis.settings.register_profile(\n', '     name=""np.test() profile"",\n', '     deadline=None, print_blob=True, database=None, derandomize=True,\n', '-    suppress_health_check=hypothesis.HealthCheck.all(),\n', ' )\n', ' # Note that the default profile is chosen based on the presence \n', ' # of pytest.ini, but can be overridden by passing the \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _require_with_like = array_function_dispatch(\n', '+    _require_dispatcher, use_like=True\n', ' )(require)\n']","[' \n', ' \n', ' _require_with_like = array_function_dispatch(\n', '-    _require_dispatcher\n', ' )(require)\n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _ones_with_like = array_function_dispatch(\n', '+    _ones_dispatcher, use_like=True\n', ' )(ones)\n', ' \n', ' \n']","[' \n', ' \n', ' _ones_with_like = array_function_dispatch(\n', '-    _ones_dispatcher\n', ' )(ones)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _full_with_like = array_function_dispatch(\n', '+    _full_dispatcher, use_like=True\n', ' )(full)\n', ' \n', ' \n']","[' \n', ' \n', ' _full_with_like = array_function_dispatch(\n', '-    _full_dispatcher\n', ' )(full)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _fromfunction_with_like = array_function_dispatch(\n', '+    _fromfunction_dispatcher, use_like=True\n', ' )(fromfunction)\n', ' \n', ' \n']","[' \n', ' \n', ' _fromfunction_with_like = array_function_dispatch(\n', '-    _fromfunction_dispatcher\n', ' )(fromfunction)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _identity_with_like = array_function_dispatch(\n', '+    _identity_dispatcher, use_like=True\n', ' )(identity)\n', ' \n', ' \n']","[' \n', ' \n', ' _identity_with_like = array_function_dispatch(\n', '-    _identity_dispatcher\n', ' )(identity)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' def array_function_dispatch(dispatcher, module=None, verify=True,\n', '+                            docs_from_dispatcher=False, use_like=False):\n', '     """"""Decorator for adding dispatch with the __array_function__ protocol.\n', ' \n', '     See NEP-18 for example usage.\n']","[' \n', ' \n', ' def array_function_dispatch(dispatcher, module=None, verify=True,\n', '-                            docs_from_dispatcher=False):\n', '     """"""Decorator for adding dispatch with the __array_function__ protocol.\n', ' \n', '     See NEP-18 for example usage.\n']"
numpy/numpy,v1.24.2,v1.24.3,"['                 raise TypeError(new_msg) from None\n', ' \n', '             return implement_array_function(\n', '+                implementation, public_api, relevant_args, args, kwargs,\n', '+                use_like)\n', ' \n', '         public_api.__code__ = public_api.__code__.replace(\n', '                 co_name=implementation.__name__,\n']","['                 raise TypeError(new_msg) from None\n', ' \n', '             return implement_array_function(\n', '-                implementation, public_api, relevant_args, args, kwargs)\n', ' \n', '         public_api.__code__ = public_api.__code__.replace(\n', '                 co_name=implementation.__name__,\n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ""         dt = np.datetime64('2000', '5μs')\n"", ""         assert np.datetime_data(dt.dtype) == ('us', 5)\n"", '+\n', '+\n', '+def test_comparisons_return_not_implemented():\n', '+    # GH#17017\n', '+\n', '+    class custom:\n', '+        __array_priority__ = 10000\n', '+\n', '+    obj = custom()\n', '+\n', ""+    dt = np.datetime64('2000', 'ns')\n"", '+    td = dt - dt\n', '+\n', '+    for item in [dt, td]:\n', '+        assert item.__eq__(obj) is NotImplemented\n', '+        assert item.__ne__(obj) is NotImplemented\n', '+        assert item.__le__(obj) is NotImplemented\n', '+        assert item.__lt__(obj) is NotImplemented\n', '+        assert item.__ge__(obj) is NotImplemented\n', '+        assert item.__gt__(obj) is NotImplemented\n']","[' \n', ""         dt = np.datetime64('2000', '5μs')\n"", ""         assert np.datetime_data(dt.dtype) == ('us', 5)\n""]"
numpy/numpy,v1.24.2,v1.24.3,"['         with pytest.raises(TypeError):\n', '             # cannot call it a second time:\n', '             np.negative._get_strided_loop(call_info)\n', '+\n', '+    def test_long_arrays(self):\n', '+        t = np.zeros((1029, 917), dtype=np.single)\n', '+        t[0][0] = 1\n', '+        t[28][414] = 1\n', '+        tc = np.cos(t)\n', '+        assert_equal(tc[0][0], tc[28][414])\n']","['         with pytest.raises(TypeError):\n', '             # cannot call it a second time:\n', '             np.negative._get_strided_loop(call_info)\n']"
numpy/numpy,v1.24.2,v1.24.3,"[' def getarrdims(a, var, verbose=0):\n', '     ret = {}\n', '     if isstring(var) and not isarray(var):\n', ""+        ret['size'] = getstrlength(var)\n"", ""+        ret['rank'] = '0'\n"", ""+        ret['dims'] = ''\n"", '     elif isscalar(var):\n', ""         ret['size'] = '1'\n"", ""         ret['rank'] = '0'\n""]","[' def getarrdims(a, var, verbose=0):\n', '     ret = {}\n', '     if isstring(var) and not isarray(var):\n', ""-        ret['dims'] = getstrlength(var)\n"", ""-        ret['size'] = ret['dims']\n"", ""-        ret['rank'] = '1'\n"", '     elif isscalar(var):\n', ""         ret['size'] = '1'\n"", ""         ret['rank'] = '0'\n""]"
numpy/numpy,v1.24.2,v1.24.3,"['                         d1[k] = unmarkouterparen(d1[k])\n', '                     else:\n', '                         del d1[k]\n', '+\n', ""+                if 'len' in d1:\n"", ""+                    if typespec in ['complex', 'integer', 'logical', 'real']:\n"", ""+                        if ('kindselector' not in edecl) or (not edecl['kindselector']):\n"", ""+                            edecl['kindselector'] = {}\n"", ""+                        edecl['kindselector']['*'] = d1['len']\n"", ""+                        del d1['len']\n"", ""+                    elif typespec == 'character':\n"", ""+                        if ('charselector' not in edecl) or (not edecl['charselector']):\n"", ""+                            edecl['charselector'] = {}\n"", ""+                        if 'len' in edecl['charselector']:\n"", ""+                            del edecl['charselector']['len']\n"", ""+                        edecl['charselector']['*'] = d1['len']\n"", ""+                        del d1['len']\n"", '+\n', ""+                if 'init' in d1:\n"", ""+                    if '=' in edecl and (not edecl['='] == d1['init']):\n"", '+                        outmess(\'updatevars: attempt to change the init expression of ""%s"" (""%s"") to ""%s"". Ignoring.\\n\' % (\n', ""+                            ename, edecl['='], d1['init']))\n"", '+                    else:\n', ""+                        edecl['='] = d1['init']\n"", '+\n', ""                 if 'len' in d1 and 'array' in d1:\n"", ""                     if d1['len'] == '':\n"", ""                         d1['len'] = d1['array']\n""]","['                         d1[k] = unmarkouterparen(d1[k])\n', '                     else:\n', '                         del d1[k]\n', ""                 if 'len' in d1 and 'array' in d1:\n"", ""                     if d1['len'] == '':\n"", ""                         d1['len'] = d1['array']\n""]"
numpy/numpy,v1.24.2,v1.24.3,"[""                         del d1['len']\n"", '                         errmess(\'updatevars: ""%s %s"" is mapped to ""%s %s(%s)""\\n\' % (\n', ""                             typespec, e, typespec, ename, d1['array']))\n"", '+\n', ""                 if 'array' in d1:\n"", ""                     dm = 'dimension(%s)' % d1['array']\n"", ""                     if 'attrspec' not in edecl or (not edecl['attrspec']):\n""]","[""                         del d1['len']\n"", '                         errmess(\'updatevars: ""%s %s"" is mapped to ""%s %s(%s)""\\n\' % (\n', ""                             typespec, e, typespec, ename, d1['array']))\n"", ""                 if 'array' in d1:\n"", ""                     dm = 'dimension(%s)' % d1['array']\n"", ""                     if 'attrspec' not in edecl or (not edecl['attrspec']):\n""]"
numpy/numpy,v1.24.2,v1.24.3,"['                                         % (ename, dm1, dm))\n', '                                 break\n', ' \n', '             else:\n', '                 outmess(\'updatevars: could not crack entity declaration ""%s"". Ignoring.\\n\' % (\n', ""                     ename + m.group('after')))\n""]","['                                         % (ename, dm1, dm))\n', '                                 break\n', ' \n', ""-                if 'len' in d1:\n"", ""-                    if typespec in ['complex', 'integer', 'logical', 'real']:\n"", ""-                        if ('kindselector' not in edecl) or (not edecl['kindselector']):\n"", ""-                            edecl['kindselector'] = {}\n"", ""-                        edecl['kindselector']['*'] = d1['len']\n"", ""-                    elif typespec == 'character':\n"", ""-                        if ('charselector' not in edecl) or (not edecl['charselector']):\n"", ""-                            edecl['charselector'] = {}\n"", ""-                        if 'len' in edecl['charselector']:\n"", ""-                            del edecl['charselector']['len']\n"", ""-                        edecl['charselector']['*'] = d1['len']\n"", ""-                if 'init' in d1:\n"", ""-                    if '=' in edecl and (not edecl['='] == d1['init']):\n"", '-                        outmess(\'updatevars: attempt to change the init expression of ""%s"" (""%s"") to ""%s"". Ignoring.\\n\' % (\n', ""-                            ename, edecl['='], d1['init']))\n"", '-                    else:\n', ""-                        edecl['='] = d1['init']\n"", '             else:\n', '                 outmess(\'updatevars: could not crack entity declaration ""%s"". Ignoring.\\n\' % (\n', ""                     ename + m.group('after')))\n""]"
numpy/numpy,v1.24.2,v1.24.3,"['         assert_equal(len(a), 2)\n', ' \n', ""         assert_raises(Exception, lambda: f(b'c'))\n"", '+\n', '+\n', '+class TestStringScalarArr(util.F2PyTest):\n', '+    sources = [util.getpath(""tests"", ""src"", ""string"", ""scalar_string.f90"")]\n', '+\n', '+    @pytest.mark.slow\n', '+    def test_char(self):\n', '+        for out in (self.module.string_test.string,\n', '+                    self.module.string_test.string77):\n', '+            expected = ()\n', '+            assert out.shape == expected\n', ""+            expected = '|S8'\n"", '+            assert out.dtype == expected\n', '+\n', '+    @pytest.mark.slow\n', '+    def test_char_arr(self):\n', '+        for out in (self.module.string_test.strarr,\n', '+                    self.module.string_test.strarr77):\n', '+            expected = (5,7)\n', '+            assert out.shape == expected\n', ""+            expected = '|S12'\n"", '+            assert out.dtype == expected\n']","['         assert_equal(len(a), 2)\n', ' \n', ""         assert_raises(Exception, lambda: f(b'c'))\n""]"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _loadtxt_with_like = array_function_dispatch(\n', '+    _loadtxt_dispatcher, use_like=True\n', ' )(loadtxt)\n', ' \n', ' \n']","[' \n', ' \n', ' _loadtxt_with_like = array_function_dispatch(\n', '-    _loadtxt_dispatcher\n', ' )(loadtxt)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _genfromtxt_with_like = array_function_dispatch(\n', '+    _genfromtxt_dispatcher, use_like=True\n', ' )(genfromtxt)\n', ' \n', ' \n']","[' \n', ' \n', ' _genfromtxt_with_like = array_function_dispatch(\n', '-    _genfromtxt_dispatcher\n', ' )(genfromtxt)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[""         assert_equal(a, l['file_a'])\n"", ""         assert_equal(b, l['file_b'])\n"", ' \n', '+    def test_named_arrays_with_like(self):\n', '+        a = np.array([[1, 2], [3, 4]], float)\n', '+        b = np.array([[1 + 2j, 2 + 7j], [3 - 6j, 4 + 12j]], complex)\n', '+        c = BytesIO()\n', '+        np.savez(c, file_a=a, like=b)\n', '+        c.seek(0)\n', '+        l = np.load(c)\n', ""+        assert_equal(a, l['file_a'])\n"", ""+        assert_equal(b, l['like'])\n"", '+\n', '     def test_BagObj(self):\n', '         a = np.array([[1, 2], [3, 4]], float)\n', '         b = np.array([[1 + 2j, 2 + 7j], [3 - 6j, 4 + 12j]], complex)\n']","[""         assert_equal(a, l['file_a'])\n"", ""         assert_equal(b, l['file_b'])\n"", ' \n', '     def test_BagObj(self):\n', '         a = np.array([[1, 2], [3, 4]], float)\n', '         b = np.array([[1 + 2j, 2 + 7j], [3 - 6j, 4 + 12j]], complex)\n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _eye_with_like = array_function_dispatch(\n', '+    _eye_dispatcher, use_like=True\n', ' )(eye)\n', ' \n', ' \n']","[' \n', ' \n', ' _eye_with_like = array_function_dispatch(\n', '-    _eye_dispatcher\n', ' )(eye)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"[' \n', ' \n', ' _tri_with_like = array_function_dispatch(\n', '+    _tri_dispatcher, use_like=True\n', ' )(tri)\n', ' \n', ' \n']","[' \n', ' \n', ' _tri_with_like = array_function_dispatch(\n', '-    _tri_dispatcher\n', ' )(tri)\n', ' \n', ' \n']"
numpy/numpy,v1.24.2,v1.24.3,"['     >>> xcenters = (xedges[:-1] + xedges[1:]) / 2\n', '     >>> ycenters = (yedges[:-1] + yedges[1:]) / 2\n', '     >>> im.set_data(xcenters, ycenters, H)\n', '+    >>> ax.add_image(im)\n', '     >>> plt.show()\n', ' \n', '     It is also possible to construct a 2-D histogram without specifying bin\n']","['     >>> xcenters = (xedges[:-1] + xedges[1:]) / 2\n', '     >>> ycenters = (yedges[:-1] + yedges[1:]) / 2\n', '     >>> im.set_data(xcenters, ycenters, H)\n', '-    >>> ax.images.append(im)\n', '     >>> plt.show()\n', ' \n', '     It is also possible to construct a 2-D histogram without specifying bin\n']"
numpy/numpy,v1.24.2,v1.24.3,"[""                 # Note: Don't try to check for m.any(), that'll take too long\n"", '         return dout\n', ' \n', '+    # setitem may put NaNs into integer arrays or occasionally overflow a\n', '+    # float.  But this may happen in masked values, so avoid otherwise\n', '+    # correct warnings (as is typical also in masked calculations).\n', ""+    @np.errstate(over='ignore', invalid='ignore')\n"", '     def __setitem__(self, indx, value):\n', '         """"""\n', '         x.__setitem__(i, y) <==> x[i]=y\n']","[""                 # Note: Don't try to check for m.any(), that'll take too long\n"", '         return dout\n', ' \n', '     def __setitem__(self, indx, value):\n', '         """"""\n', '         x.__setitem__(i, y) <==> x[i]=y\n']"
numpy/numpy,v1.24.2,v1.24.3,"[""             otherwise.  'K' means to read the elements in the order they occur\n"", '             in memory, except for reversing the data when strides are negative.\n', ""             By default, 'C' index order is used.\n"", ""+            (Masked arrays currently use 'A' on the data when 'K' is passed.)\n"", ' \n', '         Returns\n', '         -------\n']","[""             otherwise.  'K' means to read the elements in the order they occur\n"", '             in memory, except for reversing the data when strides are negative.\n', ""             By default, 'C' index order is used.\n"", ' \n', '         Returns\n', '         -------\n']"
numpy/numpy,v1.24.2,v1.24.3,"['                fill_value=999999)\n', ' \n', '         """"""\n', ""+        # The order of _data and _mask could be different (it shouldn't be\n"", '+        # normally).  Passing order `K` or `A` would be incorrect.\n', '+        # So we ignore the mask memory order.\n', ""+        # TODO: We don't actually support K, so use A instead.  We could\n"", '+        #       try to guess this correct by sorting strides or deprecate.\n', '+        if order in ""kKaA"":\n', '+            order = ""C"" if self._data.flags.fnc else ""F""\n', '         r = ndarray.ravel(self._data, order=order).view(type(self))\n', '         r._update_from(self)\n', '         if self._mask is not nomask:\n']","['                fill_value=999999)\n', ' \n', '         """"""\n', '         r = ndarray.ravel(self._data, order=order).view(type(self))\n', '         r._update_from(self)\n', '         if self._mask is not nomask:\n']"
numpy/numpy,v1.24.2,v1.24.3,"['         assert_equal(s1, s2)\n', '         assert_(x1[1:1].shape == (0,))\n', ' \n', '+    def test_setitem_no_warning(self):\n', ""+        # Setitem shouldn't warn, because the assignment might be masked\n"", '+        # and warning for a masked assignment is weird (see gh-23000)\n', '+        # (When the value is masked, otherwise a warning would be acceptable\n', '+        # but is not given currently.)\n', '+        x = np.ma.arange(60).reshape((6, 10))\n', '+        index = (slice(1, 5, 2), [7, 5])\n', '+        value = np.ma.masked_all((2, 2))\n', '+        value._data[...] = np.inf  # not a valid integer...\n', '+        x[index] = value\n', ""+        # The masked scalar is special cased, but test anyway (it's NaN):\n"", '+        x[...] = np.ma.masked\n', '+        # Finally, a large value that cannot be cast to the float32 `x`\n', '+        x = np.ma.arange(3., dtype=np.float32)\n', '+        value = np.ma.array([2e234, 1, 1], mask=[True, False, False])\n', '+        x[...] = value\n', '+        x[[0, 1, 2]] = value\n', '+\n', '     @suppress_copy_mask_on_assignment\n', '     def test_copy(self):\n', '         # Tests of some subtle points of copying and sizing.\n']","['         assert_equal(s1, s2)\n', '         assert_(x1[1:1].shape == (0,))\n', ' \n', '     @suppress_copy_mask_on_assignment\n', '     def test_copy(self):\n', '         # Tests of some subtle points of copying and sizing.\n']"
numpy/numpy,v1.24.2,v1.24.3,"[""         assert_equal(a.ravel(order='C'), [1, 2, 3, 4])\n"", ""         assert_equal(a.ravel(order='F'), [1, 3, 2, 4])\n"", ' \n', '+    @pytest.mark.parametrize(""order"", ""AKCF"")\n', '+    @pytest.mark.parametrize(""data_order"", ""CF"")\n', '+    def test_ravel_order(self, order, data_order):\n', '+        # Ravelling must ravel mask and data in the same order always to avoid\n', '+        # misaligning the two in the ravel result.\n', '+        arr = np.ones((5, 10), order=data_order)\n', '+        arr[0, :] = 0\n', '+        mask = np.ones((10, 5), dtype=bool, order=data_order).T\n', '+        mask[0, :] = False\n', '+        x = array(arr, mask=mask)\n', '+        assert x._data.flags.fnc != x._mask.flags.fnc\n', '+        assert (x.filled(0) == 0).all()\n', '+        raveled = x.ravel(order)\n', '+        assert (raveled.filled(0) == 0).all()\n', '+\n', '+\n', '     def test_reshape(self):\n', '         # Tests reshape\n', '         x = arange(4)\n']","[""         assert_equal(a.ravel(order='C'), [1, 2, 3, 4])\n"", ""         assert_equal(a.ravel(order='F'), [1, 3, 2, 4])\n"", ' \n', '     def test_reshape(self):\n', '         # Tests reshape\n', '         x = arange(4)\n']"
numpy/numpy,v1.24.2,v1.24.3,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.24.3-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.24.2-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.24.1,v1.24.2,"[' \n', ' # NOTE: Import `Sequence` from `typing` as we it is needed for a type-alias,\n', ' # not an annotation\n', '+import sys\n', ' from collections.abc import Collection, Callable\n', ' from typing import Any, Sequence, Protocol, Union, TypeVar, runtime_checkable\n', ' from numpy import (\n']","[' \n', ' # NOTE: Import `Sequence` from `typing` as we it is needed for a type-alias,\n', ' # not an annotation\n', ' from collections.abc import Collection, Callable\n', ' from typing import Any, Sequence, Protocol, Union, TypeVar, runtime_checkable\n', ' from numpy import (\n']"
numpy/numpy,v1.24.1,v1.24.2,"[' # is resolved. See also the mypy issue:\n', ' #\n', ' # https://github.com/python/typing/issues/593\n', '+if sys.version_info[:2] < (3, 9):\n', '+    ArrayLike = _DualArrayLike[\n', '+        dtype,\n', '+        Union[bool, int, float, complex, str, bytes],\n', '+    ]\n', '+else:\n', '+    ArrayLike = _DualArrayLike[\n', '+        dtype[Any],\n', '+        Union[bool, int, float, complex, str, bytes],\n', '+    ]\n', ' \n', ' # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`\n', ' # given the casting rules `same_kind`\n']","[' # is resolved. See also the mypy issue:\n', ' #\n', ' # https://github.com/python/typing/issues/593\n', '-ArrayLike = _DualArrayLike[\n', '-    dtype,\n', '-    Union[bool, int, float, complex, str, bytes],\n', '-]\n', ' \n', ' # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`\n', ' # given the casting rules `same_kind`\n']"
numpy/numpy,v1.24.1,v1.24.2,"['         assert len(self.out) == nout\n', '         self.astype = self.astype_dict.get(self.type, None)\n', ' \n', '+\n', '+def _check_order(types1, types2):\n', '+    dtype_order = allP + ""O""\n', '+    for t1, t2 in zip(types1, types2):\n', '+        # We have no opinion on object or time ordering for now:\n', '+        if t1 in ""OP"" or t2 in ""OP"":\n', '+            return True\n', '+        if t1 in ""mM"" or t2 in ""mM"":\n', '+            return True\n', '+\n', '+        t1i = dtype_order.index(t1)\n', '+        t2i = dtype_order.index(t2)\n', '+        if t1i < t2i:\n', '+            return\n', '+        if t2i > t1i:\n', '+            break\n', '+\n', '+    raise TypeError(\n', '+            f""Input dtypes are unsorted or duplicate: {types1} and {types2}"")\n', '+\n', '+\n', '+def check_td_order(tds):\n', '+    # A quick check for whether the signatures make sense, it happened too\n', '+    # often that SIMD additions added loops that do not even make some sense.\n', '+    # TODO: This should likely be a test and it would be nice if it rejected\n', '+    #       duplicate entries as well (but we have many as of writing this).\n', '+    signatures = [t.in_+t.out for t in tds]\n', '+\n', '+    for prev_i, sign in enumerate(signatures[1:]):\n', '+        if sign in signatures[:prev_i+1]:\n', '+            continue  # allow duplicates...\n', '+        \n', '+        _check_order(signatures[prev_i], sign)\n', '+\n', '+\n', ' _fdata_map = dict(\n', ""     e='npy_%sf',\n"", ""     f='npy_%sf',\n""]","['         assert len(self.out) == nout\n', '         self.astype = self.astype_dict.get(self.type, None)\n', ' \n', ' _fdata_map = dict(\n', ""     e='npy_%sf',\n"", ""     f='npy_%sf',\n""]"
numpy/numpy,v1.24.1,v1.24.2,"['         for td in self.type_descriptions:\n', '             td.finish_signature(self.nin, self.nout)\n', ' \n', '+        check_td_order(self.type_descriptions)\n', '+\n', '+\n', ' # String-handling utilities to avoid locale-dependence.\n', ' \n', ' import string\n']","['         for td in self.type_descriptions:\n', '             td.finish_signature(self.nin, self.nout)\n', ' \n', ' # String-handling utilities to avoid locale-dependence.\n', ' \n', ' import string\n']"
numpy/numpy,v1.24.1,v1.24.2,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cos'),\n"", '           None,\n', ""+          TD('e', dispatch=[('loops_umath_fp', 'e')]),\n"", ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""+          TD('d', dispatch=[('loops_umath_fp', 'd')]),\n"", ""+          TD('g' + cmplx, f='cos'),\n"", ""           TD(P, f='cos'),\n"", '           ),\n', "" 'sin':\n"", '     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.sin'),\n"", '           None,\n', ""+          TD('e', dispatch=[('loops_umath_fp', 'e')]),\n"", ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""+          TD('d', dispatch=[('loops_umath_fp', 'd')]),\n"", ""+          TD('g' + cmplx, f='sin'),\n"", ""           TD(P, f='sin'),\n"", '           ),\n', "" 'tan':\n""]","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cos'),\n"", '           None,\n', ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""-          TD('ed', dispatch=[('loops_umath_fp', 'ed')]),\n"", ""-          TD('fdg' + cmplx, f='cos'),\n"", ""           TD(P, f='cos'),\n"", '           ),\n', "" 'sin':\n"", '     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.sin'),\n"", '           None,\n', ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""-          TD('ed', dispatch=[('loops_umath_fp', 'ed')]),\n"", ""-          TD('fdg' + cmplx, f='sin'),\n"", ""           TD(P, f='sin'),\n"", '           ),\n', "" 'tan':\n""]"
numpy/numpy,v1.24.1,v1.24.2,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctan2'),\n"", '           None,\n', ""+          TD('e', f='atan2', astype={'e': 'f'}),\n"", ""           TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""+          TD('g', f='atan2', astype={'e': 'f'}),\n"", ""           TD(P, f='arctan2'),\n"", '           ),\n', "" 'remainder':\n""]","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctan2'),\n"", '           None,\n', ""           TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""-          TD(flts, f='atan2', astype={'e': 'f'}),\n"", ""           TD(P, f='arctan2'),\n"", '           ),\n', "" 'remainder':\n""]"
numpy/numpy,v1.24.1,v1.24.2,"['     # Unfortunately, they are currently still valid via `np.dtype()`\n', '     np.dtype(name)\n', '     name in np.sctypeDict\n', '+\n', '+\n', '+# Ignore the above future attribute warning for this test.\n', '+@pytest.mark.filterwarnings(""ignore:In the future:FutureWarning"")\n', '+class TestRemovedGlobals:\n', '+    # Removed 2023-01-12, NumPy 1.24.0\n', '+    # Not a deprecation, but the large error was added to aid those who missed\n', '+    # the previous deprecation, and should be removed similarly to one\n', '+    # (or faster).\n', '+    @pytest.mark.parametrize(""name"",\n', '+            [""object"", ""bool"", ""float"", ""complex"", ""str"", ""int""])\n', '+    def test_attributeerror_includes_info(self, name):\n', '+        msg = f"".*\\n`np.{name}` was a deprecated alias for the builtin""\n', '+        with pytest.raises(AttributeError, match=msg):\n', '+            getattr(np, name)\n']","['     # Unfortunately, they are currently still valid via `np.dtype()`\n', '     np.dtype(name)\n', '     name in np.sctypeDict\n']"
numpy/numpy,v1.24.1,v1.24.2,"[""         assert_array_equal(x['a'], [3.5, 3.5])\n"", ""         assert_array_equal(x['b'], [-2, -2])\n"", ' \n', '+    def test_fill_readonly(self):\n', '+        # gh-22922\n', '+        a = np.zeros(11)\n', '+        a.setflags(write=False)\n', '+        with pytest.raises(ValueError, match="".*read-only""):\n', '+            a.fill(0)\n', '+\n', ' \n', ' class TestArrayConstruction:\n', '     def test_array(self):\n']","[""         assert_array_equal(x['a'], [3.5, 3.5])\n"", ""         assert_array_equal(x['b'], [-2, -2])\n"", ' \n', ' \n', ' class TestArrayConstruction:\n', '     def test_array(self):\n']"
numpy/numpy,v1.24.1,v1.24.2,"['             np.add(1, 1)\n', ' \n', ' \n', '+def check_ufunc_scalar_equivalence(op, arr1, arr2):\n', '     scalar1 = arr1[()]\n', '     scalar2 = arr2[()]\n', '     assert isinstance(scalar1, np.generic)\n']","['             np.add(1, 1)\n', ' \n', ' \n', '-@pytest.mark.slow\n', '-@settings(max_examples=10000, deadline=2000)\n', '-@given(sampled_from(reasonable_operators_for_scalars),\n', '-       hynp.arrays(dtype=hynp.scalar_dtypes(), shape=()),\n', '-       hynp.arrays(dtype=hynp.scalar_dtypes(), shape=()))\n', '-def test_array_scalar_ufunc_equivalence(op, arr1, arr2):\n', '-    """"""\n', '-    This is a thorough test attempting to cover important promotion paths\n', '-    and ensuring that arrays and scalars stay as aligned as possible.\n', '-    However, if it creates troubles, it should maybe just be removed.\n', '-    """"""\n', '     scalar1 = arr1[()]\n', '     scalar2 = arr2[()]\n', '     assert isinstance(scalar1, np.generic)\n']"
numpy/numpy,v1.24.1,v1.24.2,"['         comp_ops = {operator.ge, operator.gt, operator.le, operator.lt}\n', '         if op in comp_ops and (np.isnan(scalar1) or np.isnan(scalar2)):\n', '             pytest.xfail(""complex comp ufuncs use sort-order, scalars do not."")\n', '+    if op == operator.pow and arr2.item() in [-1, 0, 0.5, 1, 2]:\n', '+        # array**scalar special case can have different result dtype\n', '+        # (Other powers may have issues also, but are not hit here.)\n', '+        # TODO: It would be nice to resolve this issue.\n', '+        pytest.skip(""array**2 can have incorrect/weird result dtype"")\n', ' \n', ""     # ignore fpe's since they may just mismatch for integers anyway.\n"", '     with warnings.catch_warnings(), np.errstate(all=""ignore""):\n']","['         comp_ops = {operator.ge, operator.gt, operator.le, operator.lt}\n', '         if op in comp_ops and (np.isnan(scalar1) or np.isnan(scalar2)):\n', '             pytest.xfail(""complex comp ufuncs use sort-order, scalars do not."")\n', ' \n', ""     # ignore fpe's since they may just mismatch for integers anyway.\n"", '     with warnings.catch_warnings(), np.errstate(all=""ignore""):\n']"
numpy/numpy,v1.24.1,v1.24.2,"['                 op(scalar1, scalar2)\n', '         else:\n', '             scalar_res = op(scalar1, scalar2)\n', '+            assert_array_equal(scalar_res, res, strict=True)\n', '+\n', '+\n', '+@pytest.mark.slow\n', '+@settings(max_examples=10000, deadline=2000)\n', '+@given(sampled_from(reasonable_operators_for_scalars),\n', '+       hynp.arrays(dtype=hynp.scalar_dtypes(), shape=()),\n', '+       hynp.arrays(dtype=hynp.scalar_dtypes(), shape=()))\n', '+def test_array_scalar_ufunc_equivalence(op, arr1, arr2):\n', '+    """"""\n', '+    This is a thorough test attempting to cover important promotion paths\n', '+    and ensuring that arrays and scalars stay as aligned as possible.\n', '+    However, if it creates troubles, it should maybe just be removed.\n', '+    """"""\n', '+    check_ufunc_scalar_equivalence(op, arr1, arr2)\n', '+\n', '+\n', '+@pytest.mark.slow\n', '+@given(sampled_from(reasonable_operators_for_scalars),\n', '+       hynp.scalar_dtypes(), hynp.scalar_dtypes())\n', '+def test_array_scalar_ufunc_dtypes(op, dt1, dt2):\n', ""+    # Same as above, but don't worry about sampling weird values so that we\n"", '+    # do not have to sample as much\n', '+    arr1 = np.array(2, dtype=dt1)\n', '+    arr2 = np.array(3, dtype=dt2)  # some power do weird things.\n', '+\n', '+    check_ufunc_scalar_equivalence(op, arr1, arr2)\n', '+\n', '+\n', '+@pytest.mark.parametrize(""fscalar"", [np.float16, np.float32])\n', '+def test_int_float_promotion_truediv(fscalar):\n', '+    # Promotion for mixed int and float32/float16 must not go to float64\n', '+    i = np.int8(1)\n', '+    f = fscalar(1)\n', '+    expected = np.result_type(i, f)\n', '+    assert (i / f).dtype == expected\n', '+    assert (f / i).dtype == expected\n', '+    # But normal int / int true division goes to float64:\n', '+    assert (i / i).dtype == np.dtype(""float64"")\n', '+    # For int16, result has to be ast least float32 (takes ufunc path):\n', '+    assert (np.int16(1) / f).dtype == np.dtype(""float32"")\n', ' \n', ' \n', ' class TestBaseMath:\n']","['                 op(scalar1, scalar2)\n', '         else:\n', '             scalar_res = op(scalar1, scalar2)\n', '-            assert_array_equal(scalar_res, res)\n', ' \n', ' \n', ' class TestBaseMath:\n']"
numpy/numpy,v1.24.1,v1.24.2,"['             check(func, pts, 1j)\n', '             check(func, pts, 1+1j)\n', ' \n', '+    @np.errstate(all=""ignore"")\n', '+    def test_promotion_corner_cases(self):\n', '+        for func in self.funcs:\n', '+            assert func(np.float16(1)).dtype == np.float16\n', '+            # Integer to low precision float promotion is a dubious choice:\n', '+            assert func(np.uint8(1)).dtype == np.float16\n', '+            assert func(np.int16(1)).dtype == np.float32\n', '+\n', ' \n', ' class TestAttributes:\n', '     def test_attributes(self):\n']","['             check(func, pts, 1j)\n', '             check(func, pts, 1+1j)\n', ' \n', ' \n', ' class TestAttributes:\n', '     def test_attributes(self):\n']"
numpy/numpy,v1.24.1,v1.24.2,"['         detect_arch = (\n', '             (""cc_on_x64"",      "".*(x|x86_|amd)64.*"", """"),\n', '             (""cc_on_x86"",      "".*(win32|x86|i386|i686).*"", """"),\n', '+            (""cc_on_ppc64le"",  "".*(powerpc|ppc)64(el|le).*|.*powerpc.*"",\n', '+                                          ""defined(__powerpc64__) && ""\n', '+                                          ""defined(__LITTLE_ENDIAN__)""),\n', '+            (""cc_on_ppc64"",    "".*(powerpc|ppc).*|.*powerpc.*"",\n', '+                                          ""defined(__powerpc64__) && ""\n', '+                                          ""defined(__BIG_ENDIAN__)""),\n', '             (""cc_on_aarch64"",  "".*(aarch64|arm64).*"", """"),\n', '             (""cc_on_armhf"",    "".*arm.*"", ""defined(__ARM_ARCH_7__) || ""\n', '                                           ""defined(__ARM_ARCH_7A__)""),\n']","['         detect_arch = (\n', '             (""cc_on_x64"",      "".*(x|x86_|amd)64.*"", """"),\n', '             (""cc_on_x86"",      "".*(win32|x86|i386|i686).*"", """"),\n', '-            (""cc_on_ppc64le"",  "".*(powerpc|ppc)64(el|le).*"", """"),\n', '-            (""cc_on_ppc64"",    "".*(powerpc|ppc)64.*"", """"),\n', '             (""cc_on_aarch64"",  "".*(aarch64|arm64).*"", """"),\n', '             (""cc_on_armhf"",    "".*arm.*"", ""defined(__ARM_ARCH_7__) || ""\n', '                                           ""defined(__ARM_ARCH_7A__)""),\n']"
numpy/numpy,v1.24.1,v1.24.2,"[""     array([('alpha, #42', 10.), ('beta, #64',  2.)],\n"", ""           dtype=[('label', '<U12'), ('value', '<f8')])\n"", ' \n', '+    Quoted fields can be separated by multiple whitespace characters:\n', '+\n', '+    >>> s = StringIO(\'""alpha, #42""       10.0\\n""beta, #64"" 2.0\\n\')\n', '+    >>> dtype = np.dtype([(""label"", ""U12""), (""value"", float)])\n', '+    >>> np.loadtxt(s, dtype=dtype, delimiter=None, quotechar=\'""\')\n', ""+    array([('alpha, #42', 10.), ('beta, #64',  2.)],\n"", ""+          dtype=[('label', '<U12'), ('value', '<f8')])\n"", '+\n', '     Two consecutive quote characters within a quoted field are treated as a\n', '     single escaped character:\n', ' \n']","[""     array([('alpha, #42', 10.), ('beta, #64',  2.)],\n"", ""           dtype=[('label', '<U12'), ('value', '<f8')])\n"", ' \n', '     Two consecutive quote characters within a quoted field are treated as a\n', '     single escaped character:\n', ' \n']"
numpy/numpy,v1.24.1,v1.24.2,"['     assert_array_equal(res, expected)\n', ' \n', ' \n', '+@pytest.mark.parametrize(""q"", (\'""\', ""\'"", ""`""))\n', '+def test_quoted_field_with_whitepace_delimiter(q):\n', '+    txt = StringIO(\n', '+        f""{q}alpha, x{q}     2.5\\n{q}beta, y{q} 4.5\\n{q}gamma, z{q}   5.0\\n""\n', '+    )\n', ""+    dtype = np.dtype([('f0', 'U8'), ('f1', np.float64)])\n"", '+    expected = np.array(\n', '+        [(""alpha, x"", 2.5), (""beta, y"", 4.5), (""gamma, z"", 5.0)], dtype=dtype\n', '+    )\n', '+\n', '+    res = np.loadtxt(txt, dtype=dtype, delimiter=None, quotechar=q)\n', '+    assert_array_equal(res, expected)\n', '+\n', '+\n', ' def test_quote_support_default():\n', '     """"""Support for quoted fields is disabled by default.""""""\n', '     txt = StringIO(\'""lat,long"", 45, 30\\n\')\n']","['     assert_array_equal(res, expected)\n', ' \n', ' \n', ' def test_quote_support_default():\n', '     """"""Support for quoted fields is disabled by default.""""""\n', '     txt = StringIO(\'""lat,long"", 45, 30\\n\')\n']"
numpy/numpy,v1.24.1,v1.24.2,"['     are too small or too large.\n', '     """"""\n', ' \n', ""+    @pytest.fixture(scope='class', autouse=True)\n"", '+    def use_ascii(self):\n', ""+        poly.set_default_printstyle('ascii')\n"", '+\n', '     def test_str(self):\n', '         p = poly.Polynomial([1/2, 1/7, 1/7*10**8, 1/7*10**9])\n', ""         assert_equal(str(p), '0.5 + 0.14285714 x + 14285714.28571429 x**2 '\n""]","['     are too small or too large.\n', '     """"""\n', ' \n', '     def test_str(self):\n', '         p = poly.Polynomial([1/2, 1/7, 1/7*10**8, 1/7*10**9])\n', ""         assert_equal(str(p), '0.5 + 0.14285714 x + 14285714.28571429 x**2 '\n""]"
numpy/numpy,v1.24.1,v1.24.2,"['         type of the array_like objects does not match. The special\n', '         handling for scalars mentioned in the Notes section is disabled.\n', ' \n', '+        .. versionadded:: 1.24.0\n', '+\n', '     Raises\n', '     ------\n', '     AssertionError\n']","['         type of the array_like objects does not match. The special\n', '         handling for scalars mentioned in the Notes section is disabled.\n', ' \n', '     Raises\n', '     ------\n', '     AssertionError\n']"
numpy/numpy,v1.24.1,v1.24.2,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.24.2-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.24.1-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     ""floor"", ""ceil"", ""sqrt"", ""log10"", ""log"", ""exp"", ""asin"",\n', '     ""acos"", ""atan"", ""fmod"", \'modf\', \'frexp\', \'ldexp\',\n', '     ""expm1"", ""log1p"", ""acosh"", ""asinh"", ""atanh"",\n', '+    ""rint"", ""trunc"", ""exp2"",\n', '     ""copysign"", ""nextafter"", ""strtoll"", ""strtoull"", ""cbrt"",\n', '     ""log2"", ""pow"", ""hypot"", ""atan2"",\n', '     ""creal"", ""cimag"", ""conj""\n', ' ]\n', ' \n']","['     ""floor"", ""ceil"", ""sqrt"", ""log10"", ""log"", ""exp"", ""asin"",\n', '     ""acos"", ""atan"", ""fmod"", \'modf\', \'frexp\', \'ldexp\',\n', '     ""expm1"", ""log1p"", ""acosh"", ""asinh"", ""atanh"",\n', '-    ""rint"", ""trunc"", ""exp2"", \n', '     ""copysign"", ""nextafter"", ""strtoll"", ""strtoull"", ""cbrt"",\n', '     ""log2"", ""pow"", ""hypot"", ""atan2"",\n', '-    ""csin"", ""csinh"", ""ccos"", ""ccosh"", ""ctan"", ""ctanh"",\n', '     ""creal"", ""cimag"", ""conj""\n', ' ]\n', ' \n']"
numpy/numpy,v1.24.0,v1.24.1,"[' C99_COMPLEX_FUNCS = [\n', '     ""cabs"", ""cacos"", ""cacosh"", ""carg"", ""casin"", ""casinh"", ""catan"",\n', '     ""catanh"", ""cexp"", ""clog"", ""cpow"", ""csqrt"",\n', '+    # The long double variants (like csinl)  should be mandatory on C11,\n', '+    # but are missing in FreeBSD. Issue gh-22850\n', '+    ""csin"", ""csinh"", ""ccos"", ""ccosh"", ""ctan"", ""ctanh"",\n', '     ]\n', ' \n', ' OPTIONAL_HEADERS = [\n']","[' C99_COMPLEX_FUNCS = [\n', '     ""cabs"", ""cacos"", ""cacosh"", ""carg"", ""casin"", ""casinh"", ""catan"",\n', '     ""catanh"", ""cexp"", ""clog"", ""cpow"", ""csqrt"",\n', '     ]\n', ' \n', ' OPTIONAL_HEADERS = [\n']"
numpy/numpy,v1.24.0,v1.24.1,"['                        (""__builtin_bswap32"", \'5u\'),\n', '                        (""__builtin_bswap64"", \'5u\'),\n', '                        (""__builtin_expect"", \'5, 0\'),\n', '+                       # Test `long long` for arm+clang 13 (gh-22811,\n', '+                       # but we use all versions of __builtin_mul_overflow):\n', '+                       (""__builtin_mul_overflow"", \'(long long)5, 5, (int*)5\'),\n', ""                        # MMX only needed for icc, but some clangs don't have it\n"", '                        (""_m_from_int64"", \'0\', ""emmintrin.h""),\n', '                        (""_mm_load_ps"", \'(float*)0\', ""xmmintrin.h""),  # SSE\n']","['                        (""__builtin_bswap32"", \'5u\'),\n', '                        (""__builtin_bswap64"", \'5u\'),\n', '                        (""__builtin_expect"", \'5, 0\'),\n', '-                       (""__builtin_mul_overflow"", \'5, 5, (int*)5\'),\n', ""                        # MMX only needed for icc, but some clangs don't have it\n"", '                        (""_m_from_int64"", \'0\', ""emmintrin.h""),\n', '                        (""_mm_load_ps"", \'(float*)0\', ""xmmintrin.h""),  # SSE\n']"
numpy/numpy,v1.24.0,v1.24.1,"[' # may be involved in their functionality.\n', ' import pytest, math, re\n', ' import itertools\n', '+import operator\n', '+from numpy.core._simd import targets, clear_floatstatus, get_floatstatus\n', ' from numpy.core._multiarray_umath import __cpu_baseline__\n', ' \n', '+def check_floatstatus(divbyzero=False, overflow=False,\n', '+                      underflow=False, invalid=False,\n', '+                      all=False):\n', '+    #define NPY_FPE_DIVIDEBYZERO  1\n', '+    #define NPY_FPE_OVERFLOW      2\n', '+    #define NPY_FPE_UNDERFLOW     4\n', '+    #define NPY_FPE_INVALID       8\n', '+    err = get_floatstatus()\n', '+    ret = (all or divbyzero) and (err & 1) != 0\n', '+    ret |= (all or overflow) and (err & 2) != 0\n', '+    ret |= (all or underflow) and (err & 4) != 0\n', '+    ret |= (all or invalid) and (err & 8) != 0\n', '+    return ret\n', '+\n', ' class _Test_Utility:\n', '     # submodule of the desired SIMD extension, e.g. targets[""AVX512F""]\n', '     npyv = None\n']","[' # may be involved in their functionality.\n', ' import pytest, math, re\n', ' import itertools\n', '-from numpy.core._simd import targets\n', ' from numpy.core._multiarray_umath import __cpu_baseline__\n', ' \n', ' class _Test_Utility:\n', '     # submodule of the desired SIMD extension, e.g. targets[""AVX512F""]\n', '     npyv = None\n']"
numpy/numpy,v1.24.0,v1.24.1,"['         nnan = self.notnan(self.setall(self._nan()))\n', '         assert nnan == [0]*self.nlanes\n', ' \n', '+    @pytest.mark.parametrize(""intrin_name"", [\n', '+        ""rint"", ""trunc"", ""ceil"", ""floor""\n', '+    ])\n', '+    def test_unary_invalid_fpexception(self, intrin_name):\n', '+        intrin = getattr(self, intrin_name)\n', '+        for d in [float(""nan""), float(""inf""), -float(""inf"")]:\n', '+            v = self.setall(d)\n', '+            clear_floatstatus()\n', '+            intrin(v)\n', '+            assert check_floatstatus(invalid=True) == False\n', ' \n', ""     @pytest.mark.parametrize('py_comp,np_comp', [\n"", '         (operator.lt, ""cmplt""),\n']","['         nnan = self.notnan(self.setall(self._nan()))\n', '         assert nnan == [0]*self.nlanes\n', ' \n', '-    import operator\n', ' \n', ""     @pytest.mark.parametrize('py_comp,np_comp', [\n"", '         (operator.lt, ""cmplt""),\n']"
numpy/numpy,v1.24.0,v1.24.1,"['             return [lane == mask_true for lane in vector]\n', ' \n', '         intrin = getattr(self, np_comp)\n', '+        cmp_cases = ((0, nan), (nan, 0), (nan, nan), (pinf, nan),\n', '+                     (ninf, nan), (-0.0, +0.0))\n', '         for case_operand1, case_operand2 in cmp_cases:\n', '             data_a = [case_operand1]*self.nlanes\n', '             data_b = [case_operand2]*self.nlanes\n']","['             return [lane == mask_true for lane in vector]\n', ' \n', '         intrin = getattr(self, np_comp)\n', '-        cmp_cases = ((0, nan), (nan, 0), (nan, nan), (pinf, nan), (ninf, nan))\n', '         for case_operand1, case_operand2 in cmp_cases:\n', '             data_a = [case_operand1]*self.nlanes\n', '             data_b = [case_operand2]*self.nlanes\n']"
numpy/numpy,v1.24.0,v1.24.1,"['         rev64 = self.rev64(self.load(range(self.nlanes)))\n', '         assert rev64 == data_rev64\n', ' \n', ""+    @pytest.mark.parametrize('func, intrin', [\n"", '+        (operator.lt, ""cmplt""),\n', '+        (operator.le, ""cmple""),\n', '+        (operator.gt, ""cmpgt""),\n', '+        (operator.ge, ""cmpge""),\n', '+        (operator.eq, ""cmpeq"")\n', '+    ])\n', '+    def test_operators_comparison(self, func, intrin):\n', '         if self._is_fp():\n', '             data_a = self._data()\n', '         else:\n', '             data_a = self._data(self._int_max() - self.nlanes)\n', '         data_b = self._data(self._int_min(), reverse=True)\n', '         vdata_a, vdata_b = self.load(data_a), self.load(data_b)\n', '+        intrin = getattr(self, intrin)\n', ' \n', '         mask_true = self._true_mask()\n', '         def to_bool(vector):\n', '             return [lane == mask_true for lane in vector]\n', '+\n', '+        data_cmp = [func(a, b) for a, b in zip(data_a, data_b)]\n', '+        cmp = to_bool(intrin(vdata_a, vdata_b))\n', '+        assert cmp == data_cmp\n', ' \n', '     def test_operators_logical(self):\n', '         if self._is_fp():\n']","['         rev64 = self.rev64(self.load(range(self.nlanes)))\n', '         assert rev64 == data_rev64\n', ' \n', '-    def test_operators_comparison(self):\n', '         if self._is_fp():\n', '             data_a = self._data()\n', '         else:\n', '             data_a = self._data(self._int_max() - self.nlanes)\n', '         data_b = self._data(self._int_min(), reverse=True)\n', '         vdata_a, vdata_b = self.load(data_a), self.load(data_b)\n', ' \n', '         mask_true = self._true_mask()\n', '         def to_bool(vector):\n', '             return [lane == mask_true for lane in vector]\n', '-        # equal\n', '-        data_eq = [a == b for a, b in zip(data_a, data_b)]\n', '-        cmpeq = to_bool(self.cmpeq(vdata_a, vdata_b))\n', '-        assert cmpeq == data_eq\n', '-        # not equal\n', '-        data_neq = [a != b for a, b in zip(data_a, data_b)]\n', '-        cmpneq = to_bool(self.cmpneq(vdata_a, vdata_b))\n', '-        assert cmpneq == data_neq\n', '-        # greater than\n', '-        data_gt = [a > b for a, b in zip(data_a, data_b)]\n', '-        cmpgt = to_bool(self.cmpgt(vdata_a, vdata_b))\n', '-        assert cmpgt == data_gt\n', '-        # greater than and equal\n', '-        data_ge = [a >= b for a, b in zip(data_a, data_b)]\n', '-        cmpge = to_bool(self.cmpge(vdata_a, vdata_b))\n', '-        assert cmpge == data_ge\n', '-        # less than\n', '-        data_lt  = [a < b for a, b in zip(data_a, data_b)]\n', '-        cmplt = to_bool(self.cmplt(vdata_a, vdata_b))\n', '-        assert cmplt == data_lt\n', '-        # less than and equal\n', '-        data_le  = [a <= b for a, b in zip(data_a, data_b)]\n', '-        cmple = to_bool(self.cmple(vdata_a, vdata_b))\n', '-        assert cmple == data_le\n', ' \n', '     def test_operators_logical(self):\n', '         if self._is_fp():\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     assert_array_equal(op(arr, arr2), expected)\n', '     assert_array_equal(ufunc(arr, arr2), expected)\n', '     assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n', '+\n', '+\n', '+@pytest.mark.parametrize(""str_dt"", [""S"", ""U""])\n', '+@pytest.mark.parametrize(""float_dt"", np.typecodes[""AllFloat""])\n', '+def test_float_to_string_cast(str_dt, float_dt):\n', '+    float_dt = np.dtype(float_dt)\n', '+    fi = np.finfo(float_dt)\n', '+    arr = np.array([np.nan, np.inf, -np.inf, fi.max, fi.min], dtype=float_dt)\n', '+    expected = [""nan"", ""inf"", ""-inf"", repr(fi.max), repr(fi.min)]\n', ""+    if float_dt.kind == 'c':\n"", '+        expected = [f""({r}+0j)"" for r in expected]\n', '+\n', '+    res = arr.astype(str_dt)\n', '+    assert_array_equal(res, np.array(expected, dtype=str_dt))\n']","['     assert_array_equal(op(arr, arr2), expected)\n', '     assert_array_equal(ufunc(arr, arr2), expected)\n', '     assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     )\n', ' from numpy.testing._private.utils import _glibc_older_than\n', ' \n', '+UFUNCS = [obj for obj in np.core.umath.__dict__.values()\n', '+         if isinstance(obj, np.ufunc)]\n', '+\n', '+UFUNCS_UNARY = [\n', '+    uf for uf in UFUNCS if uf.nin == 1\n', '+]\n', '+UFUNCS_UNARY_FP = [\n', ""+    uf for uf in UFUNCS_UNARY if 'f->f' in uf.types\n"", '+]\n', '+\n', '+UFUNCS_BINARY = [\n', '+    uf for uf in UFUNCS if uf.nin == 2\n', '+]\n', '+UFUNCS_BINARY_ACC = [\n', '+    uf for uf in UFUNCS_BINARY if hasattr(uf, ""accumulate"") and uf.nout == 1\n', '+]\n', ' \n', ' def interesting_binop_operands(val1, val2, dtype):\n', '     """"""\n']","['     )\n', ' from numpy.testing._private.utils import _glibc_older_than\n', ' \n', ' \n', ' def interesting_binop_operands(val1, val2, dtype):\n', '     """"""\n']"
numpy/numpy,v1.24.0,v1.24.1,"['         b_lst = b.tolist()\n', ' \n', '         # (Binary) Comparison (x1=array, x2=array)\n', '+        comp_b = np_comp(a, b).view(np.uint8)\n', '+        comp_b_list = [int(py_comp(x, y)) for x, y in zip(a_lst, b_lst)]\n', ' \n', '         # (Scalar1) Comparison (x1=scalar, x2=array)\n', '+        comp_s1 = np_comp(np_scalar, b).view(np.uint8)\n', '+        comp_s1_list = [int(py_comp(scalar, x)) for x in b_lst]\n', ' \n', '         # (Scalar2) Comparison (x1=array, x2=scalar)\n', '+        comp_s2 = np_comp(a, np_scalar).view(np.uint8)\n', '+        comp_s2_list = [int(py_comp(x, scalar)) for x in a_lst]\n', ' \n', '         # Sequence: Binary, Scalar1 and Scalar2\n', '         assert_(comp_b.tolist() == comp_b_list,\n']","['         b_lst = b.tolist()\n', ' \n', '         # (Binary) Comparison (x1=array, x2=array)\n', '-        comp_b = np_comp(a, b)\n', '-        comp_b_list = [py_comp(x, y) for x, y in zip(a_lst, b_lst)]\n', ' \n', '         # (Scalar1) Comparison (x1=scalar, x2=array)\n', '-        comp_s1 = np_comp(np_scalar, b)\n', '-        comp_s1_list = [py_comp(scalar, x) for x in b_lst]\n', ' \n', '         # (Scalar2) Comparison (x1=array, x2=scalar)\n', '-        comp_s2 = np_comp(a, np_scalar)\n', '-        comp_s2_list = [py_comp(x, scalar) for x in a_lst]\n', ' \n', '         # Sequence: Binary, Scalar1 and Scalar2\n', '         assert_(comp_b.tolist() == comp_b_list,\n']"
numpy/numpy,v1.24.0,v1.24.1,"['                                   np.array(value, dtype=dt))\n', ' \n', '     # test to ensure no spurious FP exceptions are raised due to SIMD\n', '+    INF_INVALID_ERR = [\n', '+        np.cos, np.sin, np.tan, np.arccos, np.arcsin, np.spacing, np.arctanh\n', '+    ]\n', '+    NEG_INVALID_ERR = [\n', '+        np.log, np.log2, np.log10, np.log1p, np.sqrt, np.arccosh,\n', '+        np.arctanh\n', '+    ]\n', '+    ONE_INVALID_ERR = [\n', '+        np.arctanh,\n', '+    ]\n', '+    LTONE_INVALID_ERR = [\n', '+        np.arccosh,\n', '+    ]\n', '+    BYZERO_ERR = [\n', '+        np.log, np.log2, np.log10, np.reciprocal, np.arccosh\n', '+    ]\n', '+\n', '+    @pytest.mark.parametrize(""ufunc"", UFUNCS_UNARY_FP)\n', '+    @pytest.mark.parametrize(""dtype"", (\'e\', \'f\', \'d\'))\n', '+    @pytest.mark.parametrize(""data, escape"", (\n', '+        ([0.03], LTONE_INVALID_ERR),\n', '+        ([0.03]*32, LTONE_INVALID_ERR),\n', '+        # neg\n', '+        ([-1.0], NEG_INVALID_ERR),\n', '+        ([-1.0]*32, NEG_INVALID_ERR),\n', '+        # flat\n', '+        ([1.0], ONE_INVALID_ERR),\n', '+        ([1.0]*32, ONE_INVALID_ERR),\n', '+        # zero\n', '+        ([0.0], BYZERO_ERR),\n', '+        ([0.0]*32, BYZERO_ERR),\n', '+        ([-0.0], BYZERO_ERR),\n', '+        ([-0.0]*32, BYZERO_ERR),\n', '+        # nan\n', '+        ([0.5, 0.5, 0.5, np.nan], LTONE_INVALID_ERR),\n', '+        ([0.5, 0.5, 0.5, np.nan]*32, LTONE_INVALID_ERR),\n', '+        ([np.nan, 1.0, 1.0, 1.0], ONE_INVALID_ERR),\n', '+        ([np.nan, 1.0, 1.0, 1.0]*32, ONE_INVALID_ERR),\n', '+        ([np.nan], []),\n', '+        ([np.nan]*32, []),\n', '+        # inf\n', '+        ([0.5, 0.5, 0.5, np.inf], INF_INVALID_ERR + LTONE_INVALID_ERR),\n', '+        ([0.5, 0.5, 0.5, np.inf]*32, INF_INVALID_ERR + LTONE_INVALID_ERR),\n', '+        ([np.inf, 1.0, 1.0, 1.0], INF_INVALID_ERR),\n', '+        ([np.inf, 1.0, 1.0, 1.0]*32, INF_INVALID_ERR),\n', '+        ([np.inf], INF_INVALID_ERR),\n', '+        ([np.inf]*32, INF_INVALID_ERR),\n', '+        # ninf\n', '+        ([0.5, 0.5, 0.5, -np.inf],\n', '+         NEG_INVALID_ERR + INF_INVALID_ERR + LTONE_INVALID_ERR),\n', '+        ([0.5, 0.5, 0.5, -np.inf]*32,\n', '+         NEG_INVALID_ERR + INF_INVALID_ERR + LTONE_INVALID_ERR),\n', '+        ([-np.inf, 1.0, 1.0, 1.0], NEG_INVALID_ERR + INF_INVALID_ERR),\n', '+        ([-np.inf, 1.0, 1.0, 1.0]*32, NEG_INVALID_ERR + INF_INVALID_ERR),\n', '+        ([-np.inf], NEG_INVALID_ERR + INF_INVALID_ERR),\n', '+        ([-np.inf]*32, NEG_INVALID_ERR + INF_INVALID_ERR),\n', '+    ))\n', '+    def test_unary_spurious_fpexception(self, ufunc, dtype, data, escape):\n', '+        if escape and ufunc in escape:\n', '+            return\n', '+        # FIXME: NAN raises FP invalid exception:\n', '+        #  - ceil/float16 on MSVC:32-bit\n', '+        #  - spacing/float16 on almost all platforms\n', ""+        if ufunc in (np.spacing, np.ceil) and dtype == 'e':\n"", '+            return\n', '+        array = np.array(data, dtype=dtype)\n', '+        with assert_no_warnings():\n', '+            ufunc(array)\n', ' \n', ' class TestFPClass:\n', '     @pytest.mark.parametrize(""stride"", [-4,-2,-1,1,2,4])\n']","['                                   np.array(value, dtype=dt))\n', ' \n', '     # test to ensure no spurious FP exceptions are raised due to SIMD\n', '-    def test_spurious_fpexception(self):\n', ""-        for dt in ['e', 'f', 'd']:\n"", '-            arr = np.array([1.0, 2.0], dtype=dt)\n', '-            with assert_no_warnings():\n', '-                np.log(arr)\n', '-                np.log2(arr)\n', '-                np.log10(arr)\n', '-                np.arccosh(arr)\n', '-\n', ' \n', ' class TestFPClass:\n', '     @pytest.mark.parametrize(""stride"", [-4,-2,-1,1,2,4])\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     # Rint should not change the value\n', '     assert_equal(val, np.rint(val))\n', ' \n', '+\n', "" @pytest.mark.parametrize('ftype', [np.float32, np.float64])\n"", ' def test_memoverlap_accumulate(ftype):\n', '     # Reproduces bug https://github.com/numpy/numpy/issues/15597\n']","['     # Rint should not change the value\n', '     assert_equal(val, np.rint(val))\n', ' \n', "" @pytest.mark.parametrize('ftype', [np.float32, np.float64])\n"", ' def test_memoverlap_accumulate(ftype):\n', '     # Reproduces bug https://github.com/numpy/numpy/issues/15597\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     assert_equal(np.maximum.accumulate(arr), out_max)\n', '     assert_equal(np.minimum.accumulate(arr), out_min)\n', ' \n', '+@pytest.mark.parametrize(""ufunc, dtype"", [\n', '+    (ufunc, t[0])\n', '+    for ufunc in UFUNCS_BINARY_ACC\n', '+    for t in ufunc.types\n', ""+    if t[-1] == '?' and t[0] not in 'DFGMmO'\n"", '+])\n', '+def test_memoverlap_accumulate_cmp(ufunc, dtype):\n', '+    if ufunc.signature:\n', ""+        pytest.skip('For generic signatures only')\n"", '+    for size in (2, 8, 32, 64, 128, 256):\n', '+        arr = np.array([0, 1, 1]*size, dtype=dtype)\n', ""+        acc = ufunc.accumulate(arr, dtype='?')\n"", '+        acc_u8 = acc.view(np.uint8)\n', '+        exp = np.array(list(itertools.accumulate(arr, ufunc)), dtype=np.uint8)\n', '+        assert_equal(exp, acc_u8)\n', '+\n', '+@pytest.mark.parametrize(""ufunc, dtype"", [\n', '+    (ufunc, t[0])\n', '+    for ufunc in UFUNCS_BINARY_ACC\n', '+    for t in ufunc.types\n', ""+    if t[0] == t[1] and t[0] == t[-1] and t[0] not in 'DFGMmO?'\n"", '+])\n', '+def test_memoverlap_accumulate_symmetric(ufunc, dtype):\n', '+    if ufunc.signature:\n', ""+        pytest.skip('For generic signatures only')\n"", ""+    with np.errstate(all='ignore'):\n"", '+        for size in (2, 8, 32, 64, 128, 256):\n', '+            arr = np.array([0, 1, 2]*size).astype(dtype)\n', '+            acc = ufunc.accumulate(arr, dtype=dtype)\n', '+            exp = np.array(list(itertools.accumulate(arr, ufunc)), dtype=dtype)\n', '+            assert_equal(exp, acc)\n', '+\n', ' def test_signaling_nan_exceptions():\n', '     with assert_no_warnings():\n', ""         a = np.ndarray(shape=(), dtype='float32', buffer=b'\\x00\\xe0\\xbf\\xff')\n""]","['     assert_equal(np.maximum.accumulate(arr), out_max)\n', '     assert_equal(np.minimum.accumulate(arr), out_min)\n', ' \n', ' def test_signaling_nan_exceptions():\n', '     with assert_no_warnings():\n', ""         a = np.ndarray(shape=(), dtype='float32', buffer=b'\\x00\\xe0\\xbf\\xff')\n""]"
numpy/numpy,v1.24.0,v1.24.1,"[' import platform\n', ' import codecs\n', ' try:\n', '+    import charset_normalizer\n', ' except ImportError:\n', '+    charset_normalizer = None\n', ' \n', ' from . import __version__\n', ' \n']","[' import platform\n', ' import codecs\n', ' try:\n', '-    import chardet\n', ' except ImportError:\n', '-    chardet = None\n', ' \n', ' from . import __version__\n', ' \n']"
numpy/numpy,v1.24.0,v1.24.1,"[' def openhook(filename, mode):\n', '     """"""Ensures that filename is opened with correct encoding parameter.\n', ' \n', '+    This function uses charset_normalizer package, when available, for\n', '+    determining the encoding of the file to be opened. When charset_normalizer\n', '+    is not available, the function detects only UTF encodings, otherwise, ASCII\n', '+    encoding is used as fallback.\n', '     """"""\n', '+    # Reads in the entire file. Robust detection of encoding.\n', '+    # Correctly handles comments or late stage unicode characters\n', '+    # gh-22871\n', '+    if charset_normalizer is not None:\n', '+        encoding = charset_normalizer.from_path(filename).best().encoding\n', '     else:\n', '+        # hint: install charset_normalizer for correct encoding handling\n', '+        # No need to read the whole file for trying with startswith\n', '+        nbytes = min(32, os.path.getsize(filename))\n', ""+        with open(filename, 'rb') as fhandle:\n"", '+            raw = fhandle.read(nbytes)\n', '+            if raw.startswith(codecs.BOM_UTF8):\n', ""+                encoding = 'UTF-8-SIG'\n"", '+            elif raw.startswith((codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE)):\n', ""+                encoding = 'UTF-32'\n"", '+            elif raw.startswith((codecs.BOM_LE, codecs.BOM_BE)):\n', ""+                encoding = 'UTF-16'\n"", '+            else:\n', '+                # Fallback, without charset_normalizer\n', ""+                encoding = 'ascii'\n"", '     return open(filename, mode, encoding=encoding)\n', ' \n', ' \n']","[' def openhook(filename, mode):\n', '     """"""Ensures that filename is opened with correct encoding parameter.\n', ' \n', '-    This function uses chardet package, when available, for\n', '-    determining the encoding of the file to be opened. When chardet is\n', '-    not available, the function detects only UTF encodings, otherwise,\n', '-    ASCII encoding is used as fallback.\n', '     """"""\n', '-    bytes = min(32, os.path.getsize(filename))\n', ""-    with open(filename, 'rb') as f:\n"", '-        raw = f.read(bytes)\n', '-    if raw.startswith(codecs.BOM_UTF8):\n', ""-        encoding = 'UTF-8-SIG'\n"", '-    elif raw.startswith((codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE)):\n', ""-        encoding = 'UTF-32'\n"", '-    elif raw.startswith((codecs.BOM_LE, codecs.BOM_BE)):\n', ""-        encoding = 'UTF-16'\n"", '     else:\n', '-        if chardet is not None:\n', ""-            encoding = chardet.detect(raw)['encoding']\n"", '-        else:\n', '-            # hint: install chardet to ensure correct encoding handling\n', ""-            encoding = 'ascii'\n"", '     return open(filename, mode, encoding=encoding)\n', ' \n', ' \n']"
numpy/numpy,v1.24.0,v1.24.1,"['         except UnicodeDecodeError as msg:\n', '             raise Exception(\n', ""                 f'readfortrancode: reading {fin.filename()}#{fin.lineno()}'\n"", ""+                f' failed with\\n{msg}.\\nIt is likely that installing charset_normalizer'\n"", ""                 ' package will help f2py determine the input file encoding'\n"", ""                 ' correctly.')\n"", '         if not l:\n']","['         except UnicodeDecodeError as msg:\n', '             raise Exception(\n', ""                 f'readfortrancode: reading {fin.filename()}#{fin.lineno()}'\n"", ""-                f' failed with\\n{msg}.\\nIt is likely that installing chardet'\n"", ""                 ' package will help f2py determine the input file encoding'\n"", ""                 ' correctly.')\n"", '         if not l:\n']"
numpy/numpy,v1.24.0,v1.24.1,"['+import importlib\n', ' import codecs\n', '+import unicodedata\n', ' import pytest\n', ' import numpy as np\n', ' from numpy.f2py.crackfortran import markinnerspaces\n']","[' import codecs\n', ' import pytest\n', ' import numpy as np\n', ' from numpy.f2py.crackfortran import markinnerspaces\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     def test_input_encoding(self, tmp_path, encoding):\n', '         # gh-635\n', '         f_path = tmp_path / f""input_with_{encoding}_encoding.f90""\n', ""         with f_path.open('w', encoding=encoding) as ff:\n"", '+            ff.write(""""""\n', '                      subroutine foo()\n', '                      end subroutine foo\n', '                      """""")\n', '         mod = crackfortran.crackfortran([str(f_path)])\n', ""         assert mod[0]['name'] == 'foo'\n"", '+\n', '+class TestUnicodeComment(util.F2PyTest):\n', '+    sources = [util.getpath(""tests"", ""src"", ""crackfortran"", ""unicode_comment.f90"")]\n', '+\n', '+    @pytest.mark.skipif(\n', '+        (importlib.util.find_spec(""charset_normalizer"") is None),\n', '+        reason=""test requires charset_normalizer which is not installed"",\n', '+    )\n', '+    def test_encoding_comment(self):\n', '+        self.module.foo(3)\n']","['     def test_input_encoding(self, tmp_path, encoding):\n', '         # gh-635\n', '         f_path = tmp_path / f""input_with_{encoding}_encoding.f90""\n', '-        # explicit BOM is required for UTF8\n', ""-        bom = {'utf-8': codecs.BOM_UTF8}.get(encoding, b'')\n"", ""         with f_path.open('w', encoding=encoding) as ff:\n"", '-            ff.write(bom.decode(encoding) +\n', '-                     """"""\n', '                      subroutine foo()\n', '                      end subroutine foo\n', '                      """""")\n', '         mod = crackfortran.crackfortran([str(f_path)])\n', ""         assert mod[0]['name'] == 'foo'\n""]"
numpy/numpy,v1.24.0,v1.24.1,"['         ar2_range = int(ar2_max) - int(ar2_min)\n', ' \n', '         # Constraints on whether we can actually use the table method:\n', '+        #  1. Assert memory usage is not too large\n', '         below_memory_constraint = ar2_range <= 6 * (ar1.size + ar2.size)\n', '+        #  2. Check overflows for (ar2 - ar2_min); dtype=ar2.dtype\n', '+        range_safe_from_overflow = ar2_range <= np.iinfo(ar2.dtype).max\n', '+        #  3. Check overflows for (ar1 - ar2_min); dtype=ar1.dtype\n', '+        if ar1.size > 0:\n', '+            ar1_min = np.min(ar1)\n', '+            ar1_max = np.max(ar1)\n', '+\n', '+            # After masking, the range of ar1 is guaranteed to be\n', '+            # within the range of ar2:\n', '+            ar1_upper = min(int(ar1_max), int(ar2_max))\n', '+            ar1_lower = max(int(ar1_min), int(ar2_min))\n', '+\n', '+            range_safe_from_overflow &= all((\n', '+                ar1_upper - int(ar2_min) <= np.iinfo(ar1.dtype).max,\n', '+                ar1_lower - int(ar2_min) >= np.iinfo(ar1.dtype).min\n', '+            ))\n', ' \n', '         # Optimal performance is for approximately\n', '         # log10(size) > (log10(range) - 2.27) / 0.927.\n']","['         ar2_range = int(ar2_max) - int(ar2_min)\n', ' \n', '         # Constraints on whether we can actually use the table method:\n', '-        range_safe_from_overflow = ar2_range < np.iinfo(ar2.dtype).max\n', '         below_memory_constraint = ar2_range <= 6 * (ar1.size + ar2.size)\n', ' \n', '         # Optimal performance is for approximately\n', '         # log10(size) > (log10(range) - 2.27) / 0.927.\n']"
numpy/numpy,v1.24.0,v1.24.1,"[""         elif kind == 'table':  # not range_safe_from_overflow\n"", '             raise RuntimeError(\n', '                 ""You have specified kind=\'table\', ""\n', '+                ""but the range of values in `ar2` or `ar1` exceed the ""\n', '                 ""maximum integer of the datatype. ""\n', '                 ""Please set `kind` to None or \'sort\'.""\n', '             )\n']","[""         elif kind == 'table':  # not range_safe_from_overflow\n"", '             raise RuntimeError(\n', '                 ""You have specified kind=\'table\', ""\n', '-                ""but the range of values in `ar2` exceeds the ""\n', '                 ""maximum integer of the datatype. ""\n', '                 ""Please set `kind` to None or \'sort\'.""\n', '             )\n']"
numpy/numpy,v1.24.0,v1.24.1,"['         with pytest.raises(ValueError):\n', '             in1d(a, b, kind=""table"")\n', ' \n', '+    @pytest.mark.parametrize(\n', '+        ""dtype1,dtype2"",\n', '+        [\n', '+            (np.int8, np.int16),\n', '+            (np.int16, np.int8),\n', '+            (np.uint8, np.uint16),\n', '+            (np.uint16, np.uint8),\n', '+            (np.uint8, np.int16),\n', '+            (np.int16, np.uint8),\n', '+        ]\n', '+    )\n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_in1d_mixed_dtype(self, dtype1, dtype2, kind):\n', '+        """"""Test that in1d works as expected for mixed dtype input.""""""\n', '+        is_dtype2_signed = np.issubdtype(dtype2, np.signedinteger)\n', '+        ar1 = np.array([0, 0, 1, 1], dtype=dtype1)\n', '+\n', '+        if is_dtype2_signed:\n', '+            ar2 = np.array([-128, 0, 127], dtype=dtype2)\n', '+        else:\n', '+            ar2 = np.array([127, 0, 255], dtype=dtype2)\n', '+\n', '+        expected = np.array([True, True, False, False])\n', '+\n', '+        expect_failure = kind == ""table"" and any((\n', '+            dtype1 == np.int8 and dtype2 == np.int16,\n', '+            dtype1 == np.int16 and dtype2 == np.int8\n', '+        ))\n', '+\n', '+        if expect_failure:\n', '+            with pytest.raises(RuntimeError, match=""exceed the maximum""):\n', '+                in1d(ar1, ar2, kind=kind)\n', '+        else:\n', '+            assert_array_equal(in1d(ar1, ar2, kind=kind), expected)\n', '+\n', '     @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '     def test_in1d_mixed_boolean(self, kind):\n', '         """"""Test that in1d works as expected for bool/int input.""""""\n', '         for dtype in np.typecodes[""AllInteger""]:\n', '             a = np.array([True, False, False], dtype=bool)\n', '+            b = np.array([0, 0, 0, 0], dtype=dtype)\n', '+            expected = np.array([False, True, True], dtype=bool)\n', '             assert_array_equal(in1d(a, b, kind=kind), expected)\n', ' \n', '             a, b = b, a\n']","['         with pytest.raises(ValueError):\n', '             in1d(a, b, kind=""table"")\n', ' \n', '     @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '     def test_in1d_mixed_boolean(self, kind):\n', '         """"""Test that in1d works as expected for bool/int input.""""""\n', '         for dtype in np.typecodes[""AllInteger""]:\n', '             a = np.array([True, False, False], dtype=bool)\n', '-            b = np.array([1, 1, 1, 1], dtype=dtype)\n', '-            expected = np.array([True, False, False], dtype=bool)\n', '             assert_array_equal(in1d(a, b, kind=kind), expected)\n', ' \n', '             a, b = b, a\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     """"""Byte control characters (comments, delimiter) are supported.""""""\n', '     a = np.loadtxt(StringIO(""#header\\n1,2,3""), comments=b""#"", delimiter=b"","")\n', '     assert_equal(a, [1, 2, 3])\n', '+\n', '+\n', ""+@pytest.mark.filterwarnings('ignore::UserWarning')\n"", '+def test_field_growing_cases():\n', '+    # Test empty field appending/growing (each field still takes 1 character)\n', '+    # to see if the final field appending does not create issues.\n', '+    res = np.loadtxt([""""], delimiter="","", dtype=bytes)\n', '+    assert len(res) == 0\n', '+\n', '+    for i in range(1, 1024):\n', '+        res = np.loadtxt(["","" * i], delimiter="","", dtype=bytes)\n', '+        assert len(res) == i+1\n']","['     """"""Byte control characters (comments, delimiter) are supported.""""""\n', '     a = np.loadtxt(StringIO(""#header\\n1,2,3""), comments=b""#"", delimiter=b"","")\n', '     assert_equal(a, [1, 2, 3])\n']"
numpy/numpy,v1.24.0,v1.24.1,"['             (-3, -1),\n', '         ]\n', '     )\n', '+    @pytest.mark.filterwarnings(""ignore:All-NaN slice:RuntimeWarning"")\n', '     def test_keepdims_out(self, axis):\n', '         d = np.ones((3, 5, 7, 11))\n', '         # Randomly set some elements to NaN:\n']","['             (-3, -1),\n', '         ]\n', '     )\n', '     def test_keepdims_out(self, axis):\n', '         d = np.ones((3, 5, 7, 11))\n', '         # Randomly set some elements to NaN:\n']"
numpy/numpy,v1.24.0,v1.24.1,"['             (-3, -1),\n', '         ]\n', '     )\n', '+    @pytest.mark.filterwarnings(""ignore:All-NaN slice:RuntimeWarning"")\n', '     def test_keepdims_out(self, q, axis):\n', '         d = np.ones((3, 5, 7, 11))\n', '         # Randomly set some elements to NaN:\n']","['             (-3, -1),\n', '         ]\n', '     )\n', '     def test_keepdims_out(self, q, axis):\n', '         d = np.ones((3, 5, 7, 11))\n', '         # Randomly set some elements to NaN:\n']"
numpy/numpy,v1.24.0,v1.24.1,"['            fill_value=1e+20)\n', ' \n', '     """"""\n', '+    a = np.array(a, copy=False, subok=True)\n', '+    res = masked_where(~(np.isfinite(a)), a, copy=copy)\n', '+    # masked_invalid previously never returned nomask as a mask and doing so\n', '+    # threw off matplotlib (gh-22842).  So use shrink=False:\n', '+    if res._mask is nomask:\n', '+        res._mask = make_mask_none(res.shape, res.dtype)\n', '+    return res\n', ' \n', ' ###############################################################################\n', ' #                            Printing options                                 #\n']","['            fill_value=1e+20)\n', ' \n', '     """"""\n', '-\n', '-    return masked_where(~(np.isfinite(getdata(a))), a, copy=copy)\n', ' \n', ' ###############################################################################\n', ' #                            Printing options                                 #\n']"
numpy/numpy,v1.24.0,v1.24.1,"[' from numpy.testing import (\n', '     assert_raises, assert_warns, suppress_warnings, IS_WASM\n', '     )\n', '+from numpy.testing._private.utils import requires_memory\n', ' from numpy import ndarray\n', ' from numpy.compat import asbytes\n', ' from numpy.ma.testutils import (\n']","[' from numpy.testing import (\n', '     assert_raises, assert_warns, suppress_warnings, IS_WASM\n', '     )\n', ' from numpy import ndarray\n', ' from numpy.compat import asbytes\n', ' from numpy.ma.testutils import (\n']"
numpy/numpy,v1.24.0,v1.24.1,"['         assert_equal(a.max(-1), [3, 6])\n', '         assert_equal(a.max(1), [3, 6])\n', ' \n', '+    @requires_memory(free_bytes=2 * 10000 * 1000 * 2)\n', '     def test_mean_overflow(self):\n', '         # Test overflow in masked arrays\n', '         # gh-20272\n']","['         assert_equal(a.max(-1), [3, 6])\n', '         assert_equal(a.max(1), [3, 6])\n', ' \n', '     def test_mean_overflow(self):\n', '         # Test overflow in masked arrays\n', '         # gh-20272\n']"
numpy/numpy,v1.24.0,v1.24.1,"['                            match=""not supported for the input types""):\n', '             np.ma.masked_invalid(a)\n', ' \n', '+    def test_masked_invalid_pandas(self):\n', '+        # getdata() used to be bad for pandas series due to its _data\n', '+        # attribute.  This test is a regression test mainly and may be\n', '+        # removed if getdata() is adjusted.\n', '+        class Series():\n', '+            _data = ""nonsense""\n', '+\n', '+            def __array__(self):\n', '+                return np.array([5, np.nan, np.inf])\n', '+\n', '+        arr = np.ma.masked_invalid(Series())\n', '+        assert_array_equal(arr._data, np.array(Series()))\n', '+        assert_array_equal(arr._mask, [False, True, True])\n', '+\n', '+    @pytest.mark.parametrize(""copy"", [True, False])\n', '+    def test_masked_invalid_full_mask(self, copy):\n', '+        # Matplotlib relied on masked_invalid always returning a full mask\n', '+        # (Also astropy projects, but were ok with it gh-22720 and gh-22842)\n', '+        a = np.ma.array([1, 2, 3, 4])\n', '+        assert a._mask is nomask\n', '+        res = np.ma.masked_invalid(a, copy=copy)\n', '+        assert res.mask is not nomask\n', '+        # mask of a should not be mutated\n', '+        assert a.mask is nomask\n', '+        assert np.may_share_memory(a._data, res._data) != copy\n', '+\n', '     def test_choose(self):\n', '         # Test choose\n', '         choices = [[0, 1, 2, 3], [10, 11, 12, 13],\n']","['                            match=""not supported for the input types""):\n', '             np.ma.masked_invalid(a)\n', ' \n', '     def test_choose(self):\n', '         # Test choose\n', '         choices = [[0, 1, 2, 3], [10, 11, 12, 13],\n']"
numpy/numpy,v1.24.0,v1.24.1,"[""         ret['coef'] = self.coef.copy()\n"", ""         ret['domain'] = self.domain.copy()\n"", ""         ret['window'] = self.window.copy()\n"", ""+        ret['symbol'] = self.symbol\n"", '         return ret\n', ' \n', '     def __setstate__(self, dict):\n']","[""         ret['coef'] = self.coef.copy()\n"", ""         ret['domain'] = self.domain.copy()\n"", ""         ret['window'] = self.window.copy()\n"", ""-        ret['symbol'] = self.symbol.copy()\n"", '         return ret\n', ' \n', '     def __setstate__(self, dict):\n']"
numpy/numpy,v1.24.0,v1.24.1,"[' \n', ' import numpy as np\n', ' import numpy.polynomial.polynomial as poly\n', '+import pickle\n', '+from copy import deepcopy\n', ' from numpy.testing import (\n', '     assert_almost_equal, assert_raises, assert_equal, assert_,\n', '     assert_warns, assert_array_equal, assert_raises_regex)\n']","[' \n', ' import numpy as np\n', ' import numpy.polynomial.polynomial as poly\n', ' from numpy.testing import (\n', '     assert_almost_equal, assert_raises, assert_equal, assert_,\n', '     assert_warns, assert_array_equal, assert_raises_regex)\n']"
numpy/numpy,v1.24.0,v1.24.1,"['     def test_polyx(self):\n', '         assert_equal(poly.polyx, [0, 1])\n', ' \n', '+    def test_copy(self):\n', '+        x = poly.Polynomial([1, 2, 3])\n', '+        y = deepcopy(x)\n', '+        assert_equal(x, y)\n', '+\n', '+    def test_pickle(self):\n', '+        x = poly.Polynomial([1, 2, 3])\n', '+        y = pickle.loads(pickle.dumps(x))\n', '+        assert_equal(x, y)\n', ' \n', ' class TestArithmetic:\n', ' \n']","['     def test_polyx(self):\n', '         assert_equal(poly.polyx, [0, 1])\n', ' \n', ' \n', ' class TestArithmetic:\n', ' \n']"
numpy/numpy,v1.24.0,v1.24.1,"[' SKIP_LIST_2 = [\n', ""     'numpy.math',\n"", ""     'numpy.distutils.log.sys',\n"", ""+    'numpy.distutils.log.logging',\n"", ""+    'numpy.distutils.log.warnings',\n"", ""     'numpy.doc.constants.re',\n"", ""     'numpy.doc.constants.textwrap',\n"", ""     'numpy.lib.emath',\n""]","[' SKIP_LIST_2 = [\n', ""     'numpy.math',\n"", ""     'numpy.distutils.log.sys',\n"", ""     'numpy.doc.constants.re',\n"", ""     'numpy.doc.constants.textwrap',\n"", ""     'numpy.lib.emath',\n""]"
numpy/numpy,v1.24.0,v1.24.1,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.24.1-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.24.0-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     return Array._new(np.transpose(x._array, axes))\n', ' \n', ' \n', ""+# Note: the optional argument is called 'shape', not 'newshape'\n"", ' def reshape(x: Array, /, shape: Tuple[int, ...]) -> Array:\n', '     """"""\n', '     Array API compatible wrapper for :py:func:`np.reshape <numpy.reshape>`.\n']","['     return Array._new(np.transpose(x._array, axes))\n', ' \n', ' \n', ' def reshape(x: Array, /, shape: Tuple[int, ...]) -> Array:\n', '     """"""\n', '     Array API compatible wrapper for :py:func:`np.reshape <numpy.reshape>`.\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"[' \n', ' \n', ' @pytest.mark.parametrize(""op"", reasonable_operators_for_scalars)\n', '+@pytest.mark.parametrize(""val"", [None, 2**64])\n', '+def test_longdouble_inf_loop(op, val):\n', '+    # Note: The 2**64 value will pass once NEP 50 is adopted.\n', '     try:\n', '+        op(np.longdouble(3), val)\n', '     except TypeError:\n', '         pass\n', '     try:\n', '+        op(val, np.longdouble(3))\n', '     except TypeError:\n', '         pass\n', ' \n', ' \n', ' @pytest.mark.parametrize(""op"", reasonable_operators_for_scalars)\n', '+@pytest.mark.parametrize(""val"", [None, 2**64])\n', '+def test_clongdouble_inf_loop(op, val):\n', '+    # Note: The 2**64 value will pass once NEP 50 is adopted.\n', '     try:\n', '+        op(np.clongdouble(3), val)\n', '     except TypeError:\n', '         pass\n', '     try:\n', '+        op(val, np.longdouble(3))\n', '     except TypeError:\n', '         pass\n', ' \n']","[' \n', ' \n', ' @pytest.mark.parametrize(""op"", reasonable_operators_for_scalars)\n', '-def test_longdouble_inf_loop(op):\n', '     try:\n', '-        op(np.longdouble(3), None)\n', '     except TypeError:\n', '         pass\n', '     try:\n', '-        op(None, np.longdouble(3))\n', '     except TypeError:\n', '         pass\n', ' \n', ' \n', ' @pytest.mark.parametrize(""op"", reasonable_operators_for_scalars)\n', '-def test_clongdouble_inf_loop(op):\n', '-    if op in {operator.mod} and False:\n', '-        pytest.xfail(""The modulo operator is known to be broken"")\n', '     try:\n', '-        op(np.clongdouble(3), None)\n', '     except TypeError:\n', '         pass\n', '     try:\n', '-        op(None, np.longdouble(3))\n', '     except TypeError:\n', '         pass\n', ' \n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['                 _round = intrin(data)\n', '                 assert _round == data_round\n', ' \n', '+        # test large numbers\n', '+        for i in (\n', '+            1.1529215045988576e+18, 4.6116860183954304e+18,\n', '+            5.902958103546122e+20, 2.3611832414184488e+21\n', '+        ):\n', '+            x = self.setall(i)\n', '+            y = intrin(x)\n', '+            data_round = [func(n) for n in x]\n', '+            assert y == data_round\n', '+\n', '         # signed zero\n', '         if intrin_name == ""floor"":\n', '             data_szero = (-0.0,)\n']","['                 _round = intrin(data)\n', '                 assert _round == data_round\n', ' \n', '         # signed zero\n', '         if intrin_name == ""floor"":\n', '             data_szero = (-0.0,)\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     return b\n', ' \n', ' \n', '+def _ureduce(a, func, keepdims=False, **kwargs):\n', '     """"""\n', '     Internal Function.\n', '     Call `func` with `a` as first argument swapping the axes to use extended\n']","['     return b\n', ' \n', ' \n', '-def _ureduce(a, func, **kwargs):\n', '     """"""\n', '     Internal Function.\n', '     Call `func` with `a` as first argument swapping the axes to use extended\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     """"""\n', '     a = np.asanyarray(a)\n', ""     axis = kwargs.get('axis', None)\n"", ""+    out = kwargs.get('out', None)\n"", '+\n', '+    if keepdims is np._NoValue:\n', '+        keepdims = False\n', '+\n', '+    nd = a.ndim\n', '     if axis is not None:\n', '         axis = _nx.normalize_axis_tuple(axis, nd)\n', ' \n', '+        if keepdims:\n', '+            if out is not None:\n', '+                index_out = tuple(\n', '+                    0 if i in axis else slice(None) for i in range(nd))\n', ""+                kwargs['out'] = out[(Ellipsis, ) + index_out]\n"", ' \n', '         if len(axis) == 1:\n', ""             kwargs['axis'] = axis[0]\n""]","['     """"""\n', '     a = np.asanyarray(a)\n', ""     axis = kwargs.get('axis', None)\n"", '     if axis is not None:\n', '-        keepdim = list(a.shape)\n', '-        nd = a.ndim\n', '         axis = _nx.normalize_axis_tuple(axis, nd)\n', ' \n', '-        for ax in axis:\n', '-            keepdim[ax] = 1\n', ' \n', '         if len(axis) == 1:\n', ""             kwargs['axis'] = axis[0]\n""]"
numpy/numpy,v1.24.0rc2,v1.24.0,"['             # merge reduced axis\n', '             a = a.reshape(a.shape[:nkeep] + (-1,))\n', ""             kwargs['axis'] = -1\n"", '     else:\n', '+        if keepdims:\n', '+            if out is not None:\n', '+                index_out = (0, ) * nd\n', ""+                kwargs['out'] = out[(Ellipsis, ) + index_out]\n"", ' \n', '     r = func(a, **kwargs)\n', '+\n', '+    if out is not None:\n', '+        return out\n', '+\n', '+    if keepdims:\n', '+        if axis is None:\n', '+            index_r = (np.newaxis, ) * nd\n', '+        else:\n', '+            index_r = tuple(\n', '+                np.newaxis if i in axis else slice(None)\n', '+                for i in range(nd))\n', '+        r = r[(Ellipsis, ) + index_r]\n', '+\n', '+    return r\n', ' \n', ' \n', ' def _median_dispatcher(\n']","['             # merge reduced axis\n', '             a = a.reshape(a.shape[:nkeep] + (-1,))\n', ""             kwargs['axis'] = -1\n"", '-        keepdim = tuple(keepdim)\n', '     else:\n', '-        keepdim = (1,) * a.ndim\n', ' \n', '     r = func(a, **kwargs)\n', '-    return r, keepdim\n', ' \n', ' \n', ' def _median_dispatcher(\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     >>> assert not np.all(a==b)\n', ' \n', '     """"""\n', '+    return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,\n', '                     overwrite_input=overwrite_input)\n', ' \n', ' \n', ' def _median(a, axis=None, out=None, overwrite_input=False):\n']","['     >>> assert not np.all(a==b)\n', ' \n', '     """"""\n', '-    r, k = _ureduce(a, func=_median, axis=axis, out=out,\n', '                     overwrite_input=overwrite_input)\n', '-    if keepdims:\n', '-        return r.reshape(k)\n', '-    else:\n', '-        return r\n', ' \n', ' \n', ' def _median(a, axis=None, out=None, overwrite_input=False):\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['                         method=""linear"",\n', '                         keepdims=False):\n', '     """"""Assumes that q is in [0, 1], and is an ndarray""""""\n', '+    return _ureduce(a,\n', '                     func=_quantile_ureduce_func,\n', '                     q=q,\n', '+                    keepdims=keepdims,\n', '                     axis=axis,\n', '                     out=out,\n', '                     overwrite_input=overwrite_input,\n', '                     method=method)\n', ' \n', ' \n', ' def _quantile_is_valid(q):\n']","['                         method=""linear"",\n', '                         keepdims=False):\n', '     """"""Assumes that q is in [0, 1], and is an ndarray""""""\n', '-    r, k = _ureduce(a,\n', '                     func=_quantile_ureduce_func,\n', '                     q=q,\n', '                     axis=axis,\n', '                     out=out,\n', '                     overwrite_input=overwrite_input,\n', '                     method=method)\n', '-    if keepdims:\n', '-        return r.reshape(q.shape + k)\n', '-    else:\n', '-        return r\n', ' \n', ' \n', ' def _quantile_is_valid(q):\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     if a.size == 0:\n', '         return np.nanmean(a, axis, out=out, keepdims=keepdims)\n', ' \n', '+    return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n', '+                                  axis=axis, out=out,\n', '                                   overwrite_input=overwrite_input)\n', ' \n', ' \n', ' def _nanpercentile_dispatcher(\n']","['     if a.size == 0:\n', '         return np.nanmean(a, axis, out=out, keepdims=keepdims)\n', ' \n', '-    r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n', '                                   overwrite_input=overwrite_input)\n', '-    if keepdims and keepdims is not np._NoValue:\n', '-        return r.reshape(k)\n', '-    else:\n', '-        return r\n', ' \n', ' \n', ' def _nanpercentile_dispatcher(\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     # so deal them upfront\n', '     if a.size == 0:\n', '         return np.nanmean(a, axis, out=out, keepdims=keepdims)\n', '+    return function_base._ureduce(a,\n', '                                   func=_nanquantile_ureduce_func,\n', '                                   q=q,\n', '+                                  keepdims=keepdims,\n', '                                   axis=axis,\n', '                                   out=out,\n', '                                   overwrite_input=overwrite_input,\n', '                                   method=method)\n', ' \n', ' \n', ' def _nanquantile_ureduce_func(a, q, axis=None, out=None, overwrite_input=False,\n']","['     # so deal them upfront\n', '     if a.size == 0:\n', '         return np.nanmean(a, axis, out=out, keepdims=keepdims)\n', '-    r, k = function_base._ureduce(a,\n', '                                   func=_nanquantile_ureduce_func,\n', '                                   q=q,\n', '                                   axis=axis,\n', '                                   out=out,\n', '                                   overwrite_input=overwrite_input,\n', '                                   method=method)\n', '-    if keepdims and keepdims is not np._NoValue:\n', '-        return r.reshape(q.shape + k)\n', '-    else:\n', '-        return r\n', ' \n', ' \n', ' def _nanquantile_ureduce_func(a, q, axis=None, out=None, overwrite_input=False,\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['     i0, insert, interp, kaiser, meshgrid, msort, piecewise, place, rot90,\n', '     select, setxor1d, sinc, trapz, trim_zeros, unwrap, unique, vectorize\n', '     )\n', '+from numpy.core.numeric import normalize_axis_tuple\n', ' \n', ' \n', ' def get_mat(n):\n']","['     i0, insert, interp, kaiser, meshgrid, msort, piecewise, place, rot90,\n', '     select, setxor1d, sinc, trapz, trim_zeros, unwrap, unique, vectorize\n', '     )\n', ' \n', ' \n', ' def get_mat(n):\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['         assert_equal(np.percentile(d, [1, 7], axis=(0, 3),\n', '                                    keepdims=True).shape, (2, 1, 5, 7, 1))\n', ' \n', ""+    @pytest.mark.parametrize('q', [7, [1, 7]])\n"", '+    @pytest.mark.parametrize(\n', ""+        argnames='axis',\n"", '+        argvalues=[\n', '+            None,\n', '+            1,\n', '+            (1,),\n', '+            (0, 1),\n', '+            (-3, -1),\n', '+        ]\n', '+    )\n', '+    def test_keepdims_out(self, q, axis):\n', '+        d = np.ones((3, 5, 7, 11))\n', '+        if axis is None:\n', '+            shape_out = (1,) * d.ndim\n', '+        else:\n', '+            axis_norm = normalize_axis_tuple(axis, d.ndim)\n', '+            shape_out = tuple(\n', '+                1 if i in axis_norm else d.shape[i] for i in range(d.ndim))\n', '+        shape_out = np.shape(q) + shape_out\n', '+\n', '+        out = np.empty(shape_out)\n', '+        result = np.percentile(d, q, axis=axis, keepdims=True, out=out)\n', '+        assert result is out\n', '+        assert_equal(result.shape, shape_out)\n', '+\n', '     def test_out(self):\n', '         o = np.zeros((4,))\n', '         d = np.ones((3, 4))\n']","['         assert_equal(np.percentile(d, [1, 7], axis=(0, 3),\n', '                                    keepdims=True).shape, (2, 1, 5, 7, 1))\n', ' \n', '     def test_out(self):\n', '         o = np.zeros((4,))\n', '         d = np.ones((3, 4))\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['         assert_equal(np.median(d, axis=(0, 1, 3), keepdims=True).shape,\n', '                      (1, 1, 7, 1))\n', ' \n', '+    @pytest.mark.parametrize(\n', ""+        argnames='axis',\n"", '+        argvalues=[\n', '+            None,\n', '+            1,\n', '+            (1, ),\n', '+            (0, 1),\n', '+            (-3, -1),\n', '+        ]\n', '+    )\n', '+    def test_keepdims_out(self, axis):\n', '+        d = np.ones((3, 5, 7, 11))\n', '+        if axis is None:\n', '+            shape_out = (1,) * d.ndim\n', '+        else:\n', '+            axis_norm = normalize_axis_tuple(axis, d.ndim)\n', '+            shape_out = tuple(\n', '+                1 if i in axis_norm else d.shape[i] for i in range(d.ndim))\n', '+        out = np.empty(shape_out)\n', '+        result = np.median(d, axis=axis, keepdims=True, out=out)\n', '+        assert result is out\n', '+        assert_equal(result.shape, shape_out)\n', '+\n', ' \n', ' class TestAdd_newdoc_ufunc:\n', ' \n']","['         assert_equal(np.median(d, axis=(0, 1, 3), keepdims=True).shape,\n', '                      (1, 1, 7, 1))\n', ' \n', ' \n', ' class TestAdd_newdoc_ufunc:\n', ' \n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"[' import inspect\n', ' \n', ' import numpy as np\n', '+from numpy.core.numeric import normalize_axis_tuple\n', ' from numpy.lib.nanfunctions import _nan_mask, _replace_nan\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_almost_equal, assert_raises,\n']","[' import inspect\n', ' \n', ' import numpy as np\n', ' from numpy.lib.nanfunctions import _nan_mask, _replace_nan\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_almost_equal, assert_raises,\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['             res = np.nanmedian(d, axis=(0, 1, 3), keepdims=True)\n', '             assert_equal(res.shape, (1, 1, 7, 1))\n', ' \n', '+    @pytest.mark.parametrize(\n', ""+        argnames='axis',\n"", '+        argvalues=[\n', '+            None,\n', '+            1,\n', '+            (1, ),\n', '+            (0, 1),\n', '+            (-3, -1),\n', '+        ]\n', '+    )\n', '+    def test_keepdims_out(self, axis):\n', '+        d = np.ones((3, 5, 7, 11))\n', '+        # Randomly set some elements to NaN:\n', '+        w = np.random.random((4, 200)) * np.array(d.shape)[:, None]\n', '+        w = w.astype(np.intp)\n', '+        d[tuple(w)] = np.nan\n', '+        if axis is None:\n', '+            shape_out = (1,) * d.ndim\n', '+        else:\n', '+            axis_norm = normalize_axis_tuple(axis, d.ndim)\n', '+            shape_out = tuple(\n', '+                1 if i in axis_norm else d.shape[i] for i in range(d.ndim))\n', '+        out = np.empty(shape_out)\n', '+        result = np.nanmedian(d, axis=axis, keepdims=True, out=out)\n', '+        assert result is out\n', '+        assert_equal(result.shape, shape_out)\n', '+\n', '     def test_out(self):\n', '         mat = np.random.rand(3, 3)\n', '         nan_mat = np.insert(mat, [0, 2], np.nan, axis=1)\n']","['             res = np.nanmedian(d, axis=(0, 1, 3), keepdims=True)\n', '             assert_equal(res.shape, (1, 1, 7, 1))\n', ' \n', '     def test_out(self):\n', '         mat = np.random.rand(3, 3)\n', '         nan_mat = np.insert(mat, [0, 2], np.nan, axis=1)\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['             res = np.nanpercentile(d, 90, axis=(0, 1, 3), keepdims=True)\n', '             assert_equal(res.shape, (1, 1, 7, 1))\n', ' \n', ""+    @pytest.mark.parametrize('q', [7, [1, 7]])\n"", '+    @pytest.mark.parametrize(\n', ""+        argnames='axis',\n"", '+        argvalues=[\n', '+            None,\n', '+            1,\n', '+            (1,),\n', '+            (0, 1),\n', '+            (-3, -1),\n', '+        ]\n', '+    )\n', '+    def test_keepdims_out(self, q, axis):\n', '+        d = np.ones((3, 5, 7, 11))\n', '+        # Randomly set some elements to NaN:\n', '+        w = np.random.random((4, 200)) * np.array(d.shape)[:, None]\n', '+        w = w.astype(np.intp)\n', '+        d[tuple(w)] = np.nan\n', '+        if axis is None:\n', '+            shape_out = (1,) * d.ndim\n', '+        else:\n', '+            axis_norm = normalize_axis_tuple(axis, d.ndim)\n', '+            shape_out = tuple(\n', '+                1 if i in axis_norm else d.shape[i] for i in range(d.ndim))\n', '+        shape_out = np.shape(q) + shape_out\n', '+\n', '+        out = np.empty(shape_out)\n', '+        result = np.nanpercentile(d, q, axis=axis, keepdims=True, out=out)\n', '+        assert result is out\n', '+        assert_equal(result.shape, shape_out)\n', '+\n', '     def test_out(self):\n', '         mat = np.random.rand(3, 3)\n', '         nan_mat = np.insert(mat, [0, 2], np.nan, axis=1)\n']","['             res = np.nanpercentile(d, 90, axis=(0, 1, 3), keepdims=True)\n', '             assert_equal(res.shape, (1, 1, 7, 1))\n', ' \n', '     def test_out(self):\n', '         mat = np.random.rand(3, 3)\n', '         nan_mat = np.insert(mat, [0, 2], np.nan, axis=1)\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['         else:\n', '             return m\n', ' \n', '+    return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,\n', '                     overwrite_input=overwrite_input)\n', ' \n', ' \n', ' def _median(a, axis=None, out=None, overwrite_input=False):\n']","['         else:\n', '             return m\n', ' \n', '-    r, k = _ureduce(a, func=_median, axis=axis, out=out,\n', '                     overwrite_input=overwrite_input)\n', '-    if keepdims:\n', '-        return r.reshape(k)\n', '-    else:\n', '-        return r\n', ' \n', ' \n', ' def _median(a, axis=None, out=None, overwrite_input=False):\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"[' import pytest\n', ' \n', ' import numpy as np\n', '+from numpy.core.numeric import normalize_axis_tuple\n', ' from numpy.testing import (\n', '     assert_warns, suppress_warnings\n', '     )\n']","[' import pytest\n', ' \n', ' import numpy as np\n', ' from numpy.testing import (\n', '     assert_warns, suppress_warnings\n', '     )\n']"
numpy/numpy,v1.24.0rc2,v1.24.0,"['             assert_(r is out)\n', '             assert_(type(r) is MaskedArray)\n', ' \n', '+    @pytest.mark.parametrize(\n', ""+        argnames='axis',\n"", '+        argvalues=[\n', '+            None,\n', '+            1,\n', '+            (1, ),\n', '+            (0, 1),\n', '+            (-3, -1),\n', '+        ]\n', '+    )\n', '+    def test_keepdims_out(self, axis):\n', '+        mask = np.zeros((3, 5, 7, 11), dtype=bool)\n', '+        # Randomly set some elements to True:\n', '+        w = np.random.random((4, 200)) * np.array(mask.shape)[:, None]\n', '+        w = w.astype(np.intp)\n', '+        mask[tuple(w)] = np.nan\n', '+        d = masked_array(np.ones(mask.shape), mask=mask)\n', '+        if axis is None:\n', '+            shape_out = (1,) * d.ndim\n', '+        else:\n', '+            axis_norm = normalize_axis_tuple(axis, d.ndim)\n', '+            shape_out = tuple(\n', '+                1 if i in axis_norm else d.shape[i] for i in range(d.ndim))\n', '+        out = masked_array(np.empty(shape_out))\n', '+        result = median(d, axis=axis, keepdims=True, out=out)\n', '+        assert result is out\n', '+        assert_equal(result.shape, shape_out)\n', '+\n', '     def test_single_non_masked_value_on_axis(self):\n', '         data = [[1., 0.],\n', '                 [0., 3.],\n']","['             assert_(r is out)\n', '             assert_(type(r) is MaskedArray)\n', ' \n', '     def test_single_non_masked_value_on_axis(self):\n', '         data = [[1., 0.],\n', '                 [0., 3.],\n']"
numpy/numpy,v1.24.0rc1,v1.24.0rc2,"[' \n', ' # Add additional strings to the sctypeDict\n', "" _toadd = ['int', 'float', 'complex', 'bool', 'object',\n"", ""+          'str', 'bytes', ('a', 'bytes_'),\n"", ""+          ('int0', 'intp'), ('uint0', 'uintp')]\n"", ' \n', ' for name in _toadd:\n', '     if isinstance(name, tuple):\n']","[' \n', ' # Add additional strings to the sctypeDict\n', "" _toadd = ['int', 'float', 'complex', 'bool', 'object',\n"", ""-          'str', 'bytes', ('a', 'bytes_')]\n"", ' \n', ' for name in _toadd:\n', '     if isinstance(name, tuple):\n']"
numpy/numpy,v1.24.0rc1,v1.24.0rc2,"['         with assert_raises(TypeError):\n', '             np.dtype(dtype)\n', ' \n', '+    def test_remaining_dtypes_with_bad_bytesize(self):\n', '+        # The np.<name> aliases were deprecated, these probably should be too \n', '+        assert np.dtype(""int0"") is np.dtype(""intp"")\n', '+        assert np.dtype(""uint0"") is np.dtype(""uintp"")\n', '+        assert np.dtype(""bool8"") is np.dtype(""bool"")\n', '+        assert np.dtype(""bytes0"") is np.dtype(""bytes"")\n', '+        assert np.dtype(""str0"") is np.dtype(""str"")\n', '+        assert np.dtype(""object0"") is np.dtype(""object"")\n', '+\n', '     @pytest.mark.parametrize(\n', ""         'value',\n"", ""         ['m8', 'M8', 'datetime64', 'timedelta64',\n""]","['         with assert_raises(TypeError):\n', '             np.dtype(dtype)\n', ' \n', '     @pytest.mark.parametrize(\n', ""         'value',\n"", ""         ['m8', 'M8', 'datetime64', 'timedelta64',\n""]"
numpy/numpy,v1.24.0rc1,v1.24.0rc2,"['         # numba issue gh-4733\n', ""         warnings.filterwarnings('always', '', DeprecationWarning)\n"", '         import numba\n', '+except (ImportError, SystemError):\n', '+    # Certain numpy/numba versions trigger a SystemError due to a numba bug\n', '     numba = None\n', ' \n', ' try:\n']","['         # numba issue gh-4733\n', ""         warnings.filterwarnings('always', '', DeprecationWarning)\n"", '         import numba\n', '-except ImportError:\n', '     numba = None\n', ' \n', ' try:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" # pip ignores '--global-option' when pep517 is enabled therefore we disable it.\n"", "" cmd = [sys.executable, '-mpip', 'wheel', '--no-use-pep517']\n"", ' try:\n', '+    output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, text=True)\n', ' except Exception as e:\n', '     output = str(e.output)\n', ' if ""no such option"" in output:\n']","["" # pip ignores '--global-option' when pep517 is enabled therefore we disable it.\n"", "" cmd = [sys.executable, '-mpip', 'wheel', '--no-use-pep517']\n"", ' try:\n', '-    output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, universal_newlines=True)\n', ' except Exception as e:\n', '     output = str(e.output)\n', ' if ""no such option"" in output:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from .common import Benchmark\n', ' \n', ' import numpy as np\n']","['-from __future__ import absolute_import, division, print_function\n', '-\n', ' from .common import Benchmark\n', ' \n', ' import numpy as np\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' import numpy as np\n', ' \n', '+class Linspace(Benchmark):\n', '+    def setup(self):\n', '+        self.d = np.array([1, 2, 3])\n', '+\n', '+    def time_linspace_scalar(self):\n', '+        np.linspace(0, 10, 2)\n', '+\n', '+    def time_linspace_array(self):\n', '+        np.linspace(self.d, 10, 10)\n', ' \n', ' class Histogram1D(Benchmark):\n', '     def setup(self):\n']","[' \n', ' import numpy as np\n', ' \n', ' \n', ' class Histogram1D(Benchmark):\n', '     def setup(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     param_names = ['num_lines']\n"", ' \n', '     def setup(self, num_lines):\n', ""+        data = ['1,2,3 # comment'] * num_lines\n"", '         # unfortunately, timeit will only run setup()\n', '         # between repeat events, but not for iterations\n', '         # within repeats, so the StringIO object\n', '         # will have to be rewinded in the benchmark proper\n', ""+        self.data_comments = StringIO('\\n'.join(data))\n"", ' \n', '     def time_comment_loadtxt_csv(self, num_lines):\n', '         # benchmark handling of lines with comments\n']","[""     param_names = ['num_lines']\n"", ' \n', '     def setup(self, num_lines):\n', ""-        data = [u'1,2,3 # comment'] * num_lines\n"", '         # unfortunately, timeit will only run setup()\n', '         # between repeat events, but not for iterations\n', '         # within repeats, so the StringIO object\n', '         # will have to be rewinded in the benchmark proper\n', ""-        self.data_comments = StringIO(u'\\n'.join(data))\n"", ' \n', '     def time_comment_loadtxt_csv(self, num_lines):\n', '         # benchmark handling of lines with comments\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # confounding timing result somewhat) for every\n', '         # call to timing test proper\n', '         np.loadtxt(self.data_comments,\n', ""+                   delimiter=',')\n"", '         self.data_comments.seek(0)\n', ' \n', ' class LoadtxtCSVdtypes(Benchmark):\n']","['         # confounding timing result somewhat) for every\n', '         # call to timing test proper\n', '         np.loadtxt(self.data_comments,\n', ""-                   delimiter=u',')\n"", '         self.data_comments.seek(0)\n', ' \n', ' class LoadtxtCSVdtypes(Benchmark):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     param_names = ['dtype', 'num_lines']\n"", ' \n', '     def setup(self, dtype, num_lines):\n', ""+        data = ['5, 7, 888'] * num_lines\n"", ""+        self.csv_data = StringIO('\\n'.join(data))\n"", ' \n', '     def time_loadtxt_dtypes_csv(self, dtype, num_lines):\n', '         # benchmark loading arrays of various dtypes\n']","[""     param_names = ['dtype', 'num_lines']\n"", ' \n', '     def setup(self, dtype, num_lines):\n', ""-        data = [u'5, 7, 888'] * num_lines\n"", ""-        self.csv_data = StringIO(u'\\n'.join(data))\n"", ' \n', '     def time_loadtxt_dtypes_csv(self, dtype, num_lines):\n', '         # benchmark loading arrays of various dtypes\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # rewind of StringIO object\n', ' \n', '         np.loadtxt(self.csv_data,\n', ""+                   delimiter=',',\n"", '                    dtype=dtype)\n', '         self.csv_data.seek(0)\n', ' \n']","['         # rewind of StringIO object\n', ' \n', '         np.loadtxt(self.csv_data,\n', ""-                   delimiter=u',',\n"", '                    dtype=dtype)\n', '         self.csv_data.seek(0)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def setup(self):\n', '         num_lines = 50000\n', '+        data = [""M, 21, 72, X, 155""] * num_lines\n', ""+        self.csv_data = StringIO('\\n'.join(data))\n"", ' \n', '     def time_loadtxt_csv_struct_dtype(self):\n', '         # obligate rewind of StringIO object\n', '         # between iterations of a repeat:\n', ' \n', '         np.loadtxt(self.csv_data,\n', ""+                   delimiter=',',\n"", ""                    dtype=[('category_1', 'S1'),\n"", ""                           ('category_2', 'i4'),\n"", ""                           ('category_3', 'f8'),\n""]","[' \n', '     def setup(self):\n', '         num_lines = 50000\n', '-        data = [u""M, 21, 72, X, 155""] * num_lines\n', ""-        self.csv_data = StringIO(u'\\n'.join(data))\n"", ' \n', '     def time_loadtxt_csv_struct_dtype(self):\n', '         # obligate rewind of StringIO object\n', '         # between iterations of a repeat:\n', ' \n', '         np.loadtxt(self.csv_data,\n', ""-                   delimiter=u',',\n"", ""                    dtype=[('category_1', 'S1'),\n"", ""                           ('category_2', 'i4'),\n"", ""                           ('category_3', 'f8'),\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def setup(self, size):\n', ""         arr = np.arange(size).astype('uint64') + 2**63\n"", ""+        self.data1 = StringIO('\\n'.join(arr.astype(str).tolist()))\n"", '         arr = arr.astype(object)\n', '         arr[500] = -1\n', ""+        self.data2 = StringIO('\\n'.join(arr.astype(str).tolist()))\n"", ' \n', '     def time_read_uint64(self, size):\n', '         # mandatory rewind of StringIO object\n']","[' \n', '     def setup(self, size):\n', ""         arr = np.arange(size).astype('uint64') + 2**63\n"", ""-        self.data1 = StringIO(u'\\n'.join(arr.astype(str).tolist()))\n"", '         arr = arr.astype(object)\n', '         arr[500] = -1\n', ""-        self.data2 = StringIO(u'\\n'.join(arr.astype(str).tolist()))\n"", ' \n', '     def time_read_uint64(self, size):\n', '         # mandatory rewind of StringIO object\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def setup(self, usecols):\n', '         num_lines = 5000\n', ""+        data = ['0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * num_lines\n"", ""+        self.csv_data = StringIO('\\n'.join(data))\n"", ' \n', '     def time_loadtxt_usecols_csv(self, usecols):\n', '         # must rewind StringIO because of state\n', '         # dependence of file reading\n', '         np.loadtxt(self.csv_data,\n', ""+                   delimiter=',',\n"", '                    usecols=usecols)\n', '         self.csv_data.seek(0)\n', ' \n']","[' \n', '     def setup(self, usecols):\n', '         num_lines = 5000\n', ""-        data = [u'0, 1, 2, 3, 4, 5, 6, 7, 8, 9'] * num_lines\n"", ""-        self.csv_data = StringIO(u'\\n'.join(data))\n"", ' \n', '     def time_loadtxt_usecols_csv(self, usecols):\n', '         # must rewind StringIO because of state\n', '         # dependence of file reading\n', '         np.loadtxt(self.csv_data,\n', ""-                   delimiter=u',',\n"", '                    usecols=usecols)\n', '         self.csv_data.seek(0)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         dates = np.arange('today', 20, dtype=np.datetime64)\n"", '         np.random.seed(123)\n', '         values = np.random.rand(20)\n', ""+        date_line = ''\n"", ' \n', '         for date, value in zip(dates, values):\n', ""             date_line += (str(date) + ',' + str(value) + '\\n')\n""]","[""         dates = np.arange('today', 20, dtype=np.datetime64)\n"", '         np.random.seed(123)\n', '         values = np.random.rand(20)\n', ""-        date_line = u''\n"", ' \n', '         for date, value in zip(dates, values):\n', ""             date_line += (str(date) + ',' + str(value) + '\\n')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # rewind StringIO object -- the timing iterations\n', '         # are state-dependent\n', '         X = np.loadtxt(self.csv_data,\n', ""+                       delimiter=',',\n"", ""                        dtype=([('dates', 'M8[us]'),\n"", ""                                ('values', 'float64')]))\n"", '         self.csv_data.seek(0)\n']","['         # rewind StringIO object -- the timing iterations\n', '         # are state-dependent\n', '         X = np.loadtxt(self.csv_data,\n', ""-                       delimiter=u',',\n"", ""                        dtype=([('dates', 'M8[us]'),\n"", ""                                ('values', 'float64')]))\n"", '         self.csv_data.seek(0)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from .common import Benchmark, TYPES1\n', ' \n', ' import numpy as np\n']","['-from __future__ import absolute_import, division, print_function\n', '-\n', ' from .common import Benchmark, TYPES1\n', ' \n', ' import numpy as np\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def time_unique(self, array_size, percent_nans):\n', '         np.unique(self.arr)\n', '+\n', '+\n', '+class Isin(Benchmark):\n', '+    """"""Benchmarks for `numpy.isin`.""""""\n', '+\n', '+    param_names = [""size"", ""highest_element""]\n', '+    params = [\n', '+        [10, 100000, 3000000],\n', '+        [10, 10000, int(1e8)]\n', '+    ]\n', '+\n', '+    def setup(self, size, highest_element):\n', '+        self.array = np.random.randint(\n', '+                low=0, high=highest_element, size=size)\n', '+        self.in_array = np.random.randint(\n', '+                low=0, high=highest_element, size=size)\n', '+\n', '+    def time_isin(self, size, highest_element):\n', '+        np.isin(self.array, self.in_array)\n']","[' \n', '     def time_unique(self, array_size, percent_nans):\n', '         np.unique(self.arr)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+from .common import Benchmark\n', '+\n', '+import numpy as np\n', '+import operator\n', '+\n', '+\n', '+_OPERATORS = {\n', ""+    '==': operator.eq,\n"", ""+    '!=': operator.ne,\n"", ""+    '<': operator.lt,\n"", ""+    '<=': operator.le,\n"", ""+    '>': operator.gt,\n"", ""+    '>=': operator.ge,\n"", '+}\n', '+\n', '+\n', '+class StringComparisons(Benchmark):\n', '+    # Basic string comparison speed tests\n', '+    params = [\n', '+        [100, 10000, (1000, 20)],\n', ""+        ['U', 'S'],\n"", '+        [True, False],\n', ""+        ['==', '!=', '<', '<=', '>', '>=']]\n"", ""+    param_names = ['shape', 'dtype', 'contig', 'operator']\n"", '+    int64 = np.dtype(np.int64)\n', '+\n', '+    def setup(self, shape, dtype, contig, operator):\n', '+        self.arr = np.arange(np.prod(shape)).astype(dtype).reshape(shape)\n', '+        self.arr_identical = self.arr.copy()\n', '+        self.arr_different = self.arr[::-1].copy()\n', '+\n', '+        if not contig:\n', '+            self.arr = self.arr[..., ::2]\n', '+            self.arr_identical = self.arr_identical[..., ::2]\n', '+            self.arr_different = self.arr_different[..., ::2]\n', '+\n', '+        self.operator = _OPERATORS[operator]\n', '+\n', '+    def time_compare_identical(self, shape, dtype, contig, operator):\n', '+        self.operator(self.arr, self.arr_identical)\n', '+\n', '+    def time_compare_different(self, shape, dtype, contig, operator):\n', '+        self.operator(self.arr, self.arr_different)\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def time_divide_scalar2_inplace(self, dtype):\n', '         np.divide(self.d, 1, out=self.d)\n', ' \n', '+\n', '+class CustomComparison(Benchmark):\n', '+    params = (np.int8,  np.int16,  np.int32,  np.int64, np.uint8, np.uint16,\n', '+              np.uint32, np.uint64, np.float32, np.float64, np.bool_)\n', ""+    param_names = ['dtype']\n"", '+\n', '+    def setup(self, dtype):\n', '+        self.x = np.ones(50000, dtype=dtype)\n', '+        self.y = np.ones(50000, dtype=dtype)\n', '+        self.s = np.ones(1, dtype=dtype)\n', '+\n', '+    def time_less_than_binary(self, dtype):\n', '+        (self.x < self.y)\n', '+\n', '+    def time_less_than_scalar1(self, dtype):\n', '+        (self.s < self.x)\n', '+\n', '     def time_less_than_scalar2(self, dtype):\n', '+        (self.x < self.s)\n', ' \n', ' \n', ' class CustomScalarFloorDivideInt(Benchmark):\n']","['     def time_divide_scalar2_inplace(self, dtype):\n', '         np.divide(self.d, 1, out=self.d)\n', ' \n', '     def time_less_than_scalar2(self, dtype):\n', '-        (self.d < 1)\n', ' \n', ' \n', ' class CustomScalarFloorDivideInt(Benchmark):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def time_add_reduce_arg_parsing(self, arg_pack):\n', '         np.add.reduce(*arg_pack.args, **arg_pack.kwargs)\n', '+\n', '+class BinaryBench(Benchmark):\n', '+    def setup(self):\n', '+        N = 1000000\n', '+        self.a32 = np.random.rand(N).astype(np.float32)\n', '+        self.b32 = np.random.rand(N).astype(np.float32)\n', '+        self.a64 = np.random.rand(N).astype(np.float64)\n', '+        self.b64 = np.random.rand(N).astype(np.float64)\n', '+    \n', '+    def time_pow_32(self):\n', '+        np.power(self.a32, self.b32)\n', '+\n', '+    def time_pow_64(self):\n', '+        np.power(self.a64, self.b64)\n', '+\n', '+    def time_atan2_32(self):\n', '+        np.arctan2(self.a32, self.b32)\n', '+\n', '+    def time_atan2_64(self):\n', '+        np.arctan2(self.a64, self.b64)\n']","[' \n', '     def time_add_reduce_arg_parsing(self, arg_pack):\n', '         np.add.reduce(*arg_pack.args, **arg_pack.kwargs)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' stride = [1, 2, 4]\n', ' stride_out = [1, 2, 4]\n', ""+dtype = ['e', 'f', 'd']\n"", ' \n', ' class Unary(Benchmark):\n', '     params = [UNARY_OBJECT_UFUNCS, stride, stride_out, dtype]\n']","[' \n', ' stride = [1, 2, 4]\n', ' stride_out = [1, 2, 4]\n', ""-dtype  = ['f', 'd']\n"", ' \n', ' class Unary(Benchmark):\n', '     params = [UNARY_OBJECT_UFUNCS, stride, stride_out, dtype]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-""""""This is the docstring for the example.py module.  Modules names should\n', '-have short, all-lowercase names.  The module name may have underscores if\n', '-this improves readability.\n', '-\n', '-Every module should have a docstring at the very top of the file.  The\n', ""-module's docstring may extend over multiple lines.  If your docstring does\n"", '-extend over multiple lines, the closing three quotation marks must be on\n', '-a line by itself, preferably preceded by a blank line.\n', '-\n', '-""""""\n', '-import os # standard library imports first\n', '-\n', '-# Do NOT import using *, e.g. from numpy import *\n', '-#\n', '-# Import the module using\n', '-#\n', '-#   import numpy\n', '-#\n', '-# instead or import individual functions as needed, e.g\n', '-#\n', '-#  from numpy import array, zeros\n', '-#\n', '-# If you prefer the use of abbreviated module names, we suggest the\n', '-# convention used by NumPy itself::\n', '-\n', '-import numpy as np\n', '-import matplotlib as mpl\n', '-import matplotlib.pyplot as plt\n', '-\n', '-# These abbreviated names are not to be used in docstrings; users must\n', '-# be able to paste and execute docstrings after importing only the\n', '-# numpy module itself, unabbreviated.\n', '-\n', '-from my_module import my_func, other_func\n', '-\n', ""-def foo(var1, var2, long_var_name='hi'):\n"", '-    r""""""A one-line summary that does not use variable names or the\n', '-    function name.\n', '-\n', '-    Several sentences providing an extended description. Refer to\n', '-    variables using back-ticks, e.g. `var`.\n', '-\n', '-    Parameters\n', '-    ----------\n', '-    var1 : array_like\n', '-        Array_like means all those objects -- lists, nested lists, etc. --\n', '-        that can be converted to an array.  We can also refer to\n', '-        variables like `var1`.\n', '-    var2 : int\n', '-        The type above can either refer to an actual Python type\n', '-        (e.g. ``int``), or describe the type of the variable in more\n', '-        detail, e.g. ``(N,) ndarray`` or ``array_like``.\n', ""-    long_var_name : {'hi', 'ho'}, optional\n"", '-        Choices in brackets, default first when optional.\n', '-\n', '-    Returns\n', '-    -------\n', '-    type\n', '-        Explanation of anonymous return value of type ``type``.\n', '-    describe : type\n', '-        Explanation of return value named `describe`.\n', '-    out : type\n', '-        Explanation of `out`.\n', '-\n', '-    Other Parameters\n', '-    ----------------\n', '-    only_seldom_used_keywords : type\n', '-        Explanation\n', '-    common_parameters_listed_above : type\n', '-        Explanation\n', '-\n', '-    Raises\n', '-    ------\n', '-    BadException\n', ""-        Because you shouldn't have done that.\n"", '-\n', '-    See Also\n', '-    --------\n', '-    otherfunc : relationship (optional)\n', '-    newfunc : Relationship (optional), which could be fairly long, in which\n', '-              case the line wraps here.\n', '-    thirdfunc, fourthfunc, fifthfunc\n', '-\n', '-    Notes\n', '-    -----\n', '-    Notes about the implementation algorithm (if needed).\n', '-\n', '-    This can have multiple paragraphs.\n', '-\n', '-    You may include some math:\n', '-\n', '-    .. math:: X(e^{j\\omega } ) = x(n)e^{ - j\\omega n}\n', '-\n', '-    And even use a greek symbol like :math:`omega` inline.\n', '-\n', '-    References\n', '-    ----------\n', '-    Cite the relevant literature, e.g. [1]_.  You may also cite these\n', '-    references in the notes section above.\n', '-\n', '-    .. [1] O. McNoleg, ""The integration of GIS, remote sensing,\n', '-       expert systems and adaptive co-kriging for environmental habitat\n', '-       modelling of the Highland Haggis using object-oriented, fuzzy-logic\n', '-       and neural-network techniques,"" Computers & Geosciences, vol. 22,\n', '-       pp. 585-588, 1996.\n', '-\n', '-    Examples\n', '-    --------\n', '-    These are written in doctest format, and should illustrate how to\n', '-    use the function.\n', '-\n', '-    >>> a = [1, 2, 3]\n', '-    >>> print([x + 3 for x in a])\n', '-    [4, 5, 6]\n', '-    >>> print(""a\\n\\nb"")\n', '-    a\n', '-    b\n', '-\n', '-    """"""\n', '-\n', '-    pass\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" master_doc = 'content'\n"", ' \n', ' # General information about the project.\n', ""+project = 'NumPy Enhancement Proposals'\n"", ""+copyright = '2017-2018, NumPy Developers'\n"", ""+author = 'NumPy Developers'\n"", ""+title = 'NumPy Enhancement Proposals Documentation'\n"", ' \n', "" # The version info for the project you're documenting, acts as replacement for\n"", ' # |version| and |release|, also used in various other places throughout the\n', ' # built documents.\n', ' #\n', ' # The short X.Y version.\n', ""+version = ''\n"", ' # The full version, including alpha/beta/rc tags.\n', ""+release = ''\n"", ' \n', ' # The language for content autogenerated by Sphinx. Refer to documentation\n', ' # for a list of supported languages.\n']","["" master_doc = 'content'\n"", ' \n', ' # General information about the project.\n', ""-project = u'NumPy Enhancement Proposals'\n"", ""-copyright = u'2017-2018, NumPy Developers'\n"", ""-author = u'NumPy Developers'\n"", ' \n', "" # The version info for the project you're documenting, acts as replacement for\n"", ' # |version| and |release|, also used in various other places throughout the\n', ' # built documents.\n', ' #\n', ' # The short X.Y version.\n', ""-version = u''\n"", ' # The full version, including alpha/beta/rc tags.\n', ""-release = u''\n"", ' \n', ' # The language for content autogenerated by Sphinx. Refer to documentation\n', ' # for a list of supported languages.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # (source start file, target name, title,\n', ' #  author, documentclass [howto, manual, or own class]).\n', ' latex_documents = [\n', ""+    (master_doc, 'NumPyEnhancementProposals.tex', title,\n"", ""+     'NumPy Developers', 'manual'),\n"", ' ]\n', ' \n', ' \n']","[' # (source start file, target name, title,\n', ' #  author, documentclass [howto, manual, or own class]).\n', ' latex_documents = [\n', ""-    (master_doc, 'NumPyEnhancementProposals.tex', u'NumPy Enhancement Proposals Documentation',\n"", ""-     u'NumPy Developers', 'manual'),\n"", ' ]\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # One entry per manual page. List of tuples\n', ' # (source start file, name, description, authors, manual section).\n', ' man_pages = [\n', ""+    (master_doc, 'numpyenhancementproposals', title,\n"", '      [author], 1)\n', ' ]\n', ' \n']","[' # One entry per manual page. List of tuples\n', ' # (source start file, name, description, authors, manual section).\n', ' man_pages = [\n', ""-    (master_doc, 'numpyenhancementproposals', u'NumPy Enhancement Proposals Documentation',\n"", '      [author], 1)\n', ' ]\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # (source start file, target name, title, author,\n', ' #  dir menu entry, description, category)\n', ' texinfo_documents = [\n', ""+    (master_doc, 'NumPyEnhancementProposals', title,\n"", ""      author, 'NumPyEnhancementProposals', 'One line description of project.',\n"", ""      'Miscellaneous'),\n"", ' ]\n']","[' # (source start file, target name, title, author,\n', ' #  dir menu entry, description, category)\n', ' texinfo_documents = [\n', ""-    (master_doc, 'NumPyEnhancementProposals', u'NumPy Enhancement Proposals Documentation',\n"", ""      author, 'NumPyEnhancementProposals', 'One line description of project.',\n"", ""      'Miscellaneous'),\n"", ' ]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import importlib\n', ' \n', ' # Minimum version, enforced by sphinx\n', ""+needs_sphinx = '4.3'\n"", ' \n', ' \n', ' # This is a nasty hack to use platform-agnostic names for types in the\n']","[' import importlib\n', ' \n', ' # Minimum version, enforced by sphinx\n', ""-needs_sphinx = '3.2.0'\n"", ' \n', ' \n', ' # This is a nasty hack to use platform-agnostic names for types in the\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     'IPython.sphinxext.ipython_console_highlighting',\n"", ""     'IPython.sphinxext.ipython_directive',\n"", ""     'sphinx.ext.mathjax',\n"", ""+    'sphinx_design',\n"", ' ]\n', ' \n', ' skippable_extensions = [\n']","[""     'IPython.sphinxext.ipython_console_highlighting',\n"", ""     'IPython.sphinxext.ipython_directive',\n"", ""     'sphinx.ext.mathjax',\n"", ""-    'sphinx_panels',\n"", ' ]\n', ' \n', ' skippable_extensions = [\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # The suffix of source filenames.\n', "" source_suffix = '.rst'\n"", ' \n', ' # General substitutions.\n', "" project = 'NumPy'\n"", "" copyright = '2008-2022, NumPy Developers'\n""]","[' # The suffix of source filenames.\n', "" source_suffix = '.rst'\n"", ' \n', '-# Will change to `root_doc` in Sphinx 4\n', ""-master_doc = 'index'\n"", '-\n', ' # General substitutions.\n', "" project = 'NumPy'\n"", "" copyright = '2008-2022, NumPy Developers'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" html_theme = 'pydata_sphinx_theme'\n"", ' \n', "" html_favicon = '_static/favicon/favicon.ico'\n"", ' \n', '+# Set up the version switcher.  The versions.json is stored in the doc repo.\n', "" if os.environ.get('CIRCLE_JOB', False) and \\\n"", ""         os.environ.get('CIRCLE_BRANCH', '') != 'main':\n"", '     # For PR, name is set to its ref\n']","[' \n', "" html_theme = 'pydata_sphinx_theme'\n"", ' \n', ""-html_logo = '_static/numpylogo.svg'\n"", '-\n', "" html_favicon = '_static/favicon/favicon.ico'\n"", ' \n', '-# Set up the version switcher.  The versions.json is stored in the devdocs.\n', "" if os.environ.get('CIRCLE_JOB', False) and \\\n"", ""         os.environ.get('CIRCLE_BRANCH', '') != 'main':\n"", '     # For PR, name is set to its ref\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' elif "".dev"" in version:\n', '     switcher_version = ""devdocs""\n', ' else:\n', '+    switcher_version = f""{version}""\n', ' \n', ' html_theme_options = {\n', '+  ""logo"": {\n', '+      ""image_light"": ""numpylogo.svg"",\n', '+      ""image_dark"": ""numpylogo_dark.svg"",\n', '+  },\n', '   ""github_url"": ""https://github.com/numpy/numpy"",\n', '   ""twitter_url"": ""https://twitter.com/numpy_team"",\n', '   ""collapse_navigation"": True,\n']","[' elif "".dev"" in version:\n', '     switcher_version = ""devdocs""\n', ' else:\n', '-    switcher_version = f""doc/{version}""\n', ' \n', ' html_theme_options = {\n', '-  ""logo_link"": ""index"",\n', '   ""github_url"": ""https://github.com/numpy/numpy"",\n', '   ""twitter_url"": ""https://twitter.com/numpy_team"",\n', '   ""collapse_navigation"": True,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['       {""name"": ""Learn"", ""url"": ""https://numpy.org/numpy-tutorials/""}\n', '       ],\n', '   # Add light/dark mode and documentation version switcher:\n', '+  ""navbar_end"": [""theme-switcher"", ""version-switcher"", ""navbar-icon-links""],\n', '   ""switcher"": {\n', '       ""version_match"": switcher_version,\n', '+      ""json_url"": ""https://numpy.org/doc/_static/versions.json"",\n', '   },\n', ' }\n', ' \n']","['       {""name"": ""Learn"", ""url"": ""https://numpy.org/numpy-tutorials/""}\n', '       ],\n', '   # Add light/dark mode and documentation version switcher:\n', '-  ""navbar_end"": [""version-switcher"", ""navbar-icon-links""],\n', '   ""switcher"": {\n', '       ""version_match"": switcher_version,\n', '-      ""json_url"": ""https://numpy.org/devdocs/_static/versions.json"",\n', '   },\n', ' }\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" html_static_path = ['_static']\n"", "" html_last_updated_fmt = '%b %d, %Y'\n"", ' html_css_files = [""numpy.css""]\n', '+html_context = {""default_mode"": ""light""}\n', ' html_use_modindex = True\n', ' html_copy_source = False\n', ' html_domain_indices = False\n']","["" html_static_path = ['_static']\n"", "" html_last_updated_fmt = '%b %d, %Y'\n"", ' html_css_files = [""numpy.css""]\n', '-\n', '-# Prevent sphinx-panels from loading bootstrap css, the pydata-sphinx-theme\n', '-# already loads it\n', '-panels_add_bootstrap_css = False\n', '-\n', ' html_use_modindex = True\n', ' html_copy_source = False\n', ' html_domain_indices = False\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-from scipy import misc\n', '-import matplotlib.pyplot as plt\n', '-import numpy as np\n', '-from numpy import linalg\n', '-\n', '-img = misc.face()\n', '-img_array = img / 255\n', '-img_gray = img_array @ [0.2126, 0.7152, 0.0722]\n', '-\n', '-U, s, Vt = linalg.svd(img_gray)\n', '-\n', '-Sigma = np.zeros((768, 1024))\n', '-for i in range(768):\n', '-    Sigma[i, i] = s[i]\n', '-\n', '-k = 10\n', '-\n', '-approx = U @ Sigma[:, :k] @ Vt[:k, :]\n', '-plt.imshow(approx, cmap=""gray"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-from scipy import misc\n', '-import matplotlib.pyplot as plt\n', '-\n', '-img = misc.face()\n', '-plt.imshow(img)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-from scipy import misc\n', '-import matplotlib.pyplot as plt\n', '-import numpy as np\n', '-from numpy import linalg\n', '-\n', '-img = misc.face()\n', '-img_array = img / 255\n', '-img_array_transposed = np.transpose(img_array, (2, 0, 1))\n', '-\n', '-U, s, Vt = linalg.svd(img_array_transposed)\n', '-\n', '-Sigma = np.zeros((3, 768, 1024))\n', '-for j in range(3):\n', '-    np.fill_diagonal(Sigma[j, :, :], s[j, :])\n', '-\n', '-k = 10\n', '-\n', '-approx_img = U @ Sigma[..., :k] @ Vt[..., :k, :]\n', '-plt.imshow(np.transpose(approx_img, (1, 2, 0)))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-from scipy import misc\n', '-import matplotlib.pyplot as plt\n', '-import numpy as np\n', '-\n', '-img = misc.face()\n', '-img_array = img / 255\n', '-img_gray = img_array @ [0.2126, 0.7152, 0.0722]\n', '-plt.imshow(img_gray, cmap=""gray"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-from scipy import misc\n', '-import matplotlib.pyplot as plt\n', '-import numpy as np\n', '-from numpy import linalg\n', '-\n', '-img = misc.face()\n', '-img_array = img / 255\n', '-img_gray = img_array @ [0.2126, 0.7152, 0.0722]\n', '-\n', '-U, s, Vt = linalg.svd(img_gray)\n', '-\n', '-Sigma = np.zeros((768, 1024))\n', '-for i in range(768):\n', '-    Sigma[i, i] = s[i]\n', '-\n', '-plt.plot(s)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,[],"['-from scipy import misc\n', '-import matplotlib.pyplot as plt\n', '-import numpy as np\n', '-from numpy import linalg\n', '-\n', '-img = misc.face()\n', '-img_array = img / 255\n', '-img_array_transposed = np.transpose(img_array, (2, 0, 1))\n', '-\n', '-U, s, Vt = linalg.svd(img_array_transposed)\n', '-\n', '-Sigma = np.zeros((3, 768, 1024))\n', '-for j in range(3):\n', '-    np.fill_diagonal(Sigma[j, :, :], s[j, :])\n', '-\n', '-reconstructed = U @ Sigma @ Vt\n', '-plt.imshow(np.transpose(reconstructed, (1, 2, 0)))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import numpy as np\n', '+import matplotlib.pyplot as plt\n', '+\n', '+x = np.array([0, 1, 2, 3])\n', '+y = np.array([0, 1, 2, 3, 4, 5])\n', '+xx, yy = np.meshgrid(x, y)\n', ""+plt.plot(xx, yy, marker='o', color='k', linestyle='none')\n""]",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"['             cls.__instance = super().__new__(cls)\n', '         return cls.__instance\n', ' \n', '     def __repr__(self):\n', '         return ""<no value>""\n', ' \n']","['             cls.__instance = super().__new__(cls)\n', '         return cls.__instance\n', ' \n', '-    # needed for python 2 to preserve identity through a pickle\n', '-    def __reduce__(self):\n', '-        return (self.__class__, ())\n', '-\n', '     def __repr__(self):\n', '         return ""<no value>""\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' modules or shared libraries. This script should aim to touch as many of those\n', ' as possible in an attempt to trip a ModuleNotFoundError or a DLL load failure\n', ' due to an uncollected resource. Missing resources are unlikely to lead to\n', ""+arithmetic errors so there's generally no need to verify any calculation's\n"", ' output - merely that it made it to the end OK. This script should not\n', "" explicitly import any of numpy's submodules as that gives PyInstaller undue\n"", ' hints that those submodules exist and should be collected (accessing implicitly\n']","[' modules or shared libraries. This script should aim to touch as many of those\n', ' as possible in an attempt to trip a ModuleNotFoundError or a DLL load failure\n', ' due to an uncollected resource. Missing resources are unlikely to lead to\n', ""-arithmitic errors so there's generally no need to verify any calculation's\n"", ' output - merely that it made it to the end OK. This script should not\n', "" explicitly import any of numpy's submodules as that gives PyInstaller undue\n"", ' hints that those submodules exist and should be collected (accessing implicitly\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" __all__ = ['PytestTester']\n"", ' \n', ' \n', ' def _show_numpy_info():\n', '     import numpy as np\n', ' \n']","["" __all__ = ['PytestTester']\n"", ' \n', ' \n', '-\n', ' def _show_numpy_info():\n', '     import numpy as np\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     print(""NumPy CPU features: "", (info if info else \'nothing enabled\'))\n', ' \n', ' \n', ' class PytestTester:\n', '     """"""\n', '     Pytest test runner.\n']","['     print(""NumPy CPU features: "", (info if info else \'nothing enabled\'))\n', ' \n', ' \n', '-\n', ' class PytestTester:\n', '     """"""\n', '     Pytest test runner.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             ]\n', ' \n', '         if doctests:\n', '+            pytest_args += [""--doctest-modules""]\n', ' \n', '         if extra_argv:\n', '             pytest_args += list(extra_argv)\n']","['             ]\n', ' \n', '         if doctests:\n', '-            raise ValueError(""Doctests not supported"")\n', ' \n', '         if extra_argv:\n', '             pytest_args += list(extra_argv)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # NOTE: Import `Sequence` from `typing` as we it is needed for a type-alias,\n', ' # not an annotation\n', ' from collections.abc import Collection, Callable\n', '+from typing import Any, Sequence, Protocol, Union, TypeVar, runtime_checkable\n', ' from numpy import (\n', '     ndarray,\n', '     dtype,\n']","[' # NOTE: Import `Sequence` from `typing` as we it is needed for a type-alias,\n', ' # not an annotation\n', ' from collections.abc import Collection, Callable\n', '-from typing import Any, Sequence, Protocol, Union, TypeVar\n', ' from numpy import (\n', '     ndarray,\n', '     dtype,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # array.\n', ' # Concrete implementations of the protocol are responsible for adding\n', ' # any and all remaining overloads\n', '+@runtime_checkable\n', ' class _SupportsArray(Protocol[_DType_co]):\n', '     def __array__(self) -> ndarray[Any, _DType_co]: ...\n', ' \n', ' \n', '+@runtime_checkable\n', ' class _SupportsArrayFunc(Protocol):\n', '     """"""A protocol class representing `~class.__array_function__`.""""""\n', '     def __array_function__(\n']","[' # array.\n', ' # Concrete implementations of the protocol are responsible for adding\n', ' # any and all remaining overloads\n', ' class _SupportsArray(Protocol[_DType_co]):\n', '     def __array__(self) -> ndarray[Any, _DType_co]: ...\n', ' \n', ' \n', ' class _SupportsArrayFunc(Protocol):\n', '     """"""A protocol class representing `~class.__array_function__`.""""""\n', '     def __array_function__(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ""dtype[integer[Any]]"",\n', '     int,\n', ' ]\n', '+\n', '+# Extra ArrayLike type so that pyright can deal with NDArray[Any]\n', '+# Used as the first overload, should only match NDArray[Any],\n', '+# not any actual types.\n', '+# https://github.com/numpy/numpy/pull/22193\n', '+class _UnknownType:\n', '+    ...\n', '+\n', '+\n', '+_ArrayLikeUnknown = _DualArrayLike[\n', '+    ""dtype[_UnknownType]"",\n', '+    _UnknownType,\n', '+]\n']","['     ""dtype[integer[Any]]"",\n', '     int,\n', ' ]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     TypeVar,\n', '     Protocol,\n', '     TypedDict,\n', '+    runtime_checkable,\n', ' )\n', ' \n', ' import numpy as np\n']","['     TypeVar,\n', '     Protocol,\n', '     TypedDict,\n', ' )\n', ' \n', ' import numpy as np\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' # A protocol for anything with the dtype attribute\n', '+@runtime_checkable\n', ' class _SupportsDType(Protocol[_DType_co]):\n', '     @property\n', '     def dtype(self) -> _DType_co: ...\n']","[' \n', ' \n', ' # A protocol for anything with the dtype attribute\n', ' class _SupportsDType(Protocol[_DType_co]):\n', '     @property\n', '     def dtype(self) -> _DType_co: ...\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         args.append(value)\n', ' \n', '     cls = type(alias)\n', '+    return cls(alias.__origin__, tuple(args), alias.__unpacked__)\n', ' \n', ' \n', ' class _GenericAlias:\n']","['         args.append(value)\n', ' \n', '     cls = type(alias)\n', '-    return cls(alias.__origin__, tuple(args))\n', ' \n', ' \n', ' class _GenericAlias:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     """"""\n', ' \n', '+    __slots__ = (\n', '+        ""__weakref__"",\n', '+        ""_origin"",\n', '+        ""_args"",\n', '+        ""_parameters"",\n', '+        ""_hash"",\n', '+        ""_starred"",\n', '+    )\n', ' \n', '     @property\n', '     def __origin__(self) -> type:\n']","[' \n', '     """"""\n', ' \n', '-    __slots__ = (""__weakref__"", ""_origin"", ""_args"", ""_parameters"", ""_hash"")\n', ' \n', '     @property\n', '     def __origin__(self) -> type:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         """"""Type variables in the ``GenericAlias``.""""""\n', '         return super().__getattribute__(""_parameters"")\n', ' \n', '+    @property\n', '+    def __unpacked__(self) -> bool:\n', '+        return super().__getattribute__(""_starred"")\n', '+\n', '+    @property\n', '+    def __typing_unpacked_tuple_args__(self) -> tuple[object, ...] | None:\n', '+        # NOTE: This should return `__args__` if `__origin__` is a tuple,\n', '+        # which should never be the case with how `_GenericAlias` is used\n', '+        # within numpy\n', '+        return None\n', '+\n', '     def __init__(\n', '         self,\n', '         origin: type,\n', '         args: object | tuple[object, ...],\n', '+        starred: bool = False,\n', '     ) -> None:\n', '         self._origin = origin\n', '         self._args = args if isinstance(args, tuple) else (args,)\n', '         self._parameters = tuple(_parse_parameters(self.__args__))\n', '+        self._starred = starred\n', ' \n', '     @property\n', '     def __call__(self) -> type[Any]:\n']","['         """"""Type variables in the ``GenericAlias``.""""""\n', '         return super().__getattribute__(""_parameters"")\n', ' \n', '     def __init__(\n', '         self,\n', '         origin: type,\n', '         args: object | tuple[object, ...],\n', '     ) -> None:\n', '         self._origin = origin\n', '         self._args = args if isinstance(args, tuple) else (args,)\n', '         self._parameters = tuple(_parse_parameters(self.__args__))\n', ' \n', '     @property\n', '     def __call__(self) -> type[Any]:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def __reduce__(self: _T) -> tuple[\n', '         type[_T],\n', '+        tuple[type[Any], tuple[object, ...], bool],\n', '     ]:\n', '         cls = type(self)\n', '+        return cls, (self.__origin__, self.__args__, self.__unpacked__)\n', ' \n', '     def __mro_entries__(self, bases: Iterable[object]) -> tuple[type[Any]]:\n', '         return (self.__origin__,)\n']","[' \n', '     def __reduce__(self: _T) -> tuple[\n', '         type[_T],\n', '-        tuple[type[Any], tuple[object, ...]],\n', '     ]:\n', '         cls = type(self)\n', '-        return cls, (self.__origin__, self.__args__)\n', ' \n', '     def __mro_entries__(self, bases: Iterable[object]) -> tuple[type[Any]]:\n', '         return (self.__origin__,)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         try:\n', '             return super().__getattribute__(""_hash"")\n', '         except AttributeError:\n', '+            self._hash: int = (\n', '+                hash(self.__origin__) ^\n', '+                hash(self.__args__) ^\n', '+                hash(self.__unpacked__)\n', '+            )\n', '             return super().__getattribute__(""_hash"")\n', ' \n', '     def __instancecheck__(self, obj: object) -> NoReturn:\n']","['         try:\n', '             return super().__getattribute__(""_hash"")\n', '         except AttributeError:\n', '-            self._hash: int = hash(self.__origin__) ^ hash(self.__args__)\n', '             return super().__getattribute__(""_hash"")\n', ' \n', '     def __instancecheck__(self, obj: object) -> NoReturn:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         """"""Return ``repr(self)``.""""""\n', '         args = "", "".join(_to_str(i) for i in self.__args__)\n', '         origin = _to_str(self.__origin__)\n', '+        prefix = ""*"" if self.__unpacked__ else """"\n', '+        return f""{prefix}{origin}[{args}]""\n', ' \n', '     def __getitem__(self: _T, key: object | tuple[object, ...]) -> _T:\n', '         """"""Return ``self[key]``.""""""\n']","['         """"""Return ``repr(self)``.""""""\n', '         args = "", "".join(_to_str(i) for i in self.__args__)\n', '         origin = _to_str(self.__origin__)\n', '-        return f""{origin}[{args}]""\n', ' \n', '     def __getitem__(self: _T, key: object | tuple[object, ...]) -> _T:\n', '         """"""Return ``self[key]``.""""""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             return NotImplemented\n', '         return (\n', '             self.__origin__ == value.__origin__ and\n', '+            self.__args__ == value.__args__ and\n', '+            self.__unpacked__ == getattr(\n', '+                value, ""__unpacked__"", self.__unpacked__\n', '+            )\n', '         )\n', ' \n', '+    def __iter__(self: _T) -> Generator[_T, None, None]:\n', '+        """"""Return ``iter(self)``.""""""\n', '+        cls = type(self)\n', '+        yield cls(self.__origin__, self.__args__, True)\n', '+\n', '     _ATTR_EXCEPTIONS: ClassVar[frozenset[str]] = frozenset({\n', '         ""__origin__"",\n', '         ""__args__"",\n']","['             return NotImplemented\n', '         return (\n', '             self.__origin__ == value.__origin__ and\n', '-            self.__args__ == value.__args__\n', '         )\n', ' \n', '     _ATTR_EXCEPTIONS: ClassVar[frozenset[str]] = frozenset({\n', '         ""__origin__"",\n', '         ""__args__"",\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         ""__reduce_ex__"",\n', '         ""__copy__"",\n', '         ""__deepcopy__"",\n', '+        ""__unpacked__"",\n', '+        ""__typing_unpacked_tuple_args__"",\n', '+        ""__class__"",\n', '     })\n', ' \n', '     def __getattribute__(self, name: str) -> Any:\n']","['         ""__reduce_ex__"",\n', '         ""__copy__"",\n', '         ""__deepcopy__"",\n', '     })\n', ' \n', '     def __getattribute__(self, name: str) -> Any:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     overload,\n', '     TypeVar,\n', '     Protocol,\n', '+    runtime_checkable,\n', ' )\n', ' \n', ' __all__ = [""_NestedSequence""]\n']","['     overload,\n', '     TypeVar,\n', '     Protocol,\n', ' )\n', ' \n', ' __all__ = [""_NestedSequence""]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' _T_co = TypeVar(""_T_co"", covariant=True)\n', ' \n', ' \n', '+@runtime_checkable\n', ' class _NestedSequence(Protocol[_T_co]):\n', '     """"""A protocol for representing nested sequences.\n', ' \n']","[' _T_co = TypeVar(""_T_co"", covariant=True)\n', ' \n', ' \n', ' class _NestedSequence(Protocol[_T_co]):\n', '     """"""A protocol for representing nested sequences.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         >>> from typing import TYPE_CHECKING\n', '         >>> import numpy as np\n', '+        >>> from numpy._typing import _NestedSequence\n', ' \n', '+        >>> def get_dtype(seq: _NestedSequence[float]) -> np.dtype[np.float64]:\n', '         ...     return np.asarray(seq).dtype\n', ' \n', '         >>> a = get_dtype([1.0])\n']","[' \n', '         >>> from typing import TYPE_CHECKING\n', '         >>> import numpy as np\n', '-        >>> from numpy._typing import _NestedSequnce\n', ' \n', '-        >>> def get_dtype(seq: _NestedSequnce[float]) -> np.dtype[np.float64]:\n', '         ...     return np.asarray(seq).dtype\n', ' \n', '         >>> a = get_dtype([1.0])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+\n', ' # This file helps to compute a version number in source trees obtained from\n', ' # git-archive tarball (such as those provided by githubs download-from-tag\n', ' # feature). Distribution tarballs (built by setup.py sdist) and build\n', ' # directories (produced by setup.py build) will contain a much shorter file\n', ' # that just contains the computed version number.\n', ' \n', '+# This file is released into the public domain.\n', '+# Generated by versioneer-0.26\n', '+# https://github.com/python-versioneer/python-versioneer\n', ' \n', ' """"""Git implementation of _version.py.""""""\n', ' \n']","[' # This file helps to compute a version number in source trees obtained from\n', ' # git-archive tarball (such as those provided by githubs download-from-tag\n', ' # feature). Distribution tarballs (built by setup.py sdist) and build\n', ' # directories (produced by setup.py build) will contain a much shorter file\n', ' # that just contains the computed version number.\n', ' \n', '-# This file is released into the public domain. Generated by\n', '-# versioneer-0.19 (https://github.com/python-versioneer/python-versioneer)\n', ' \n', ' """"""Git implementation of _version.py.""""""\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import re\n', ' import subprocess\n', ' import sys\n', '+from typing import Callable, Dict\n', '+import functools\n', ' \n', ' \n', ' def get_keywords():\n']","[' import re\n', ' import subprocess\n', ' import sys\n', ' \n', ' \n', ' def get_keywords():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""Exception raised if a method is not valid for the current scenario.""""""\n', ' \n', ' \n', '+LONG_VERSION_PY: Dict[str, str] = {}\n', '+HANDLERS: Dict[str, Dict[str, Callable]] = {}\n', ' \n', ' \n', ' def register_vcs_handler(vcs, method):  # decorator\n']","['     """"""Exception raised if a method is not valid for the current scenario.""""""\n', ' \n', ' \n', '-LONG_VERSION_PY = {}\n', '-HANDLERS = {}\n', ' \n', ' \n', ' def register_vcs_handler(vcs, method):  # decorator\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 env=None):\n', '     """"""Call the given command(s).""""""\n', '     assert isinstance(commands, list)\n', '+    process = None\n', '+\n', '+    popen_kwargs = {}\n', '+    if sys.platform == ""win32"":\n', '+        # This hides the console window if pythonw.exe is used\n', '+        startupinfo = subprocess.STARTUPINFO()\n', '+        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n', '+        popen_kwargs[""startupinfo""] = startupinfo\n', '+\n', '+    for command in commands:\n', '         try:\n', '+            dispcmd = str([command] + args)\n', '             # remember shell=False, so use git.cmd on windows, not just git\n', '+            process = subprocess.Popen([command] + args, cwd=cwd, env=env,\n', '+                                       stdout=subprocess.PIPE,\n', '+                                       stderr=(subprocess.PIPE if hide_stderr\n', '+                                               else None), **popen_kwargs)\n', '             break\n', '+        except OSError:\n', '             e = sys.exc_info()[1]\n', '             if e.errno == errno.ENOENT:\n', '                 continue\n']","['                 env=None):\n', '     """"""Call the given command(s).""""""\n', '     assert isinstance(commands, list)\n', '-    p = None\n', '-    for c in commands:\n', '         try:\n', '-            dispcmd = str([c] + args)\n', '             # remember shell=False, so use git.cmd on windows, not just git\n', '-            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n', '-                                 stdout=subprocess.PIPE,\n', '-                                 stderr=(subprocess.PIPE if hide_stderr\n', '-                                         else None))\n', '             break\n', '-        except EnvironmentError:\n', '             e = sys.exc_info()[1]\n', '             if e.errno == errno.ENOENT:\n', '                 continue\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if verbose:\n', '             print(""unable to find command, tried %s"" % (commands,))\n', '         return None, None\n', '+    stdout = process.communicate()[0].strip().decode()\n', '+    if process.returncode != 0:\n', '         if verbose:\n', '             print(""unable to run %s (error)"" % dispcmd)\n', '             print(""stdout was %s"" % stdout)\n', '+        return None, process.returncode\n', '+    return stdout, process.returncode\n', ' \n', ' \n', ' def versions_from_parentdir(parentdir_prefix, root, verbose):\n']","['         if verbose:\n', '             print(""unable to find command, tried %s"" % (commands,))\n', '         return None, None\n', '-    stdout = p.communicate()[0].strip().decode()\n', '-    if p.returncode != 0:\n', '         if verbose:\n', '             print(""unable to run %s (error)"" % dispcmd)\n', '             print(""stdout was %s"" % stdout)\n', '-        return None, p.returncode\n', '-    return stdout, p.returncode\n', ' \n', ' \n', ' def versions_from_parentdir(parentdir_prefix, root, verbose):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     rootdirs = []\n', ' \n', '+    for _ in range(3):\n', '         dirname = os.path.basename(root)\n', '         if dirname.startswith(parentdir_prefix):\n', '             return {""version"": dirname[len(parentdir_prefix):],\n', '                     ""full-revisionid"": None,\n', '                     ""dirty"": False, ""error"": None, ""date"": None}\n', '+        rootdirs.append(root)\n', '+        root = os.path.dirname(root)  # up a level\n', ' \n', '     if verbose:\n', '         print(""Tried directories %s but none started with prefix %s"" %\n']","['     """"""\n', '     rootdirs = []\n', ' \n', '-    for i in range(3):\n', '         dirname = os.path.basename(root)\n', '         if dirname.startswith(parentdir_prefix):\n', '             return {""version"": dirname[len(parentdir_prefix):],\n', '                     ""full-revisionid"": None,\n', '                     ""dirty"": False, ""error"": None, ""date"": None}\n', '-        else:\n', '-            rootdirs.append(root)\n', '-            root = os.path.dirname(root)  # up a level\n', ' \n', '     if verbose:\n', '         print(""Tried directories %s but none started with prefix %s"" %\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # _version.py.\n', '     keywords = {}\n', '     try:\n', '+        with open(versionfile_abs, ""r"") as fobj:\n', '+            for line in fobj:\n', '                 if line.strip().startswith(""git_refnames =""):\n', '                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n']","['     # _version.py.\n', '     keywords = {}\n', '     try:\n', '-        with open(versionfile_abs, ""r"") as f:\n', '-            for line in f.readlines():\n', '                 if line.strip().startswith(""git_refnames =""):\n', '                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n', '                         keywords[""date""] = mo.group(1)\n', '+    except OSError:\n', '         pass\n', '     return keywords\n', ' \n']","['                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n', '                         keywords[""date""] = mo.group(1)\n', '-    except EnvironmentError:\n', '         pass\n', '     return keywords\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @register_vcs_handler(""git"", ""keywords"")\n', ' def git_versions_from_keywords(keywords, tag_prefix, verbose):\n', '     """"""Get version information from git keywords.""""""\n', '+    if ""refnames"" not in keywords:\n', '+        raise NotThisMethod(""Short version file found"")\n', '     date = keywords.get(""date"")\n', '     if date is not None:\n', '         # Use only the last line.  Previous lines may contain GPG signature\n']","[' @register_vcs_handler(""git"", ""keywords"")\n', ' def git_versions_from_keywords(keywords, tag_prefix, verbose):\n', '     """"""Get version information from git keywords.""""""\n', '-    if not keywords:\n', '-        raise NotThisMethod(""no keywords at all, weird"")\n', '     date = keywords.get(""date"")\n', '     if date is not None:\n', '         # Use only the last line.  Previous lines may contain GPG signature\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if verbose:\n', '             print(""keywords are unexpanded, not using"")\n', '         raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n', '+    refs = {r.strip() for r in refnames.strip(""()"").split("","")}\n', '     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n', '     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n', '     TAG = ""tag: ""\n', '+    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n', '     if not tags:\n', ""         # Either we're using git < 1.8.3, or there really are no tags. We use\n"", '         # a heuristic: assume all version tags have a digit. The old git %d\n']","['         if verbose:\n', '             print(""keywords are unexpanded, not using"")\n', '         raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n', '-    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n', '     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n', '     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n', '     TAG = ""tag: ""\n', '-    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n', '     if not tags:\n', ""         # Either we're using git < 1.8.3, or there really are no tags. We use\n"", '         # a heuristic: assume all version tags have a digit. The old git %d\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n', '         # between branches and tags. By ignoring refnames without digits, we\n', '         # filter out many common branch names like ""release"" and\n', '+        # ""stabilization"", as well as ""HEAD"" and ""master"".\n', ""+        tags = {r for r in refs if re.search(r'\\d', r)}\n"", '         if verbose:\n', '             print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n', '     if verbose:\n']","['         # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n', '         # between branches and tags. By ignoring refnames without digits, we\n', '         # filter out many common branch names like ""release"" and\n', '-        # ""stabilization"", as well as ""HEAD"" and ""main"".\n', ""-        tags = set([r for r in refs if re.search(r'\\d', r)])\n"", '         if verbose:\n', '             print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n', '     if verbose:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n', '         if ref.startswith(tag_prefix):\n', '             r = ref[len(tag_prefix):]\n', ""+            # Filter out refs that exactly match prefix or that don't start\n"", '+            # with a number once the prefix is stripped (mostly a concern\n', ""+            # when prefix is '')\n"", ""+            if not re.match(r'\\d', r):\n"", '+                continue\n', '             if verbose:\n', '                 print(""picking %s"" % r)\n', '             return {""version"": r,\n']","['         # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n', '         if ref.startswith(tag_prefix):\n', '             r = ref[len(tag_prefix):]\n', '             if verbose:\n', '                 print(""picking %s"" % r)\n', '             return {""version"": r,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @register_vcs_handler(""git"", ""pieces_from_vcs"")\n', '+def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):\n', '     """"""Get version from \'git describe\' in the root of the source tree.\n', ' \n', ""     This only gets called if the git-archive 'subst' keywords were *not*\n""]","[' \n', ' \n', ' @register_vcs_handler(""git"", ""pieces_from_vcs"")\n', '-def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n', '     """"""Get version from \'git describe\' in the root of the source tree.\n', ' \n', ""     This only gets called if the git-archive 'subst' keywords were *not*\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', ' \n', '+    # GIT_DIR can interfere with correct operation of Versioneer.\n', '+    # It may be intended to be passed to the Versioneer-versioned project,\n', '+    # but that should not change where we get our version from.\n', '+    env = os.environ.copy()\n', '+    env.pop(""GIT_DIR"", None)\n', '+    runner = functools.partial(runner, env=env)\n', '+\n', '+    _, rc = runner(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n', '+                   hide_stderr=not verbose)\n', '     if rc != 0:\n', '         if verbose:\n', '             print(""Directory %s not under git control"" % root)\n']","['     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', ' \n', '-    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n', '-                          hide_stderr=True)\n', '     if rc != 0:\n', '         if verbose:\n', '             print(""Directory %s not under git control"" % root)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n', ""     # if there isn't one, this yields HEX[-dirty] (no NUM)\n"", '+    describe_out, rc = runner(GITS, [\n', '+        ""describe"", ""--tags"", ""--dirty="", ""--always"", ""--long"",\n', '+        ""--match"", f""{tag_prefix}[[:digit:]]*""\n', '+    ], cwd=root)\n', '     # --long was added in git-1.5.5\n', '     if describe_out is None:\n', '         raise NotThisMethod(""\'git describe\' failed"")\n', '     describe_out = describe_out.strip()\n', '+    full_out, rc = runner(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n', '     if full_out is None:\n', '         raise NotThisMethod(""\'git rev-parse\' failed"")\n', '     full_out = full_out.strip()\n']","[' \n', '     # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n', ""     # if there isn't one, this yields HEX[-dirty] (no NUM)\n"", '-    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty="",\n', '-                                          ""--always"", ""--long"",\n', '-                                          ""--match"", ""%s*"" % tag_prefix],\n', '-                                   cwd=root)\n', '     # --long was added in git-1.5.5\n', '     if describe_out is None:\n', '         raise NotThisMethod(""\'git describe\' failed"")\n', '     describe_out = describe_out.strip()\n', '-    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n', '     if full_out is None:\n', '         raise NotThisMethod(""\'git rev-parse\' failed"")\n', '     full_out = full_out.strip()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     pieces[""short""] = full_out[:7]  # maybe improved later\n', '     pieces[""error""] = None\n', ' \n', '+    branch_name, rc = runner(GITS, [""rev-parse"", ""--abbrev-ref"", ""HEAD""],\n', '+                             cwd=root)\n', '+    # --abbrev-ref was added in git-1.6.3\n', '+    if rc != 0 or branch_name is None:\n', '+        raise NotThisMethod(""\'git rev-parse --abbrev-ref\' returned error"")\n', '+    branch_name = branch_name.strip()\n', '+\n', '+    if branch_name == ""HEAD"":\n', ""+        # If we aren't exactly on a branch, pick a branch which represents\n"", '+        # the current commit. If all else fails, we are on a branchless\n', '+        # commit.\n', '+        branches, rc = runner(GITS, [""branch"", ""--contains""], cwd=root)\n', '+        # --contains was added in git-1.5.4\n', '+        if rc != 0 or branches is None:\n', '+            raise NotThisMethod(""\'git branch --contains\' returned error"")\n', '+        branches = branches.split(""\\n"")\n', '+\n', ""+        # Remove the first line if we're running detached\n"", '+        if ""("" in branches[0]:\n', '+            branches.pop(0)\n', '+\n', '+        # Strip off the leading ""* "" from the list of branches.\n', '+        branches = [branch[2:] for branch in branches]\n', '+        if ""master"" in branches:\n', '+            branch_name = ""master""\n', '+        elif not branches:\n', '+            branch_name = None\n', '+        else:\n', '+            # Pick the first branch that is returned. Good or bad.\n', '+            branch_name = branches[0]\n', '+\n', '+    pieces[""branch""] = branch_name\n', '+\n', '     # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n', '     # TAG might have hyphens.\n', '     git_describe = describe_out\n']","['     pieces[""short""] = full_out[:7]  # maybe improved later\n', '     pieces[""error""] = None\n', ' \n', '     # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n', '     # TAG might have hyphens.\n', '     git_describe = describe_out\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # TAG-NUM-gHEX\n', ""         mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n"", '         if not mo:\n', '+            # unparsable. Maybe git-describe is misbehaving?\n', '             pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n', '                                % describe_out)\n', '             return pieces\n']","['         # TAG-NUM-gHEX\n', ""         mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n"", '         if not mo:\n', '-            # unparseable. Maybe git-describe is misbehaving?\n', '             pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n', '                                % describe_out)\n', '             return pieces\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', '         # HEX: no tags\n', '         pieces[""closest-tag""] = None\n', '+        out, rc = runner(GITS, [""rev-list"", ""HEAD"", ""--left-right""], cwd=root)\n', '+        pieces[""distance""] = len(out.split())  # total number of commits\n', ' \n', '     # commit date: see ISO-8601 comment in git_versions_from_keywords()\n', '+    date = runner(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[0].strip()\n', '     # Use only the last line.  Previous lines may contain GPG signature\n', '     # information.\n', '     date = date.splitlines()[-1]\n']","['     else:\n', '         # HEX: no tags\n', '         pieces[""closest-tag""] = None\n', '-        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n', '-                                    cwd=root)\n', '-        pieces[""distance""] = int(count_out)  # total number of commits\n', ' \n', '     # commit date: see ISO-8601 comment in git_versions_from_keywords()\n', '-    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n', '-                       cwd=root)[0].strip()\n', '     # Use only the last line.  Previous lines may contain GPG signature\n', '     # information.\n', '     date = date.splitlines()[-1]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return rendered\n', ' \n', ' \n', '+def render_pep440_branch(pieces):\n', '+    """"""TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n', '+\n', '+    The "".dev0"" means not master branch. Note that .dev0 sorts backwards\n', '+    (a feature branch will appear ""older"" than the master branch).\n', '+\n', '+    Exceptions:\n', '+    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n', '+    """"""\n', '+    if pieces[""closest-tag""]:\n', '+        rendered = pieces[""closest-tag""]\n', '+        if pieces[""distance""] or pieces[""dirty""]:\n', '+            if pieces[""branch""] != ""master"":\n', '+                rendered += "".dev0""\n', '+            rendered += plus_or_dot(pieces)\n', '+            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n', '+            if pieces[""dirty""]:\n', '+                rendered += "".dirty""\n', '+    else:\n', '+        # exception #1\n', '+        rendered = ""0""\n', '+        if pieces[""branch""] != ""master"":\n', '+            rendered += "".dev0""\n', '+        rendered += ""+untagged.%d.g%s"" % (pieces[""distance""],\n', '+                                          pieces[""short""])\n', '+        if pieces[""dirty""]:\n', '+            rendered += "".dirty""\n', '+    return rendered\n', '+\n', '+\n', '+def pep440_split_post(ver):\n', '+    """"""Split pep440 version string at the post-release segment.\n', '+\n', '+    Returns the release segments before the post-release and the\n', '+    post-release version number (or -1 if no post-release segment is present).\n', '+    """"""\n', '+    vc = str.split(ver, "".post"")\n', '+    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n', '+\n', '+\n', ' def render_pep440_pre(pieces):\n', '+    """"""TAG[.postN.devDISTANCE] -- No -dirty.\n', ' \n', '     Exceptions:\n', '     1: no tags. 0.post0.devDISTANCE\n', '     """"""\n', '     if pieces[""closest-tag""]:\n', '         if pieces[""distance""]:\n', '+            # update the post release segment\n', '+            tag_version, post_version = pep440_split_post(pieces[""closest-tag""])\n', '+            rendered = tag_version\n', '+            if post_version is not None:\n', '+                rendered += "".post%d.dev%d"" % (post_version + 1, pieces[""distance""])\n', '+            else:\n', '+                rendered += "".post0.dev%d"" % (pieces[""distance""])\n', '+        else:\n', '+            # no commits, use the tag as the version\n', '+            rendered = pieces[""closest-tag""]\n', '     else:\n', '         # exception #1\n', '         rendered = ""0.post0.dev%d"" % pieces[""distance""]\n']","['     return rendered\n', ' \n', ' \n', ' def render_pep440_pre(pieces):\n', '-    """"""TAG[.post0.devDISTANCE] -- No -dirty.\n', ' \n', '     Exceptions:\n', '     1: no tags. 0.post0.devDISTANCE\n', '     """"""\n', '     if pieces[""closest-tag""]:\n', '-        rendered = pieces[""closest-tag""]\n', '         if pieces[""distance""]:\n', '-            rendered += "".post0.dev%d"" % pieces[""distance""]\n', '     else:\n', '         # exception #1\n', '         rendered = ""0.post0.dev%d"" % pieces[""distance""]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return rendered\n', ' \n', ' \n', '+def render_pep440_post_branch(pieces):\n', '+    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n', '+\n', '+    The "".dev0"" means not master branch.\n', '+\n', '+    Exceptions:\n', '+    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n', '+    """"""\n', '+    if pieces[""closest-tag""]:\n', '+        rendered = pieces[""closest-tag""]\n', '+        if pieces[""distance""] or pieces[""dirty""]:\n', '+            rendered += "".post%d"" % pieces[""distance""]\n', '+            if pieces[""branch""] != ""master"":\n', '+                rendered += "".dev0""\n', '+            rendered += plus_or_dot(pieces)\n', '+            rendered += ""g%s"" % pieces[""short""]\n', '+            if pieces[""dirty""]:\n', '+                rendered += "".dirty""\n', '+    else:\n', '+        # exception #1\n', '+        rendered = ""0.post%d"" % pieces[""distance""]\n', '+        if pieces[""branch""] != ""master"":\n', '+            rendered += "".dev0""\n', '+        rendered += ""+g%s"" % pieces[""short""]\n', '+        if pieces[""dirty""]:\n', '+            rendered += "".dirty""\n', '+    return rendered\n', '+\n', '+\n', ' def render_pep440_old(pieces):\n', '     """"""TAG[.postDISTANCE[.dev0]] .\n', ' \n']","['     return rendered\n', ' \n', ' \n', ' def render_pep440_old(pieces):\n', '     """"""TAG[.postDISTANCE[.dev0]] .\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     if style == ""pep440"":\n', '         rendered = render_pep440(pieces)\n', '+    elif style == ""pep440-branch"":\n', '+        rendered = render_pep440_branch(pieces)\n', '     elif style == ""pep440-pre"":\n', '         rendered = render_pep440_pre(pieces)\n', '     elif style == ""pep440-post"":\n', '         rendered = render_pep440_post(pieces)\n', '+    elif style == ""pep440-post-branch"":\n', '+        rendered = render_pep440_post_branch(pieces)\n', '     elif style == ""pep440-old"":\n', '         rendered = render_pep440_old(pieces)\n', '     elif style == ""git-describe"":\n']","[' \n', '     if style == ""pep440"":\n', '         rendered = render_pep440(pieces)\n', '     elif style == ""pep440-pre"":\n', '         rendered = render_pep440_pre(pieces)\n', '     elif style == ""pep440-post"":\n', '         rendered = render_pep440_post(pieces)\n', '     elif style == ""pep440-old"":\n', '         rendered = render_pep440_old(pieces)\n', '     elif style == ""git-describe"":\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # versionfile_source is the relative path from the top of the source\n', '         # tree (where the .git directory might live) to this file. Invert\n', '         # this to find the root from __file__.\n', ""+        for _ in cfg.versionfile_source.split('/'):\n"", '             root = os.path.dirname(root)\n', '     except NameError:\n', '         return {""version"": ""0+unknown"", ""full-revisionid"": None,\n']","['         # versionfile_source is the relative path from the top of the source\n', '         # tree (where the .git directory might live) to this file. Invert\n', '         # this to find the root from __file__.\n', ""-        for i in cfg.versionfile_source.split('/'):\n"", '             root = os.path.dirname(root)\n', '     except NameError:\n', '         return {""version"": ""0+unknown"", ""full-revisionid"": None,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return_counts=True,\n', '         return_index=True,\n', '         return_inverse=True,\n', '+        equal_nan=False,\n', '     )\n', ""     # np.unique() flattens inverse indices, but they need to share x's shape\n"", '     # See https://github.com/numpy/numpy/issues/20638\n']","['         return_counts=True,\n', '         return_index=True,\n', '         return_inverse=True,\n', '     )\n', ""     # np.unique() flattens inverse indices, but they need to share x's shape\n"", '     # See https://github.com/numpy/numpy/issues/20638\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return_counts=True,\n', '         return_index=False,\n', '         return_inverse=False,\n', '+        equal_nan=False,\n', '     )\n', ' \n', '     return UniqueCountsResult(*[Array._new(i) for i in res])\n']","['         return_counts=True,\n', '         return_index=False,\n', '         return_inverse=False,\n', '     )\n', ' \n', '     return UniqueCountsResult(*[Array._new(i) for i in res])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return_counts=False,\n', '         return_index=False,\n', '         return_inverse=True,\n', '+        equal_nan=False,\n', '     )\n', ""     # np.unique() flattens inverse indices, but they need to share x's shape\n"", '     # See https://github.com/numpy/numpy/issues/20638\n']","['         return_counts=False,\n', '         return_index=False,\n', '         return_inverse=True,\n', '     )\n', ""     # np.unique() flattens inverse indices, but they need to share x's shape\n"", '     # See https://github.com/numpy/numpy/issues/20638\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return_counts=False,\n', '         return_index=False,\n', '         return_inverse=False,\n', '+        equal_nan=False,\n', '     )\n', '     return Array._new(res)\n']","['         return_counts=False,\n', '         return_index=False,\n', '         return_inverse=False,\n', '     )\n', '     return Array._new(res)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from __future__ import annotations\n', ' \n', ' from ._dtypes import _floating_dtypes, _numeric_dtypes\n', '+from ._manipulation_functions import reshape\n', ' from ._array_object import Array\n', ' \n', '+from ..core.numeric import normalize_axis_tuple\n', '+\n', ' from typing import TYPE_CHECKING\n', ' if TYPE_CHECKING:\n', '     from ._typing import Literal, Optional, Sequence, Tuple, Union\n']","[' from __future__ import annotations\n', ' \n', ' from ._dtypes import _floating_dtypes, _numeric_dtypes\n', ' from ._array_object import Array\n', ' \n', ' from typing import TYPE_CHECKING\n', ' if TYPE_CHECKING:\n', '     from ._typing import Literal, Optional, Sequence, Tuple, Union\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' def vecdot(x1: Array, x2: Array, /, *, axis: int = -1) -> Array:\n', '     if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:\n', ""         raise TypeError('Only numeric dtypes are allowed in vecdot')\n"", '+    ndim = max(x1.ndim, x2.ndim)\n', '+    x1_shape = (1,)*(ndim - x1.ndim) + tuple(x1.shape)\n', '+    x2_shape = (1,)*(ndim - x2.ndim) + tuple(x2.shape)\n', '+    if x1_shape[axis] != x2_shape[axis]:\n', '+        raise ValueError(""x1 and x2 must have the same size along the given axis"")\n', '+\n', '+    x1_, x2_ = np.broadcast_arrays(x1._array, x2._array)\n', '+    x1_ = np.moveaxis(x1_, axis, -1)\n', '+    x2_ = np.moveaxis(x2_, axis, -1)\n', '+\n', '+    res = x1_[..., None, :] @ x2_[..., None]\n', '+    return Array._new(res[..., 0, 0])\n', ' \n', ' \n', ' # Note: the name here is different from norm(). The array API norm is split\n']","[' def vecdot(x1: Array, x2: Array, /, *, axis: int = -1) -> Array:\n', '     if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:\n', ""         raise TypeError('Only numeric dtypes are allowed in vecdot')\n"", '-    return tensordot(x1, x2, axes=((axis,), (axis,)))\n', ' \n', ' \n', ' # Note: the name here is different from norm(). The array API norm is split\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if x.dtype not in _floating_dtypes:\n', ""         raise TypeError('Only floating-point dtypes are allowed in norm')\n"", ' \n', '+    # np.linalg.norm tries to do a matrix norm whenever axis is a 2-tuple or\n', '+    # when axis=None and the input is 2-D, so to force a vector norm, we make\n', '+    # it so the input is 1-D (for axis=None), or reshape so that norm is done\n', '+    # on a single dimension.\n', '     a = x._array\n', '     if axis is None:\n', ""+        # Note: np.linalg.norm() doesn't handle 0-D arrays\n"", '+        a = a.ravel()\n', '+        _axis = 0\n', '     elif isinstance(axis, tuple):\n', '+        # Note: The axis argument supports any number of axes, whereas\n', '+        # np.linalg.norm() only supports a single axis for vector norm.\n', '+        normalized_axis = normalize_axis_tuple(axis, x.ndim)\n', '+        rest = tuple(i for i in range(a.ndim) if i not in normalized_axis)\n', '         newshape = axis + rest\n', '+        a = np.transpose(a, newshape).reshape(\n', '+            (np.prod([a.shape[i] for i in axis], dtype=int), *[a.shape[i] for i in rest]))\n', '+        _axis = 0\n', '+    else:\n', '+        _axis = axis\n', '+\n', '+    res = Array._new(np.linalg.norm(a, axis=_axis, ord=ord))\n', '+\n', '+    if keepdims:\n', ""+        # We can't reuse np.linalg.norm(keepdims) because of the reshape hacks\n"", '+        # above to avoid matrix norm logic.\n', '+        shape = list(x.shape)\n', '+        _axis = normalize_axis_tuple(range(x.ndim) if axis is None else axis, x.ndim)\n', '+        for i in _axis:\n', '+            shape[i] = 1\n', '+        res = reshape(res, tuple(shape))\n', ' \n', '+    return res\n', ' \n', "" __all__ = ['cholesky', 'cross', 'det', 'diagonal', 'eigh', 'eigvalsh', 'inv', 'matmul', 'matrix_norm', 'matrix_power', 'matrix_rank', 'matrix_transpose', 'outer', 'pinv', 'qr', 'slogdet', 'solve', 'svd', 'svdvals', 'tensordot', 'trace', 'vecdot', 'vector_norm']\n""]","['     if x.dtype not in _floating_dtypes:\n', ""         raise TypeError('Only floating-point dtypes are allowed in norm')\n"", ' \n', '     a = x._array\n', '     if axis is None:\n', '-        a = a.flatten()\n', '-        axis = 0\n', '     elif isinstance(axis, tuple):\n', '-        # Note: The axis argument supports any number of axes, whereas norm()\n', '-        # only supports a single axis for vector norm.\n', '-        rest = tuple(i for i in range(a.ndim) if i not in axis)\n', '         newshape = axis + rest\n', '-        a = np.transpose(a, newshape).reshape((np.prod([a.shape[i] for i in axis]), *[a.shape[i] for i in rest]))\n', '-        axis = 0\n', '-    return Array._new(np.linalg.norm(a, axis=axis, keepdims=keepdims, ord=ord))\n', ' \n', ' \n', "" __all__ = ['cholesky', 'cross', 'det', 'diagonal', 'eigh', 'eigvalsh', 'inv', 'matmul', 'matrix_norm', 'matrix_power', 'matrix_rank', 'matrix_transpose', 'outer', 'pinv', 'qr', 'slogdet', 'solve', 'svd', 'svdvals', 'tensordot', 'trace', 'vecdot', 'vector_norm']\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     in __getitem__(). This is achieved by passing array_api arrays with 0-sized\n', '     dimensions, which NumPy-proper treats erroneously - not sure why!\n', ' \n', '+    TODO: Find and use appropriate __setitem__() case.\n', '     """"""\n', '     a = ones((0, 0), dtype=bool_)\n', '     assert a[a].shape == (0,)\n']","['     in __getitem__(). This is achieved by passing array_api arrays with 0-sized\n', '     dimensions, which NumPy-proper treats erroneously - not sure why!\n', ' \n', '-    TODO: Find and use appropiate __setitem__() case.\n', '     """"""\n', '     a = ones((0, 0), dtype=bool_)\n', '     assert a[a].shape == (0,)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @pytest.fixture(autouse=True)\n', ' def env_setup(monkeypatch):\n', ""     monkeypatch.setenv('PYTHONHASHSEED', '0')\n"", '+\n', '+\n', '+@pytest.fixture(params=[True, False])\n', '+def weak_promotion(request):\n', '+    """"""\n', '+    Fixture to ensure ""legacy"" promotion state or change it to use the new\n', '+    weak promotion (plus warning).  `old_promotion` should be used as a\n', '+    parameter in the function.\n', '+    """"""\n', '+    state = numpy._get_promotion_state()\n', '+    if request.param:\n', '+        numpy._set_promotion_state(""weak_and_warn"")\n', '+    else:\n', '+        numpy._set_promotion_state(""legacy"")\n', '+\n', '+    yield request.param\n', '+    numpy._set_promotion_state(state)\n']","[' @pytest.fixture(autouse=True)\n', ' def env_setup(monkeypatch):\n', ""     monkeypatch.setenv('PYTHONHASHSEED', '0')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Examples\n', '     --------\n', '+    Starting with a Fortran-contiguous array:\n', '+\n', ""+    >>> x = np.ones((2, 3), order='F')\n"", ""+    >>> x.flags['F_CONTIGUOUS']\n"", '+    True\n', '+\n', '+    Calling ``ascontiguousarray`` makes a C-contiguous copy:\n', '+\n', '+    >>> y = np.ascontiguousarray(x)\n', ""+    >>> y.flags['C_CONTIGUOUS']\n"", '+    True\n', '+    >>> np.may_share_memory(x, y)\n', '+    False\n', '+\n', '+    Now, starting with a C-contiguous array:\n', '+\n', ""+    >>> x = np.ones((2, 3), order='C')\n"", ""     >>> x.flags['C_CONTIGUOUS']\n"", '     True\n', ' \n', '+    Then, calling ``ascontiguousarray`` returns the same object:\n', '+\n', '+    >>> y = np.ascontiguousarray(x)\n', '+    >>> x is y\n', '+    True\n', '+\n', '     Note: This function returns an array with at least one-dimension (1-d)\n', '     so it will not preserve 0-d arrays.\n', ' \n']","[' \n', '     Examples\n', '     --------\n', '-    >>> x = np.arange(6).reshape(2,3)\n', '-    >>> np.ascontiguousarray(x, dtype=np.float32)\n', '-    array([[0., 1., 2.],\n', '-           [3., 4., 5.]], dtype=float32)\n', ""     >>> x.flags['C_CONTIGUOUS']\n"", '     True\n', ' \n', '     Note: This function returns an array with at least one-dimension (1-d)\n', '     so it will not preserve 0-d arrays.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Examples\n', '     --------\n', '+    Starting with a C-contiguous array:\n', '+\n', ""+    >>> x = np.ones((2, 3), order='C')\n"", ""+    >>> x.flags['C_CONTIGUOUS']\n"", '+    True\n', '+\n', '+    Calling ``asfortranarray`` makes a Fortran-contiguous copy:\n', '+\n', '     >>> y = np.asfortranarray(x)\n', ""     >>> y.flags['F_CONTIGUOUS']\n"", '     True\n', '+    >>> np.may_share_memory(x, y)\n', '+    False\n', '+\n', '+    Now, starting with a Fortran-contiguous array:\n', '+\n', ""+    >>> x = np.ones((2, 3), order='F')\n"", ""+    >>> x.flags['F_CONTIGUOUS']\n"", '+    True\n', '+\n', '+    Then, calling ``asfortranarray`` returns the same object:\n', '+\n', '+    >>> y = np.asfortranarray(x)\n', '+    >>> x is y\n', '+    True\n', ' \n', '     Note: This function returns an array with at least one-dimension (1-d)\n', '     so it will not preserve 0-d arrays.\n']","[' \n', '     Examples\n', '     --------\n', '-    >>> x = np.arange(6).reshape(2,3)\n', '     >>> y = np.asfortranarray(x)\n', ""-    >>> x.flags['F_CONTIGUOUS']\n"", '-    False\n', ""     >>> y.flags['F_CONTIGUOUS']\n"", '     True\n', ' \n', '     Note: This function returns an array with at least one-dimension (1-d)\n', '     so it will not preserve 0-d arrays.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             decimal numbers, an operation which is better spelt\n', '             ``frombuffer(string, dtype, count)``. If `string` contains unicode\n', '             text, the binary mode of `fromstring` will first encode it into\n', '+            bytes using utf-8, which will not produce sane results.\n', ' \n', '     ${ARRAY_FUNCTION_LIKE}\n', ' \n']","['             decimal numbers, an operation which is better spelt\n', '             ``frombuffer(string, dtype, count)``. If `string` contains unicode\n', '             text, the binary mode of `fromstring` will first encode it into\n', '-            bytes using either utf-8 (python 3) or the default encoding\n', '-            (python 2), neither of which produce sane results.\n', ' \n', '     ${ARRAY_FUNCTION_LIKE}\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -------\n', '     out : ndarray\n', ' \n', '+    See also\n', '+    --------\n', '+    ndarray.tobytes\n', '+        Inverse of this operation, construct Python bytes from the raw data\n', '+        bytes in the array.\n', '+\n', '     Notes\n', '     -----\n', '     If the buffer has data that is not in machine byte-order, this should\n']","['     -------\n', '     out : ndarray\n', ' \n', '     Notes\n', '     -----\n', '     If the buffer has data that is not in machine byte-order, this should\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """""")\n', ' \n', "" add_newdoc('numpy.core', 'fastCopyAndTranspose',\n"", '+    """"""\n', '+    fastCopyAndTranspose(a)\n', '+\n', '+    .. deprecated:: 1.24\n', '+\n', '+       fastCopyAndTranspose is deprecated and will be removed. Use the copy and\n', '+       transpose methods instead, e.g. ``arr.T.copy()``\n', '+    """""")\n', ' \n', "" add_newdoc('numpy.core.multiarray', 'correlate',\n"", '     """"""cross_correlate(a,v, mode=0)"""""")\n']","['     """""")\n', ' \n', "" add_newdoc('numpy.core', 'fastCopyAndTranspose',\n"", '-    """"""_fastCopyAndTranspose(a)"""""")\n', ' \n', "" add_newdoc('numpy.core.multiarray', 'correlate',\n"", '     """"""cross_correlate(a,v, mode=0)"""""")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     In such cases, the use of `numpy.linspace` should be preferred.\n', ' \n', '     The built-in :py:class:`range` generates :std:doc:`Python built-in integers\n', '+    that have arbitrary size <python:c-api/long>`, while `numpy.arange`\n', '+    produces `numpy.int32` or `numpy.int64` numbers. This may result in\n', '+    incorrect results for large integer values::\n', ' \n', '       >>> power = 40\n', '       >>> modulo = 10000\n']","['     In such cases, the use of `numpy.linspace` should be preferred.\n', ' \n', '     The built-in :py:class:`range` generates :std:doc:`Python built-in integers\n', '-    that have arbitrary size <c-api/long>`, while `numpy.arange` produces\n', '-    `numpy.int32` or `numpy.int64` numbers. This may result in incorrect\n', '-    results for large integer values::\n', ' \n', '       >>> power = 40\n', '       >>> modulo = 10000\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n', '     numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n', '     numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n', '+    :ref:`how-to-partition`\n', ' \n', '     Examples\n', '     --------\n']","['     numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n', '     numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n', '     numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" add_newdoc('numpy.core.multiarray', 'ndarray', ('T',\n"", '     """"""\n', '+    View of the transposed array.\n', ' \n', '     Same as ``self.transpose()``.\n', ' \n', '     Examples\n', '     --------\n', '+    >>> a = np.array([[1, 2], [3, 4]])\n', '+    >>> a\n', '+    array([[1, 2],\n', '+           [3, 4]])\n', '+    >>> a.T\n', '+    array([[1, 3],\n', '+           [2, 4]])\n', '+\n', '+    >>> a = np.array([1, 2, 3, 4])\n', '+    >>> a\n', '+    array([1, 2, 3, 4])\n', '+    >>> a.T\n', '+    array([1, 2, 3, 4])\n', ' \n', '     See Also\n', '     --------\n']","[' \n', "" add_newdoc('numpy.core.multiarray', 'ndarray', ('T',\n"", '     """"""\n', '-    The transposed array.\n', ' \n', '     Same as ``self.transpose()``.\n', ' \n', '     Examples\n', '     --------\n', '-    >>> x = np.array([[1.,2.],[3.,4.]])\n', '-    >>> x\n', '-    array([[ 1.,  2.],\n', '-           [ 3.,  4.]])\n', '-    >>> x.T\n', '-    array([[ 1.,  3.],\n', '-           [ 2.,  4.]])\n', '-    >>> x = np.array([1.,2.,3.,4.])\n', '-    >>> x\n', '-    array([ 1.,  2.,  3.,  4.])\n', '-    >>> x.T\n', '-    array([ 1.,  2.,  3.,  4.])\n', ' \n', '     See Also\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> a\n', '     array([1.,  1.])\n', ' \n', '+    Fill expects a scalar value and always behaves the same as assigning\n', '+    to a single array element.  The following is a rare example where this\n', '+    distinction is important:\n', '+\n', '+    >>> a = np.array([None, None], dtype=object)\n', '+    >>> a[0] = np.array(3)\n', '+    >>> a\n', '+    array([array(3), None], dtype=object)\n', '+    >>> a.fill(np.array(3))\n', '+    >>> a\n', '+    array([array(3), array(3)], dtype=object)\n', '+\n', '+    Where other forms of assignments will unpack the array being assigned:\n', '+\n', '+    >>> a[...] = np.array(3)\n', '+    >>> a\n', '+    array([3, 3], dtype=object)\n', '+\n', '     """"""))\n', ' \n', ' \n']","['     >>> a\n', '     array([1.,  1.])\n', ' \n', '     """"""))\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     s : bytes\n', ""         Python bytes exhibiting a copy of `a`'s raw data.\n"", ' \n', '+    See also\n', '+    --------\n', '+    frombuffer\n', '+        Inverse of this operation, construct a 1-dimensional array from Python\n', '+        bytes.\n', '+\n', '     Examples\n', '     --------\n', ""     >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')\n""]","['     s : bytes\n', ""         Python bytes exhibiting a copy of `a`'s raw data.\n"", ' \n', '     Examples\n', '     --------\n', ""     >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Returns a view of the array with axes transposed.\n', ' \n', '+    Refer to `numpy.transpose` for full documentation.\n', ' \n', '     Parameters\n', '     ----------\n']","[' \n', '     Returns a view of the array with axes transposed.\n', ' \n', '-    For a 1-D array this has no effect, as a transposed vector is simply the\n', '-    same vector. To convert a 1-D array into a 2D column vector, an additional\n', '-    dimension must be added. `np.atleast2d(a).T` achieves this, as does\n', '-    `a[:, np.newaxis]`.\n', '-    For a 2-D array, this is a standard matrix transpose.\n', '-    For an n-D array, if axes are given, their order indicates how the\n', '-    axes are permuted (see Examples). If axes are not provided and\n', '-    ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n', '-    ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n', ' \n', '     Parameters\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '      * None or no argument: reverses the order of the axes.\n', ' \n', '+     * tuple of ints: `i` in the `j`-th place in the tuple means that the\n', ""+       array's `i`-th axis becomes the transposed array's `j`-th axis.\n"", ' \n', '      * `n` ints: same as an n-tuple of the same ints (this form is\n', '+       intended simply as a ""convenience"" alternative to the tuple form).\n', ' \n', '     Returns\n', '     -------\n', '+    p : ndarray\n', '+        View of the array with its axes suitably permuted.\n', ' \n', '     See Also\n', '     --------\n', '+    transpose : Equivalent function.\n', '     ndarray.T : Array property returning the array transposed.\n', '     ndarray.reshape : Give a new shape to an array without changing its data.\n', ' \n']","[' \n', '      * None or no argument: reverses the order of the axes.\n', ' \n', ""-     * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n"", ""-       `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n"", ' \n', '      * `n` ints: same as an n-tuple of the same ints (this form is\n', '-       intended simply as a ""convenience"" alternative to the tuple form)\n', ' \n', '     Returns\n', '     -------\n', '-    out : ndarray\n', '-        View of `a`, with axes suitably permuted.\n', ' \n', '     See Also\n', '     --------\n', '-    transpose : Equivalent function\n', '     ndarray.T : Array property returning the array transposed.\n', '     ndarray.reshape : Give a new shape to an array without changing its data.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     array([[1, 3],\n', '            [2, 4]])\n', ' \n', '+    >>> a = np.array([1, 2, 3, 4])\n', '+    >>> a\n', '+    array([1, 2, 3, 4])\n', '+    >>> a.transpose()\n', '+    array([1, 2, 3, 4])\n', '+\n', '     """"""))\n', ' \n', ' \n']","['     array([[1, 3],\n', '            [2, 4]])\n', ' \n', '     """"""))\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     """"""))\n', ' \n', ""+add_newdoc('numpy.core', 'ufunc', ('resolve_dtypes',\n"", '+    """"""\n', '+    resolve_dtypes(dtypes, *, signature=None, casting=None, reduction=False)\n', '+\n', '+    Find the dtypes NumPy will use for the operation.  Both input and\n', '+    output dtypes are returned and may differ from those provided.\n', '+\n', '+    .. note::\n', '+\n', '+        This function always applies NEP 50 rules since it is not provided\n', '+        any actual values.  The Python types ``int``, ``float``, and\n', '+        ``complex`` thus behave weak and should be passed for ""untyped""\n', '+        Python input.\n', '+\n', '+    Parameters\n', '+    ----------\n', '+    dtypes : tuple of dtypes, None, or literal int, float, complex\n', '+        The input dtypes for each operand.  Output operands can be\n', '+        None, indicating that the dtype must be found.\n', '+    signature : tuple of DTypes or None, optional\n', '+        If given, enforces exact DType (classes) of the specific operand.\n', '+        The ufunc ``dtype`` argument is equivalent to passing a tuple with\n', '+        only output dtypes set.\n', ""+    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n"", '+        The casting mode when casting is necessary.  This is identical to\n', '+        the ufunc call casting modes.\n', '+    reduction : boolean\n', '+        If given, the resolution assumes a reduce operation is happening\n', '+        which slightly changes the promotion and type resolution rules.\n', '+        `dtypes` is usually something like ``(None, np.dtype(""i2""), None)``\n', '+        for reductions (first input is also the output).\n', '+\n', '+        .. note::\n', '+\n', '+            The default casting mode is ""same_kind"", however, as of\n', '+            NumPy 1.24, NumPy uses ""unsafe"" for reductions.\n', '+\n', '+    Returns\n', '+    -------\n', '+    dtypes : tuple of dtypes\n', '+        The dtypes which NumPy would use for the calculation.  Note that\n', '+        dtypes may not match the passed in ones (casting is necessary).\n', '+\n', '+    See Also\n', '+    --------\n', '+    numpy.ufunc._resolve_dtypes_and_context :\n', '+        Similar function to this, but returns additional information which\n', '+        give access to the core C functionality of NumPy.\n', '+\n', '+    Examples\n', '+    --------\n', '+    This API requires passing dtypes, define them for convenience:\n', '+\n', '+    >>> int32 = np.dtype(""int32"")\n', '+    >>> float32 = np.dtype(""float32"")\n', '+\n', '+    The typical ufunc call does not pass an output dtype.  `np.add` has two\n', '+    inputs and one output, so leave the output as ``None`` (not provided):\n', '+\n', '+    >>> np.add.resolve_dtypes((int32, float32, None))\n', ""+    (dtype('float64'), dtype('float64'), dtype('float64'))\n"", '+\n', '+    The loop found uses ""float64"" for all operands (including the output), the\n', '+    first input would be cast.\n', '+\n', '+    ``resolve_dtypes`` supports ""weak"" handling for Python scalars by passing\n', '+    ``int``, ``float``, or ``complex``:\n', '+\n', '+    >>> np.add.resolve_dtypes((float32, float, None))\n', ""+    (dtype('float32'), dtype('float32'), dtype('float32'))\n"", '+\n', '+    Where the Python ``float`` behaves samilar to a Python value ``0.0``\n', '+    in a ufunc call.  (See :ref:`NEP 50 <NEP50>` for details.)\n', '+\n', '+    """"""))\n', '+\n', ""+add_newdoc('numpy.core', 'ufunc', ('_resolve_dtypes_and_context',\n"", '+    """"""\n', '+    _resolve_dtypes_and_context(dtypes, *, signature=None, casting=None, reduction=False)\n', '+\n', '+    See `numpy.ufunc.resolve_dtypes` for parameter information.  This\n', '+    function is considered *unstable*.  You may use it, but the returned\n', '+    information is NumPy version specific and expected to change.\n', '+    Large API/ABI changes are not expected, but a new NumPy version is\n', '+    expected to require updating code using this functionality.\n', '+\n', '+    This function is designed to be used in conjunction with\n', '+    `numpy.ufunc._get_strided_loop`.  The calls are split to mirror the C API\n', '+    and allow future improvements.\n', '+\n', '+    Returns\n', '+    -------\n', '+    dtypes : tuple of dtypes\n', '+    call_info :\n', '+        PyCapsule with all necessary information to get access to low level\n', '+        C calls.  See `numpy.ufunc._get_strided_loop` for more information.\n', '+\n', '+    """"""))\n', '+\n', ""+add_newdoc('numpy.core', 'ufunc', ('_get_strided_loop',\n"", '+    """"""\n', '+    _get_strided_loop(call_info, /, *, fixed_strides=None)\n', '+\n', '+    This function fills in the ``call_info`` capsule to include all\n', '+    information necessary to call the low-level strided loop from NumPy.\n', '+\n', '+    See notes for more information.\n', '+\n', '+    Parameters\n', '+    ----------\n', '+    call_info : PyCapsule\n', '+        The PyCapsule returned by `numpy.ufunc._resolve_dtypes_and_context`.\n', '+    fixed_strides : tuple of int or None, optional\n', '+        A tuple with fixed byte strides of all input arrays.  NumPy may use\n', '+        this information to find specialized loops, so any call must follow\n', '+        the given stride.  Use ``None`` to indicate that the stride is not\n', '+        known (or not fixed) for all calls.\n', '+\n', '+    Notes\n', '+    -----\n', '+    Together with `numpy.ufunc._resolve_dtypes_and_context` this function\n', '+    gives low-level access to the NumPy ufunc loops.\n', '+    The first function does general preparation and returns the required\n', '+    information. It returns this as a C capsule with the version specific\n', '+    name ``numpy_1.24_ufunc_call_info``.\n', '+    The NumPy 1.24 ufunc call info capsule has the following layout::\n', '+\n', '+        typedef struct {\n', '+            PyArrayMethod_StridedLoop *strided_loop;\n', '+            PyArrayMethod_Context *context;\n', '+            NpyAuxData *auxdata;\n', '+\n', '+            /* Flag information (expected to change) */\n', '+            npy_bool requires_pyapi;  /* GIL is required by loop */\n', '+\n', ""+            /* Loop doesn't set FPE flags; if not set check FPE flags */\n"", '+            npy_bool no_floatingpoint_errors;\n', '+        } ufunc_call_info;\n', '+\n', '+    Note that the first call only fills in the ``context``.  The call to\n', '+    ``_get_strided_loop`` fills in all other data.\n', '+    Please see the ``numpy/experimental_dtype_api.h`` header for exact\n', '+    call information; the main thing to note is that the new-style loops\n', '+    return 0 on success, -1 on failure.  They are passed context as new\n', '+    first input and ``auxdata`` as (replaced) last.\n', '+\n', '+    Only the ``strided_loop``signature is considered guaranteed stable\n', '+    for NumPy bug-fix releases.  All other API is tied to the experimental\n', '+    API versioning.\n', '+\n', '+    The reason for the split call is that cast information is required to\n', '+    decide what the fixed-strides will be.\n', '+\n', '+    NumPy ties the lifetime of the ``auxdata`` information to the capsule.\n', '+\n', '+    """"""))\n', '+\n', '+\n', '+\n', ' ##############################################################################\n', ' #\n', ' # Documentation for dtype attributes and methods\n']","[' \n', '     """"""))\n', ' \n', ' ##############################################################################\n', ' #\n', ' # Documentation for dtype attributes and methods\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' our sphinx ``conf.py`` during doc builds, where we want to avoid showing\n', ' platform-dependent information.\n', ' """"""\n', '+import sys\n', '+import os\n', ' from numpy.core import dtype\n', ' from numpy.core import numerictypes as _numerictypes\n', ' from numpy.core.function_base import add_newdoc\n', ' \n', ' ##############################################################################\n', ' #\n']","[' our sphinx ``conf.py`` during doc builds, where we want to avoid showing\n', ' platform-dependent information.\n', ' """"""\n', ' from numpy.core import dtype\n', ' from numpy.core import numerictypes as _numerictypes\n', ' from numpy.core.function_base import add_newdoc\n', '-import platform\n', ' \n', ' ##############################################################################\n', ' #\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ])\n', ' \n', ' \n', '+def _get_platform_and_machine():\n', '+    try:\n', '+        system, _, _, _, machine = os.uname()\n', '+    except AttributeError:\n', '+        system = sys.platform\n', ""+        if system == 'win32':\n"", ""+            machine = os.environ.get('PROCESSOR_ARCHITEW6432', '') \\\n"", ""+                    or os.environ.get('PROCESSOR_ARCHITECTURE', '')\n"", '+        else:\n', ""+            machine = 'unknown'\n"", '+    return system, machine\n', '+\n', '+\n', '+_system, _machine = _get_platform_and_machine()\n', '+_doc_alias_string = f"":Alias on this platform ({_system} {_machine}):""\n', ' \n', ' \n', ' def add_newdoc_for_scalar_type(obj, fixed_aliases, doc):\n']","['     ])\n', ' \n', ' \n', ' \n', ' \n', ' def add_newdoc_for_scalar_type(obj, fixed_aliases, doc):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     o = getattr(_numerictypes, obj)\n', ' \n', '     character_code = dtype(o).char\n', '+    canonical_name_doc = """" if obj == o.__name__ else \\\n', '+                        f"":Canonical name: `numpy.{obj}`\\n    ""\n', '+    if fixed_aliases:\n', '+        alias_doc = \'\'.join(f"":Alias: `numpy.{alias}`\\n    ""\n', '+                            for alias in fixed_aliases)\n', '+    else:\n', ""+        alias_doc = ''\n"", '+    alias_doc += \'\'.join(f""{_doc_alias_string} `numpy.{alias}`: {doc}.\\n    ""\n', '                          for (alias_type, alias, doc) in possible_aliases if alias_type is o)\n', '+\n', '+    docstring = f""""""\n', '+    {doc.strip()}\n', ' \n', ""     :Character code: ``'{character_code}'``\n"", '     {canonical_name_doc}{alias_doc}\n', '+    """"""\n', ' \n', ""     add_newdoc('numpy.core.numerictypes', obj, docstring)\n"", ' \n']","['     o = getattr(_numerictypes, obj)\n', ' \n', '     character_code = dtype(o).char\n', '-    canonical_name_doc = """" if obj == o.__name__ else "":Canonical name: `numpy.{}`\\n    "".format(obj)\n', '-    alias_doc = \'\'.join("":Alias: `numpy.{}`\\n    "".format(alias) for alias in fixed_aliases)\n', '-    alias_doc += \'\'.join("":Alias on this platform ({} {}): `numpy.{}`: {}.\\n    "".format(platform.system(), platform.machine(), alias, doc)\n', '                          for (alias_type, alias, doc) in possible_aliases if alias_type is o)\n', '-    docstring = """"""\n', '-    {doc}\n', ' \n', ""     :Character code: ``'{character_code}'``\n"", '     {canonical_name_doc}{alias_doc}\n', '-    """""".format(doc=doc.strip(), character_code=character_code,\n', '-               canonical_name_doc=canonical_name_doc, alias_doc=alias_doc)\n', ' \n', ""     add_newdoc('numpy.core.numerictypes', obj, docstring)\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" add_newdoc_for_scalar_type('void', [],\n"", '     r""""""\n', '+    np.void(length_or_data, /, dtype=None)\n', '+\n', '+    Create a new structured or unstructured void scalar.\n', '+\n', '+    Parameters\n', '+    ----------\n', '+    length_or_data : int, array-like, bytes-like, object\n', '+       One of multiple meanings (see notes).  The length or\n', '+       bytes data of an unstructured void.  Or alternatively,\n', '+       the data to be stored in the new scalar when `dtype`\n', '+       is provided.\n', '+       This can be an array-like, in which case an array may\n', '+       be returned.\n', '+    dtype : dtype, optional\n', '+        If provided the dtype of the new scalar.  This dtype must\n', '+        be ""void"" dtype (i.e. a structured or unstructured void,\n', '+        see also :ref:`defining-structured-types`).\n', '+\n', '+       ..versionadded:: 1.24\n', '+\n', '+    Notes\n', '+    -----\n', '+    For historical reasons and because void scalars can represent both\n', '+    arbitrary byte data and structured dtypes, the void constructor\n', '+    has three calling conventions:\n', '+\n', '+    1. ``np.void(5)`` creates a ``dtype=""V5""`` scalar filled with five\n', '+       ``\\0`` bytes.  The 5 can be a Python or NumPy integer.\n', '+    2. ``np.void(b""bytes-like"")`` creates a void scalar from the byte string.\n', '+       The dtype itemsize will match the byte string length, here ``""V10""``.\n', '+    3. When a ``dtype=`` is passed the call is rougly the same as an\n', '+       array creation.  However, a void scalar rather than array is returned.\n', '+\n', '+    Please see the examples which show all three different conventions.\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> np.void(5)\n', ""+    void(b'\\x00\\x00\\x00\\x00\\x00')\n"", ""     >>> np.void(b'abcd')\n"", ""     void(b'\\x61\\x62\\x63\\x64')\n"", '+    >>> np.void((5, 3.2, ""eggs""), dtype=""i,d,S5"")\n', ""+    (5, 3.2, b'eggs')  # looks like a tuple, but is `np.void`\n"", ""+    >>> np.void(3, dtype=[('x', np.int8), ('y', np.int8)])\n"", '+    (3, 3)  # looks like a tuple, but is `np.void`\n', ' \n', '     """""")\n', ' \n', "" add_newdoc_for_scalar_type('datetime64', [],\n""]","[' \n', "" add_newdoc_for_scalar_type('void', [],\n"", '     r""""""\n', '-    Either an opaque sequence of bytes, or a structure.\n', ' \n', ""     >>> np.void(b'abcd')\n"", ""     void(b'\\x61\\x62\\x63\\x64')\n"", ' \n', '-    Structured `void` scalars can only be constructed via extraction from :ref:`structured_arrays`:\n', '-\n', ""-    >>> arr = np.array((1, 2), dtype=[('x', np.int8), ('y', np.int8)])\n"", '-    >>> arr[()]\n', '-    (1, 2)  # looks like a tuple, but is `np.void`\n', '     """""")\n', ' \n', "" add_newdoc_for_scalar_type('datetime64', [],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' __all__ = [""require""]\n', ' \n', ' \n', '+POSSIBLE_FLAGS = {\n', ""+    'C': 'C', 'C_CONTIGUOUS': 'C', 'CONTIGUOUS': 'C',\n"", ""+    'F': 'F', 'F_CONTIGUOUS': 'F', 'FORTRAN': 'F',\n"", ""+    'A': 'A', 'ALIGNED': 'A',\n"", ""+    'W': 'W', 'WRITEABLE': 'W',\n"", ""+    'O': 'O', 'OWNDATA': 'O',\n"", ""+    'E': 'E', 'ENSUREARRAY': 'E'\n"", '+}\n', '+\n', ' \n', ' def _require_dispatcher(a, dtype=None, requirements=None, *, like=None):\n', '     return (like,)\n']","[' __all__ = [""require""]\n', ' \n', ' \n', ' \n', ' def _require_dispatcher(a, dtype=None, requirements=None, *, like=None):\n', '     return (like,)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['        The required data-type. If None preserve the current dtype. If your\n', '        application requires the data to be in native byteorder, include\n', '        a byteorder specification as a part of the dtype specification.\n', '+    requirements : str or sequence of str\n', '        The requirements list can be any of the following\n', ' \n', ""        * 'F_CONTIGUOUS' ('F') - ensure a Fortran-contiguous array\n""]","['        The required data-type. If None preserve the current dtype. If your\n', '        application requires the data to be in native byteorder, include\n', '        a byteorder specification as a part of the dtype specification.\n', '-    requirements : str or list of str\n', '        The requirements list can be any of the following\n', ' \n', ""        * 'F_CONTIGUOUS' ('F') - ensure a Fortran-contiguous array\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             like=like,\n', '         )\n', ' \n', '     if not requirements:\n', '         return asanyarray(a, dtype=dtype)\n', '+\n', '+    requirements = {POSSIBLE_FLAGS[x.upper()] for x in requirements}\n', ' \n', ""     if 'E' in requirements:\n"", ""         requirements.remove('E')\n""]","['             like=like,\n', '         )\n', ' \n', ""-    possible_flags = {'C': 'C', 'C_CONTIGUOUS': 'C', 'CONTIGUOUS': 'C',\n"", ""-                      'F': 'F', 'F_CONTIGUOUS': 'F', 'FORTRAN': 'F',\n"", ""-                      'A': 'A', 'ALIGNED': 'A',\n"", ""-                      'W': 'W', 'WRITEABLE': 'W',\n"", ""-                      'O': 'O', 'OWNDATA': 'O',\n"", ""-                      'E': 'E', 'ENSUREARRAY': 'E'}\n"", '     if not requirements:\n', '         return asanyarray(a, dtype=dtype)\n', '-    else:\n', '-        requirements = {possible_flags[x.upper()] for x in requirements}\n', ' \n', ""     if 'E' in requirements:\n"", ""         requirements.remove('E')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     for prop in requirements:\n', '         if not arr.flags[prop]:\n', '+            return arr.copy(order)\n', '     return arr\n', ' \n', ' \n']","[' \n', '     for prop in requirements:\n', '         if not arr.flags[prop]:\n', '-            arr = arr.copy(order)\n', '-            break\n', '     return arr\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # Exception used in shares_memory()\n', "" @set_module('numpy')\n"", ' class TooHardError(RuntimeError):\n', '+    """"""max_work was exceeded.\n', '+\n', '+    This is raised whenever the maximum number of candidate solutions \n', '+    to consider specified by the ``max_work`` parameter is exceeded.\n', '+    Assigning a finite number to max_work may have caused the operation \n', '+    to fail.\n', '+\n', '+    """"""\n', '+    \n', '     pass\n', ' \n', ' \n']","[' # Exception used in shares_memory()\n', "" @set_module('numpy')\n"", ' class TooHardError(RuntimeError):\n', '     pass\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import ast\n', ' import re\n', ' import sys\n', ' import warnings\n', ' \n', ' from .multiarray import dtype, array, ndarray, promote_types\n']","[' import ast\n', ' import re\n', ' import sys\n', '-import platform\n', ' import warnings\n', ' \n', ' from .multiarray import dtype, array, ndarray, promote_types\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' except ImportError:\n', '     ctypes = None\n', ' \n', ""+IS_PYPY = sys.implementation.name == 'pypy'\n"", ' \n', "" if sys.byteorder == 'little':\n"", ""     _nbo = '<'\n""]","[' except ImportError:\n', '     ctypes = None\n', ' \n', ""-IS_PYPY = platform.python_implementation() == 'PyPy'\n"", ' \n', "" if sys.byteorder == 'little':\n"", ""     _nbo = '<'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.tiny = self.xmin\n', '         self.huge = self.xmax\n', '         self.smallest_normal = self.xmin\n', '+        self._str_smallest_normal = float_to_str(self.xmin)\n', '         self.smallest_subnormal = float_to_float(smallest_subnormal)\n', '+        self._str_smallest_subnormal = float_to_str(smallest_subnormal)\n', ' \n', '         import math\n', '         self.precision = int(-math.log10(float_to_float(self.eps)))\n']","['         self.tiny = self.xmin\n', '         self.huge = self.xmax\n', '         self.smallest_normal = self.xmin\n', '         self.smallest_subnormal = float_to_float(smallest_subnormal)\n', ' \n', '         import math\n', '         self.precision = int(-math.log10(float_to_float(self.eps)))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.core.multiarray import asanyarray\n', ' from numpy.core import numerictypes as nt\n', ' from numpy.core import _exceptions\n', '+from numpy.core._ufunc_config import _no_nep50_warning\n', ' from numpy._globals import _NoValue\n', ' from numpy.compat import pickle, os_fspath\n', ' \n']","[' from numpy.core.multiarray import asanyarray\n', ' from numpy.core import numerictypes as nt\n', ' from numpy.core import _exceptions\n', ' from numpy._globals import _NoValue\n', ' from numpy.compat import pickle, os_fspath\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n', '     if isinstance(ret, mu.ndarray):\n', '+        with _no_nep50_warning():\n', '+            ret = um.true_divide(\n', ""+                    ret, rcount, out=ret, casting='unsafe', subok=False)\n"", '         if is_float16_result and out is None:\n', '             ret = arr.dtype.type(ret)\n', ""     elif hasattr(ret, 'dtype'):\n""]","[' \n', '     ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n', '     if isinstance(ret, mu.ndarray):\n', '-        ret = um.true_divide(\n', ""-                ret, rcount, out=ret, casting='unsafe', subok=False)\n"", '         if is_float16_result and out is None:\n', '             ret = arr.dtype.type(ret)\n', ""     elif hasattr(ret, 'dtype'):\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # matching rcount to arrmean when where is specified as array\n', '         div = rcount.reshape(arrmean.shape)\n', '     if isinstance(arrmean, mu.ndarray):\n', '+        with _no_nep50_warning():\n', '+            arrmean = um.true_divide(arrmean, div, out=arrmean,\n', ""+                                     casting='unsafe', subok=False)\n"", '     elif hasattr(arrmean, ""dtype""):\n', '         arrmean = arrmean.dtype.type(arrmean / rcount)\n', '     else:\n']","['         # matching rcount to arrmean when where is specified as array\n', '         div = rcount.reshape(arrmean.shape)\n', '     if isinstance(arrmean, mu.ndarray):\n', ""-        arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n"", '-                                 subok=False)\n', '     elif hasattr(arrmean, ""dtype""):\n', '         arrmean = arrmean.dtype.type(arrmean / rcount)\n', '     else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # divide by degrees of freedom\n', '     if isinstance(ret, mu.ndarray):\n', '+        with _no_nep50_warning():\n', '+            ret = um.true_divide(\n', ""+                    ret, rcount, out=ret, casting='unsafe', subok=False)\n"", ""     elif hasattr(ret, 'dtype'):\n"", '         ret = ret.dtype.type(ret / rcount)\n', '     else:\n']","[' \n', '     # divide by degrees of freedom\n', '     if isinstance(ret, mu.ndarray):\n', '-        ret = um.true_divide(\n', ""-                ret, rcount, out=ret, casting='unsafe', subok=False)\n"", ""     elif hasattr(ret, 'dtype'):\n"", '         ret = ret.dtype.type(ret / rcount)\n', '     else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         if name in ('longdouble', 'clongdouble') and myname in allTypes:\n"", '             continue\n', ' \n', '+        # Add to the main namespace if desired:\n', '+        if bit != 0 and base != ""bool"":\n', '+            allTypes[myname] = info.type\n', ' \n', '         # add forward, reverse, and string mapping to numarray\n', '         sctypeDict[char] = info.type\n', ' \n', '+        # add mapping for both the bit name\n', '+        sctypeDict[myname] = info.type\n', '+\n', ' \n', ' _add_aliases()\n', ' \n']","[""         if name in ('longdouble', 'clongdouble') and myname in allTypes:\n"", '             continue\n', ' \n', '-        allTypes[myname] = info.type\n', '-\n', '-        # add mapping for both the bit name and the numarray name\n', '-        sctypeDict[myname] = info.type\n', ' \n', '         # add forward, reverse, and string mapping to numarray\n', '         sctypeDict[char] = info.type\n', ' \n', ' \n', ' _add_aliases()\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' #\n', ' def _set_up_aliases():\n', ""     type_pairs = [('complex_', 'cdouble'),\n"", ""                   ('single', 'float'),\n"", ""                   ('csingle', 'cfloat'),\n"", ""                   ('singlecomplex', 'cfloat'),\n""]","[' #\n', ' def _set_up_aliases():\n', ""     type_pairs = [('complex_', 'cdouble'),\n"", ""-                  ('int0', 'intp'),\n"", ""-                  ('uint0', 'uintp'),\n"", ""                   ('single', 'float'),\n"", ""                   ('csingle', 'cfloat'),\n"", ""                   ('singlecomplex', 'cfloat'),\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' """"""\n', ' import collections.abc\n', ' import contextlib\n', '+import contextvars\n', ' \n', ' from .overrides import set_module\n', ' from .umath import (\n']","[' """"""\n', ' import collections.abc\n', ' import contextlib\n', ' \n', ' from .overrides import set_module\n', ' from .umath import (\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' __all__ = [\n', '     ""seterr"", ""geterr"", ""setbufsize"", ""getbufsize"", ""seterrcall"", ""geterrcall"",\n', '+    ""errstate"", \'_no_nep50_warning\'\n', ' ]\n', ' \n', ' _errdict = {""ignore"": ERR_IGNORE,\n']","[' \n', ' __all__ = [\n', '     ""seterr"", ""geterr"", ""setbufsize"", ""getbufsize"", ""seterrcall"", ""geterrcall"",\n', '-    ""errstate"",\n', ' ]\n', ' \n', ' _errdict = {""ignore"": ERR_IGNORE,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> np.int16(32000) * np.int16(3)\n', '     Traceback (most recent call last):\n', '       File ""<stdin>"", line 1, in <module>\n', '+    FloatingPointError: overflow encountered in scalar multiply\n', ' \n', ""     >>> old_settings = np.seterr(all='print')\n"", '     >>> np.geterr()\n']","['     >>> np.int16(32000) * np.int16(3)\n', '     Traceback (most recent call last):\n', '       File ""<stdin>"", line 1, in <module>\n', '-    FloatingPointError: overflow encountered in short_scalars\n', ' \n', ""     >>> old_settings = np.seterr(all='print')\n"", '     >>> np.geterr()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' # set the default values\n', ' _setdef()\n', '+\n', '+\n', '+NO_NEP50_WARNING = contextvars.ContextVar(""_no_nep50_warning"", default=False)\n', '+\n', ""+@set_module('numpy')\n"", '+@contextlib.contextmanager\n', '+def _no_nep50_warning():\n', '+    """"""\n', '+    Context manager to disable NEP 50 warnings.  This context manager is\n', '+    only relevant if the NEP 50 warnings are enabled globally (which is not\n', '+    thread/context safe).\n', '+\n', '+    This warning context manager itself is fully safe, however.\n', '+    """"""\n', '+    token = NO_NEP50_WARNING.set(True)\n', '+    try:\n', '+        yield\n', '+    finally:\n', '+        NO_NEP50_WARNING.reset(token)\n']","[' \n', ' # set the default values\n', ' _setdef()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' _typelessdata = [int_, float_, complex_, bool_]\n', ' \n', ' \n', ' def dtype_is_implied(dtype):\n']","[' \n', ' \n', ' _typelessdata = [int_, float_, complex_, bool_]\n', '-if issubclass(intc, int):\n', '-    _typelessdata.append(intc)\n', '-if issubclass(longlong, int):\n', '-    _typelessdata.append(longlong)\n', ' \n', ' \n', ' def dtype_is_implied(dtype):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['   }\n', '   if (NPY_FEATURE_VERSION > PyArray_GetNDArrayCFeatureVersion()) {\n', '       PyErr_Format(PyExc_RuntimeError, ""module compiled against ""\\\n', '+             ""API version 0x%%x but this version of numpy is 0x%%x . ""\\\n', '+             ""Check the section C-API incompatibility at the ""\\\n', '+             ""Troubleshooting ImportError section at ""\\\n', '+             ""https://numpy.org/devdocs/user/troubleshooting-importerror.html""\\\n', '+             ""#c-api-incompatibility ""\\\n', '+              ""for indications on how to solve this problem ."", \\\n', '              (int) NPY_FEATURE_VERSION, (int) PyArray_GetNDArrayCFeatureVersion());\n', '       return -1;\n', '   }\n']","['   }\n', '   if (NPY_FEATURE_VERSION > PyArray_GetNDArrayCFeatureVersion()) {\n', '       PyErr_Format(PyExc_RuntimeError, ""module compiled against ""\\\n', '-             ""API version 0x%%x but this version of numpy is 0x%%x"", \\\n', '              (int) NPY_FEATURE_VERSION, (int) PyArray_GetNDArrayCFeatureVersion());\n', '       return -1;\n', '   }\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['    */\n', '   st = PyArray_GetEndianness();\n', '   if (st == NPY_CPU_UNKNOWN_ENDIAN) {\n', '+      PyErr_SetString(PyExc_RuntimeError,\n', '+                      ""FATAL: module compiled as unknown endian"");\n', '       return -1;\n', '   }\n', ' #if NPY_BYTE_ORDER == NPY_BIG_ENDIAN\n', '   if (st != NPY_CPU_BIG) {\n', '+      PyErr_SetString(PyExc_RuntimeError,\n', '+                      ""FATAL: module compiled as big endian, but ""\n', '+                      ""detected different endianness at runtime"");\n', '       return -1;\n', '   }\n', ' #elif NPY_BYTE_ORDER == NPY_LITTLE_ENDIAN\n', '   if (st != NPY_CPU_LITTLE) {\n', '+      PyErr_SetString(PyExc_RuntimeError,\n', '+                      ""FATAL: module compiled as little endian, but ""\n', '+                      ""detected different endianness at runtime"");\n', '       return -1;\n', '   }\n', ' #endif\n']","['    */\n', '   st = PyArray_GetEndianness();\n', '   if (st == NPY_CPU_UNKNOWN_ENDIAN) {\n', '-      PyErr_Format(PyExc_RuntimeError, ""FATAL: module compiled as unknown endian"");\n', '       return -1;\n', '   }\n', ' #if NPY_BYTE_ORDER == NPY_BIG_ENDIAN\n', '   if (st != NPY_CPU_BIG) {\n', '-      PyErr_Format(PyExc_RuntimeError, ""FATAL: module compiled as ""\\\n', '-             ""big endian, but detected different endianness at runtime"");\n', '       return -1;\n', '   }\n', ' #elif NPY_BYTE_ORDER == NPY_LITTLE_ENDIAN\n', '   if (st != NPY_CPU_LITTLE) {\n', '-      PyErr_Format(PyExc_RuntimeError, ""FATAL: module compiled as ""\\\n', '-             ""little endian, but detected different endianness at runtime"");\n', '       return -1;\n', '   }\n', ' #endif\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""           docstrings.get('numpy.core.umath.power'),\n"", '           None,\n', '           TD(ints),\n', ""+          TD('e', f='pow', astype={'e': 'f'}),\n"", ""+          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='pow', astype={'e': 'f'}),\n"", ""           TD(O, f='npy_ObjectPower'),\n"", '           ),\n']","[""           docstrings.get('numpy.core.umath.power'),\n"", '           None,\n', '           TD(ints),\n', ""           TD(inexact, f='pow', astype={'e': 'f'}),\n"", ""           TD(O, f='npy_ObjectPower'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.greater'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""+          TD(all, out='?', dispatch=[('loops_comparison', bints+'fd')]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.greater'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""-          TD(all, out='?', simd=[('avx2', ints)]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.greater_equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""+          TD(all, out='?', dispatch=[('loops_comparison', bints+'fd')]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.greater_equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""-          TD(all, out='?', simd=[('avx2', ints)]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.less'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""+          TD(all, out='?', dispatch=[('loops_comparison', bints+'fd')]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.less'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""-          TD(all, out='?', simd=[('avx2', ints)]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.less_equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""+          TD(all, out='?', dispatch=[('loops_comparison', bints+'fd')]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.less_equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""-          TD(all, out='?', simd=[('avx2', ints)]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""+          TD(all, out='?', dispatch=[('loops_comparison', bints+'fd')]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""-          TD(all, out='?', simd=[('avx2', ints)]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.not_equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""+          TD(all, out='?', dispatch=[('loops_comparison', bints+'fd')]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.not_equal'),\n"", ""           'PyUFunc_SimpleBinaryComparisonTypeResolver',\n"", ""-          TD(all, out='?', simd=[('avx2', ints)]),\n"", ""           [TypeDescription('O', FullTypeDescr, 'OO', 'O')],\n"", ""           TD('O', out='?'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, ReorderableNone,\n', ""           docstrings.get('numpy.core.umath.fmax'),\n"", ""           'PyUFunc_SimpleUniformOperationTypeResolver',\n"", ""+          TD(noobj, dispatch=[('loops_minmax', 'fdg')]),\n"", ""           TD(O, f='npy_ObjectMax')\n"", '           ),\n', "" 'fmin':\n"", '     Ufunc(2, 1, ReorderableNone,\n', ""           docstrings.get('numpy.core.umath.fmin'),\n"", ""           'PyUFunc_SimpleUniformOperationTypeResolver',\n"", ""+          TD(noobj, dispatch=[('loops_minmax', 'fdg')]),\n"", ""           TD(O, f='npy_ObjectMin')\n"", '           ),\n', "" 'logaddexp':\n""]","['     Ufunc(2, 1, ReorderableNone,\n', ""           docstrings.get('numpy.core.umath.fmax'),\n"", ""           'PyUFunc_SimpleUniformOperationTypeResolver',\n"", ""-          TD('fdg', dispatch=[('loops_minmax', 'fdg')]),\n"", '-          TD(noobj),\n', ""           TD(O, f='npy_ObjectMax')\n"", '           ),\n', "" 'fmin':\n"", '     Ufunc(2, 1, ReorderableNone,\n', ""           docstrings.get('numpy.core.umath.fmin'),\n"", ""           'PyUFunc_SimpleUniformOperationTypeResolver',\n"", ""-          TD('fdg', dispatch=[('loops_minmax', 'fdg')]),\n"", '-          TD(noobj),\n', ""           TD(O, f='npy_ObjectMin')\n"", '           ),\n', "" 'logaddexp':\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arccos'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='acos', astype={'e': 'f'}),\n"", ""           TD(P, f='arccos'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arccos'),\n"", '           None,\n', ""-          TD('e', f='acos', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='acos', astype={'e': 'f'}),\n"", ""           TD(P, f='arccos'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arccosh'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='acosh', astype={'e': 'f'}),\n"", ""           TD(P, f='arccosh'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arccosh'),\n"", '           None,\n', ""-          TD('e', f='acosh', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='acosh', astype={'e': 'f'}),\n"", ""           TD(P, f='arccosh'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arcsin'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='asin', astype={'e': 'f'}),\n"", ""           TD(P, f='arcsin'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arcsin'),\n"", '           None,\n', ""-          TD('e', f='asin', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='asin', astype={'e': 'f'}),\n"", ""           TD(P, f='arcsin'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arcsinh'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='asinh', astype={'e': 'f'}),\n"", ""           TD(P, f='arcsinh'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arcsinh'),\n"", '           None,\n', ""-          TD('e', f='asinh', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='asinh', astype={'e': 'f'}),\n"", ""           TD(P, f='arcsinh'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctan'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='atan', astype={'e': 'f'}),\n"", ""           TD(P, f='arctan'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctan'),\n"", '           None,\n', ""-          TD('e', f='atan', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='atan', astype={'e': 'f'}),\n"", ""           TD(P, f='arctan'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctanh'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='atanh', astype={'e': 'f'}),\n"", ""           TD(P, f='arctanh'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctanh'),\n"", '           None,\n', ""-          TD('e', f='atanh', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='atanh', astype={'e': 'f'}),\n"", ""           TD(P, f='arctanh'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cos'),\n"", '           None,\n', ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""+          TD('ed', dispatch=[('loops_umath_fp', 'ed')]),\n"", ""           TD('fdg' + cmplx, f='cos'),\n"", ""           TD(P, f='cos'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cos'),\n"", '           None,\n', ""-          TD('e', f='cos', astype={'e': 'f'}),\n"", ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""-          TD('d', dispatch=[('loops_umath_fp', 'd')]),\n"", ""           TD('fdg' + cmplx, f='cos'),\n"", ""           TD(P, f='cos'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.sin'),\n"", '           None,\n', ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""+          TD('ed', dispatch=[('loops_umath_fp', 'ed')]),\n"", ""           TD('fdg' + cmplx, f='sin'),\n"", ""           TD(P, f='sin'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.sin'),\n"", '           None,\n', ""-          TD('e', f='sin', astype={'e': 'f'}),\n"", ""           TD('f', dispatch=[('loops_trigonometric', 'f')]),\n"", ""-          TD('d', dispatch=[('loops_umath_fp', 'd')]),\n"", ""           TD('fdg' + cmplx, f='sin'),\n"", ""           TD(P, f='sin'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.tan'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='tan', astype={'e': 'f'}),\n"", ""           TD(P, f='tan'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.tan'),\n"", '           None,\n', ""-          TD('e', f='tan', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='tan', astype={'e': 'f'}),\n"", ""           TD(P, f='tan'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cosh'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='cosh', astype={'e': 'f'}),\n"", ""           TD(P, f='cosh'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cosh'),\n"", '           None,\n', ""-          TD('e', f='cosh', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='cosh', astype={'e': 'f'}),\n"", ""           TD(P, f='cosh'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.sinh'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='sinh', astype={'e': 'f'}),\n"", ""           TD(P, f='sinh'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.sinh'),\n"", '           None,\n', ""-          TD('e', f='sinh', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='sinh', astype={'e': 'f'}),\n"", ""           TD(P, f='sinh'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.tanh'),\n"", '           None,\n', ""+          TD('e', dispatch=[('loops_umath_fp', 'e')]),\n"", ""           TD('fd', dispatch=[('loops_hyperbolic', 'fd')]),\n"", ""           TD(inexact, f='tanh', astype={'e': 'f'}),\n"", ""           TD(P, f='tanh'),\n""]","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.tanh'),\n"", '           None,\n', ""-          TD('e', f='tanh', astype={'e': 'f'}),\n"", ""           TD('fd', dispatch=[('loops_hyperbolic', 'fd')]),\n"", ""           TD(inexact, f='tanh', astype={'e': 'f'}),\n"", ""           TD(P, f='tanh'),\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.exp'),\n"", '           None,\n', ""+          TD('e', dispatch=[('loops_umath_fp', 'e')]),\n"", ""           TD('fd', dispatch=[('loops_exponent_log', 'fd')]),\n"", ""           TD('fdg' + cmplx, f='exp'),\n"", ""           TD(P, f='exp'),\n""]","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.exp'),\n"", '           None,\n', ""-          TD('e', f='exp', astype={'e': 'f'}),\n"", ""           TD('fd', dispatch=[('loops_exponent_log', 'fd')]),\n"", ""           TD('fdg' + cmplx, f='exp'),\n"", ""           TD(P, f='exp'),\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.exp2'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='exp2', astype={'e': 'f'}),\n"", ""           TD(P, f='exp2'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.exp2'),\n"", '           None,\n', ""-          TD('e', f='exp2', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='exp2', astype={'e': 'f'}),\n"", ""           TD(P, f='exp2'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.expm1'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='expm1', astype={'e': 'f'}),\n"", ""           TD(P, f='expm1'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.expm1'),\n"", '           None,\n', ""-          TD('e', f='expm1', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='expm1', astype={'e': 'f'}),\n"", ""           TD(P, f='expm1'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log'),\n"", '           None,\n', ""+          TD('e', dispatch=[('loops_umath_fp', 'e')]),\n"", ""           TD('fd', dispatch=[('loops_exponent_log', 'fd')]),\n"", ""           TD('fdg' + cmplx, f='log'),\n"", ""           TD(P, f='log'),\n""]","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log'),\n"", '           None,\n', ""-          TD('e', f='log', astype={'e': 'f'}),\n"", ""           TD('fd', dispatch=[('loops_exponent_log', 'fd')]),\n"", ""           TD('fdg' + cmplx, f='log'),\n"", ""           TD(P, f='log'),\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log2'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='log2', astype={'e': 'f'}),\n"", ""           TD(P, f='log2'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log2'),\n"", '           None,\n', ""-          TD('e', f='log2', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='log2', astype={'e': 'f'}),\n"", ""           TD(P, f='log2'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log10'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='log10', astype={'e': 'f'}),\n"", ""           TD(P, f='log10'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log10'),\n"", '           None,\n', ""-          TD('e', f='log10', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='log10', astype={'e': 'f'}),\n"", ""           TD(P, f='log10'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log1p'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(inexact, f='log1p', astype={'e': 'f'}),\n"", ""           TD(P, f='log1p'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.log1p'),\n"", '           None,\n', ""-          TD('e', f='log1p', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(inexact, f='log1p', astype={'e': 'f'}),\n"", ""           TD(P, f='log1p'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cbrt'),\n"", '           None,\n', ""+          TD('efd', dispatch=[('loops_umath_fp', 'efd')]),\n"", ""           TD(flts, f='cbrt', astype={'e': 'f'}),\n"", ""           TD(P, f='cbrt'),\n"", '           ),\n']","['     Ufunc(1, 1, None,\n', ""           docstrings.get('numpy.core.umath.cbrt'),\n"", '           None,\n', ""-          TD('e', f='cbrt', astype={'e': 'f'}),\n"", ""-          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(flts, f='cbrt', astype={'e': 'f'}),\n"", ""           TD(P, f='cbrt'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctan2'),\n"", '           None,\n', ""+          TD('fd', dispatch=[('loops_umath_fp', 'fd')]),\n"", ""           TD(flts, f='atan2', astype={'e': 'f'}),\n"", ""           TD(P, f='arctan2'),\n"", '           ),\n']","['     Ufunc(2, 1, None,\n', ""           docstrings.get('numpy.core.umath.arctan2'),\n"", '           None,\n', ""           TD(flts, f='atan2', astype={'e': 'f'}),\n"", ""           TD(P, f='arctan2'),\n"", '           ),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         return 0;\n', '     }\n', '+    """""") % (os.path.basename(filename), code1, code2, code3)\n', '     return code\n', ' \n', ' \n']","[' \n', '         return 0;\n', '     }\n', '-    """""") % (filename, code1, code2, code3)\n', '     return code\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -----\n', '     Logarithm is a multivalued function: for each `x` there is an infinite\n', '     number of `z` such that `exp(z) = x`. The convention is to return the\n', '+    `z` whose imaginary part lies in `(-pi, pi]`.\n', ' \n', '     For real-valued input data types, `log` always returns real output. For\n', '     each value that cannot be expressed as a real number or infinity, it\n']","['     -----\n', '     Logarithm is a multivalued function: for each `x` there is an infinite\n', '     number of `z` such that `exp(z) = x`. The convention is to return the\n', '-    `z` whose imaginary part lies in `[-pi, pi]`.\n', ' \n', '     For real-valued input data types, `log` always returns real output. For\n', '     each value that cannot be expressed as a real number or infinity, it\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     has a branch cut `[-inf, 0]` and is continuous from above on it. `log`\n', '     handles the floating-point negative zero as an infinitesimal negative\n', '     number, conforming to the C99 standard.\n', '+    \n', '+    In the cases where the input has a negative real part and a very small\n', '+    negative complex part (approaching 0), the result is so close to `-pi`\n', '+    that it evaluates to exactly `-pi`.\n', ' \n', '     References\n', '     ----------\n']","['     has a branch cut `[-inf, 0]` and is continuous from above on it. `log`\n', '     handles the floating-point negative zero as an infinitesimal negative\n', '     number, conforming to the C99 standard.\n', ' \n', '     References\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -----\n', '     Logarithm is a multivalued function: for each `x` there is an infinite\n', '     number of `z` such that `10**z = x`. The convention is to return the\n', '+    `z` whose imaginary part lies in `(-pi, pi]`.\n', ' \n', '     For real-valued input data types, `log10` always returns real output.\n', '     For each value that cannot be expressed as a real number or infinity,\n']","['     -----\n', '     Logarithm is a multivalued function: for each `x` there is an infinite\n', '     number of `z` such that `10**z = x`. The convention is to return the\n', '-    `z` whose imaginary part lies in `[-pi, pi]`.\n', ' \n', '     For real-valued input data types, `log10` always returns real output.\n', '     For each value that cannot be expressed as a real number or infinity,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     `log10` handles the floating-point negative zero as an infinitesimal\n', '     negative number, conforming to the C99 standard.\n', ' \n', '+    In the cases where the input has a negative real part and a very small\n', '+    negative complex part (approaching 0), the result is so close to `-pi`\n', '+    that it evaluates to exactly `-pi`.\n', '+\n', '     References\n', '     ----------\n', '     .. [1] M. Abramowitz and I.A. Stegun, ""Handbook of Mathematical Functions"",\n']","['     `log10` handles the floating-point negative zero as an infinitesimal\n', '     negative number, conforming to the C99 standard.\n', ' \n', '     References\n', '     ----------\n', '     .. [1] M. Abramowitz and I.A. Stegun, ""Handbook of Mathematical Functions"",\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Logarithm is a multivalued function: for each `x` there is an infinite\n', '     number of `z` such that `2**z = x`. The convention is to return the `z`\n', '+    whose imaginary part lies in `(-pi, pi]`.\n', ' \n', '     For real-valued input data types, `log2` always returns real output.\n', '     For each value that cannot be expressed as a real number or infinity,\n']","[' \n', '     Logarithm is a multivalued function: for each `x` there is an infinite\n', '     number of `z` such that `2**z = x`. The convention is to return the `z`\n', '-    whose imaginary part lies in `[-pi, pi]`.\n', ' \n', '     For real-valued input data types, `log2` always returns real output.\n', '     For each value that cannot be expressed as a real number or infinity,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     handles the floating-point negative zero as an infinitesimal negative\n', '     number, conforming to the C99 standard.\n', ' \n', '+    In the cases where the input has a negative real part and a very small\n', '+    negative complex part (approaching 0), the result is so close to `-pi`\n', '+    that it evaluates to exactly `-pi`.\n', '+\n', '     Examples\n', '     --------\n', '     >>> x = np.array([0, 1, 2, 2**4])\n']","['     handles the floating-point negative zero as an infinitesimal negative\n', '     number, conforming to the C99 standard.\n', ' \n', '     Examples\n', '     --------\n', '     >>> x = np.array([0, 1, 2, 2**4])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['       (9, 5, 7, 3)\n', '       >>> # n is 7, k is 4, m is 3\n', ' \n', '+    The matmul function implements the semantics of the ``@`` operator\n', '+    introduced in Python 3.5 following :pep:`465`.\n', '+\n', '+    It uses an optimized BLAS library when possible (see `numpy.linalg`).\n', ' \n', '     Examples\n', '     --------\n']","['       (9, 5, 7, 3)\n', '       >>> # n is 7, k is 4, m is 3\n', ' \n', '-    The matmul function implements the semantics of the ``@`` operator introduced\n', '-    in Python 3.5 following :pep:`465`.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     builtins.len\n', '+\n', '+    Examples\n', '+    --------\n', ""+    >>> a = np.array(['Grace Hopper Conference', 'Open Source Day'])\n"", '+    >>> np.char.str_len(a)\n', '+    array([23, 15])\n', ""+    >>> a = np.array([u'\\u0420', u'\\u043e'])\n"", '+    >>> np.char.str_len(a)\n', '+    array([1, 1])\n', ""+    >>> a = np.array([['hello', 'world'], [u'\\u0420', u'\\u043e']])\n"", '+    >>> np.char.str_len(a)\n', '+    array([[5, 5], [1, 1]])\n', '     """"""\n', '     # Note: __len__, etc. currently return ints, which are not C-integers.\n', '     # Generally intp would be expected for lengths, although int is sufficient\n']","['     See Also\n', '     --------\n', '     builtins.len\n', '     """"""\n', '     # Note: __len__, etc. currently return ints, which are not C-integers.\n', '     # Generally intp would be expected for lengths, although int is sufficient\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -------\n', '     out : ndarray\n', '         Output array of str or unicode, depending on input types\n', '+    \n', '+    Examples\n', '+    --------\n', '+    >>> a = np.array([""a"", ""b"", ""c""])\n', '+    >>> np.char.multiply(x, 3)\n', ""+    array(['aaa', 'bbb', 'ccc'], dtype='<U3')\n"", '+    >>> i = np.array([1, 2, 3])\n', '+    >>> np.char.multiply(a, i)\n', ""+    array(['a', 'bb', 'ccc'], dtype='<U3')\n"", ""+    >>> np.char.multiply(np.array(['a']), i)\n"", ""+    array(['a', 'aa', 'aaa'], dtype='<U3')\n"", ""+    >>> a = np.array(['a', 'b', 'c', 'd', 'e', 'f']).reshape((2, 3))\n"", '+    >>> np.char.multiply(a, 3)\n', ""+    array([['aaa', 'bbb', 'ccc'],\n"", ""+           ['ddd', 'eee', 'fff']], dtype='<U3')\n"", '+    >>> np.char.multiply(a, i)\n', ""+    array([['a', 'bb', 'ccc'],\n"", ""+           ['d', 'ee', 'fff']], dtype='<U3')\n"", '     """"""\n', '     a_arr = numpy.asarray(a)\n', '     i_arr = numpy.asarray(i)\n']","['     -------\n', '     out : ndarray\n', '         Output array of str or unicode, depending on input types\n', '-\n', '     """"""\n', '     a_arr = numpy.asarray(a)\n', '     i_arr = numpy.asarray(i)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     str.center\n', '+    \n', '+    Notes\n', '+    -----\n', '+    This function is intended to work with arrays of strings.  The\n', '+    fill character is not applied to numeric types.\n', '+\n', '+    Examples\n', '+    --------\n', ""+    >>> c = np.array(['a1b2','1b2a','b2a1','2a1b']); c\n"", ""+    array(['a1b2', '1b2a', 'b2a1', '2a1b'], dtype='<U4')\n"", '+    >>> np.char.center(c, width=9)\n', ""+    array(['   a1b2  ', '   1b2a  ', '   b2a1  ', '   2a1b  '], dtype='<U9')\n"", ""+    >>> np.char.center(c, width=9, fillchar='*')\n"", ""+    array(['***a1b2**', '***1b2a**', '***b2a1**', '***2a1b**'], dtype='<U9')\n"", '+    >>> np.char.center(c, width=1)\n', ""+    array(['a', '1', 'b', '2'], dtype='<U1')\n"", ' \n', '     """"""\n', '     a_arr = numpy.asarray(a)\n']","['     See Also\n', '     --------\n', '     str.center\n', ' \n', '     """"""\n', '     a_arr = numpy.asarray(a)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' @array_function_dispatch(_code_dispatcher)\n', ' def decode(a, encoding=None, errors=None):\n', '+    r""""""\n', '+    Calls ``bytes.decode`` element-wise.\n', ' \n', '     The set of available codecs comes from the Python standard library,\n', '     and may be extended at runtime.  For more information, see the\n']","[' \n', ' @array_function_dispatch(_code_dispatcher)\n', ' def decode(a, encoding=None, errors=None):\n', '-    """"""\n', '-    Calls `str.decode` element-wise.\n', ' \n', '     The set of available codecs comes from the Python standard library,\n', '     and may be extended at runtime.  For more information, see the\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     See Also\n', '     --------\n', '+    :py:meth:`bytes.decode`\n', ' \n', '     Notes\n', '     -----\n']","[' \n', '     See Also\n', '     --------\n', '-    str.decode\n', ' \n', '     Notes\n', '     -----\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Examples\n', '     --------\n', ""+    >>> c = np.array([b'\\x81\\xc1\\x81\\xc1\\x81\\xc1', b'@@\\x81\\xc1@@',\n"", ""+    ...               b'\\x81\\x82\\xc2\\xc1\\xc2\\x82\\x81'])\n"", '     >>> c\n', ""+    array([b'\\x81\\xc1\\x81\\xc1\\x81\\xc1', b'@@\\x81\\xc1@@',\n"", ""+    ...    b'\\x81\\x82\\xc2\\xc1\\xc2\\x82\\x81'], dtype='|S7')\n"", ""+    >>> np.char.decode(c, encoding='cp037')\n"", ""     array(['aAaAaA', '  aA  ', 'abBABba'], dtype='<U7')\n"", ' \n', '     """"""\n', '     return _to_string_or_unicode_array(\n']","[' \n', '     Examples\n', '     --------\n', ""-    >>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])\n"", '     >>> c\n', ""     array(['aAaAaA', '  aA  ', 'abBABba'], dtype='<U7')\n"", ""-    >>> np.char.encode(c, encoding='cp037')\n"", ""-    array(['\\\\x81\\\\xc1\\\\x81\\\\xc1\\\\x81\\\\xc1', '@@\\\\x81\\\\xc1@@',\n"", ""-        '\\\\x81\\\\x82\\\\xc2\\\\xc1\\\\xc2\\\\x82\\\\x81'],\n"", ""-        dtype='|S7')\n"", ' \n', '     """"""\n', '     return _to_string_or_unicode_array(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     str.find\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> a = np.array([""NumPy is a Python library""])\n', '+    >>> np.char.find(a, ""Python"", start=0, end=None)\n', '+    array([11])\n', '+\n', '     """"""\n', '     return _vec_string(\n', ""         a, int_, 'find', [sub, start] + _clean_args(end))\n""]","['     --------\n', '     str.find\n', ' \n', '     """"""\n', '     return _vec_string(\n', ""         a, int_, 'find', [sub, start] + _clean_args(end))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     find, str.find\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> a = np.array([""Computer Science""])\n', '+    >>> np.char.index(a, ""Science"", start=0, end=None)\n', '+    array([9])\n', '+\n', '     """"""\n', '     return _vec_string(\n', ""         a, int_, 'index', [sub, start] + _clean_args(end))\n""]","['     --------\n', '     find, str.find\n', ' \n', '     """"""\n', '     return _vec_string(\n', ""         a, int_, 'index', [sub, start] + _clean_args(end))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     str.isdigit\n', '+\n', '+    Examples\n', '+    --------\n', ""+    >>> a = np.array(['a', 'b', '0'])\n"", '+    >>> np.char.isdigit(a)\n', '+    array([False, False,  True])\n', ""+    >>> a = np.array([['a', 'b', '0'], ['c', '1', '2']])\n"", '+    >>> np.char.isdigit(a)\n', '+    array([[False, False,  True], [False,  True,  True]])\n', '     """"""\n', ""     return _vec_string(a, bool_, 'isdigit')\n"", ' \n']","['     See Also\n', '     --------\n', '     str.isdigit\n', '     """"""\n', ""     return _vec_string(a, bool_, 'isdigit')\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @array_function_dispatch(_unary_op_dispatcher)\n', ' def isupper(a):\n', '     """"""\n', '+    Return true for each element if all cased characters in the\n', '     string are uppercase and there is at least one character, false\n', '     otherwise.\n', ' \n']","[' @array_function_dispatch(_unary_op_dispatcher)\n', ' def isupper(a):\n', '     """"""\n', '-    Returns true for each element if all cased characters in the\n', '     string are uppercase and there is at least one character, false\n', '     otherwise.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     str.isupper\n', '+\n', '+    Examples\n', '+    --------\n', '+    >>> str = ""GHC""\n', '+    >>> np.char.isupper(str)\n', '+    array(True)     \n', '+    >>> a = np.array([""hello"", ""HELLO"", ""Hello""])\n', '+    >>> np.char.isupper(a)\n', '+    array([False,  True, False]) \n', '+\n', '     """"""\n', ""     return _vec_string(a, bool_, 'isupper')\n"", ' \n']","['     See Also\n', '     --------\n', '     str.isupper\n', '     """"""\n', ""     return _vec_string(a, bool_, 'isupper')\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     str.join\n', '+\n', '+    Examples\n', '+    --------\n', ""+    >>> np.char.join('-', 'osd')\n"", ""+    array('o-s-d', dtype='<U5')\n"", '+\n', ""+    >>> np.char.join(['-', '.'], ['ghc', 'osd'])\n"", ""+    array(['g-h-c', 'o.s.d'], dtype='<U5')\n"", '+\n', '     """"""\n', '     return _to_string_or_unicode_array(\n', ""         _vec_string(sep, object_, 'join', (seq,)))\n""]","['     See Also\n', '     --------\n', '     str.join\n', '     """"""\n', '     return _to_string_or_unicode_array(\n', ""         _vec_string(sep, object_, 'join', (seq,)))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     str.replace\n', '+    \n', '+    Examples\n', '+    --------\n', '+    >>> a = np.array([""That is a mango"", ""Monkeys eat mangos""])\n', ""+    >>> np.char.replace(a, 'mango', 'banana')\n"", ""+    array(['That is a banana', 'Monkeys eat bananas'], dtype='<U19')\n"", ' \n', '+    >>> a = np.array([""The dish is fresh"", ""This is it""])\n', ""+    >>> np.char.replace(a, 'is', 'was')\n"", ""+    array(['The dwash was fresh', 'Thwas was it'], dtype='<U19')\n"", '     """"""\n', '     return _to_string_or_unicode_array(\n', '         _vec_string(\n']","['     See Also\n', '     --------\n', '     str.replace\n', ' \n', '     """"""\n', '     return _to_string_or_unicode_array(\n', '         _vec_string(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     unicode.isnumeric\n', ' \n', '+    Examples\n', '+    --------\n', ""+    >>> np.char.isnumeric(['123', '123abc', '9.0', '1/4', 'VIII'])\n"", '+    array([ True, False, False, False, False])\n', '+\n', '     """"""\n', '     if _use_unicode(a) != unicode_:\n', '         raise TypeError(""isnumeric is only available for Unicode strings and arrays"")\n']","['     --------\n', '     unicode.isnumeric\n', ' \n', '     """"""\n', '     if _use_unicode(a) != unicode_:\n', '         raise TypeError(""isnumeric is only available for Unicode strings and arrays"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     unicode.isdecimal\n', ' \n', '+    Examples\n', '+    --------\n', ""+    >>> np.char.isdecimal(['12345', '4.99', '123ABC', ''])\n"", '+    array([ True, False, False, False])\n', '+\n', '+    """""" \n', '     if _use_unicode(a) != unicode_:\n', '         raise TypeError(""isnumeric is only available for Unicode strings and arrays"")\n', ""     return _vec_string(a, bool_, 'isdecimal')\n""]","['     --------\n', '     unicode.isdecimal\n', ' \n', '-    """"""\n', '     if _use_unicode(a) != unicode_:\n', '         raise TypeError(""isnumeric is only available for Unicode strings and arrays"")\n', ""     return _vec_string(a, bool_, 'isdecimal')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def decode(self, encoding=None, errors=None):\n', '         """"""\n', '+        Calls ``bytes.decode`` element-wise.\n', ' \n', '         See Also\n', '         --------\n']","[' \n', '     def decode(self, encoding=None, errors=None):\n', '         """"""\n', '-        Calls `str.decode` element-wise.\n', ' \n', '         See Also\n', '         --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if path_type is None:\n', '         path_type = False\n', ' \n', '+    explicit_einsum_path = False\n', '     memory_limit = None\n', ' \n', '     # No optimization or a named path algorithm\n']","['     if path_type is None:\n', '         path_type = False\n', ' \n', '     memory_limit = None\n', ' \n', '     # No optimization or a named path algorithm\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # Given an explicit path\n', ""     elif len(path_type) and (path_type[0] == 'einsum_path'):\n"", '+        explicit_einsum_path = True\n', ' \n', '     # Path tuple with memory limit\n', '     elif ((len(path_type) == 2) and isinstance(path_type[0], str) and\n']","[' \n', '     # Given an explicit path\n', ""     elif len(path_type) and (path_type[0] == 'einsum_path'):\n"", '-        pass\n', ' \n', '     # Path tuple with memory limit\n', '     elif ((len(path_type) == 2) and isinstance(path_type[0], str) and\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     naive_cost = _flop_count(indices, inner_product, len(input_list), dimension_dict)\n', ' \n', '     # Compute the path\n', '+    if explicit_einsum_path:\n', '+        path = path_type[1:]\n', '+    elif (\n', '+        (path_type is False)\n', '+        or (len(input_list) in [1, 2])\n', '+        or (indices == output_set)\n', '+    ):\n', '         # Nothing to be optimized, leave it to einsum\n', '         path = [tuple(range(len(input_list)))]\n', '     elif path_type == ""greedy"":\n', '         path = _greedy_path(input_sets, output_set, dimension_dict, memory_arg)\n', '     elif path_type == ""optimal"":\n', '         path = _optimal_path(input_sets, output_set, dimension_dict, memory_arg)\n', '     else:\n', '         raise KeyError(""Path name %s not found"", path_type)\n', ' \n']","['     naive_cost = _flop_count(indices, inner_product, len(input_list), dimension_dict)\n', ' \n', '     # Compute the path\n', '-    if (path_type is False) or (len(input_list) in [1, 2]) or (indices == output_set):\n', '         # Nothing to be optimized, leave it to einsum\n', '         path = [tuple(range(len(input_list)))]\n', '     elif path_type == ""greedy"":\n', '         path = _greedy_path(input_sets, output_set, dimension_dict, memory_arg)\n', '     elif path_type == ""optimal"":\n', '         path = _optimal_path(input_sets, output_set, dimension_dict, memory_arg)\n', ""-    elif path_type[0] == 'einsum_path':\n"", '-        path = path_type[1:]\n', '     else:\n', '         raise KeyError(""Path name %s not found"", path_type)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     opt_cost = sum(cost_list) + 1\n', ' \n', '+    if len(input_list) != 1:\n', '+        # Explicit ""einsum_path"" is usually trusted, but we detect this kind of\n', '+        # mistake in order to prevent from returning an intermediate value.\n', '+        raise RuntimeError(\n', '+            ""Invalid einsum_path is specified: {} more operands has to be ""\n', '+            ""contracted."".format(len(input_list) - 1))\n', '+\n', '     if einsum_call_arg:\n', '         return (operands, contraction_list)\n', ' \n']","[' \n', '     opt_cost = sum(cost_list) + 1\n', ' \n', '     if einsum_call_arg:\n', '         return (operands, contraction_list)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @array_function_dispatch(_transpose_dispatcher)\n', ' def transpose(a, axes=None):\n', '     """"""\n', '+    Returns an array with axes transposed.\n', '+\n', '+    For a 1-D array, this returns an unchanged view of the original array, as a\n', '+    transposed vector is simply the same vector.\n', '+    To convert a 1-D array into a 2-D column vector, an additional dimension\n', '+    must be added, e.g., ``np.atleast2d(a).T`` achieves this, as does\n', '+    ``a[:, np.newaxis]``.\n', '+    For a 2-D array, this is the standard matrix transpose.\n', '+    For an n-D array, if axes are given, their order indicates how the\n', '+    axes are permuted (see Examples). If axes are not provided, then\n', '+    ``transpose(a).shape == a.shape[::-1]``.\n', ' \n', '     Parameters\n', '     ----------\n', '     a : array_like\n', '         Input array.\n', '     axes : tuple or list of ints, optional\n', '+        If specified, it must be a tuple or list which contains a permutation\n', ""+        of [0,1,...,N-1] where N is the number of axes of `a`. The `i`'th axis\n"", '+        of the returned array will correspond to the axis numbered ``axes[i]``\n', '+        of the input. If not specified, defaults to ``range(a.ndim)[::-1]``,\n', '+        which reverses the order of the axes.\n', ' \n', '     Returns\n', '     -------\n', '     p : ndarray\n', '+        `a` with its axes permuted. A view is returned whenever possible.\n', ' \n', '     See Also\n', '     --------\n', '+    ndarray.transpose : Equivalent method.\n', '+    moveaxis : Move axes of an array to new positions.\n', '+    argsort : Return the indices that would sort an array.\n', ' \n', '     Notes\n', '     -----\n', '+    Use ``transpose(a, argsort(axes))`` to invert the transposition of tensors\n', '     when using the `axes` keyword argument.\n', ' \n', '     Examples\n', '     --------\n', '+    >>> a = np.array([[1, 2], [3, 4]])\n', '+    >>> a\n', '+    array([[1, 2],\n', '+           [3, 4]])\n', '+    >>> np.transpose(a)\n', '+    array([[1, 3],\n', '+           [2, 4]])\n', ' \n', '+    >>> a = np.array([1, 2, 3, 4])\n', '+    >>> a\n', '+    array([1, 2, 3, 4])\n', '+    >>> np.transpose(a)\n', '+    array([1, 2, 3, 4])\n', ' \n', '+    >>> a = np.ones((1, 2, 3))\n', '+    >>> np.transpose(a, (1, 0, 2)).shape\n', '     (2, 1, 3)\n', ' \n', '+    >>> a = np.ones((2, 3, 4, 5))\n', '+    >>> np.transpose(a).shape\n', '     (5, 4, 3, 2)\n', ' \n', '     """"""\n']","[' @array_function_dispatch(_transpose_dispatcher)\n', ' def transpose(a, axes=None):\n', '     """"""\n', '-    Reverse or permute the axes of an array; returns the modified array.\n', '-\n', '-    For an array a with two axes, transpose(a) gives the matrix transpose.\n', '-\n', '-    Refer to `numpy.ndarray.transpose` for full documentation.\n', ' \n', '     Parameters\n', '     ----------\n', '     a : array_like\n', '         Input array.\n', '     axes : tuple or list of ints, optional\n', '-        If specified, it must be a tuple or list which contains a permutation of\n', ""-        [0,1,..,N-1] where N is the number of axes of a.  The i'th axis of the\n"", '-        returned array will correspond to the axis numbered ``axes[i]`` of the\n', '-        input.  If not specified, defaults to ``range(a.ndim)[::-1]``, which\n', '-        reverses the order of the axes.\n', ' \n', '     Returns\n', '     -------\n', '     p : ndarray\n', '-        `a` with its axes permuted.  A view is returned whenever\n', '-        possible.\n', ' \n', '     See Also\n', '     --------\n', '-    ndarray.transpose : Equivalent method\n', '-    moveaxis\n', '-    argsort\n', ' \n', '     Notes\n', '     -----\n', '-    Use `transpose(a, argsort(axes))` to invert the transposition of tensors\n', '     when using the `axes` keyword argument.\n', ' \n', '-    Transposing a 1-D array returns an unchanged view of the original array.\n', '-\n', '     Examples\n', '     --------\n', '-    >>> x = np.arange(4).reshape((2,2))\n', '-    >>> x\n', '-    array([[0, 1],\n', '-           [2, 3]])\n', ' \n', '-    >>> np.transpose(x)\n', '-    array([[0, 2],\n', '-           [1, 3]])\n', ' \n', '-    >>> x = np.ones((1, 2, 3))\n', '-    >>> np.transpose(x, (1, 0, 2)).shape\n', '     (2, 1, 3)\n', ' \n', '-    >>> x = np.ones((2, 3, 4, 5))\n', '-    >>> np.transpose(x).shape\n', '     (5, 4, 3, 2)\n', ' \n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Return a partitioned copy of an array.\n', ' \n', '     Creates a copy of the array with its elements rearranged in such a\n', '+    way that the value of the element in k-th position is in the position\n', '+    the value would be in a sorted array.  In the partitioned array, all\n', '+    elements before the k-th element are less than or equal to that\n', '+    element, and all the elements after the k-th element are greater than\n', '+    or equal to that element.  The ordering of the elements in the two\n', '     partitions is undefined.\n', ' \n', '     .. versionadded:: 1.8.0\n']","['     Return a partitioned copy of an array.\n', ' \n', '     Creates a copy of the array with its elements rearranged in such a\n', '-    way that the value of the element in k-th position is in the\n', '-    position it would be in a sorted array. All elements smaller than\n', '-    the k-th element are moved before this element and all equal or\n', '-    greater are moved behind it. The ordering of the elements in the two\n', '     partitions is undefined.\n', ' \n', '     .. versionadded:: 1.8.0\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Examples\n', '     --------\n', '+    >>> a = np.array([7, 1, 7, 7, 1, 5, 7, 2, 3, 2, 6, 2, 3, 0])\n', '+    >>> p = np.partition(a, 4)\n', '+    >>> p\n', '+    array([0, 1, 2, 1, 2, 5, 2, 3, 3, 6, 7, 7, 7, 7])\n', ' \n', '+    ``p[4]`` is 2;  all elements in ``p[:4]`` are less than or equal\n', '+    to ``p[4]``, and all elements in ``p[5:]`` are greater than or\n', '+    equal to ``p[4]``.  The partition is::\n', '+\n', '+        [0, 1, 2, 1], [2], [5, 2, 3, 3, 6, 7, 7, 7, 7]\n', ' \n', '+    The next example shows the use of multiple values passed to `kth`.\n', '+\n', '+    >>> p2 = np.partition(a, (4, 8))\n', '+    >>> p2\n', '+    array([0, 1, 2, 1, 2, 3, 3, 2, 5, 6, 7, 7, 7, 7])\n', '+\n', '+    ``p2[4]`` is 2  and ``p2[8]`` is 5.  All elements in ``p2[:4]``\n', '+    are less than or equal to ``p2[4]``, all elements in ``p2[5:8]``\n', '+    are greater than or equal to ``p2[4]`` and less than or equal to\n', '+    ``p2[8]``, and all elements in ``p2[9:]`` are greater than or\n', '+    equal to ``p2[8]``.  The partition is::\n', '+\n', '+        [0, 1, 2, 1], [2], [3, 3, 2], [5], [6, 7, 7, 7, 7]\n', '     """"""\n', '     if axis is None:\n', '         # flatten returns (1, N) for np.matrix, so always use the last axis\n']","[' \n', '     Examples\n', '     --------\n', '-    >>> a = np.array([3, 4, 2, 1])\n', '-    >>> np.partition(a, 3)\n', '-    array([2, 1, 3, 4])\n', ' \n', '-    >>> np.partition(a, (1, 3))\n', '-    array([1, 2, 3, 4])\n', ' \n', '     """"""\n', '     if axis is None:\n', '         # flatten returns (1, N) for np.matrix, so always use the last axis\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     kth : int or sequence of ints\n', '         Element index to partition by. The k-th element will be in its\n', '         final sorted position and all smaller elements will be moved\n', '+        before it and all larger elements behind it. The order of all\n', '         elements in the partitions is undefined. If provided with a\n', '         sequence of k-th it will partition all of them into their sorted\n', '         position at once.\n']","['     kth : int or sequence of ints\n', '         Element index to partition by. The k-th element will be in its\n', '         final sorted position and all smaller elements will be moved\n', '-        before it and all larger elements behind it. The order all\n', '         elements in the partitions is undefined. If provided with a\n', '         sequence of k-th it will partition all of them into their sorted\n', '         position at once.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     index_array : ndarray, int\n', '         Array of indices that partition `a` along the specified axis.\n', '         If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.\n', '+        More generally, ``np.take_along_axis(a, index_array, axis=axis)``\n', '         always yields the partitioned `a`, irrespective of dimensionality.\n', ' \n', '     See Also\n']","['     index_array : ndarray, int\n', '         Array of indices that partition `a` along the specified axis.\n', '         If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.\n', '-        More generally, ``np.take_along_axis(a, index_array, axis)``\n', '         always yields the partitioned `a`, irrespective of dimensionality.\n', ' \n', '     See Also\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Returns\n', '     -------\n', '+    ptp : ndarray or scalar\n', '+        The range of a given array - `scalar` if array is one-dimensional\n', '+        or a new array holding the result along the given axis\n', ' \n', '     Examples\n', '     --------\n']","[' \n', '     Returns\n', '     -------\n', '-    ptp : ndarray\n', '-        A new array holding the result, unless `out` was\n', '-        specified, in which case a reference to `out` is returned.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -------\n', '     amax : ndarray or scalar\n', '         Maximum of `a`. If `axis` is None, the result is a scalar value.\n', '+        If `axis` is an int, the result is an array of dimension\n', '+        ``a.ndim - 1``. If `axis` is a tuple, the result is an array of \n', '+        dimension ``a.ndim - len(axis)``.\n', ' \n', '     See Also\n', '     --------\n']","['     -------\n', '     amax : ndarray or scalar\n', '         Maximum of `a`. If `axis` is None, the result is a scalar value.\n', '-        If `axis` is given, the result is an array of dimension\n', '-        ``a.ndim - 1``.\n', ' \n', '     See Also\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -------\n', '     amin : ndarray or scalar\n', '         Minimum of `a`. If `axis` is None, the result is a scalar value.\n', '+        If `axis` is an int, the result is an array of dimension\n', '+        ``a.ndim - 1``.  If `axis` is a tuple, the result is an array of \n', '+        dimension ``a.ndim - len(axis)``.\n', ' \n', '     See Also\n', '     --------\n']","['     -------\n', '     amin : ndarray or scalar\n', '         Minimum of `a`. If `axis` is None, the result is a scalar value.\n', '-        If `axis` is given, the result is an array of dimension\n', '-        ``a.ndim - 1``.\n', ' \n', '     See Also\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Even when the input array is two-dimensional:\n', ' \n', '+    >>> a = np.array([[1., 2.], [3., 4.]])\n', '+    >>> np.prod(a)\n', '     24.0\n', ' \n', '     But we can also specify the axis over which to multiply:\n', ' \n', '+    >>> np.prod(a, axis=1)\n', '     array([  2.,  12.])\n', '+    >>> np.prod(a, axis=0)\n', '+    array([3., 8.])\n', '+    \n', '     Or select specific elements to include:\n', ' \n', '     >>> np.prod([1., np.nan, 3.], where=[True, False, True])\n']","[' \n', '     Even when the input array is two-dimensional:\n', ' \n', '-    >>> np.prod([[1.,2.],[3.,4.]])\n', '     24.0\n', ' \n', '     But we can also specify the axis over which to multiply:\n', ' \n', '-    >>> np.prod([[1.,2.],[3.,4.]], axis=1)\n', '     array([  2.,  12.])\n', '-\n', '     Or select specific elements to include:\n', ' \n', '     >>> np.prod([1., np.nan, 3.], where=[True, False, True])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     See Also\n', '     --------\n', '     ndarray.round : equivalent method\n', '     ceil, fix, floor, rint, trunc\n', ' \n', ' \n', '     Notes\n', '     -----\n', '+    `~numpy.round` is often used as an alias for `~numpy.around`.\n', '+    \n', '     For values exactly halfway between rounded decimal values, NumPy\n', '     rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n', '     -0.5 and 0.5 round to 0.0, etc.\n']","['     See Also\n', '     --------\n', '     ndarray.round : equivalent method\n', '-\n', '     ceil, fix, floor, rint, trunc\n', ' \n', ' \n', '     Notes\n', '     -----\n', '     For values exactly halfway between rounded decimal values, NumPy\n', '     rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n', '     -0.5 and 0.5 round to 0.0, etc.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 scale (a geometric progression).\n', '     logspace : Similar to `geomspace`, but with the end points specified as\n', '                logarithms.\n', '+    :ref:`how-to-partition`\n', ' \n', '     Examples\n', '     --------\n']","['                 scale (a geometric progression).\n', '     logspace : Similar to `geomspace`, but with the end points specified as\n', '                logarithms.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     dt = result_type(start, stop, float(num))\n', '     if dtype is None:\n', '         dtype = dt\n', '+        integer_dtype = False\n', '+    else:\n', '+        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n', ' \n', '     delta = stop - start\n', '     y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))\n', '     # In-place multiplication y *= delta/div is faster, but prevents the multiplicant\n', '     # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n', '     # see gh-7142. Hence, we multiply in place only for standard scalar types.\n', '     if div > 0:\n', '+        _mult_inplace = _nx.isscalar(delta)\n', '         step = delta / div\n', '+        any_step_zero = (\n', '+            step == 0 if _mult_inplace else _nx.asanyarray(step == 0).any())\n', '+        if any_step_zero:\n', '             # Special handling for denormal numbers, gh-5437\n', '             y /= div\n', '             if _mult_inplace:\n']","['     dt = result_type(start, stop, float(num))\n', '     if dtype is None:\n', '         dtype = dt\n', ' \n', '     delta = stop - start\n', '     y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))\n', '     # In-place multiplication y *= delta/div is faster, but prevents the multiplicant\n', '     # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n', '     # see gh-7142. Hence, we multiply in place only for standard scalar types.\n', '-    _mult_inplace = _nx.isscalar(delta)\n', '     if div > 0:\n', '         step = delta / div\n', '-        if _nx.any(step == 0):\n', '             # Special handling for denormal numbers, gh-5437\n', '             y /= div\n', '             if _mult_inplace:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if axis != 0:\n', '         y = _nx.moveaxis(y, 0, axis)\n', ' \n', '+    if integer_dtype:\n', '         _nx.floor(y, out=y)\n', ' \n', '     if retstep:\n']","['     if axis != 0:\n', '         y = _nx.moveaxis(y, 0, axis)\n', ' \n', '-    if _nx.issubdtype(dtype, _nx.integer):\n', '         _nx.floor(y, out=y)\n', ' \n', '     if retstep:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     linspace : Similar to logspace, but with the samples uniformly distributed\n', '                in linear space, instead of log space.\n', '     geomspace : Similar to logspace, but with endpoints specified directly.\n', '+    :ref:`how-to-partition`\n', ' \n', '     Notes\n', '     -----\n']","['     linspace : Similar to logspace, but with the samples uniformly distributed\n', '                in linear space, instead of log space.\n', '     geomspace : Similar to logspace, but with endpoints specified directly.\n', ' \n', '     Notes\n', '     -----\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                progression.\n', '     arange : Similar to linspace, with the step size specified instead of the\n', '              number of samples.\n', '+    :ref:`how-to-partition`\n', ' \n', '     Notes\n', '     -----\n']","['                progression.\n', '     arange : Similar to linspace, with the step size specified instead of the\n', '              number of samples.\n', ' \n', '     Notes\n', '     -----\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return ma_like\n', '     # Fall back to parameter discovery\n', '     warnings.warn(\n', ""+        f'Signature {key} for {ftype} does not match any known type: '\n"", ""+        'falling back to type probe function.\\n'\n"", ""+        'This warnings indicates broken support for the dtype!',\n"", '         UserWarning, stacklevel=2)\n', '     return _discovered_machar(ftype)\n', ' \n']","['         return ma_like\n', '     # Fall back to parameter discovery\n', '     warnings.warn(\n', ""-        'Signature {} for {} does not match any known type: '\n"", ""-        'falling back to type probe function'.format(key, ftype),\n"", '         UserWarning, stacklevel=2)\n', '     return _discovered_machar(ftype)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ----------\n', '     bits : int\n', '         The number of bits occupied by the type.\n', '+    dtype : dtype\n', '+        Returns the dtype for which `finfo` returns information. For complex\n', '+        input, the returned dtype is the associated ``float*`` dtype for its\n', '+        real and complex components.\n', '     eps : float\n', '         The difference between 1.0 and the next smallest representable float\n', '         larger than 1.0. For example, for 64-bit binary floats in the IEEE-754\n']","['     ----------\n', '     bits : int\n', '         The number of bits occupied by the type.\n', '     eps : float\n', '         The difference between 1.0 and the next smallest representable float\n', '         larger than 1.0. For example, for 64-bit binary floats in the IEEE-754\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Parameters\n', '     ----------\n', '     dtype : float, dtype, or instance\n', '+        Kind of floating point or complex floating point\n', '+        data-type about which to get information.\n', ' \n', '     See Also\n', '     --------\n']","['     Parameters\n', '     ----------\n', '     dtype : float, dtype, or instance\n', '-        Kind of floating point data-type about which to get information.\n', ' \n', '     See Also\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     fill the gap between 0 and ``smallest_normal``. However, subnormal numbers\n', '     may have significantly reduced precision [2]_.\n', ' \n', '+    This function can also be used for complex data types as well. If used,\n', '+    the output will be the same as the corresponding real float type\n', '+    (e.g. numpy.finfo(numpy.csingle) is the same as numpy.finfo(numpy.single)).\n', '+    However, the output is true for the real and imaginary components.\n', '+\n', '     References\n', '     ----------\n', '     .. [1] IEEE Standard for Floating-Point Arithmetic, IEEE Std 754-2008,\n', '            pp.1-70, 2008, http://www.doi.org/10.1109/IEEESTD.2008.4610935\n', '     .. [2] Wikipedia, ""Denormal Numbers"",\n', '            https://en.wikipedia.org/wiki/Denormal_number\n', '+\n', '+    Examples\n', '+    --------\n', '+    >>> np.finfo(np.float64).dtype\n', ""+    dtype('float64')\n"", '+    >>> np.finfo(np.complex64).dtype\n', ""+    dtype('float32')\n"", '+\n', '     """"""\n', ' \n', '     _finfo_cache = {}\n']","['     fill the gap between 0 and ``smallest_normal``. However, subnormal numbers\n', '     may have significantly reduced precision [2]_.\n', ' \n', '     References\n', '     ----------\n', '     .. [1] IEEE Standard for Floating-Point Arithmetic, IEEE Std 754-2008,\n', '            pp.1-70, 2008, http://www.doi.org/10.1109/IEEESTD.2008.4610935\n', '     .. [2] Wikipedia, ""Denormal Numbers"",\n', '            https://en.wikipedia.org/wiki/Denormal_number\n', '     """"""\n', ' \n', '     _finfo_cache = {}\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ----------\n', '     bits : int\n', '         The number of bits occupied by the type.\n', '+    dtype : dtype\n', '+        Returns the dtype for which `iinfo` returns information.\n', '     min : int\n', '         The smallest integer expressible by the type.\n', '     max : int\n']","['     ----------\n', '     bits : int\n', '         The number of bits occupied by the type.\n', '     min : int\n', '         The smallest integer expressible by the type.\n', '     max : int\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # do not change them. issue gh-15518\n', ' # _get_ndarray_c_version is semi-public, on purpose not added to __all__\n', ' from ._multiarray_umath import (\n', '+    fastCopyAndTranspose, _flagdict, from_dlpack, _insert, _reconstruct,\n', '     _vec_string, _ARRAY_API, _monotonicity, _get_ndarray_c_version,\n', '     _get_madvise_hugepage, _set_madvise_hugepage,\n', '+    _get_promotion_state, _set_promotion_state,\n', '     )\n', ' \n', ' __all__ = [\n', ""     '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',\n"", ""     'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',\n"", ""     'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',\n"", ""+    'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP',\n"", ""     '_flagdict', 'from_dlpack', '_insert', '_reconstruct', '_vec_string',\n"", ""     '_monotonicity', 'add_docstring', 'arange', 'array', 'asarray',\n"", ""     'asanyarray', 'ascontiguousarray', 'asfortranarray', 'bincount',\n""]","[' # do not change them. issue gh-15518\n', ' # _get_ndarray_c_version is semi-public, on purpose not added to __all__\n', ' from ._multiarray_umath import (\n', '-    _fastCopyAndTranspose, _flagdict, from_dlpack, _insert, _reconstruct,\n', '     _vec_string, _ARRAY_API, _monotonicity, _get_ndarray_c_version,\n', '     _get_madvise_hugepage, _set_madvise_hugepage,\n', '     )\n', ' \n', ' __all__ = [\n', ""     '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',\n"", ""     'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',\n"", ""     'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',\n"", ""-    'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',\n"", ""     '_flagdict', 'from_dlpack', '_insert', '_reconstruct', '_vec_string',\n"", ""     '_monotonicity', 'add_docstring', 'arange', 'array', 'asarray',\n"", ""     'asanyarray', 'ascontiguousarray', 'asfortranarray', 'bincount',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     'ravel_multi_index', 'result_type', 'scalar', 'set_datetimeparse_function',\n"", ""     'set_legacy_print_mode', 'set_numeric_ops', 'set_string_function',\n"", ""     'set_typeDict', 'shares_memory', 'tracemalloc_domain', 'typeinfo',\n"", ""+    'unpackbits', 'unravel_index', 'vdot', 'where', 'zeros',\n"", ""+    '_get_promotion_state', '_set_promotion_state']\n"", ' \n', ' # For backward compatibility, make sure pickle imports these functions from here\n', "" _reconstruct.__module__ = 'numpy.core.multiarray'\n""]","[""     'ravel_multi_index', 'result_type', 'scalar', 'set_datetimeparse_function',\n"", ""     'set_legacy_print_mode', 'set_numeric_ops', 'set_string_function',\n"", ""     'set_typeDict', 'shares_memory', 'tracemalloc_domain', 'typeinfo',\n"", ""-    'unpackbits', 'unravel_index', 'vdot', 'where', 'zeros']\n"", ' \n', ' # For backward compatibility, make sure pickle imports these functions from here\n', "" _reconstruct.__module__ = 'numpy.core.multiarray'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" set_numeric_ops.__module__ = 'numpy'\n"", "" seterrobj.__module__ = 'numpy'\n"", "" zeros.__module__ = 'numpy'\n"", ""+_get_promotion_state.__module__ = 'numpy'\n"", ""+_set_promotion_state.__module__ = 'numpy'\n"", ' \n', ' \n', "" # We can't verify dispatcher signatures because NumPy's C functions don't\n""]","["" set_numeric_ops.__module__ = 'numpy'\n"", "" seterrobj.__module__ = 'numpy'\n"", "" zeros.__module__ = 'numpy'\n"", ' \n', ' \n', "" # We can't verify dispatcher signatures because NumPy's C functions don't\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         np.inner(a, b) = sum(a[:]*b[:])\n', ' \n', '+    More generally, if ``ndim(a) = r > 0`` and ``ndim(b) = s > 0``::\n', ' \n', '         np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))\n', ' \n']","[' \n', '         np.inner(a, b) = sum(a[:]*b[:])\n', ' \n', '-    More generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`::\n', ' \n', '         np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n', '       but using :func:`matmul` or ``a @ b`` is preferred.\n', ' \n', '+    - If either `a` or `b` is 0-D (scalar), it is equivalent to\n', '+      :func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b`` is\n', '+      preferred.\n', ' \n', '     - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n', '       the last axis of `a` and `b`.\n', ' \n', '     - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n', '+      sum product over the last axis of `a` and the second-to-last axis of\n', '+      `b`::\n', ' \n', '         dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n', ' \n', '+    It uses an optimized BLAS library when possible (see `numpy.linalg`).\n', '+\n', '     Parameters\n', '     ----------\n', '     a : array_like\n']","['     - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n', '       but using :func:`matmul` or ``a @ b`` is preferred.\n', ' \n', '-    - If either `a` or `b` is 0-D (scalar), it is equivalent to :func:`multiply`\n', '-      and using ``numpy.multiply(a, b)`` or ``a * b`` is preferred.\n', ' \n', '     - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n', '       the last axis of `a` and `b`.\n', ' \n', '     - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n', '-      sum product over the last axis of `a` and the second-to-last axis of `b`::\n', ' \n', '         dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n', ' \n', '     Parameters\n', '     ----------\n', '     a : array_like\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         A boolean array which is broadcasted to match the dimensions\n', '         of `dst`, and selects elements to copy from `src` to `dst`\n', '         wherever it contains the value True.\n', '+\n', '+    Examples\n', '+    --------\n', '+    >>> A = np.array([4, 5, 6])\n', '+    >>> B = [1, 2, 3]\n', '+    >>> np.copyto(A, B)\n', '+    >>> A\n', '+    array([1, 2, 3])\n', '+\n', '+    >>> A = np.array([[1, 2, 3], [4, 5, 6]])\n', '+    >>> B = [[4, 5, 6], [7, 8, 9]]\n', '+    >>> np.copyto(A, B)\n', '+    >>> A\n', '+    array([[4, 5, 6],\n', '+           [7, 8, 9]])\n', '+       \n', '     """"""\n', '     return (dst, src, where)\n', ' \n']","['         A boolean array which is broadcasted to match the dimensions\n', '         of `dst`, and selects elements to copy from `src` to `dst`\n', '         wherever it contains the value True.\n', '     """"""\n', '     return (dst, src, where)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy as np\n', ' from . import multiarray\n', ' from .multiarray import (\n', '+    fastCopyAndTranspose, ALLOW_THREADS,\n', '     BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT, RAISE,\n', '     WRAP, arange, array, asarray, asanyarray, ascontiguousarray,\n', '     asfortranarray, broadcast, can_cast, compare_chararrays,\n']","[' import numpy as np\n', ' from . import multiarray\n', ' from .multiarray import (\n', '-    _fastCopyAndTranspose as fastCopyAndTranspose, ALLOW_THREADS,\n', '     BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT, RAISE,\n', '     WRAP, arange, array, asarray, asanyarray, ascontiguousarray,\n', '     asfortranarray, broadcast, can_cast, compare_chararrays,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     fromstring, inner, lexsort, matmul, may_share_memory,\n', '     min_scalar_type, ndarray, nditer, nested_iters, promote_types,\n', '     putmask, result_type, set_numeric_ops, shares_memory, vdot, where,\n', '+    zeros, normalize_axis_index, _get_promotion_state, _set_promotion_state)\n', ' \n', ' from . import overrides\n', ' from . import umath\n']","['     fromstring, inner, lexsort, matmul, may_share_memory,\n', '     min_scalar_type, ndarray, nditer, nested_iters, promote_types,\n', '     putmask, result_type, set_numeric_ops, shares_memory, vdot, where,\n', '-    zeros, normalize_axis_index)\n', ' \n', ' from . import overrides\n', ' from . import umath\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from . import numerictypes\n', ' from .numerictypes import longlong, intc, int_, float_, complex_, bool_\n', ' from ._exceptions import TooHardError, AxisError\n', '+from ._ufunc_config import errstate, _no_nep50_warning\n', ' \n', ' bitwise_not = invert\n', ' ufunc = type(sin)\n']","[' from . import numerictypes\n', ' from .numerictypes import longlong, intc, int_, float_, complex_, bool_\n', ' from ._exceptions import TooHardError, AxisError\n', '-from ._ufunc_config import errstate\n', ' \n', ' bitwise_not = invert\n', ' ufunc = type(sin)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     'False_', 'True_', 'bitwise_not', 'CLIP', 'RAISE', 'WRAP', 'MAXDIMS',\n"", ""     'BUFSIZE', 'ALLOW_THREADS', 'ComplexWarning', 'full', 'full_like',\n"", ""     'matmul', 'shares_memory', 'may_share_memory', 'MAY_SHARE_BOUNDS',\n"", ""+    'MAY_SHARE_EXACT', 'TooHardError', 'AxisError',\n"", ""+    '_get_promotion_state', '_set_promotion_state']\n"", ' \n', ' \n', "" @set_module('numpy')\n""]","[""     'False_', 'True_', 'bitwise_not', 'CLIP', 'RAISE', 'WRAP', 'MAXDIMS',\n"", ""     'BUFSIZE', 'ALLOW_THREADS', 'ComplexWarning', 'full', 'full_like',\n"", ""     'matmul', 'shares_memory', 'may_share_memory', 'MAY_SHARE_BOUNDS',\n"", ""-    'MAY_SHARE_EXACT', 'TooHardError', 'AxisError']\n"", ' \n', ' \n', "" @set_module('numpy')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     This function computes the correlation as generally defined in signal\n', '     processing texts:\n', ' \n', '+    .. math:: c_k = \\sum_n a_{n+k} \\cdot \\overline{v}_n\n', ' \n', '     with a and v sequences being zero-padded where necessary and\n', '     :math:`\\overline x` denoting complex conjugation.\n']","['     This function computes the correlation as generally defined in signal\n', '     processing texts:\n', ' \n', '-    .. math:: c_k = \\sum_n a_{n+k} \\cdot \\overline{v_n}\n', ' \n', '     with a and v sequences being zero-padded where necessary and\n', '     :math:`\\overline x` denoting complex conjugation.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     dtype = promote_types(a.dtype, b.dtype)\n', '     cp = empty(shape, dtype)\n', ' \n', '+    # recast arrays as dtype\n', '+    a = a.astype(dtype)\n', '+    b = b.astype(dtype)\n', '+\n', '     # create local aliases for readability\n', '     a0 = a[..., 0]\n', '     a1 = a[..., 1]\n']","['     dtype = promote_types(a.dtype, b.dtype)\n', '     cp = empty(shape, dtype)\n', ' \n', '     # create local aliases for readability\n', '     a0 = a[..., 0]\n', '     a1 = a[..., 1]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Notes\n', '     -----\n', '+    Keywords other than `dtype` and `like` are passed to `function`.\n', ' \n', '     Examples\n', '     --------\n']","[' \n', '     Notes\n', '     -----\n', '-    Keywords other than `dtype` are passed to `function`.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     array([False,  True])\n', '     """"""\n', '     def within_tol(x, y, atol, rtol):\n', ""+        with errstate(invalid='ignore'), _no_nep50_warning():\n"", '             return less_equal(abs(x-y), atol + rtol * abs(y))\n', ' \n', '     x = asanyarray(a)\n']","['     array([False,  True])\n', '     """"""\n', '     def within_tol(x, y, atol, rtol):\n', ""-        with errstate(invalid='ignore'):\n"", '             return less_equal(abs(x-y), atol + rtol * abs(y))\n', ' \n', '     x = asanyarray(a)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['      |   |   |     byte\n', '      |   |   |     short\n', '      |   |   |     intc\n', '+     |   |   |     intp\n', '      |   |   |     int_\n', '      |   |   |     longlong\n', '      |   |   \\\\-> unsignedinteger  (uintxx)     (kind=u)\n', '      |   |         ubyte\n', '      |   |         ushort\n', '      |   |         uintc\n', '+     |   |         uintp\n', '      |   |         uint_\n', '      |   |         ulonglong\n', '      |   +-> inexact\n']","['      |   |   |     byte\n', '      |   |   |     short\n', '      |   |   |     intc\n', '-     |   |   |     intp            int0\n', '      |   |   |     int_\n', '      |   |   |     longlong\n', '      |   |   \\\\-> unsignedinteger  (uintxx)     (kind=u)\n', '      |   |         ubyte\n', '      |   |         ushort\n', '      |   |         uintc\n', '-     |   |         uintp           uint0\n', '      |   |         uint_\n', '      |   |         ulonglong\n', '      |   +-> inexact\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         @functools.wraps(implementation)\n', '         def public_api(*args, **kwargs):\n', '+            try:\n', '+                relevant_args = dispatcher(*args, **kwargs)\n', '+            except TypeError as exc:\n', '+                # Try to clean up a signature related TypeError.  Such an\n', '+                # error will be something like:\n', '+                #     dispatcher.__name__() got an unexpected keyword argument\n', '+                #\n', '+                # So replace the dispatcher name in this case.  In principle\n', '+                # TypeErrors may be raised from _within_ the dispatcher, so\n', '+                # we check that the traceback contains a string that starts\n', '+                # with the name.  (In principle we could also check the\n', '+                # traceback length, as it would be deeper.)\n', '+                msg = exc.args[0]\n', '+                disp_name = dispatcher.__name__\n', '+                if not isinstance(msg, str) or not msg.startswith(disp_name):\n', '+                    raise\n', '+\n', '+                # Replace with the correct name and re-raise:\n', '+                new_msg = msg.replace(disp_name, public_api.__name__)\n', '+                raise TypeError(new_msg) from None\n', '+\n', '             return implement_array_function(\n', '                 implementation, public_api, relevant_args, args, kwargs)\n', ' \n']","[' \n', '         @functools.wraps(implementation)\n', '         def public_api(*args, **kwargs):\n', '-            relevant_args = dispatcher(*args, **kwargs)\n', '             return implement_array_function(\n', '                 implementation, public_api, relevant_args, args, kwargs)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import pathlib\n', ' import sys\n', ' import textwrap\n', ' \n', ' from numpy.distutils.misc_util import mingw32\n', ' \n']","[' import pathlib\n', ' import sys\n', ' import textwrap\n', '-import warnings\n', ' \n', ' from numpy.distutils.misc_util import mingw32\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # (*not* C_ABI_VERSION) would be increased.  Whenever binary compatibility is\n', ' # broken, both C_API_VERSION and C_ABI_VERSION should be increased.\n', ' #\n', '+# The version needs to be kept in sync with that in cversions.txt.\n', '+#\n', ' # 0x00000008 - 1.7.x\n', ' # 0x00000009 - 1.8.x\n', ' # 0x00000009 - 1.9.x\n']","[' # (*not* C_ABI_VERSION) would be increased.  Whenever binary compatibility is\n', ' # broken, both C_API_VERSION and C_ABI_VERSION should be increased.\n', ' #\n', ' # 0x00000008 - 1.7.x\n', ' # 0x00000009 - 1.8.x\n', ' # 0x00000009 - 1.9.x\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # 0x0000000e - 1.20.x\n', ' # 0x0000000e - 1.21.x\n', ' # 0x0000000f - 1.22.x\n', '+# 0x00000010 - 1.23.x\n', '+# 0x00000010 - 1.24.x\n', '+C_API_VERSION = 0x00000010\n', ' \n', '+class MismatchCAPIError(ValueError):\n', '     pass\n', ' \n', ' \n']","[' # 0x0000000e - 1.20.x\n', ' # 0x0000000e - 1.21.x\n', ' # 0x0000000f - 1.22.x\n', '-# 0x0000000f - 1.23.x\n', '-C_API_VERSION = 0x0000000f\n', ' \n', '-class MismatchCAPIWarning(Warning):\n', '     pass\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # To compute the checksum of the current API, use numpy/core/cversions.py\n', '     if not curapi_hash == api_hash:\n', '         msg = (""API mismatch detected, the C API version ""\n', '+               ""numbers have to be updated. Current C api version is ""\n', '+               f""{apiversion}, with checksum {curapi_hash}, but recorded ""\n', '+               f""checksum in core/codegen_dir/cversions.txt is {api_hash}. If ""\n', '+               ""functions were added in the C API, you have to update ""\n', '+               f""C_API_VERSION in {__file__}.""\n', '                )\n', '+        raise MismatchCAPIError(msg)\n', ' \n', ' \n', ' FUNC_CALL_ARGS = {}\n']","['     # To compute the checksum of the current API, use numpy/core/cversions.py\n', '     if not curapi_hash == api_hash:\n', '         msg = (""API mismatch detected, the C API version ""\n', '-               ""numbers have to be updated. Current C api version is %d, ""\n', '-               ""with checksum %s, but recorded checksum for C API version %d ""\n', '-               ""in core/codegen_dir/cversions.txt is %s. If functions were ""\n', '-               ""added in the C API, you have to update C_API_VERSION in %s.""\n', '                )\n', '-        warnings.warn(msg % (apiversion, curapi_hash, apiversion, api_hash,\n', '-                             __file__),\n', '-                      MismatchCAPIWarning, stacklevel=2)\n', ' \n', ' \n', ' FUNC_CALL_ARGS = {}\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     args = args.rpartition("")"")[0]\n', '     funcname = prefix.rpartition("" "")[-1]\n', '     args = [arg.strip() for arg in args.split("","")]\n', '+    # We use {0} because 0 alone cannot be cast to complex on MSVC in C:\n', '+    FUNC_CALL_ARGS[funcname] = "", "".join(""(%s){0}"" % arg for arg in args)\n', ' \n', ' \n', ' for file in [\n', '     ""feature_detection_locale.h"",\n', '     ""feature_detection_math.h"",\n', '+    ""feature_detection_cmath.h"",\n', '     ""feature_detection_misc.h"",\n', '     ""feature_detection_stdio.h"",\n', ' ]:\n']","['     args = args.rpartition("")"")[0]\n', '     funcname = prefix.rpartition("" "")[-1]\n', '     args = [arg.strip() for arg in args.split("","")]\n', '-    FUNC_CALL_ARGS[funcname] = "", "".join(""(%s) 0"" % arg for arg in args)\n', ' \n', ' \n', ' for file in [\n', '     ""feature_detection_locale.h"",\n', '     ""feature_detection_math.h"",\n', '     ""feature_detection_misc.h"",\n', '     ""feature_detection_stdio.h"",\n', ' ]:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             set_sig(line)\n', ' \n', ' # Mandatory functions: if not found, fail the build\n', '+# Some of these can still be blocklisted if the C99 implementation\n', '+# is buggy, see numpy/core/src/common/npy_config.h\n', '+MANDATORY_FUNCS = [\n', '+    ""sin"", ""cos"", ""tan"", ""sinh"", ""cosh"", ""tanh"", ""fabs"",\n', '+    ""floor"", ""ceil"", ""sqrt"", ""log10"", ""log"", ""exp"", ""asin"",\n', '+    ""acos"", ""atan"", ""fmod"", \'modf\', \'frexp\', \'ldexp\',\n', '+    ""expm1"", ""log1p"", ""acosh"", ""asinh"", ""atanh"",\n', '+    ""rint"", ""trunc"", ""exp2"", \n', '+    ""copysign"", ""nextafter"", ""strtoll"", ""strtoull"", ""cbrt"",\n', '+    ""log2"", ""pow"", ""hypot"", ""atan2"",\n', '+    ""csin"", ""csinh"", ""ccos"", ""ccosh"", ""ctan"", ""ctanh"",\n', '+    ""creal"", ""cimag"", ""conj""\n', '+]\n', ' \n', ' OPTIONAL_LOCALE_FUNCS = [""strtold_l""]\n', ' OPTIONAL_FILE_FUNCS = [""ftello"", ""fseeko"", ""fallocate""]\n', ' OPTIONAL_MISC_FUNCS = [""backtrace"", ""madvise""]\n', ' \n', '+# variable attributes tested via ""int %s a"" % attribute\n', '+OPTIONAL_VARIABLE_ATTRIBUTES = [""__thread"", ""__declspec(thread)""]\n', '+\n', '+# Subset of OPTIONAL_*_FUNCS which may already have HAVE_* defined by Python.h\n', '+OPTIONAL_FUNCS_MAYBE = [\n', '+    ""ftello"", ""fseeko""\n', '+    ]\n', '+\n', '+C99_COMPLEX_TYPES = [\n', ""+    'complex double', 'complex float', 'complex long double'\n"", '+    ]\n', '+C99_COMPLEX_FUNCS = [\n', '+    ""cabs"", ""cacos"", ""cacosh"", ""carg"", ""casin"", ""casinh"", ""catan"",\n', '+    ""catanh"", ""cexp"", ""clog"", ""cpow"", ""csqrt"",\n', '+    ]\n', ' \n', ' OPTIONAL_HEADERS = [\n', ' # sse headers only enabled automatically on amd64/x32 builds\n']","['             set_sig(line)\n', ' \n', ' # Mandatory functions: if not found, fail the build\n', '-MANDATORY_FUNCS = [""sin"", ""cos"", ""tan"", ""sinh"", ""cosh"", ""tanh"", ""fabs"",\n', '-        ""floor"", ""ceil"", ""sqrt"", ""log10"", ""log"", ""exp"", ""asin"",\n', '-        ""acos"", ""atan"", ""fmod"", \'modf\', \'frexp\', \'ldexp\']\n', '-\n', '-# Standard functions which may not be available and for which we have a\n', '-# replacement implementation. Note that some of these are C99 functions.\n', '-OPTIONAL_STDFUNCS = [""expm1"", ""log1p"", ""acosh"", ""asinh"", ""atanh"",\n', '-        ""rint"", ""trunc"", ""exp2"", ""log2"", ""hypot"", ""atan2"", ""pow"",\n', '-        ""copysign"", ""nextafter"", ""strtoll"", ""strtoull"", ""cbrt""]\n', ' \n', ' OPTIONAL_LOCALE_FUNCS = [""strtold_l""]\n', ' OPTIONAL_FILE_FUNCS = [""ftello"", ""fseeko"", ""fallocate""]\n', ' OPTIONAL_MISC_FUNCS = [""backtrace"", ""madvise""]\n', ' \n', ' \n', ' OPTIONAL_HEADERS = [\n', ' # sse headers only enabled automatically on amd64/x32 builds\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 ""immintrin.h"",  # AVX\n', '                 ""features.h"",  # for glibc version linux\n', '                 ""xlocale.h"",  # see GH#8367\n', '+                ""dlfcn.h"",  # dladdr\n', '+                ""execinfo.h"",  # backtrace\n', '+                ""libunwind.h"",  # backtrace for LLVM/Clang using libunwind\n', '                 ""sys/mman.h"", #madvise\n', ' ]\n', ' \n']","['                 ""immintrin.h"",  # AVX\n', '                 ""features.h"",  # for glibc version linux\n', '                 ""xlocale.h"",  # see GH#8367\n', '-                ""dlfcn.h"", # dladdr\n', '                 ""sys/mman.h"", #madvise\n', ' ]\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                  'attribute_optimize_opt_2'),\n"", ""                                 ('__attribute__((nonnull (1)))',\n"", ""                                  'attribute_nonnull'),\n"", '                                 ]\n', ' \n', '+OPTIONAL_FUNCTION_ATTRIBUTES_AVX = [(\'__attribute__((target (""avx"")))\',\n', ""+    'attribute_target_avx'),\n"", '+    (\'__attribute__((target (""avx2"")))\',\n', ""+    'attribute_target_avx2'),\n"", '+    (\'__attribute__((target (""avx512f"")))\',\n', ""+    'attribute_target_avx512f'),\n"", '+    (\'__attribute__((target (""avx512f,avx512dq,avx512bw,avx512vl,avx512cd"")))\',\n', ""+    'attribute_target_avx512_skx'),\n"", '+    ]\n', '+\n', ' # function attributes with intrinsics\n', ' # To ensure your compiler can compile avx intrinsics with just the attributes\n', ' # gcc 4.8.4 support attributes but not with intrisics\n']","[""                                  'attribute_optimize_opt_2'),\n"", ""                                 ('__attribute__((nonnull (1)))',\n"", ""                                  'attribute_nonnull'),\n"", '-                                (\'__attribute__((target (""avx"")))\',\n', ""-                                 'attribute_target_avx'),\n"", '-                                (\'__attribute__((target (""avx2"")))\',\n', ""-                                 'attribute_target_avx2'),\n"", '-                                (\'__attribute__((target (""avx512f"")))\',\n', ""-                                 'attribute_target_avx512f'),\n"", '-                                (\'__attribute__((target (""avx512f,avx512dq,avx512bw,avx512vl,avx512cd"")))\',\n', ""-                                 'attribute_target_avx512_skx'),\n"", '                                 ]\n', ' \n', ' # function attributes with intrinsics\n', ' # To ensure your compiler can compile avx intrinsics with just the attributes\n', ' # gcc 4.8.4 support attributes but not with intrisics\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # The _mm512_castps_si512 instruction is specific check for AVX-512F support\n', ' # in gcc-4.9 which is missing a subset of intrinsics. See\n', ' # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=61878\n', '+OPTIONAL_FUNCTION_ATTRIBUTES_WITH_INTRINSICS_AVX = [\n', '+    (\'__attribute__((target(""avx2,fma"")))\',\n', ""+    'attribute_target_avx2_with_intrinsics',\n"", ""+    '__m256 temp = _mm256_set1_ps(1.0); temp = \\\n"", ""+    _mm256_fmadd_ps(temp, temp, temp)',\n"", ""+    'immintrin.h'),\n"", '+    (\'__attribute__((target(""avx512f"")))\',\n', ""+    'attribute_target_avx512f_with_intrinsics',\n"", ""+    '__m512i temp = _mm512_castps_si512(_mm512_set1_ps(1.0))',\n"", ""+    'immintrin.h'),\n"", '+    (\'__attribute__((target (""avx512f,avx512dq,avx512bw,avx512vl,avx512cd"")))\',\n', ""+    'attribute_target_avx512_skx_with_intrinsics',\n"", ""+    '__mmask8 temp = _mm512_fpclass_pd_mask(_mm512_set1_pd(1.0), 0x01);\\\n"", '+    __m512i unused_temp = \\\n', '+        _mm512_castps_si512(_mm512_set1_ps(1.0));\\\n', ""+    _mm_mask_storeu_epi8(NULL, 0xFF, _mm_broadcastmb_epi64(temp))',\n"", ""+    'immintrin.h'),\n"", '     ]\n', ' \n', ' def fname2def(name):\n']","[' # The _mm512_castps_si512 instruction is specific check for AVX-512F support\n', ' # in gcc-4.9 which is missing a subset of intrinsics. See\n', ' # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=61878\n', '-OPTIONAL_FUNCTION_ATTRIBUTES_WITH_INTRINSICS = [(\'__attribute__((target(""avx2,fma"")))\',\n', ""-                                'attribute_target_avx2_with_intrinsics',\n"", ""-                                '__m256 temp = _mm256_set1_ps(1.0); temp = \\\n"", ""-                                _mm256_fmadd_ps(temp, temp, temp)',\n"", ""-                                'immintrin.h'),\n"", '-                                (\'__attribute__((target(""avx512f"")))\',\n', ""-                                'attribute_target_avx512f_with_intrinsics',\n"", ""-                                '__m512i temp = _mm512_castps_si512(_mm512_set1_ps(1.0))',\n"", ""-                                'immintrin.h'),\n"", '-                                (\'__attribute__((target (""avx512f,avx512dq,avx512bw,avx512vl,avx512cd"")))\',\n', ""-                                'attribute_target_avx512_skx_with_intrinsics',\n"", ""-                                '__mmask8 temp = _mm512_fpclass_pd_mask(_mm512_set1_pd(1.0), 0x01);\\\n"", '-                                __m512i unused_temp = \\\n', '-                                    _mm512_castps_si512(_mm512_set1_ps(1.0));\\\n', ""-                                _mm_mask_storeu_epi8(NULL, 0xFF, _mm_broadcastmb_epi64(temp))',\n"", ""-                                'immintrin.h'),\n"", '-                                ]\n', '-\n', '-# variable attributes tested via ""int %s a"" % attribute\n', '-OPTIONAL_VARIABLE_ATTRIBUTES = [""__thread"", ""__declspec(thread)""]\n', '-\n', '-# Subset of OPTIONAL_STDFUNCS which may already have HAVE_* defined by Python.h\n', '-OPTIONAL_STDFUNCS_MAYBE = [\n', '-    ""expm1"", ""log1p"", ""acosh"", ""atanh"", ""asinh"", ""hypot"", ""copysign"",\n', '-    ""ftello"", ""fseeko""\n', '-    ]\n', '-\n', '-# C99 functions: float and long double versions\n', '-C99_FUNCS = [\n', '-    ""sin"", ""cos"", ""tan"", ""sinh"", ""cosh"", ""tanh"", ""fabs"", ""floor"", ""ceil"",\n', '-    ""rint"", ""trunc"", ""sqrt"", ""log10"", ""log"", ""log1p"", ""exp"", ""expm1"",\n', '-    ""asin"", ""acos"", ""atan"", ""asinh"", ""acosh"", ""atanh"", ""hypot"", ""atan2"",\n', '-    ""pow"", ""fmod"", ""modf"", \'frexp\', \'ldexp\', ""exp2"", ""log2"", ""copysign"",\n', '-    ""nextafter"", ""cbrt""\n', '-    ]\n', ""-C99_FUNCS_SINGLE = [f + 'f' for f in C99_FUNCS]\n"", ""-C99_FUNCS_EXTENDED = [f + 'l' for f in C99_FUNCS]\n"", '-C99_COMPLEX_TYPES = [\n', ""-    'complex double', 'complex float', 'complex long double'\n"", '-    ]\n', '-C99_COMPLEX_FUNCS = [\n', '-    ""cabs"", ""cacos"", ""cacosh"", ""carg"", ""casin"", ""casinh"", ""catan"",\n', '-    ""catanh"", ""ccos"", ""ccosh"", ""cexp"", ""cimag"", ""clog"", ""conj"", ""cpow"",\n', '-    ""cproj"", ""creal"", ""csin"", ""csinh"", ""csqrt"", ""ctan"", ""ctanh""\n', '     ]\n', ' \n', ' def fname2def(name):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return arrays\n', ' \n', ' \n', '+def _vhstack_dispatcher(tup, *, \n', '+                        dtype=None, casting=None):\n', '     return _arrays_for_stack_dispatcher(tup)\n', ' \n', ' \n', ' @array_function_dispatch(_vhstack_dispatcher)\n', '+def vstack(tup, *, dtype=None, casting=""same_kind""):\n', '     """"""\n', '     Stack arrays in sequence vertically (row wise).\n', ' \n']","['     return arrays\n', ' \n', ' \n', '-def _vhstack_dispatcher(tup):\n', '     return _arrays_for_stack_dispatcher(tup)\n', ' \n', ' \n', ' @array_function_dispatch(_vhstack_dispatcher)\n', '-def vstack(tup):\n', '     """"""\n', '     Stack arrays in sequence vertically (row wise).\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n', '     `block` provide more general stacking and concatenation operations.\n', ' \n', '+    ``np.row_stack`` is an alias for `vstack`. They are the same function.\n', '+\n', '     Parameters\n', '     ----------\n', '     tup : sequence of ndarrays\n', '         The arrays must have the same shape along all but the first axis.\n', '         1-D arrays must have the same length.\n', ' \n', '+    dtype : str or dtype\n', '+        If provided, the destination array will have this dtype. Cannot be\n', '+        provided together with `out`.\n', '+\n', '+    .. versionadded:: 1.24\n', '+\n', ""+    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n"", ""+        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n"", '+\n', '+    .. versionadded:: 1.24\n', '+\n', '     Returns\n', '     -------\n', '     stacked : ndarray\n']","['     and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n', '     `block` provide more general stacking and concatenation operations.\n', ' \n', '     Parameters\n', '     ----------\n', '     tup : sequence of ndarrays\n', '         The arrays must have the same shape along all but the first axis.\n', '         1-D arrays must have the same length.\n', ' \n', '     Returns\n', '     -------\n', '     stacked : ndarray\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     arrs = atleast_2d(*tup)\n', '     if not isinstance(arrs, list):\n', '         arrs = [arrs]\n', '+    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)\n', ' \n', ' \n', ' @array_function_dispatch(_vhstack_dispatcher)\n', '+def hstack(tup, *, dtype=None, casting=""same_kind""):\n', '     """"""\n', '     Stack arrays in sequence horizontally (column wise).\n', ' \n']","['     arrs = atleast_2d(*tup)\n', '     if not isinstance(arrs, list):\n', '         arrs = [arrs]\n', '-    return _nx.concatenate(arrs, 0)\n', ' \n', ' \n', ' @array_function_dispatch(_vhstack_dispatcher)\n', '-def hstack(tup):\n', '     """"""\n', '     Stack arrays in sequence horizontally (column wise).\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         The arrays must have the same shape along all but the second axis,\n', '         except 1-D arrays which can be any length.\n', ' \n', '+    dtype : str or dtype\n', '+        If provided, the destination array will have this dtype. Cannot be\n', '+        provided together with `out`.\n', '+\n', '+    .. versionadded:: 1.24\n', '+\n', ""+    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n"", ""+        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n"", '+\n', '+    .. versionadded:: 1.24\n', '+\n', '     Returns\n', '     -------\n', '     stacked : ndarray\n']","['         The arrays must have the same shape along all but the second axis,\n', '         except 1-D arrays which can be any length.\n', ' \n', '     Returns\n', '     -------\n', '     stacked : ndarray\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         arrs = [arrs]\n', '     # As a special case, dimension 0 of 1-dimensional arrays is ""horizontal""\n', '     if arrs and arrs[0].ndim == 1:\n', '+        return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)\n', '     else:\n', '+        return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n', ' \n', ' \n', '+def _stack_dispatcher(arrays, axis=None, out=None, *,\n', '+                      dtype=None, casting=None):\n', '     arrays = _arrays_for_stack_dispatcher(arrays, stacklevel=6)\n', '     if out is not None:\n', '         # optimize for the typical case where only arrays is provided\n']","['         arrs = [arrs]\n', '     # As a special case, dimension 0 of 1-dimensional arrays is ""horizontal""\n', '     if arrs and arrs[0].ndim == 1:\n', '-        return _nx.concatenate(arrs, 0)\n', '     else:\n', '-        return _nx.concatenate(arrs, 1)\n', ' \n', ' \n', '-def _stack_dispatcher(arrays, axis=None, out=None):\n', '     arrays = _arrays_for_stack_dispatcher(arrays, stacklevel=6)\n', '     if out is not None:\n', '         # optimize for the typical case where only arrays is provided\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @array_function_dispatch(_stack_dispatcher)\n', '+def stack(arrays, axis=0, out=None, *, dtype=None, casting=""same_kind""):\n', '     """"""\n', '     Join a sequence of arrays along a new axis.\n', ' \n']","[' \n', ' \n', ' @array_function_dispatch(_stack_dispatcher)\n', '-def stack(arrays, axis=0, out=None):\n', '     """"""\n', '     Join a sequence of arrays along a new axis.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         correct, matching that of what stack would have returned if no\n', '         out argument were specified.\n', ' \n', '+    dtype : str or dtype\n', '+        If provided, the destination array will have this dtype. Cannot be\n', '+        provided together with `out`.\n', '+\n', '+        .. versionadded:: 1.24\n', '+\n', ""+    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n"", ""+        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n"", '+\n', '+        .. versionadded:: 1.24\n', '+\n', '+\n', '     Returns\n', '     -------\n', '     stacked : ndarray\n']","['         correct, matching that of what stack would have returned if no\n', '         out argument were specified.\n', ' \n', '     Returns\n', '     -------\n', '     stacked : ndarray\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     sl = (slice(None),) * axis + (_nx.newaxis,)\n', '     expanded_arrays = [arr[sl] for arr in arrays]\n', '+    return _nx.concatenate(expanded_arrays, axis=axis, out=out,\n', '+                           dtype=dtype, casting=casting)\n', ' \n', ' \n', ' # Internal functions to eliminate the overhead of repeated dispatch in one of\n']","[' \n', '     sl = (slice(None),) * axis + (_nx.newaxis,)\n', '     expanded_arrays = [arr[sl] for arr in arrays]\n', '-    return _nx.concatenate(expanded_arrays, axis=axis, out=out)\n', ' \n', ' \n', ' # Internal functions to eliminate the overhead of repeated dispatch in one of\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # Use getattr to protect against __array_function__ being disabled.\n', "" _size = getattr(_from_nx.size, '__wrapped__', _from_nx.size)\n"", "" _ndim = getattr(_from_nx.ndim, '__wrapped__', _from_nx.ndim)\n"", '+_concatenate = getattr(_from_nx.concatenate,\n', ""+                       '__wrapped__', _from_nx.concatenate)\n"", ' \n', ' \n', ' def _block_format_index(index):\n']","[' # Use getattr to protect against __array_function__ being disabled.\n', "" _size = getattr(_from_nx.size, '__wrapped__', _from_nx.size)\n"", "" _ndim = getattr(_from_nx.ndim, '__wrapped__', _from_nx.ndim)\n"", ""-_concatenate = getattr(_from_nx.concatenate, '__wrapped__', _from_nx.concatenate)\n"", ' \n', ' \n', ' def _block_format_index(index):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""Given array shapes, return the resulting shape and slices prefixes.\n', ' \n', '     These help in nested concatenation.\n', '+\n', '     Returns\n', '     -------\n', '     shape: tuple of int\n']","['     """"""Given array shapes, return the resulting shape and slices prefixes.\n', ' \n', '     These help in nested concatenation.\n', '-    \n', '     Returns\n', '     -------\n', '     shape: tuple of int\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     (cur_locale, tst_locale) = find_comma_decimal_point_locale()\n', ' \n', '+    def setup_method(self):\n', '         if self.tst_locale is None:\n', '             pytest.skip(""No French locale available"")\n', '         locale.setlocale(locale.LC_NUMERIC, locale=self.tst_locale)\n', ' \n', '+    def teardown_method(self):\n', '         locale.setlocale(locale.LC_NUMERIC, locale=self.cur_locale)\n', ' \n', '     def __enter__(self):\n']","['     """"""\n', '     (cur_locale, tst_locale) = find_comma_decimal_point_locale()\n', ' \n', '-    def setup(self):\n', '         if self.tst_locale is None:\n', '             pytest.skip(""No French locale available"")\n', '         locale.setlocale(locale.LC_NUMERIC, locale=self.tst_locale)\n', ' \n', '-    def teardown(self):\n', '         locale.setlocale(locale.LC_NUMERIC, locale=self.cur_locale)\n', ' \n', '     def __enter__(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_floats(self):\n', ""         for t in sctypes['float']:\n"", '             assert_(isinstance(t(), numbers.Real),\n', '+                    f""{t.__name__} is not instance of Real"")\n', '             assert_(issubclass(t, numbers.Real),\n', '+                    f""{t.__name__} is not subclass of Real"")\n', '             assert_(not isinstance(t(), numbers.Rational),\n', '+                    f""{t.__name__} is instance of Rational"")\n', '             assert_(not issubclass(t, numbers.Rational),\n', '+                    f""{t.__name__} is subclass of Rational"")\n', ' \n', '     def test_complex(self):\n', ""         for t in sctypes['complex']:\n"", '             assert_(isinstance(t(), numbers.Complex),\n', '+                    f""{t.__name__} is not instance of Complex"")\n', '             assert_(issubclass(t, numbers.Complex),\n', '+                    f""{t.__name__} is not subclass of Complex"")\n', '             assert_(not isinstance(t(), numbers.Real),\n', '+                    f""{t.__name__} is instance of Real"")\n', '             assert_(not issubclass(t, numbers.Real),\n', '+                    f""{t.__name__} is subclass of Real"")\n', ' \n', '     def test_int(self):\n', ""         for t in sctypes['int']:\n"", '             assert_(isinstance(t(), numbers.Integral),\n', '+                    f""{t.__name__} is not instance of Integral"")\n', '             assert_(issubclass(t, numbers.Integral),\n', '+                    f""{t.__name__} is not subclass of Integral"")\n', ' \n', '     def test_uint(self):\n', ""         for t in sctypes['uint']:\n"", '             assert_(isinstance(t(), numbers.Integral),\n', '+                    f""{t.__name__} is not instance of Integral"")\n', '             assert_(issubclass(t, numbers.Integral),\n', '+                    f""{t.__name__} is not subclass of Integral"")\n']","['     def test_floats(self):\n', ""         for t in sctypes['float']:\n"", '             assert_(isinstance(t(), numbers.Real),\n', '-                    ""{0} is not instance of Real"".format(t.__name__))\n', '             assert_(issubclass(t, numbers.Real),\n', '-                    ""{0} is not subclass of Real"".format(t.__name__))\n', '             assert_(not isinstance(t(), numbers.Rational),\n', '-                    ""{0} is instance of Rational"".format(t.__name__))\n', '             assert_(not issubclass(t, numbers.Rational),\n', '-                    ""{0} is subclass of Rational"".format(t.__name__))\n', ' \n', '     def test_complex(self):\n', ""         for t in sctypes['complex']:\n"", '             assert_(isinstance(t(), numbers.Complex),\n', '-                    ""{0} is not instance of Complex"".format(t.__name__))\n', '             assert_(issubclass(t, numbers.Complex),\n', '-                    ""{0} is not subclass of Complex"".format(t.__name__))\n', '             assert_(not isinstance(t(), numbers.Real),\n', '-                    ""{0} is instance of Real"".format(t.__name__))\n', '             assert_(not issubclass(t, numbers.Real),\n', '-                    ""{0} is subclass of Real"".format(t.__name__))\n', ' \n', '     def test_int(self):\n', ""         for t in sctypes['int']:\n"", '             assert_(isinstance(t(), numbers.Integral),\n', '-                    ""{0} is not instance of Integral"".format(t.__name__))\n', '             assert_(issubclass(t, numbers.Integral),\n', '-                    ""{0} is not subclass of Integral"".format(t.__name__))\n', ' \n', '     def test_uint(self):\n', ""         for t in sctypes['uint']:\n"", '             assert_(isinstance(t(), numbers.Integral),\n', '-                    ""{0} is not instance of Integral"".format(t.__name__))\n', '             assert_(issubclass(t, numbers.Integral),\n', '-                    ""{0} is not subclass of Integral"".format(t.__name__))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         np.array(rt, dtype=""M8"")\n', ' \n', ' \n', '+# TODO: remove when fastCopyAndTranspose deprecation expires\n', '+@pytest.mark.parametrize(""a"",\n', '+    (\n', '+        np.array(2),  # 0D array\n', '+        np.array([3, 2, 7, 0]),  # 1D array\n', '+        np.arange(6).reshape(2, 3)  # 2D array\n', '+    ),\n', '+)\n', '+def test_fastCopyAndTranspose(a):\n', '+    with pytest.deprecated_call():\n', '+        b = np.fastCopyAndTranspose(a)\n', '+        assert_equal(b, a.T)\n', '+        assert b.flags.owndata\n', '+\n', ' \n', ' def test_array_astype():\n', ""     a = np.arange(6, dtype='f4').reshape(2, 3)\n""]","['         np.array(rt, dtype=""M8"")\n', ' \n', ' \n', '-def test_fastCopyAndTranspose():\n', '-    # 0D array\n', '-    a = np.array(2)\n', '-    b = np.fastCopyAndTranspose(a)\n', '-    assert_equal(b, a.T)\n', '-    assert_(b.flags.owndata)\n', '-\n', '-    # 1D array\n', '-    a = np.array([3, 2, 7, 0])\n', '-    b = np.fastCopyAndTranspose(a)\n', '-    assert_equal(b, a.T)\n', '-    assert_(b.flags.owndata)\n', '-\n', '-    # 2D array\n', '-    a = np.arange(6).reshape(2, 3)\n', '-    b = np.fastCopyAndTranspose(a)\n', '-    assert_equal(b, a.T)\n', '-    assert_(b.flags.owndata)\n', ' \n', ' def test_array_astype():\n', ""     a = np.arange(6, dtype='f4').reshape(2, 3)\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     b = a.astype('S')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('S100'))\n"", ""+    a = np.array(['a'*100], dtype='O')\n"", ""     b = a.astype('U')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('U100'))\n""]","[""     b = a.astype('S')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('S100'))\n"", ""-    a = np.array([u'a'*100], dtype='O')\n"", ""     b = a.astype('U')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('U100'))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     b = a.astype('S')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('S10'))\n"", ""+    a = np.array(['a'*10], dtype='O')\n"", ""     b = a.astype('U')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('U10'))\n""]","[""     b = a.astype('S')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('S10'))\n"", ""-    a = np.array([u'a'*10], dtype='O')\n"", ""     b = a.astype('U')\n"", '     assert_equal(a, b)\n', ""     assert_equal(b.dtype, np.dtype('U10'))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     a = np.array(123456789012345678901234567890, dtype='O').astype('S')\n"", ""     assert_array_equal(a, np.array(b'1234567890' * 3, dtype='S30'))\n"", ""     a = np.array(123456789012345678901234567890, dtype='O').astype('U')\n"", ""+    assert_array_equal(a, np.array('1234567890' * 3, dtype='U30'))\n"", ' \n', ""     a = np.array([123456789012345678901234567890], dtype='O').astype('S')\n"", ""     assert_array_equal(a, np.array(b'1234567890' * 3, dtype='S30'))\n"", ""     a = np.array([123456789012345678901234567890], dtype='O').astype('U')\n"", ""+    assert_array_equal(a, np.array('1234567890' * 3, dtype='U30'))\n"", ' \n', ""     a = np.array(123456789012345678901234567890, dtype='S')\n"", ""     assert_array_equal(a, np.array(b'1234567890' * 3, dtype='S30'))\n"", ""     a = np.array(123456789012345678901234567890, dtype='U')\n"", ""+    assert_array_equal(a, np.array('1234567890' * 3, dtype='U30'))\n"", ' \n', ""+    a = np.array('a\\u0140', dtype='U')\n"", ""     b = np.ndarray(buffer=a, dtype='uint32', shape=2)\n"", '     assert_(b.size == 2)\n', ' \n']","[""     a = np.array(123456789012345678901234567890, dtype='O').astype('S')\n"", ""     assert_array_equal(a, np.array(b'1234567890' * 3, dtype='S30'))\n"", ""     a = np.array(123456789012345678901234567890, dtype='O').astype('U')\n"", ""-    assert_array_equal(a, np.array(u'1234567890' * 3, dtype='U30'))\n"", ' \n', ""     a = np.array([123456789012345678901234567890], dtype='O').astype('S')\n"", ""     assert_array_equal(a, np.array(b'1234567890' * 3, dtype='S30'))\n"", ""     a = np.array([123456789012345678901234567890], dtype='O').astype('U')\n"", ""-    assert_array_equal(a, np.array(u'1234567890' * 3, dtype='U30'))\n"", ' \n', ""     a = np.array(123456789012345678901234567890, dtype='S')\n"", ""     assert_array_equal(a, np.array(b'1234567890' * 3, dtype='S30'))\n"", ""     a = np.array(123456789012345678901234567890, dtype='U')\n"", ""-    assert_array_equal(a, np.array(u'1234567890' * 3, dtype='U30'))\n"", ' \n', ""-    a = np.array(u'a\\u0140', dtype='U')\n"", ""     b = np.ndarray(buffer=a, dtype='uint32', shape=2)\n"", '     assert_(b.size == 2)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' are tested (sometimes indirectly) elsewhere.\n', ' """"""\n', ' \n', '+from itertools import permutations, product\n', '+\n', ' import pytest\n', ' from pytest import param\n', ' \n', ' import numpy as np\n', ' from numpy.core._rational_tests import rational\n', ' from numpy.core._multiarray_umath import _discover_array_parameters\n']","[' are tested (sometimes indirectly) elsewhere.\n', ' """"""\n', ' \n', ' import pytest\n', ' from pytest import param\n', ' \n', '-from itertools import product\n', '-\n', ' import numpy as np\n', ' from numpy.core._rational_tests import rational\n', ' from numpy.core._multiarray_umath import _discover_array_parameters\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def is_parametric_dtype(dtype):\n', '+    """"""Returns True if the dtype is a parametric legacy dtype (itemsize\n', '     is 0, or a datetime without units)\n', '     """"""\n', '     if dtype.itemsize == 0:\n']","[' \n', ' \n', ' def is_parametric_dtype(dtype):\n', '-    """"""Returns True if the the dtype is a parametric legacy dtype (itemsize\n', '     is 0, or a datetime without units)\n', '     """"""\n', '     if dtype.itemsize == 0:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert discovered_dtype.itemsize == dtype.itemsize\n', ' \n', '     @pytest.mark.parametrize(""dtype"", np.typecodes[""Integer""])\n', '+    @pytest.mark.parametrize([""scalar"", ""error""],\n', '+            [(np.float64(np.nan), ValueError),\n', '+             (np.array(-1).astype(np.ulonglong)[()], OverflowError)])\n', '+    def test_scalar_to_int_coerce_does_not_cast(self, dtype, scalar, error):\n', '         """"""\n', '         Signed integers are currently different in that they do not cast other\n', '         NumPy scalar, but instead use scalar.__int__(). The hardcoded\n', '         exception to this rule is `np.array(scalar, dtype=integer)`.\n', '         """"""\n', '         dtype = np.dtype(dtype)\n', ' \n', '+        # This is a special case using casting logic.  It warns for the NaN\n', '+        # but allows the cast (giving undefined behaviour).\n', '+        with np.errstate(invalid=""ignore""):\n', '             coerced = np.array(scalar, dtype=dtype)\n', '             cast = np.array(scalar).astype(dtype)\n', '+        assert_array_equal(coerced, cast)\n', ' \n', '+        # However these fail:\n', '+        with pytest.raises(error):\n', '+            np.array([scalar], dtype=dtype)\n', '+        with pytest.raises(error):\n', '+            cast[()] = scalar\n', ' \n', ' \n', ' class TestTimeScalars:\n']","['         assert discovered_dtype.itemsize == dtype.itemsize\n', ' \n', '     @pytest.mark.parametrize(""dtype"", np.typecodes[""Integer""])\n', '-    def test_scalar_to_int_coerce_does_not_cast(self, dtype):\n', '         """"""\n', '         Signed integers are currently different in that they do not cast other\n', '         NumPy scalar, but instead use scalar.__int__(). The hardcoded\n', '         exception to this rule is `np.array(scalar, dtype=integer)`.\n', '         """"""\n', '         dtype = np.dtype(dtype)\n', '-        invalid_int = np.ulonglong(-1)\n', ' \n', '-        float_nan = np.float64(np.nan)\n', '-\n', '-        for scalar in [float_nan, invalid_int]:\n', '-            # This is a special case using casting logic and thus not failing:\n', '             coerced = np.array(scalar, dtype=dtype)\n', '             cast = np.array(scalar).astype(dtype)\n', '-            assert_array_equal(coerced, cast)\n', ' \n', '-            # However these fail:\n', '-            with pytest.raises((ValueError, OverflowError)):\n', '-                np.array([scalar], dtype=dtype)\n', '-            with pytest.raises((ValueError, OverflowError)):\n', '-                cast[()] = scalar\n', ' \n', ' \n', ' class TestTimeScalars:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with pytest.raises(ValueError):\n', '             np.array([nested], dtype=""float64"")\n', ' \n', '+        with pytest.raises(ValueError, match="".*would exceed the maximum""):\n', '+            np.array([nested])  # user must ask for `object` explicitly\n', '+\n', '+        arr = np.array([nested], dtype=object)\n', '         assert arr.dtype == np.dtype(""O"")\n', '         assert arr.shape == (1,) * np.MAXDIMS\n', '         assert arr.item() is initial\n']","['         with pytest.raises(ValueError):\n', '             np.array([nested], dtype=""float64"")\n', ' \n', '-        # We discover object automatically at this time:\n', '-        with assert_warns(np.VisibleDeprecationWarning):\n', '-            arr = np.array([nested])\n', '         assert arr.dtype == np.dtype(""O"")\n', '         assert arr.shape == (1,) * np.MAXDIMS\n', '         assert arr.item() is initial\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         for i in range(np.MAXDIMS - 1):\n', '             nested = [nested]\n', ' \n', '+        with pytest.raises(ValueError, match="".*would exceed the maximum""):\n', '             # It will refuse to assign the array into\n', '             np.array(nested, dtype=""float64"")\n', ' \n']","['         for i in range(np.MAXDIMS - 1):\n', '             nested = [nested]\n', ' \n', '-        with pytest.warns(DeprecationWarning):\n', '             # It will refuse to assign the array into\n', '             np.array(nested, dtype=""float64"")\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         obj.append([2, 3])\n', '         obj.append(mylist([1, 2]))\n', '+        # Does not crash:\n', '+        np.array(obj)\n', ' \n', '     def test_replace_0d_array(self):\n', '         # List to coerce, `mylist` will mutate the first element\n']","[' \n', '         obj.append([2, 3])\n', '         obj.append(mylist([1, 2]))\n', '-        with pytest.raises(RuntimeError):\n', '-            np.array(obj)\n', ' \n', '     def test_replace_0d_array(self):\n', '         # List to coerce, `mylist` will mutate the first element\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             np.array(BadSequence())\n', ' \n', ' \n', '+class TestAsArray:\n', '+    """"""Test expected behaviors of ``asarray``.""""""\n', '+\n', '+    def test_dtype_identity(self):\n', '+        """"""Confirm the intended behavior for *dtype* kwarg.\n', '+\n', '+        The result of ``asarray()`` should have the dtype provided through the\n', '+        keyword argument, when used. This forces unique array handles to be\n', '+        produced for unique np.dtype objects, but (for equivalent dtypes), the\n', '+        underlying data (the base object) is shared with the original array\n', '+        object.\n', '+\n', '+        Ref https://github.com/numpy/numpy/issues/1468\n', '+        """"""\n', ""+        int_array = np.array([1, 2, 3], dtype='i')\n"", '+        assert np.asarray(int_array) is int_array\n', '+\n', '+        # The character code resolves to the singleton dtype object provided\n', '+        # by the numpy package.\n', ""+        assert np.asarray(int_array, dtype='i') is int_array\n"", '+\n', ""+        # Derive a dtype from n.dtype('i'), but add a metadata object to force\n"", '+        # the dtype to be distinct.\n', ""+        unequal_type = np.dtype('i', metadata={'spam': True})\n"", '+        annotated_int_array = np.asarray(int_array, dtype=unequal_type)\n', '+        assert annotated_int_array is not int_array\n', '+        assert annotated_int_array.base is int_array\n', '+        # Create an equivalent descriptor with a new and distinct dtype\n', '+        # instance.\n', ""+        equivalent_requirement = np.dtype('i', metadata={'spam': True})\n"", '+        annotated_int_array_alt = np.asarray(annotated_int_array,\n', '+                                             dtype=equivalent_requirement)\n', '+        assert unequal_type == equivalent_requirement\n', '+        assert unequal_type is not equivalent_requirement\n', '+        assert annotated_int_array_alt is not annotated_int_array\n', '+        assert annotated_int_array_alt.dtype is equivalent_requirement\n', '+\n', '+        # Check the same logic for a pair of C types whose equivalence may vary\n', '+        # between computing environments.\n', '+        # Find an equivalent pair.\n', ""+        integer_type_codes = ('i', 'l', 'q')\n"", '+        integer_dtypes = [np.dtype(code) for code in integer_type_codes]\n', '+        typeA = None\n', '+        typeB = None\n', '+        for typeA, typeB in permutations(integer_dtypes, r=2):\n', '+            if typeA == typeB:\n', '+                assert typeA is not typeB\n', '+                break\n', '+        assert isinstance(typeA, np.dtype) and isinstance(typeB, np.dtype)\n', '+\n', '+        # These ``asarray()`` calls may produce a new view or a copy,\n', '+        # but never the same object.\n', ""+        long_int_array = np.asarray(int_array, dtype='l')\n"", ""+        long_long_int_array = np.asarray(int_array, dtype='q')\n"", '+        assert long_int_array is not int_array\n', '+        assert long_long_int_array is not int_array\n', ""+        assert np.asarray(long_int_array, dtype='q') is not long_int_array\n"", '+        array_a = np.asarray(int_array, dtype=typeA)\n', '+        assert typeA == typeB\n', '+        assert typeA is not typeB\n', '+        assert array_a.dtype is typeA\n', '+        assert array_a is not np.asarray(array_a, dtype=typeB)\n', '+        assert np.asarray(array_a, dtype=typeB).dtype is typeB\n', '+        assert array_a is np.asarray(array_a, dtype=typeB).base\n', '+\n', '+\n', ' class TestSpecialAttributeLookupFailure:\n', '     # An exception was raised while fetching the attribute\n', ' \n']","['             np.array(BadSequence())\n', ' \n', ' \n', ' class TestSpecialAttributeLookupFailure:\n', '     # An exception was raised while fetching the attribute\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         This class is for testing the timing of the PyCapsule destructor\n', '         invoked when numpy release its reference to the shared data as part of\n', '         the numpy array interface protocol. If the PyCapsule destructor is\n', '+        called early the shared data is freed and invalid memory accesses will\n', '         occur.\n', '         """"""\n', ' \n']","['         This class is for testing the timing of the PyCapsule destructor\n', '         invoked when numpy release its reference to the shared data as part of\n', '         the numpy array interface protocol. If the PyCapsule destructor is\n', '-        called early the shared data is freed and invlaid memory accesses will\n', '         occur.\n', '         """"""\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' this is private API, but when added, public API may be added here.\n', ' """"""\n', ' \n', '+from __future__ import annotations\n', '+\n', ' import sys\n', ' import types\n', '+from typing import Any\n', ' \n', ' import pytest\n', ' \n']","[' this is private API, but when added, public API may be added here.\n', ' """"""\n', ' \n', ' import sys\n', ' import types\n', '-from typing import Any, Type\n', ' \n', ' import pytest\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @pytest.mark.skipif(sys.version_info < (3, 9), reason=""Requires python 3.9"")\n', '+@pytest.mark.parametrize(\n', '+    ""cls"", [np.ndarray, np.recarray, np.chararray, np.matrix, np.memmap]\n', '+)\n', ' class TestClassGetItem:\n', '+    def test_class_getitem(self, cls: type[np.ndarray]) -> None:\n', '         """"""Test `ndarray.__class_getitem__`.""""""\n', '         alias = cls[Any, Any]\n', '         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is cls\n', ' \n', '     @pytest.mark.parametrize(""arg_len"", range(4))\n', '+    def test_subscript_tup(self, cls: type[np.ndarray], arg_len: int) -> None:\n', '         arg_tup = (Any,) * arg_len\n', '+        if arg_len in (1, 2):\n', '+            assert cls[arg_tup]\n', '         else:\n', '+            match = f""Too {\'few\' if arg_len == 0 else \'many\'} arguments""\n', '+            with pytest.raises(TypeError, match=match):\n', '+                cls[arg_tup]\n', ' \n', ' \n', ' @pytest.mark.skipif(sys.version_info >= (3, 9), reason=""Requires python 3.8"")\n']","[' \n', ' \n', ' @pytest.mark.skipif(sys.version_info < (3, 9), reason=""Requires python 3.9"")\n', ' class TestClassGetItem:\n', '-    @pytest.mark.parametrize(\n', '-        ""cls"", [np.ndarray, np.recarray, np.chararray, np.matrix, np.memmap]\n', '-    )\n', '-    def test_class_getitem(self, cls: Type[np.ndarray]) -> None:\n', '         """"""Test `ndarray.__class_getitem__`.""""""\n', '         alias = cls[Any, Any]\n', '         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is cls\n', ' \n', '     @pytest.mark.parametrize(""arg_len"", range(4))\n', '-    def test_subscript_tuple(self, arg_len: int) -> None:\n', '         arg_tup = (Any,) * arg_len\n', '-        if arg_len == 2:\n', '-            assert np.ndarray[arg_tup]\n', '         else:\n', '-            with pytest.raises(TypeError):\n', '-                np.ndarray[arg_tup]\n', '-\n', '-    def test_subscript_scalar(self) -> None:\n', '-        with pytest.raises(TypeError):\n', '-            np.ndarray[Any]\n', ' \n', ' \n', ' @pytest.mark.skipif(sys.version_info >= (3, 9), reason=""Requires python 3.8"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestPrintOptions:\n', '     """"""Test getting and setting global print options.""""""\n', ' \n', '+    def setup_method(self):\n', '         self.oldopts = np.get_printoptions()\n', ' \n', '+    def teardown_method(self):\n', '         np.set_printoptions(**self.oldopts)\n', ' \n', '     def test_basic(self):\n']","[' class TestPrintOptions:\n', '     """"""Test getting and setting global print options.""""""\n', ' \n', '-    def setup(self):\n', '         self.oldopts = np.get_printoptions()\n', ' \n', '-    def teardown(self):\n', '         np.set_printoptions(**self.oldopts)\n', ' \n', '     def test_basic(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(repr(x), ""array([0., 1., 2.])"")\n', ' \n', '     def test_0d_arrays(self):\n', ""+        assert_equal(str(np.array('café', '<U4')), 'café')\n"", ' \n', ""         assert_equal(repr(np.array('café', '<U4')),\n"", '                      ""array(\'café\', dtype=\'<U4\')"")\n']","['         assert_equal(repr(x), ""array([0., 1., 2.])"")\n', ' \n', '     def test_0d_arrays(self):\n', ""-        assert_equal(str(np.array(u'café', '<U4')), u'café')\n"", ' \n', ""         assert_equal(repr(np.array('café', '<U4')),\n"", '                      ""array(\'café\', dtype=\'<U4\')"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' def test_unicode_object_array():\n', '     expected = ""array([\'é\'], dtype=object)""\n', ""+    x = np.array(['\\xe9'], dtype=object)\n"", '     assert_equal(repr(x), expected)\n', ' \n', ' \n']","[' \n', ' def test_unicode_object_array():\n', '     expected = ""array([\'é\'], dtype=object)""\n', ""-    x = np.array([u'\\xe9'], dtype=object)\n"", '     assert_equal(repr(x), expected)\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import pytest\n', '+from pytest import param\n', '+from numpy.testing import IS_WASM\n', '+import numpy as np\n', '+\n', '+\n', '+def values_and_dtypes():\n', '+    """"""\n', '+    Generate value+dtype pairs that generate floating point errors during\n', '+    casts.  The invalid casts to integers will generate ""invalid"" value\n', '+    warnings, the float casts all generate ""overflow"".\n', '+\n', ""+    (The Python int/float paths don't need to get tested in all the same\n"", '+    situations, but it does not hurt.)\n', '+    """"""\n', '+    # Casting to float16:\n', '+    yield param(70000, ""float16"", id=""int-to-f2"")\n', '+    yield param(""70000"", ""float16"", id=""str-to-f2"")\n', '+    yield param(70000.0, ""float16"", id=""float-to-f2"")\n', '+    yield param(np.longdouble(70000.), ""float16"", id=""longdouble-to-f2"")\n', '+    yield param(np.float64(70000.), ""float16"", id=""double-to-f2"")\n', '+    yield param(np.float32(70000.), ""float16"", id=""float-to-f2"")\n', '+    # Casting to float32:\n', '+    yield param(10**100, ""float32"", id=""int-to-f4"")\n', '+    yield param(1e100, ""float32"", id=""float-to-f2"")\n', '+    yield param(np.longdouble(1e300), ""float32"", id=""longdouble-to-f2"")\n', '+    yield param(np.float64(1e300), ""float32"", id=""double-to-f2"")\n', '+    # Casting to float64:\n', '+    # If longdouble is double-double, its max can be rounded down to the double\n', '+    # max.  So we correct the double spacing (a bit weird, admittedly):\n', '+    max_ld = np.finfo(np.longdouble).max\n', '+    spacing = np.spacing(np.nextafter(np.finfo(""f8"").max, 0))\n', '+    if max_ld - spacing > np.finfo(""f8"").max:\n', '+        yield param(np.finfo(np.longdouble).max, ""float64"",\n', '+                    id=""longdouble-to-f8"")\n', '+\n', '+    # Cast to complex32:\n', '+    yield param(2e300, ""complex64"", id=""float-to-c8"")\n', '+    yield param(2e300+0j, ""complex64"", id=""complex-to-c8"")\n', '+    yield param(2e300j, ""complex64"", id=""complex-to-c8"")\n', '+    yield param(np.longdouble(2e300), ""complex64"", id=""longdouble-to-c8"")\n', '+\n', '+    # Invalid float to integer casts:\n', '+    with np.errstate(over=""ignore""):\n', '+        for to_dt in np.typecodes[""AllInteger""]:\n', '+            for value in [np.inf, np.nan]:\n', '+                for from_dt in np.typecodes[""AllFloat""]:\n', '+                    from_dt = np.dtype(from_dt)\n', '+                    from_val = from_dt.type(value)\n', '+\n', '+                    yield param(from_val, to_dt, id=f""{from_val}-to-{to_dt}"")\n', '+\n', '+\n', '+def check_operations(dtype, value):\n', '+    """"""\n', '+    There are many dedicated paths in NumPy which cast and should check for\n', '+    floating point errors which occurred during those casts.\n', '+    """"""\n', ""+    if dtype.kind != 'i':\n"", '+        # These assignments use the stricter setitem logic:\n', '+        def assignment():\n', '+            arr = np.empty(3, dtype=dtype)\n', '+            arr[0] = value\n', '+\n', '+        yield assignment\n', '+\n', '+        def fill():\n', '+            arr = np.empty(3, dtype=dtype)\n', '+            arr.fill(value)\n', '+\n', '+        yield fill\n', '+\n', '+    def copyto_scalar():\n', '+        arr = np.empty(3, dtype=dtype)\n', '+        np.copyto(arr, value, casting=""unsafe"")\n', '+\n', '+    yield copyto_scalar\n', '+\n', '+    def copyto():\n', '+        arr = np.empty(3, dtype=dtype)\n', '+        np.copyto(arr, np.array([value, value, value]), casting=""unsafe"")\n', '+\n', '+    yield copyto\n', '+\n', '+    def copyto_scalar_masked():\n', '+        arr = np.empty(3, dtype=dtype)\n', '+        np.copyto(arr, value, casting=""unsafe"",\n', '+                  where=[True, False, True])\n', '+\n', '+    yield copyto_scalar_masked\n', '+\n', '+    def copyto_masked():\n', '+        arr = np.empty(3, dtype=dtype)\n', '+        np.copyto(arr, np.array([value, value, value]), casting=""unsafe"",\n', '+                  where=[True, False, True])\n', '+\n', '+    yield copyto_masked\n', '+\n', '+    def direct_cast():\n', '+        np.array([value, value, value]).astype(dtype)\n', '+\n', '+    yield direct_cast\n', '+\n', '+    def direct_cast_nd_strided():\n', '+        arr = np.full((5, 5, 5), fill_value=value)[:, ::2, :]\n', '+        arr.astype(dtype)\n', '+\n', '+    yield direct_cast_nd_strided\n', '+\n', '+    def boolean_array_assignment():\n', '+        arr = np.empty(3, dtype=dtype)\n', '+        arr[[True, False, True]] = np.array([value, value])\n', '+\n', '+    yield boolean_array_assignment\n', '+\n', '+    def integer_array_assignment():\n', '+        arr = np.empty(3, dtype=dtype)\n', '+        values = np.array([value, value])\n', '+\n', '+        arr[[0, 1]] = values\n', '+\n', '+    yield integer_array_assignment\n', '+\n', '+    def integer_array_assignment_with_subspace():\n', '+        arr = np.empty((5, 3), dtype=dtype)\n', '+        values = np.array([value, value, value])\n', '+\n', '+        arr[[0, 2]] = values\n', '+\n', '+    yield integer_array_assignment_with_subspace\n', '+\n', '+    def flat_assignment():\n', '+        arr = np.empty((3,), dtype=dtype)\n', '+        values = np.array([value, value, value])\n', '+        arr.flat[:] = values\n', '+\n', '+    yield flat_assignment\n', '+\n', '+@pytest.mark.skipif(IS_WASM, reason=""no wasm fp exception support"")\n', '+@pytest.mark.parametrize([""value"", ""dtype""], values_and_dtypes())\n', '+@pytest.mark.filterwarnings(""ignore::numpy.ComplexWarning"")\n', '+def test_floatingpoint_errors_casting(dtype, value):\n', '+    dtype = np.dtype(dtype)\n', '+    for operation in check_operations(dtype, value):\n', '+        dtype = np.dtype(dtype)\n', '+\n', '+        match = ""invalid"" if dtype.kind in \'iu\' else ""overflow""\n', '+        with pytest.warns(RuntimeWarning, match=match):\n', '+            operation()\n', '+\n', '+        with np.errstate(all=""raise""):\n', '+            with pytest.raises(FloatingPointError, match=match):\n', '+                operation()\n', '+\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import textwrap\n', ' import enum\n', ' import random\n', '+import ctypes\n', ' \n', ' import numpy as np\n', ' from numpy.lib.stride_tricks import as_strided\n']","[' import textwrap\n', ' import enum\n', ' import random\n', ' \n', ' import numpy as np\n', ' from numpy.lib.stride_tricks import as_strided\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         for i, value in enumerate(values):\n', '             # Use item assignment to ensure this is not using casting:\n', '+            if value < 0 and dtype1.kind == ""u"":\n', '+                # Manually rollover unsigned integers (-1 -> int.max)\n', '+                value = value + np.iinfo(dtype1).max + 1\n', '             arr1[i] = value\n', ' \n', '         if dtype2 is None:\n']","[' \n', '         for i, value in enumerate(values):\n', '             # Use item assignment to ensure this is not using casting:\n', '             arr1[i] = value\n', ' \n', '         if dtype2 is None:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         for i, value in enumerate(values):\n', '             # Use item assignment to ensure this is not using casting:\n', '+            if value < 0 and dtype2.kind == ""u"":\n', '+                # Manually rollover unsigned integers (-1 -> int.max)\n', '+                value = value + np.iinfo(dtype2).max + 1\n', '             arr2[i] = value\n', ' \n', '         return arr1, arr2, values\n']","[' \n', '         for i, value in enumerate(values):\n', '             # Use item assignment to ensure this is not using casting:\n', '             arr2[i] = value\n', ' \n', '         return arr1, arr2, values\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         # None to <other> casts may succeed or fail, but a NULL'ed array must\n"", ""         # behave the same as one filled with None's.\n"", '         arr_normal = np.array([None] * 5)\n', '+        arr_NULLs = np.empty_like(arr_normal)\n', '+        ctypes.memset(arr_NULLs.ctypes.data, 0, arr_NULLs.nbytes)\n', '         # If the check fails (maybe it should) the test would lose its purpose:\n', '         assert arr_NULLs.tobytes() == b""\\x00"" * arr_NULLs.nbytes\n', ' \n']","[""         # None to <other> casts may succeed or fail, but a NULL'ed array must\n"", ""         # behave the same as one filled with None's.\n"", '         arr_normal = np.array([None] * 5)\n', '-        arr_NULLs = np.empty_like([None] * 5)\n', '         # If the check fails (maybe it should) the test would lose its purpose:\n', '         assert arr_NULLs.tobytes() == b""\\x00"" * arr_NULLs.nbytes\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import pytest\n', ' \n', ' import numpy as np\n', '+from numpy.testing import IS_WASM\n', ' \n', ' # This import is copied from random.tests.test_extending\n', ' try:\n']","[' import pytest\n', ' \n', ' import numpy as np\n', ' \n', ' # This import is copied from random.tests.test_extending\n', ' try:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @pytest.fixture\n', ' def install_temp(request, tmp_path):\n', '     # Based in part on test_cython from random.tests.test_extending\n', '+    if IS_WASM:\n', '+        pytest.skip(""No subprocess"")\n', ' \n', '     here = os.path.dirname(__file__)\n', '     ext_dir = os.path.join(here, ""examples"", ""cython"")\n']","[' @pytest.fixture\n', ' def install_temp(request, tmp_path):\n', '     # Based in part on test_cython from random.tests.test_extending\n', ' \n', '     here = os.path.dirname(__file__)\n', '     ext_dir = os.path.join(here, ""examples"", ""cython"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import datetime\n', ' import pytest\n', ' from numpy.testing import (\n', '+    IS_WASM,\n', '     assert_, assert_equal, assert_raises, assert_warns, suppress_warnings,\n', '     assert_raises_regex, assert_array_equal,\n', '     )\n']","[' import datetime\n', ' import pytest\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_warns, suppress_warnings,\n', '     assert_raises_regex, assert_array_equal,\n', '     )\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_timedelta_floor_divide(self, op1, op2, exp):\n', '         assert_equal(op1 // op2, exp)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.parametrize(""op1, op2"", [\n', '         # div by 0\n', ""         (np.timedelta64(10, 'us'),\n""]","['     def test_timedelta_floor_divide(self, op1, op2, exp):\n', '         assert_equal(op1 // op2, exp)\n', ' \n', '     @pytest.mark.parametrize(""op1, op2"", [\n', '         # div by 0\n', ""         (np.timedelta64(10, 'us'),\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         expected = (op1 // op2, op1 % op2)\n', '         assert_equal(divmod(op1, op2), expected)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""does not work in wasm"")\n', '     @pytest.mark.parametrize(""op1, op2"", [\n', '         # reuse cases from floordiv\n', '         # div by 0\n']","['         expected = (op1 // op2, op1 % op2)\n', '         assert_equal(divmod(op1, op2), expected)\n', ' \n', '     @pytest.mark.parametrize(""op1, op2"", [\n', '         # reuse cases from floordiv\n', '         # div by 0\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with assert_raises_regex(TypeError, ""common metadata divisor""):\n', '             val1 % val2\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_timedelta_modulus_div_by_zero(self):\n', '         with assert_warns(RuntimeWarning):\n', ""             actual = np.timedelta64(10, 's') % np.timedelta64(0, 's')\n""]","['         with assert_raises_regex(TypeError, ""common metadata divisor""):\n', '             val1 % val2\n', ' \n', '     def test_timedelta_modulus_div_by_zero(self):\n', '         with assert_warns(RuntimeWarning):\n', ""             actual = np.timedelta64(10, 's') % np.timedelta64(0, 's')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy as np\n', ' from numpy.core.multiarray import _vec_string\n', ' from numpy.testing import (\n']","['-\n', ' import numpy as np\n', ' from numpy.core.multiarray import _vec_string\n', ' from numpy.testing import (\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                [b'long', b'0123456789']])\n"", ' \n', '     def test_from_object_array_unicode(self):\n', ""+        A = np.array([['abc', 'Sigma \\u03a3'],\n"", ""                       ['long   ', '0123456789']], dtype='O')\n"", '         assert_raises(ValueError, np.char.array, (A,))\n', '         B = np.char.array(A, **kw_unicode_true)\n', ""         assert_equal(B.dtype.itemsize, 10 * np.array('a', 'U').dtype.itemsize)\n"", ""+        assert_array_equal(B, [['abc', 'Sigma \\u03a3'],\n"", ""                                ['long', '0123456789']])\n"", ' \n', '     def test_from_string_array(self):\n']","[""                                [b'long', b'0123456789']])\n"", ' \n', '     def test_from_object_array_unicode(self):\n', ""-        A = np.array([['abc', u'Sigma \\u03a3'],\n"", ""                       ['long   ', '0123456789']], dtype='O')\n"", '         assert_raises(ValueError, np.char.array, (A,))\n', '         B = np.char.array(A, **kw_unicode_true)\n', ""         assert_equal(B.dtype.itemsize, 10 * np.array('a', 'U').dtype.itemsize)\n"", ""-        assert_array_equal(B, [['abc', u'Sigma \\u03a3'],\n"", ""                                ['long', '0123456789']])\n"", ' \n', '     def test_from_string_array(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(C[0, 0] == A[0, 0])\n', ' \n', '     def test_from_unicode_array(self):\n', ""+        A = np.array([['abc', 'Sigma \\u03a3'],\n"", ""                       ['long   ', '0123456789']])\n"", '         assert_equal(A.dtype.type, np.unicode_)\n', '         B = np.char.array(A)\n']","['         assert_(C[0, 0] == A[0, 0])\n', ' \n', '     def test_from_unicode_array(self):\n', ""-        A = np.array([['abc', u'Sigma \\u03a3'],\n"", ""                       ['long   ', '0123456789']])\n"", '         assert_equal(A.dtype.type, np.unicode_)\n', '         B = np.char.array(A)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_unicode_upconvert(self):\n', ""         A = np.char.array(['abc'])\n"", ""+        B = np.char.array(['\\u03a3'])\n"", '         assert_(issubclass((A + B).dtype.type, np.unicode_))\n', ' \n', '     def test_from_string(self):\n']","[' \n', '     def test_unicode_upconvert(self):\n', ""         A = np.char.array(['abc'])\n"", ""-        B = np.char.array([u'\\u03a3'])\n"", '         assert_(issubclass((A + B).dtype.type, np.unicode_))\n', ' \n', '     def test_from_string(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(issubclass(A.dtype.type, np.string_))\n', ' \n', '     def test_from_unicode(self):\n', ""+        A = np.char.array('\\u03a3')\n"", '         assert_equal(len(A), 1)\n', '         assert_equal(len(A[0]), 1)\n', '         assert_equal(A.itemsize, 4)\n']","['         assert_(issubclass(A.dtype.type, np.string_))\n', ' \n', '     def test_from_unicode(self):\n', ""-        A = np.char.array(u'\\u03a3')\n"", '         assert_equal(len(A), 1)\n', '         assert_equal(len(A[0]), 1)\n', '         assert_equal(A.itemsize, 4)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestWhitespace:\n', '+    def setup_method(self):\n', ""         self.A = np.array([['abc ', '123  '],\n"", ""                            ['789 ', 'xyz ']]).view(np.chararray)\n"", ""         self.B = np.array([['abc', '123'],\n""]","[' \n', ' \n', ' class TestWhitespace:\n', '-    def setup(self):\n', ""         self.A = np.array([['abc ', '123  '],\n"", ""                            ['789 ', 'xyz ']]).view(np.chararray)\n"", ""         self.B = np.array([['abc', '123'],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(not np.any(self.A != self.B))\n', ' \n', ' class TestChar:\n', '+    def setup_method(self):\n', ""         self.A = np.array('abc1', dtype='c').view(np.chararray)\n"", ' \n', '     def test_it(self):\n']","['         assert_(not np.any(self.A != self.B))\n', ' \n', ' class TestChar:\n', '-    def setup(self):\n', ""         self.A = np.array('abc1', dtype='c').view(np.chararray)\n"", ' \n', '     def test_it(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         assert_equal(self.A.upper()[:2].tobytes(), b'AB')\n"", ' \n', ' class TestComparisons:\n', '+    def setup_method(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '123  '],\n""]","[""         assert_equal(self.A.upper()[:2].tobytes(), b'AB')\n"", ' \n', ' class TestComparisons:\n', '-    def setup(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '123  '],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestComparisonsMixed1(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '+    def setup_method(self):\n', '+        TestComparisons.setup_method(self)\n', ""         self.B = np.array([['efg', '123  '],\n"", ""                            ['051', 'tuv']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestComparisonsMixed2(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '+    def setup_method(self):\n', '+        TestComparisons.setup_method(self)\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestInformation:\n', '+    def setup_method(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']]).view(np.chararray)\n"", ""+        self.B = np.array([[' \\u03a3 ', ''],\n"", ""+                           ['12345', 'MixedCase'],\n"", ""+                           ['123 \\t 345 \\0 ', 'UPPER']]).view(np.chararray)\n"", ' \n', '     def test_len(self):\n', '         assert_(issubclass(np.char.str_len(self.A).dtype.type, np.integer))\n']","[' class TestComparisonsMixed1(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '-    def setup(self):\n', '-        TestComparisons.setup(self)\n', ""         self.B = np.array([['efg', '123  '],\n"", ""                            ['051', 'tuv']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestComparisonsMixed2(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '-    def setup(self):\n', '-        TestComparisons.setup(self)\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestInformation:\n', '-    def setup(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']]).view(np.chararray)\n"", ""-        self.B = np.array([[u' \\u03a3 ', u''],\n"", ""-                           [u'12345', u'MixedCase'],\n"", ""-                           [u'123 \\t 345 \\0 ', u'UPPER']]).view(np.chararray)\n"", ' \n', '     def test_len(self):\n', '         assert_(issubclass(np.char.str_len(self.A).dtype.type, np.integer))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestMethods:\n', '+    def setup_method(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']],\n"", ""                           dtype='S').view(np.chararray)\n"", ""+        self.B = np.array([[' \\u03a3 ', ''],\n"", ""+                           ['12345', 'MixedCase'],\n"", ""+                           ['123 \\t 345 \\0 ', 'UPPER']]).view(np.chararray)\n"", ' \n', '     def test_capitalize(self):\n', ""         tgt = [[b' abc ', b''],\n""]","[' \n', ' \n', ' class TestMethods:\n', '-    def setup(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']],\n"", ""                           dtype='S').view(np.chararray)\n"", ""-        self.B = np.array([[u' \\u03a3 ', u''],\n"", ""-                           [u'12345', u'MixedCase'],\n"", ""-                           [u'123 \\t 345 \\0 ', u'UPPER']]).view(np.chararray)\n"", ' \n', '     def test_capitalize(self):\n', ""         tgt = [[b' abc ', b''],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(issubclass(self.A.capitalize().dtype.type, np.string_))\n', '         assert_array_equal(self.A.capitalize(), tgt)\n', ' \n', ""+        tgt = [[' \\u03c3 ', ''],\n"", ""                ['12345', 'Mixedcase'],\n"", ""                ['123 \\t 345 \\0 ', 'Upper']]\n"", '         assert_(issubclass(self.B.capitalize().dtype.type, np.unicode_))\n']","['         assert_(issubclass(self.A.capitalize().dtype.type, np.string_))\n', '         assert_array_equal(self.A.capitalize(), tgt)\n', ' \n', ""-        tgt = [[u' \\u03c3 ', ''],\n"", ""                ['12345', 'Mixedcase'],\n"", ""                ['123 \\t 345 \\0 ', 'Upper']]\n"", '         assert_(issubclass(self.B.capitalize().dtype.type, np.unicode_))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(issubclass(self.A.lower().dtype.type, np.string_))\n', '         assert_array_equal(self.A.lower(), tgt)\n', ' \n', ""+        tgt = [[' \\u03c3 ', ''],\n"", ""+               ['12345', 'mixedcase'],\n"", ""+               ['123 \\t 345 \\0 ', 'upper']]\n"", '         assert_(issubclass(self.B.lower().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.lower(), tgt)\n', ' \n']","['         assert_(issubclass(self.A.lower().dtype.type, np.string_))\n', '         assert_array_equal(self.A.lower(), tgt)\n', ' \n', ""-        tgt = [[u' \\u03c3 ', u''],\n"", ""-               [u'12345', u'mixedcase'],\n"", ""-               [u'123 \\t 345 \\0 ', u'upper']]\n"", '         assert_(issubclass(self.B.lower().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.lower(), tgt)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                [b'23 \\t 345 \\x00', b'UPPER']]\n"", ""         assert_array_equal(self.A.lstrip([b'1', b'M']), tgt)\n"", ' \n', ""+        tgt = [['\\u03a3 ', ''],\n"", ""                ['12345', 'MixedCase'],\n"", ""                ['123 \\t 345 \\0 ', 'UPPER']]\n"", '         assert_(issubclass(self.B.lstrip().dtype.type, np.unicode_))\n']","[""                [b'23 \\t 345 \\x00', b'UPPER']]\n"", ""         assert_array_equal(self.A.lstrip([b'1', b'M']), tgt)\n"", ' \n', ""-        tgt = [[u'\\u03a3 ', ''],\n"", ""                ['12345', 'MixedCase'],\n"", ""                ['123 \\t 345 \\0 ', 'UPPER']]\n"", '         assert_(issubclass(self.B.lstrip().dtype.type, np.unicode_))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                ]\n', ""         assert_array_equal(self.A.rstrip([b'5', b'ER']), tgt)\n"", ' \n', ""+        tgt = [[' \\u03a3', ''],\n"", ""                ['12345', 'MixedCase'],\n"", ""                ['123 \\t 345', 'UPPER']]\n"", '         assert_(issubclass(self.B.rstrip().dtype.type, np.unicode_))\n']","['                ]\n', ""         assert_array_equal(self.A.rstrip([b'5', b'ER']), tgt)\n"", ' \n', ""-        tgt = [[u' \\u03a3', ''],\n"", ""                ['12345', 'MixedCase'],\n"", ""                ['123 \\t 345', 'UPPER']]\n"", '         assert_(issubclass(self.B.rstrip().dtype.type, np.unicode_))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                [b'23 \\t 345 \\x00', b'UPP']]\n"", ""         assert_array_equal(self.A.strip([b'15', b'EReM']), tgt)\n"", ' \n', ""+        tgt = [['\\u03a3', ''],\n"", ""                ['12345', 'MixedCase'],\n"", ""                ['123 \\t 345', 'UPPER']]\n"", '         assert_(issubclass(self.B.strip().dtype.type, np.unicode_))\n']","[""                [b'23 \\t 345 \\x00', b'UPP']]\n"", ""         assert_array_equal(self.A.strip([b'15', b'EReM']), tgt)\n"", ' \n', ""-        tgt = [[u'\\u03a3', ''],\n"", ""                ['12345', 'MixedCase'],\n"", ""                ['123 \\t 345', 'UPPER']]\n"", '         assert_(issubclass(self.B.strip().dtype.type, np.unicode_))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(issubclass(self.A.swapcase().dtype.type, np.string_))\n', '         assert_array_equal(self.A.swapcase(), tgt)\n', ' \n', ""+        tgt = [[' \\u03c3 ', ''],\n"", ""+               ['12345', 'mIXEDcASE'],\n"", ""+               ['123 \\t 345 \\0 ', 'upper']]\n"", '         assert_(issubclass(self.B.swapcase().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.swapcase(), tgt)\n', ' \n']","['         assert_(issubclass(self.A.swapcase().dtype.type, np.string_))\n', '         assert_array_equal(self.A.swapcase(), tgt)\n', ' \n', ""-        tgt = [[u' \\u03c3 ', u''],\n"", ""-               [u'12345', u'mIXEDcASE'],\n"", ""-               [u'123 \\t 345 \\0 ', u'upper']]\n"", '         assert_(issubclass(self.B.swapcase().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.swapcase(), tgt)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(issubclass(self.A.title().dtype.type, np.string_))\n', '         assert_array_equal(self.A.title(), tgt)\n', ' \n', ""+        tgt = [[' \\u03a3 ', ''],\n"", ""+               ['12345', 'Mixedcase'],\n"", ""+               ['123 \\t 345 \\0 ', 'Upper']]\n"", '         assert_(issubclass(self.B.title().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.title(), tgt)\n', ' \n']","['         assert_(issubclass(self.A.title().dtype.type, np.string_))\n', '         assert_array_equal(self.A.title(), tgt)\n', ' \n', ""-        tgt = [[u' \\u03a3 ', u''],\n"", ""-               [u'12345', u'Mixedcase'],\n"", ""-               [u'123 \\t 345 \\0 ', u'Upper']]\n"", '         assert_(issubclass(self.B.title().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.title(), tgt)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(issubclass(self.A.upper().dtype.type, np.string_))\n', '         assert_array_equal(self.A.upper(), tgt)\n', ' \n', ""+        tgt = [[' \\u03a3 ', ''],\n"", ""+               ['12345', 'MIXEDCASE'],\n"", ""+               ['123 \\t 345 \\0 ', 'UPPER']]\n"", '         assert_(issubclass(self.B.upper().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.upper(), tgt)\n', ' \n']","['         assert_(issubclass(self.A.upper().dtype.type, np.string_))\n', '         assert_array_equal(self.A.upper(), tgt)\n', ' \n', ""-        tgt = [[u' \\u03a3 ', u''],\n"", ""-               [u'12345', u'MIXEDCASE'],\n"", ""-               [u'123 \\t 345 \\0 ', u'UPPER']]\n"", '         assert_(issubclass(self.B.upper().dtype.type, np.unicode_))\n', '         assert_array_equal(self.B.upper(), tgt)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestOperations:\n', '+    def setup_method(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '456'],\n""]","[' \n', ' \n', ' class TestOperations:\n', '-    def setup(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '456'],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     message = ''\n"", '     warning_cls = DeprecationWarning\n', ' \n', '+    def setup_method(self):\n', '         self.warn_ctx = warnings.catch_warnings(record=True)\n', '         self.log = self.warn_ctx.__enter__()\n', ' \n']","[""     message = ''\n"", '     warning_cls = DeprecationWarning\n', ' \n', '-    def setup(self):\n', '         self.warn_ctx = warnings.catch_warnings(record=True)\n', '         self.log = self.warn_ctx.__enter__()\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         warnings.filterwarnings(""always"", message=self.message,\n', '                                 category=self.warning_cls)\n', ' \n', '+    def teardown_method(self):\n', '         self.warn_ctx.__exit__()\n', ' \n', '     def assert_deprecated(self, function, num=1, ignore_others=False,\n']","['         warnings.filterwarnings(""always"", message=self.message,\n', '                                 category=self.warning_cls)\n', ' \n', '-    def teardown(self):\n', '         self.warn_ctx.__exit__()\n', ' \n', '     def assert_deprecated(self, function, num=1, ignore_others=False,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # For two string arrays, strings always raised the broadcasting error:\n', ""         a = np.array(['a', 'b'])\n"", ""         b = np.array(['a', 'b', 'c'])\n"", '+        assert_warns(FutureWarning, lambda x, y: x == y, a, b)\n', ' \n', '         # The empty list is not cast to string, and this used to pass due\n', '         # to dtype mismatch; now (2018-06-21) it correctly leads to a\n']","['         # For two string arrays, strings always raised the broadcasting error:\n', ""         a = np.array(['a', 'b'])\n"", ""         b = np.array(['a', 'b', 'c'])\n"", '-        assert_raises(ValueError, lambda x, y: x == y, a, b)\n', ' \n', '         # The empty list is not cast to string, and this used to pass due\n', '         # to dtype mismatch; now (2018-06-21) it correctly leads to a\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestTestDeprecated:\n', '     def test_assert_deprecated(self):\n', '         test_case_instance = _DeprecationTestCase()\n', '+        test_case_instance.setup_method()\n', '         assert_raises(AssertionError,\n', '                       test_case_instance.assert_deprecated,\n', '                       lambda: None)\n']","[' class TestTestDeprecated:\n', '     def test_assert_deprecated(self):\n', '         test_case_instance = _DeprecationTestCase()\n', '-        test_case_instance.setup()\n', '         assert_raises(AssertionError,\n', '                       test_case_instance.assert_deprecated,\n', '                       lambda: None)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             warnings.warn(""foo"", category=DeprecationWarning, stacklevel=2)\n', ' \n', '         test_case_instance.assert_deprecated(foo)\n', '+        test_case_instance.teardown_method()\n', ' \n', ' \n', ' class TestNonNumericConjugate(_DeprecationTestCase):\n']","['             warnings.warn(""foo"", category=DeprecationWarning, stacklevel=2)\n', ' \n', '         test_case_instance.assert_deprecated(foo)\n', '-        test_case_instance.teardown()\n', ' \n', ' \n', ' class TestNonNumericConjugate(_DeprecationTestCase):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.assert_deprecated(lambda: np.nonzero(np.array(1)))\n', ' \n', ' \n', ' class TestToString(_DeprecationTestCase):\n', '     # 2020-03-06 1.19.0\n', '     message = re.escape(""tostring() is deprecated. Use tobytes() instead."")\n']","['         self.assert_deprecated(lambda: np.nonzero(np.array(1)))\n', ' \n', ' \n', '-def test_deprecate_ragged_arrays():\n', '-    # 2019-11-29 1.19.0\n', '-    #\n', '-    # NEP 34 deprecated automatic object dtype when creating ragged\n', '-    # arrays. Also see the ""ragged"" tests in `test_multiarray`\n', '-    #\n', '-    # emits a VisibleDeprecationWarning\n', '-    arg = [1, [2, 3]]\n', '-    with assert_warns(np.VisibleDeprecationWarning):\n', '-        np.array(arg)\n', '-\n', '-\n', '-class TestTooDeepDeprecation(_VisibleDeprecationTestCase):\n', '-    # NumPy 1.20, 2020-05-08\n', '-    # This is a bit similar to the above ragged array deprecation case.\n', '-    message = re.escape(""Creating an ndarray from nested sequences exceeding"")\n', '-\n', '-    def test_deprecation(self):\n', '-        nested = [1]\n', '-        for i in range(np.MAXDIMS - 1):\n', '-            nested = [nested]\n', '-        self.assert_not_deprecated(np.array, args=(nested,))\n', '-        self.assert_not_deprecated(np.array,\n', '-                args=(nested,), kwargs=dict(dtype=object))\n', '-\n', '-        self.assert_deprecated(np.array, args=([nested],))\n', '-\n', '-\n', ' class TestToString(_DeprecationTestCase):\n', '     # 2020-03-06 1.19.0\n', '     message = re.escape(""tostring() is deprecated. Use tobytes() instead."")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         self.assert_deprecated(lambda: np.searchsorted(arr[0], 4, side='Random'))\n"", ' \n', ' \n', ' class TestMatrixInOuter(_DeprecationTestCase):\n', '     # 2020-05-13 NumPy 1.20.0\n', '     message = (r""add.outer\\(\\) was passed a numpy matrix as ""\n']","[""         self.assert_deprecated(lambda: np.searchsorted(arr[0], 4, side='Random'))\n"", ' \n', ' \n', '-class TestDeprecatedGlobals(_DeprecationTestCase):\n', '-    # 2020-06-06\n', '-    def test_type_aliases(self):\n', '-        # from builtins\n', '-        self.assert_deprecated(lambda: np.bool(True))\n', '-        self.assert_deprecated(lambda: np.int(1))\n', '-        self.assert_deprecated(lambda: np.float(1))\n', '-        self.assert_deprecated(lambda: np.complex(1))\n', '-        self.assert_deprecated(lambda: np.object())\n', ""-        self.assert_deprecated(lambda: np.str('abc'))\n"", '-\n', '-        # from np.compat\n', '-        self.assert_deprecated(lambda: np.long(1))\n', ""-        self.assert_deprecated(lambda: np.unicode('abc'))\n"", '-\n', '-        # from np.core.numerictypes\n', '-        self.assert_deprecated(lambda: np.typeDict)\n', '-\n', '-\n', ' class TestMatrixInOuter(_DeprecationTestCase):\n', '     # 2020-05-13 NumPy 1.20.0\n', '     message = (r""add.outer\\(\\) was passed a numpy matrix as ""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.assert_not_deprecated(np.add.outer, args=(arr, arr))\n', ' \n', ' \n', ' class FlatteningConcatenateUnsafeCast(_DeprecationTestCase):\n', '     # NumPy 1.20, 2020-09-03\n', '     message = ""concatenate with `axis=None` will use same-kind casting""\n']","['         self.assert_not_deprecated(np.add.outer, args=(arr, arr))\n', ' \n', ' \n', '-class TestRaggedArray(_DeprecationTestCase):\n', '-    # 2020-07-24, NumPy 1.20.0\n', '-    message = ""setting an array element with a sequence""\n', '-\n', '-    def test_deprecated(self):\n', '-        arr = np.ones((1, 1))\n', '-        # Deprecated if the array is a leave node:\n', '-        self.assert_deprecated(lambda: np.array([arr, 0], dtype=np.float64))\n', '-        self.assert_deprecated(lambda: np.array([0, arr], dtype=np.float64))\n', '-        # And when it is an assignment into a lower dimensional subarray:\n', '-        self.assert_deprecated(lambda: np.array([arr, [0]], dtype=np.float64))\n', '-        self.assert_deprecated(lambda: np.array([[0], arr], dtype=np.float64))\n', '-\n', '-\n', ' class FlatteningConcatenateUnsafeCast(_DeprecationTestCase):\n', '     # NumPy 1.20, 2020-09-03\n', '     message = ""concatenate with `axis=None` will use same-kind casting""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.assert_deprecated(lambda: np.add(1, 2, sig=(np.dtype(""l""),)))\n', ' \n', ' \n', ' class TestCtypesGetter(_DeprecationTestCase):\n', '     # Deprecated 2021-05-18, Numpy 1.21.0\n', '     warning_cls = DeprecationWarning\n']","['         self.assert_deprecated(lambda: np.add(1, 2, sig=(np.dtype(""l""),)))\n', ' \n', ' \n', '-class TestComparisonBadDType(_DeprecationTestCase):\n', '-    # Deprecated 2021-04-01, NumPy 1.21\n', '-    message = r""using `dtype=` in comparisons is only useful for""\n', '-\n', '-    def test_deprecated(self):\n', '-        self.assert_deprecated(lambda: np.equal(1, 1, dtype=np.int64))\n', '-        # Not an error only for the transition\n', '-        self.assert_deprecated(lambda: np.equal(1, 1, sig=(None, None, ""l"")))\n', '-\n', '-    def test_not_deprecated(self):\n', '-        np.equal(True, False, dtype=bool)\n', '-        np.equal(3, 5, dtype=bool, casting=""unsafe"")\n', '-        np.equal([None], [4], dtype=object)\n', '-\n', '-class TestComparisonBadObjectDType(_DeprecationTestCase):\n', '-    # Deprecated 2021-04-01, NumPy 1.21  (different branch of the above one)\n', '-    message = r""using `dtype=object` \\(or equivalent signature\\) will""\n', '-    warning_cls = FutureWarning\n', '-\n', '-    def test_deprecated(self):\n', '-        self.assert_deprecated(lambda: np.equal(1, 1, dtype=object))\n', '-        self.assert_deprecated(\n', '-                lambda: np.equal(1, 1, sig=(None, None, object)))\n', '-\n', '-\n', ' class TestCtypesGetter(_DeprecationTestCase):\n', '     # Deprecated 2021-05-18, Numpy 1.21.0\n', '     warning_cls = DeprecationWarning\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.assert_not_deprecated(lambda: getattr(self.ctypes, name))\n', ' \n', ' \n', ' PARTITION_DICT = {\n', '     ""partition method"": np.arange(10).partition,\n', '     ""argpartition method"": np.arange(10).argpartition,\n']","['         self.assert_not_deprecated(lambda: getattr(self.ctypes, name))\n', ' \n', ' \n', '-class TestUFuncForcedDTypeWarning(_DeprecationTestCase):\n', '-    message = ""The `dtype` and `signature` arguments to ufuncs only select the""\n', '-\n', '-    def test_not_deprecated(self):\n', '-        import pickle\n', '-        # does not warn (test relies on bad pickling behaviour, simply remove\n', '-        # it if the `assert int64 is not int64_2` should start failing.\n', '-        int64 = np.dtype(""int64"")\n', '-        int64_2 = pickle.loads(pickle.dumps(int64))\n', '-        assert int64 is not int64_2\n', '-        self.assert_not_deprecated(lambda: np.add(3, 4, dtype=int64_2))\n', '-\n', '-    def test_deprecation(self):\n', '-        int64 = np.dtype(""int64"")\n', '-        self.assert_deprecated(lambda: np.add(3, 5, dtype=int64.newbyteorder()))\n', '-        self.assert_deprecated(lambda: np.add(3, 5, dtype=""m8[ns]""))\n', '-\n', '-    def test_behaviour(self):\n', '-        int64 = np.dtype(""int64"")\n', '-        arr = np.arange(10, dtype=""m8[s]"")\n', '-\n', '-        with pytest.warns(DeprecationWarning, match=self.message):\n', '-            np.add(3, 5, dtype=int64.newbyteorder())\n', '-        with pytest.warns(DeprecationWarning, match=self.message):\n', '-            np.add(3, 5, dtype=""m8[ns]"")  # previously used the ""ns""\n', '-        with pytest.warns(DeprecationWarning, match=self.message):\n', '-            np.add(arr, arr, dtype=""m8[ns]"")  # never preserved the ""ns""\n', '-        with pytest.warns(DeprecationWarning, match=self.message):\n', '-            np.maximum(arr, arr, dtype=""m8[ns]"")  # previously used the ""ns""\n', '-        with pytest.warns(DeprecationWarning, match=self.message):\n', '-            np.maximum.reduce(arr, dtype=""m8[ns]"")  # never preserved the ""ns""\n', '-\n', '-\n', ' PARTITION_DICT = {\n', '     ""partition method"": np.arange(10).partition,\n', '     ""argpartition method"": np.arange(10).argpartition,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Deprecated 2021-10-19, NumPy 1.22\n', '     warning_cls = DeprecationWarning\n', ' \n', '     def test_deprecated_module(self):\n', '         self.assert_deprecated(lambda: getattr(np.core, ""machar""))\n', ' \n']","['     # Deprecated 2021-10-19, NumPy 1.22\n', '     warning_cls = DeprecationWarning\n', ' \n', '-    def test_deprecated(self):\n', '-        self.assert_deprecated(lambda: np.MachAr)\n', '-\n', '     def test_deprecated_module(self):\n', '         self.assert_deprecated(lambda: getattr(np.core, ""machar""))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_deprecated(self):\n', '         a = np.zeros((1,)*32)\n', '         self.assert_deprecated(lambda: np.repeat(a, 1, axis=np.MAXDIMS))\n', '+\n', '+\n', '+class TestLoadtxtParseIntsViaFloat(_DeprecationTestCase):\n', '+    # Deprecated 2022-07-03, NumPy 1.23\n', '+    # This test can be removed without replacement after the deprecation.\n', '+    # The tests:\n', '+    #   * numpy/lib/tests/test_loadtxt.py::test_integer_signs\n', '+    #   * lib/tests/test_loadtxt.py::test_implicit_cast_float_to_int_fails\n', '+    # Have a warning filter that needs to be removed.\n', '+    message = r""loadtxt\\(\\): Parsing an integer via a float is deprecated.*""\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_deprecated_warning(self, dtype):\n', '+        with pytest.warns(DeprecationWarning, match=self.message):\n', '+            np.loadtxt([""10.5""], dtype=dtype)\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_deprecated_raised(self, dtype):\n', '+        # The DeprecationWarning is chained when raised, so test manually:\n', '+        with warnings.catch_warnings():\n', '+            warnings.simplefilter(""error"", DeprecationWarning)\n', '+            try:\n', '+                np.loadtxt([""10.5""], dtype=dtype)\n', '+            except ValueError as e:\n', '+                assert isinstance(e.__cause__, DeprecationWarning)\n', '+\n', '+\n', '+class TestPyIntConversion(_DeprecationTestCase):\n', '+    message = r"".*stop allowing conversion of out-of-bound.*""\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_deprecated_scalar(self, dtype):\n', '+        dtype = np.dtype(dtype)\n', '+        info = np.iinfo(dtype)\n', '+\n', '+        # Cover the most common creation paths (all end up in the\n', '+        # same place):\n', '+        def scalar(value, dtype):\n', '+            dtype.type(value)\n', '+\n', '+        def assign(value, dtype):\n', '+            arr = np.array([0, 0, 0], dtype=dtype)\n', '+            arr[2] = value\n', '+\n', '+        def create(value, dtype):\n', '+            np.array([value], dtype=dtype)\n', '+\n', '+        for creation_func in [scalar, assign, create]:\n', '+            try:\n', '+                self.assert_deprecated(\n', '+                        lambda: creation_func(info.min - 1, dtype))\n', '+            except OverflowError:\n', '+                pass  # OverflowErrors always happened also before and are OK.\n', '+\n', '+            try:\n', '+                self.assert_deprecated(\n', '+                        lambda: creation_func(info.max + 1, dtype))\n', '+            except OverflowError:\n', '+                pass  # OverflowErrors always happened also before and are OK.\n', '+\n', '+\n', '+class TestDeprecatedGlobals(_DeprecationTestCase):\n', '+    # Deprecated 2022-11-17, NumPy 1.24\n', '+    def test_type_aliases(self):\n', '+        # from builtins\n', '+        self.assert_deprecated(lambda: np.bool8)\n', '+        self.assert_deprecated(lambda: np.int0)\n', '+        self.assert_deprecated(lambda: np.uint0)\n', '+        self.assert_deprecated(lambda: np.bytes0)\n', '+        self.assert_deprecated(lambda: np.str0)\n', '+        self.assert_deprecated(lambda: np.object0)\n', '+\n', '+\n', '+@pytest.mark.parametrize(""name"",\n', '+        [""bool"", ""long"", ""ulong"", ""str"", ""bytes"", ""object""])\n', '+def test_future_scalar_attributes(name):\n', '+    # FutureWarning added 2022-11-17, NumPy 1.24,\n', '+    assert name not in dir(np)  # we may want to not add them\n', '+    with pytest.warns(FutureWarning,\n', '+            match=f""In the future .*{name}""):\n', '+        assert not hasattr(np, name)\n', '+\n', '+    # Unfortunately, they are currently still valid via `np.dtype()`\n', '+    np.dtype(name)\n', '+    name in np.sctypeDict\n']","['     def test_deprecated(self):\n', '         a = np.zeros((1,)*32)\n', '         self.assert_deprecated(lambda: np.repeat(a, 1, axis=np.MAXDIMS))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         y = np.zeros((5,), dtype=dt)\n', ""         z = y['int']\n"", ' \n', '+        with pytest.raises(BufferError):\n', '             np.from_dlpack(z)\n', ' \n', '     @pytest.mark.skipif(IS_PYPY, reason=""PyPy can\'t get refcounts."")\n']","['         y = np.zeros((5,), dtype=dt)\n', ""         z = y['int']\n"", ' \n', '-        with pytest.raises(RuntimeError):\n', '             np.from_dlpack(z)\n', ' \n', '     @pytest.mark.skipif(IS_PYPY, reason=""PyPy can\'t get refcounts."")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_invalid_dtype(self):\n', ""         x = np.asarray(np.datetime64('2021-05-27'))\n"", ' \n', '+        with pytest.raises(BufferError):\n', '             np.from_dlpack(x)\n', ' \n', '     def test_invalid_byte_swapping(self):\n', ""         dt = np.dtype('=i8').newbyteorder()\n"", '         x = np.arange(5, dtype=dt)\n', ' \n', '+        with pytest.raises(BufferError):\n', '             np.from_dlpack(x)\n', ' \n', '     def test_non_contiguous(self):\n']","['     def test_invalid_dtype(self):\n', ""         x = np.asarray(np.datetime64('2021-05-27'))\n"", ' \n', '-        with pytest.raises(TypeError):\n', '             np.from_dlpack(x)\n', ' \n', '     def test_invalid_byte_swapping(self):\n', ""         dt = np.dtype('=i8').newbyteorder()\n"", '         x = np.arange(5, dtype=dt)\n', ' \n', '-        with pytest.raises(TypeError):\n', '             np.from_dlpack(x)\n', ' \n', '     def test_non_contiguous(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         x = np.arange(5)\n', '         _ = x.__dlpack__()\n', '         raise RuntimeError\n', '+\n', '     def test_dlpack_destructor_exception(self):\n', '         with pytest.raises(RuntimeError):\n', '             self.dlpack_deleter_exception()\n']","['         x = np.arange(5)\n', '         _ = x.__dlpack__()\n', '         raise RuntimeError\n', '-    \n', '     def test_dlpack_destructor_exception(self):\n', '         with pytest.raises(RuntimeError):\n', '             self.dlpack_deleter_exception()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_readonly(self):\n', '         x = np.arange(5)\n', '         x.flags.writeable = False\n', '+        with pytest.raises(BufferError):\n', '             x.__dlpack__()\n', ' \n', '     def test_ndim0(self):\n']","['     def test_readonly(self):\n', '         x = np.arange(5)\n', '         x.flags.writeable = False\n', '-        with pytest.raises(TypeError):\n', '             x.__dlpack__()\n', ' \n', '     def test_ndim0(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.core._multiarray_tests import create_custom_field_dtype\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_array_equal, assert_raises, HAS_REFCOUNT,\n', '+    IS_PYSTON, _OLD_PROMOTION)\n', ' from numpy.compat import pickle\n', ' from itertools import permutations\n', ' import random\n']","[' from numpy.core._multiarray_tests import create_custom_field_dtype\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_array_equal, assert_raises, HAS_REFCOUNT,\n', '-    IS_PYSTON)\n', ' from numpy.compat import pickle\n', ' from itertools import permutations\n', ' import random\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert refcounts == refcounts_new\n', ' \n', '     def test_mutate(self):\n', '+        # Mutating a dtype should reset the cached hash value.\n', '+        # NOTE: Mutating should be deprecated, but new API added to replace it.\n', ""         a = np.dtype([('yo', int)])\n"", ""         b = np.dtype([('yo', int)])\n"", ""         c = np.dtype([('ye', int)])\n""]","['         assert refcounts == refcounts_new\n', ' \n', '     def test_mutate(self):\n', '-        # Mutating a dtype should reset the cached hash value\n', ""         a = np.dtype([('yo', int)])\n"", ""         b = np.dtype([('yo', int)])\n"", ""         c = np.dtype([('ye', int)])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_dtype_equal(a, b)\n', '         assert_dtype_not_equal(a, c)\n', ' \n', '+    def test_mutate_error(self):\n', '+        # NOTE: Mutating should be deprecated, but new API added to replace it.\n', '+        a = np.dtype(""i,i"")\n', '+\n', '+        with pytest.raises(ValueError, match=""must replace all names at once""):\n', '+            a.names = [""f0""]\n', '+\n', '+        with pytest.raises(ValueError, match="".*and not string""):\n', '+            a.names = [""f0"", b""not a unicode name""]\n', '+\n', '     def test_not_lists(self):\n', '         """"""Test if an appropriate exception is raised when passing bad values to\n', '         the dtype constructor.\n']","['         assert_dtype_equal(a, b)\n', '         assert_dtype_not_equal(a, c)\n', ' \n', '     def test_not_lists(self):\n', '         """"""Test if an appropriate exception is raised when passing bad values to\n', '         the dtype constructor.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         dt2 = np.dtype({'names':['f2', 'f0', 'f1'],\n"", ""                         'formats':['<u4', '<u2', '<u2'],\n"", ""                         'offsets':[4, 0, 2]}, align=True)\n"", '+        vals = [(0, 1, 2), (3, 2**15-1, 4)]\n', '+        vals2 = [(0, 1, 2), (3, 2**15-1, 4)]\n', '         a = np.array(vals, dt)\n', '         b = np.array(vals2, dt2)\n', '         assert_equal(a.astype(dt2), b)\n']","[""         dt2 = np.dtype({'names':['f2', 'f0', 'f1'],\n"", ""                         'formats':['<u4', '<u2', '<u2'],\n"", ""                         'offsets':[4, 0, 2]}, align=True)\n"", '-        vals = [(0, 1, 2), (3, -1, 4)]\n', '-        vals2 = [(0, 1, 2), (3, -1, 4)]\n', '         a = np.array(vals, dt)\n', '         b = np.array(vals2, dt2)\n', '         assert_equal(a.astype(dt2), b)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         dt = np.dtype({""names"": [], ""formats"": [], ""itemsize"": 0}, align=True)\n', '         assert dt == np.dtype([])\n', ' \n', '+    def test_subarray_base_item(self):\n', '+        arr = np.ones(3, dtype=[(""f"", ""i"", 3)])\n', '+        # Extracting the field ""absorbs"" the subarray into a view:\n', '+        assert arr[""f""].base is arr\n', '+        # Extract the structured item, and then check the tuple component:\n', '+        item = arr.item(0)\n', '+        assert type(item) is tuple and len(item) == 1\n', '+        assert item[0].base is arr\n', '+\n', '+    def test_subarray_cast_copies(self):\n', '+        # Older versions of NumPy did NOT copy, but they got the ownership\n', '+        # wrong (not actually knowing the correct base!).  Versions since 1.21\n', '+        # (I think) crashed fairly reliable.  This defines the correct behavior\n', '+        # as a copy.  Keeping the ownership would be possible (but harder)\n', '+        arr = np.ones(3, dtype=[(""f"", ""i"", 3)])\n', '+        cast = arr.astype(object)\n', '+        for fields in cast:\n', '+            assert type(fields) == tuple and len(fields) == 1\n', '+            subarr = fields[0]\n', '+            assert subarr.base is None\n', '+            assert subarr.flags.owndata\n', '+\n', '+\n', ' def iter_struct_object_dtypes():\n', '     """"""\n', '     Iterates over a few complex dtypes and object pattern which\n']","['         dt = np.dtype({""names"": [], ""formats"": [], ""itemsize"": 0}, align=True)\n', '         assert dt == np.dtype([])\n', ' \n', ' def iter_struct_object_dtypes():\n', '     """"""\n', '     Iterates over a few complex dtypes and object pattern which\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""Test cases related to more complex DType promotions.  Further promotion\n', '     tests are defined in `test_numeric.py`\n', '     """"""\n', '+    @np._no_nep50_warning()\n', '+    @pytest.mark.parametrize([""other"", ""expected"", ""expected_weak""],\n', '+            [(2**16-1, np.complex64, None),\n', '+             (2**32-1, np.complex128, np.complex64),\n', '+             (np.float16(2), np.complex64, None),\n', '+             (np.float32(2), np.complex64, None),\n', '+             (np.longdouble(2), np.complex64, np.clongdouble),\n', '              # Base of the double value to sidestep any rounding issues:\n', '+             (np.longdouble(np.nextafter(1.7e308, 0.)),\n', '+                  np.complex128, np.clongdouble),\n', '              # Additionally use ""nextafter"" so the cast can\'t round down:\n', '+             (np.longdouble(np.nextafter(1.7e308, np.inf)),\n', '+                  np.clongdouble, None),\n', '              # repeat for complex scalars:\n', '+             (np.complex64(2), np.complex64, None),\n', '+             (np.clongdouble(2), np.complex64, np.clongdouble),\n', '              # Base of the double value to sidestep any rounding issues:\n', '+             (np.clongdouble(np.nextafter(1.7e308, 0.) * 1j),\n', '+                  np.complex128, np.clongdouble),\n', '              # Additionally use ""nextafter"" so the cast can\'t round down:\n', '+             (np.clongdouble(np.nextafter(1.7e308, np.inf)),\n', '+                  np.clongdouble, None),\n', '              ])\n', '+    def test_complex_other_value_based(self,\n', '+            weak_promotion, other, expected, expected_weak):\n', '+        if weak_promotion and expected_weak is not None:\n', '+            expected = expected_weak\n', '+\n', '         # This would change if we modify the value based promotion\n', '         min_complex = np.dtype(np.complex64)\n', ' \n']","['     """"""Test cases related to more complex DType promotions.  Further promotion\n', '     tests are defined in `test_numeric.py`\n', '     """"""\n', '-    @pytest.mark.parametrize([""other"", ""expected""],\n', '-            [(2**16-1, np.complex64),\n', '-             (2**32-1, np.complex128),\n', '-             (np.float16(2), np.complex64),\n', '-             (np.float32(2), np.complex64),\n', '-             (np.longdouble(2), np.complex64),\n', '              # Base of the double value to sidestep any rounding issues:\n', '-             (np.longdouble(np.nextafter(1.7e308, 0.)), np.complex128),\n', '              # Additionally use ""nextafter"" so the cast can\'t round down:\n', '-             (np.longdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),\n', '              # repeat for complex scalars:\n', '-             (np.complex64(2), np.complex64),\n', '-             (np.clongdouble(2), np.complex64),\n', '              # Base of the double value to sidestep any rounding issues:\n', '-             (np.clongdouble(np.nextafter(1.7e308, 0.) * 1j), np.complex128),\n', '              # Additionally use ""nextafter"" so the cast can\'t round down:\n', '-             (np.clongdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),\n', '              ])\n', '-    def test_complex_other_value_based(self, other, expected):\n', '         # This would change if we modify the value based promotion\n', '         min_complex = np.dtype(np.complex64)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_complex_pyscalar_promote_rational(self):\n', '         with pytest.raises(TypeError,\n', '+                match=r"".* no common DType exists for the given inputs""):\n', '             np.result_type(1j, rational)\n', ' \n', '         with pytest.raises(TypeError,\n', '                 match=r"".* no common DType exists for the given inputs""):\n', '             np.result_type(1j, rational(1, 2))\n', ' \n', '+    @pytest.mark.parametrize(""val"", [2, 2**32, 2**63, 2**64, 2*100])\n', '+    def test_python_integer_promotion(self, val):\n', '+        # If we only path scalars (mainly python ones!), the result must take\n', '+        # into account that the integer may be considered int32, int64, uint64,\n', '+        # or object depending on the input value.  So test those paths!\n', '+        expected_dtype = np.result_type(np.array(val).dtype, np.array(0).dtype)\n', '+        assert np.result_type(val, 0) == expected_dtype\n', '+        # For completeness sake, also check with a NumPy scalar as second arg:\n', '+        assert np.result_type(val, np.int8(0)) == expected_dtype\n', '+\n', '     @pytest.mark.parametrize([""other"", ""expected""],\n', '             [(1, rational), (1., np.float64)])\n', '+    @np._no_nep50_warning()\n', '+    def test_float_int_pyscalar_promote_rational(\n', '+            self, weak_promotion, other, expected):\n', '         # Note that rationals are a bit akward as they promote with float64\n', '         # or default ints, but not float16 or uint8/int8 (which looks\n', '+        # inconsistent here).  The new promotion fixes this (partially?)\n', '+        if not weak_promotion and type(other) == float:\n', '+            # The float version, checks float16 in the legacy path, which fails\n', '+            # the integer version seems to check int8 (also), so it can\n', '+            # pass.\n', '+            with pytest.raises(TypeError,\n', '+                    match=r"".* do not have a common DType""):\n', '+                np.result_type(other, rational)\n', '+        else:\n', '+            assert np.result_type(other, rational) == expected\n', ' \n', '         assert np.result_type(other, rational(1, 2)) == expected\n', ' \n']","[' \n', '     def test_complex_pyscalar_promote_rational(self):\n', '         with pytest.raises(TypeError,\n', '-                match=r"".* do not have a common DType""):\n', '             np.result_type(1j, rational)\n', ' \n', '         with pytest.raises(TypeError,\n', '                 match=r"".* no common DType exists for the given inputs""):\n', '             np.result_type(1j, rational(1, 2))\n', ' \n', '     @pytest.mark.parametrize([""other"", ""expected""],\n', '             [(1, rational), (1., np.float64)])\n', '-    def test_float_int_pyscalar_promote_rational(self, other, expected):\n', '         # Note that rationals are a bit akward as they promote with float64\n', '         # or default ints, but not float16 or uint8/int8 (which looks\n', '-        # inconsistent here)\n', '-        with pytest.raises(TypeError,\n', '-                match=r"".* do not have a common DType""):\n', '-            np.result_type(other, rational)\n', ' \n', '         assert np.result_type(other, rational(1, 2)) == expected\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' def test_invalid_dtype_string():\n', '     # test for gh-10440\n', ""     assert_raises(TypeError, np.dtype, 'f8,i8,[f8,i8]')\n"", ""+    assert_raises(TypeError, np.dtype, 'Fl\\xfcgel')\n"", ' \n', ' \n', ' def test_keyword_argument():\n']","[' def test_invalid_dtype_string():\n', '     # test for gh-10440\n', ""     assert_raises(TypeError, np.dtype, 'f8,i8,[f8,i8]')\n"", ""-    assert_raises(TypeError, np.dtype, u'Fl\\xfcgel')\n"", ' \n', ' \n', ' def test_keyword_argument():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             assert_(b.base is a)\n', '             assert_equal(b, a.swapaxes(0, 1))\n', ' \n', '+    @np._no_nep50_warning()\n', '     def check_einsum_sums(self, dtype, do_opt=False):\n', '+        dtype = np.dtype(dtype)\n', '         # Check various sums.  Does many sizes to exercise unrolled loops.\n', ' \n', '         # sum(a, axis=-1)\n']","['             assert_(b.base is a)\n', '             assert_equal(b, a.swapaxes(0, 1))\n', ' \n', '     def check_einsum_sums(self, dtype, do_opt=False):\n', '         # Check various sums.  Does many sizes to exercise unrolled loops.\n', ' \n', '         # sum(a, axis=-1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                              axes=([1, 0], [0, 1])).astype(dtype))\n', ' \n', '         # logical_and(logical_and(a!=0, b!=0), c!=0)\n', '+        neg_val = -2 if dtype.kind != ""u"" else np.iinfo(dtype).max - 1\n', '+        a = np.array([1,   3,   neg_val, 0,  12,  13,   0,   1], dtype=dtype)\n', '+        b = np.array([0,   3.5, 0., neg_val,  0,   1,    3,   12], dtype=dtype)\n', '         c = np.array([True, True, False, True, True, False, True, True])\n', '+\n', '         assert_equal(np.einsum(""i,i,i->i"", a, b, c,\n', ""                      dtype='?', casting='unsafe', optimize=do_opt),\n"", '                      np.logical_and(np.logical_and(a != 0, b != 0), c != 0))\n']","['                              axes=([1, 0], [0, 1])).astype(dtype))\n', ' \n', '         # logical_and(logical_and(a!=0, b!=0), c!=0)\n', '-        a = np.array([1,   3,   -2,   0,   12,  13,   0,   1], dtype=dtype)\n', '-        b = np.array([0,   3.5, 0.,   -2,  0,   1,    3,   12], dtype=dtype)\n', '         c = np.array([True, True, False, True, True, False, True, True])\n', '         assert_equal(np.einsum(""i,i,i->i"", a, b, c,\n', ""                      dtype='?', casting='unsafe', optimize=do_opt),\n"", '                      np.logical_and(np.logical_and(a != 0, b != 0), c != 0))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         assert_equal(np.einsum('ij...,j...->i...', a, b, optimize=True), [[[2], [2]]])\n"", ' \n', '         # Regression test for issue #10369 (test unicode inputs with Python 2)\n', ""+        assert_equal(np.einsum('ij...,j...->i...', a, b), [[[2], [2]]])\n"", ""         assert_equal(np.einsum('...i,...i', [1, 2, 3], [2, 3, 4]), 20)\n"", ""         assert_equal(np.einsum('...i,...i', [1, 2, 3], [2, 3, 4],\n"", ""+                               optimize='greedy'), 20)\n"", ' \n', '         # The iterator had an issue with buffering this reduction\n', '         a = np.ones((5, 12, 4, 2, 3), np.int64)\n']","[""         assert_equal(np.einsum('ij...,j...->i...', a, b, optimize=True), [[[2], [2]]])\n"", ' \n', '         # Regression test for issue #10369 (test unicode inputs with Python 2)\n', ""-        assert_equal(np.einsum(u'ij...,j...->i...', a, b), [[[2], [2]]])\n"", ""         assert_equal(np.einsum('...i,...i', [1, 2, 3], [2, 3, 4]), 20)\n"", ""-        assert_equal(np.einsum(u'...i,...i', [1, 2, 3], [2, 3, 4]), 20)\n"", ""         assert_equal(np.einsum('...i,...i', [1, 2, 3], [2, 3, 4],\n"", ""-                               optimize=u'greedy'), 20)\n"", ' \n', '         # The iterator had an issue with buffering this reduction\n', '         a = np.ones((5, 12, 4, 2, 3), np.int64)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         opt = np.einsum(*path_test, optimize=exp_path)\n', '         assert_almost_equal(noopt, opt)\n', ' \n', '+    def test_path_type_input_internal_trace(self):\n', '+        #gh-20962\n', ""+        path_test = self.build_operands('cab,cdd->ab')\n"", ""+        exp_path = ['einsum_path', (1,), (0, 1)]\n"", '+\n', '+        path, path_str = np.einsum_path(*path_test, optimize=exp_path)\n', '+        self.assert_path_equal(path, exp_path)\n', '+\n', '+        # Double check einsum works on the input path\n', '+        noopt = np.einsum(*path_test, optimize=False)\n', '+        opt = np.einsum(*path_test, optimize=exp_path)\n', '+        assert_almost_equal(noopt, opt)\n', '+\n', '+    def test_path_type_input_invalid(self):\n', ""+        path_test = self.build_operands('ab,bc,cd,de->ae')\n"", ""+        exp_path = ['einsum_path', (2, 3), (0, 1)]\n"", '+        assert_raises(RuntimeError, np.einsum, *path_test, optimize=exp_path)\n', '+        assert_raises(\n', '+            RuntimeError, np.einsum_path, *path_test, optimize=exp_path)\n', '+\n', ""+        path_test = self.build_operands('a,a,a->a')\n"", ""+        exp_path = ['einsum_path', (1,), (0, 1)]\n"", '+        assert_raises(RuntimeError, np.einsum, *path_test, optimize=exp_path)\n', '+        assert_raises(\n', '+            RuntimeError, np.einsum_path, *path_test, optimize=exp_path)\n', '+\n', '     def test_spaces(self):\n', '         #gh-10794\n', '         arr = np.array([[1]])\n']","['         opt = np.einsum(*path_test, optimize=exp_path)\n', '         assert_almost_equal(noopt, opt)\n', ' \n', '     def test_spaces(self):\n', '         #gh-10794\n', '         arr = np.array([[1]])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import sysconfig\n', ' \n', ' import numpy as np\n', '+from numpy.testing import assert_, assert_raises, IS_WASM\n', ' \n', ' # The floating point emulation on ARM EABI systems lacking a hardware FPU is\n', ' # known to be buggy. This is an attempt to identify these hosts. It may not\n']","[' import sysconfig\n', ' \n', ' import numpy as np\n', '-from numpy.testing import assert_, assert_raises\n', ' \n', ' # The floating point emulation on ARM EABI systems lacking a hardware FPU is\n', ' # known to be buggy. This is an attempt to identify these hosts. It may not\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" arm_softfloat = False if hosttype is None else hosttype.endswith('gnueabi')\n"", ' \n', ' class TestErrstate:\n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.skipif(arm_softfloat,\n', ""                         reason='platform/cpu issue with FPU (gh-413,-15562)')\n"", '     def test_invalid(self):\n']","["" arm_softfloat = False if hosttype is None else hosttype.endswith('gnueabi')\n"", ' \n', ' class TestErrstate:\n', '     @pytest.mark.skipif(arm_softfloat,\n', ""                         reason='platform/cpu issue with FPU (gh-413,-15562)')\n"", '     def test_invalid(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             with assert_raises(FloatingPointError):\n', '                 np.sqrt(a)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.skipif(arm_softfloat,\n', ""                         reason='platform/cpu issue with FPU (gh-15562)')\n"", '     def test_divide(self):\n']","['             with assert_raises(FloatingPointError):\n', '                 np.sqrt(a)\n', ' \n', '     @pytest.mark.skipif(arm_softfloat,\n', ""                         reason='platform/cpu issue with FPU (gh-15562)')\n"", '     def test_divide(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_unsigned_max(self):\n', ""         types = np.sctypes['uint']\n"", '         for T in types:\n', '+            with np.errstate(over=""ignore""):\n', '+                max_calculated = T(0) - T(1)\n', '+            assert_equal(iinfo(T).max, max_calculated)\n', ' \n', ' class TestRepr:\n', '     def test_iinfo_repr(self):\n']","['     def test_unsigned_max(self):\n', ""         types = np.sctypes['uint']\n"", '         for T in types:\n', '-            assert_equal(iinfo(T).max, T(-1))\n', ' \n', ' class TestRepr:\n', '     def test_iinfo_repr(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' import numpy as np\n', ' from numpy import uint16, float16, float32, float64\n', '+from numpy.testing import assert_, assert_equal, _OLD_PROMOTION, IS_WASM\n', ' \n', ' \n', ' def assert_raises_fpe(strmatch, callable, *args, **kwargs):\n']","[' \n', ' import numpy as np\n', ' from numpy import uint16, float16, float32, float64\n', '-from numpy.testing import assert_, assert_equal\n', ' \n', ' \n', ' def assert_raises_fpe(strmatch, callable, *args, **kwargs):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 ""Did not raise floating point %s error"" % strmatch)\n', ' \n', ' class TestHalf:\n', '+    def setup_method(self):\n', '         # An array of all possible float16 values\n', '         self.all_f16 = np.arange(0x10000, dtype=uint16)\n', '         self.all_f16.dtype = float16\n']","['                 ""Did not raise floating point %s error"" % strmatch)\n', ' \n', ' class TestHalf:\n', '-    def setup(self):\n', '         # An array of all possible float16 values\n', '         self.all_f16 = np.arange(0x10000, dtype=uint16)\n', '         self.all_f16.dtype = float16\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     @pytest.mark.parametrize(""offset"", [None, ""up"", ""down""])\n', '     @pytest.mark.parametrize(""shift"", [None, ""up"", ""down""])\n', '     @pytest.mark.parametrize(""float_t"", [np.float32, np.float64])\n', '+    @np._no_nep50_warning()\n', '     def test_half_conversion_rounding(self, float_t, shift, offset):\n', '         # Assumes that round to even is used during casting.\n', '         max_pattern = np.float16(np.finfo(np.float16).max).view(np.uint16)\n']","['     @pytest.mark.parametrize(""offset"", [None, ""up"", ""down""])\n', '     @pytest.mark.parametrize(""shift"", [None, ""up"", ""down""])\n', '     @pytest.mark.parametrize(""float_t"", [np.float32, np.float64])\n', '     def test_half_conversion_rounding(self, float_t, shift, offset):\n', '         # Assumes that round to even is used during casting.\n', '         max_pattern = np.float16(np.finfo(np.float16).max).view(np.uint16)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         # Increase the float by a minimal value:\n', '         if offset == ""up"":\n', '+            f16s_float = np.nextafter(f16s_float, float_t(np.inf))\n', '         elif offset == ""down"":\n', '+            f16s_float = np.nextafter(f16s_float, float_t(-np.inf))\n', ' \n', '         # Convert back to float16 and its bit pattern:\n', '         res_patterns = f16s_float.astype(np.float16).view(np.uint16)\n']","[' \n', '         # Increase the float by a minimal value:\n', '         if offset == ""up"":\n', '-            f16s_float = np.nextafter(f16s_float, float_t(1e50))\n', '         elif offset == ""down"":\n', '-            f16s_float = np.nextafter(f16s_float, float_t(-1e50))\n', ' \n', '         # Convert back to float16 and its bit pattern:\n', '         res_patterns = f16s_float.astype(np.float16).view(np.uint16)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                    np.inf]\n', ' \n', '         # Check float64->float16 rounding\n', '+        with np.errstate(over=""ignore""):\n', '+            b = np.array(a, dtype=float16)\n', '         assert_equal(b, rounded)\n', ' \n', '         # Check float32->float16 rounding\n', '         a = np.array(a, dtype=float32)\n', '+        with np.errstate(over=""ignore""):\n', '+            b = np.array(a, dtype=float16)\n', '         assert_equal(b, rounded)\n', ' \n', '     def test_half_correctness(self):\n']","['                    np.inf]\n', ' \n', '         # Check float64->float16 rounding\n', '-        b = np.array(a, dtype=float16)\n', '         assert_equal(b, rounded)\n', ' \n', '         # Check float32->float16 rounding\n', '         a = np.array(a, dtype=float32)\n', '-        b = np.array(a, dtype=float16)\n', '         assert_equal(b, rounded)\n', ' \n', '     def test_half_correctness(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(np.frexp(b), ([-0.5, 0.625, 0.5, 0.5, 0.75], [2, 3, 1, 3, 2]))\n', '         assert_equal(np.ldexp(b, [0, 1, 2, 4, 2]), [-2, 10, 4, 64, 12])\n', ' \n', '+    @np._no_nep50_warning()\n', '+    def test_half_coercion(self, weak_promotion):\n', '         """"""Test that half gets coerced properly with the other types""""""\n', '         a16 = np.array((1,), dtype=float16)\n', '         a32 = np.array((1,), dtype=float32)\n', '         b16 = float16(1)\n', '         b32 = float32(1)\n', ' \n', '+        assert np.power(a16, 2).dtype == float16\n', '+        assert np.power(a16, 2.0).dtype == float16\n', '+        assert np.power(a16, b16).dtype == float16\n', '+        expected_dt = float32 if weak_promotion else float16\n', '+        assert np.power(a16, b32).dtype == expected_dt\n', '+        assert np.power(a16, a16).dtype == float16\n', '+        assert np.power(a16, a32).dtype == float32\n', '+\n', '+        expected_dt = float16 if weak_promotion else float64\n', '+        assert np.power(b16, 2).dtype == expected_dt\n', '+        assert np.power(b16, 2.0).dtype == expected_dt\n', '+        assert np.power(b16, b16).dtype, float16\n', '+        assert np.power(b16, b32).dtype, float32\n', '+        assert np.power(b16, a16).dtype, float16\n', '+        assert np.power(b16, a32).dtype, float32\n', '+\n', '+        assert np.power(a32, a16).dtype == float32\n', '+        assert np.power(a32, b16).dtype == float32\n', '+        expected_dt = float32 if weak_promotion else float16\n', '+        assert np.power(b32, a16).dtype == expected_dt\n', '+        assert np.power(b32, b16).dtype == float32\n', ' \n', '     @pytest.mark.skipif(platform.machine() == ""armv5tel"",\n', '                         reason=""See gh-413."")\n', '+    @pytest.mark.skipif(IS_WASM,\n', '+                        reason=""fp exceptions don\'t work in wasm."")\n', '     def test_half_fpe(self):\n', ""         with np.errstate(all='raise'):\n"", '             sx16 = np.array((1e-4,), dtype=float16)\n']","['         assert_equal(np.frexp(b), ([-0.5, 0.625, 0.5, 0.5, 0.75], [2, 3, 1, 3, 2]))\n', '         assert_equal(np.ldexp(b, [0, 1, 2, 4, 2]), [-2, 10, 4, 64, 12])\n', ' \n', '-    def test_half_coercion(self):\n', '         """"""Test that half gets coerced properly with the other types""""""\n', '         a16 = np.array((1,), dtype=float16)\n', '         a32 = np.array((1,), dtype=float32)\n', '         b16 = float16(1)\n', '         b32 = float32(1)\n', ' \n', '-        assert_equal(np.power(a16, 2).dtype, float16)\n', '-        assert_equal(np.power(a16, 2.0).dtype, float16)\n', '-        assert_equal(np.power(a16, b16).dtype, float16)\n', '-        assert_equal(np.power(a16, b32).dtype, float16)\n', '-        assert_equal(np.power(a16, a16).dtype, float16)\n', '-        assert_equal(np.power(a16, a32).dtype, float32)\n', '-\n', '-        assert_equal(np.power(b16, 2).dtype, float64)\n', '-        assert_equal(np.power(b16, 2.0).dtype, float64)\n', '-        assert_equal(np.power(b16, b16).dtype, float16)\n', '-        assert_equal(np.power(b16, b32).dtype, float32)\n', '-        assert_equal(np.power(b16, a16).dtype, float16)\n', '-        assert_equal(np.power(b16, a32).dtype, float32)\n', '-\n', '-        assert_equal(np.power(a32, a16).dtype, float32)\n', '-        assert_equal(np.power(a32, b16).dtype, float32)\n', '-        assert_equal(np.power(b32, a16).dtype, float16)\n', '-        assert_equal(np.power(b32, b16).dtype, float32)\n', ' \n', '     @pytest.mark.skipif(platform.machine() == ""armv5tel"",\n', '                         reason=""See gh-413."")\n', '     def test_half_fpe(self):\n', ""         with np.errstate(all='raise'):\n"", '             sx16 = np.array((1e-4,), dtype=float16)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from itertools import product\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_raises_regex,\n', '+    assert_array_equal, assert_warns, HAS_REFCOUNT, IS_WASM\n', '     )\n', ' \n', ' \n']","[' from itertools import product\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_raises_regex,\n', '-    assert_array_equal, assert_warns, HAS_REFCOUNT,\n', '     )\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with pytest.raises(IndexError):\n', '             arr[(index,) * num] = 1.\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""no threading"")\n', '     def test_structured_advanced_indexing(self):\n', '         # Test that copyswap(n) used by integer array indexing is threadsafe\n', '         # for structured datatypes, see gh-15387. This test can behave randomly.\n']","['         with pytest.raises(IndexError):\n', '             arr[(index,) * num] = 1.\n', ' \n', '     def test_structured_advanced_indexing(self):\n', '         # Test that copyswap(n) used by integer array indexing is threadsafe\n', '         # for structured datatypes, see gh-15387. This test can behave randomly.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     """"""\n', ' \n', '+    def setup_method(self):\n', '         self.a = np.arange(np.prod([3, 1, 5, 6])).reshape(3, 1, 5, 6)\n', '         self.b = np.empty((3, 0, 5, 6))\n', ""         self.complex_indices = ['skip', Ellipsis,\n""]","[' \n', '     """"""\n', ' \n', '-    def setup(self):\n', '         self.a = np.arange(np.prod([3, 1, 5, 6])).reshape(3, 1, 5, 6)\n', '         self.b = np.empty((3, 0, 5, 6))\n', ""         self.complex_indices = ['skip', Ellipsis,\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_boolean_indexing_weirdness(self):\n', '         # Weird boolean indexing things\n', '         a = np.ones((2, 3, 4))\n', '+        assert a[False, True, ...].shape == (0, 2, 3, 4)\n', '+        assert a[True, [0, 1], True, True, [1], [[2]]].shape == (1, 2)\n', '         assert_raises(IndexError, lambda: a[False, [0, 1], ...])\n', ' \n', '     def test_boolean_indexing_fast_path(self):\n', '         # These used to either give the wrong error, or incorrectly give no\n', '         # error.\n']","['     def test_boolean_indexing_weirdness(self):\n', '         # Weird boolean indexing things\n', '         a = np.ones((2, 3, 4))\n', '-        a[False, True, ...].shape == (0, 2, 3, 4)\n', '-        a[True, [0, 1], True, True, [1], [[2]]] == (1, 2)\n', '         assert_raises(IndexError, lambda: a[False, [0, 1], ...])\n', ' \n', '-\n', '     def test_boolean_indexing_fast_path(self):\n', '         # These used to either give the wrong error, or incorrectly give no\n', '         # error.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import sysconfig\n', ' import pytest\n', ' \n', '+from numpy.testing import IS_WASM\n', ' \n', '+\n', '+@pytest.mark.skipif(IS_WASM, reason=""Can\'t start subprocess"")\n', ' @pytest.mark.xfail(\n', '     sysconfig.get_config_var(""Py_DEBUG""),\n', '     reason=(\n']","[' import sysconfig\n', ' import pytest\n', ' \n', ' \n', ' @pytest.mark.xfail(\n', '     sysconfig.get_config_var(""Py_DEBUG""),\n', '     reason=(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                       for j in range(ndim))\n', ' \n', '             b_ub = min(max_int-2, sum(a*ub for a, ub in zip(A, U)))\n', '+            b = int(rng.randint(-1, b_ub+2, dtype=np.intp))\n', ' \n', '             if ndim == 0 and feasible_count < min_count:\n', '                 b = 0\n']","['                       for j in range(ndim))\n', ' \n', '             b_ub = min(max_int-2, sum(a*ub for a, ub in zip(A, U)))\n', '-            b = rng.randint(-1, b_ub+2, dtype=np.intp)\n', ' \n', '             if ndim == 0 and feasible_count < min_count:\n', '                 b = 0\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy as np\n', ' import threading\n', ' import warnings\n', '+from numpy.testing import extbuild, assert_warns, IS_WASM\n', ' import sys\n', ' \n', ' \n']","[' import numpy as np\n', ' import threading\n', ' import warnings\n', '-from numpy.testing import extbuild, assert_warns\n', ' import sys\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', ""     if sys.platform.startswith('cygwin'):\n"", ""         pytest.skip('link fails on cygwin')\n"", '+    if IS_WASM:\n', '+        pytest.skip(""Can\'t build module inside Wasm"")\n', '     functions = [\n', '         (""get_default_policy"", ""METH_NOARGS"", """"""\n', '              Py_INCREF(PyDataMem_DefaultHandler);\n']","['     """"""\n', ""     if sys.platform.startswith('cygwin'):\n"", ""         pytest.skip('link fails on cygwin')\n"", '     functions = [\n', '         (""get_default_policy"", ""METH_NOARGS"", """"""\n', '              Py_INCREF(PyDataMem_DefaultHandler);\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     )\n', ' \n', ' class TestMemmap:\n', '+    def setup_method(self):\n', ""         self.tmpfp = NamedTemporaryFile(prefix='mmap')\n"", '         self.shape = (3, 4)\n', ""         self.dtype = 'float32'\n"", '         self.data = arange(12, dtype=self.dtype)\n', '         self.data.resize(self.shape)\n', ' \n', '+    def teardown_method(self):\n', '         self.tmpfp.close()\n', '         self.data = None\n', '         if IS_PYPY:\n']","['     )\n', ' \n', ' class TestMemmap:\n', '-    def setup(self):\n', ""         self.tmpfp = NamedTemporaryFile(prefix='mmap')\n"", '         self.shape = (3, 4)\n', ""         self.dtype = 'float32'\n"", '         self.data = arange(12, dtype=self.dtype)\n', '         self.data.resize(self.shape)\n', ' \n', '-    def teardown(self):\n', '         self.tmpfp.close()\n', '         self.data = None\n', '         if IS_PYPY:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import ctypes\n', ' import os\n', ' import gc\n', '+import re\n', ' import weakref\n', ' import pytest\n', ' from contextlib import contextmanager\n']","[' import ctypes\n', ' import os\n', ' import gc\n', ' import weakref\n', ' import pytest\n', ' from contextlib import contextmanager\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_allclose, IS_PYPY, IS_PYSTON, HAS_REFCOUNT, assert_array_less,\n', '     runstring, temppath, suppress_warnings, break_cycles,\n', '     )\n', '+from numpy.testing._private.utils import requires_memory, _no_tracing\n', ' from numpy.core.tests._locales import CommaDecimalPointLocale\n', ' from numpy.lib.recfunctions import repack_fields\n', ' \n']","['     assert_allclose, IS_PYPY, IS_PYSTON, HAS_REFCOUNT, assert_array_less,\n', '     runstring, temppath, suppress_warnings, break_cycles,\n', '     )\n', '-from numpy.testing._private.utils import _no_tracing\n', ' from numpy.core.tests._locales import CommaDecimalPointLocale\n', ' from numpy.lib.recfunctions import repack_fields\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Note: slices producing 0-size arrays do not necessarily change\n', '     # data pointer --- so we use and allocate size+1\n', '     buf = buf[offset:offset+size+1][:-1]\n', '+    buf.fill(0)\n', '     data = np.ndarray(shape, dtype, buf, order=order)\n', '     return data\n', ' \n', ' \n', ' class TestFlags:\n', '+    def setup_method(self):\n', '         self.a = np.arange(10)\n', ' \n', '     def test_writeable(self):\n']","['     # Note: slices producing 0-size arrays do not necessarily change\n', '     # data pointer --- so we use and allocate size+1\n', '     buf = buf[offset:offset+size+1][:-1]\n', '     data = np.ndarray(shape, dtype, buf, order=order)\n', '-    data.fill(0)\n', '     return data\n', ' \n', ' \n', ' class TestFlags:\n', '-    def setup(self):\n', '         self.a = np.arange(10)\n', ' \n', '     def test_writeable(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestAttributes:\n', '+    def setup_method(self):\n', '         self.one = np.arange(10)\n', '         self.two = np.arange(20).reshape(4, 5)\n', '         self.three = np.arange(60, dtype=np.float64).reshape(2, 5, 6)\n']","[' \n', ' \n', ' class TestAttributes:\n', '-    def setup(self):\n', '         self.one = np.arange(10)\n', '         self.two = np.arange(20).reshape(4, 5)\n', '         self.three = np.arange(60, dtype=np.float64).reshape(2, 5, 6)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             finally:\n', '                 set_string_function(None, repr=False)\n', ' \n', ""+        a1d = np.array(['test'])\n"", ""+        a0d = np.array('done')\n"", ""+        with inject_str('bad'):\n"", '             a1d[0] = a0d  # previously this would invoke __str__\n', ""+        assert_equal(a1d[0], 'done')\n"", ' \n', '         # this would crash for the same reason\n', ""+        np.array([np.array('\\xe5\\xe4\\xf6')])\n"", ' \n', '     def test_stringlike_empty_list(self):\n', '         # gh-8902\n', ""+        u = np.array(['done'])\n"", ""         b = np.array([b'done'])\n"", ' \n', '         class bad_sequence:\n']","['             finally:\n', '                 set_string_function(None, repr=False)\n', ' \n', ""-        a1d = np.array([u'test'])\n"", ""-        a0d = np.array(u'done')\n"", ""-        with inject_str(u'bad'):\n"", '             a1d[0] = a0d  # previously this would invoke __str__\n', ""-        assert_equal(a1d[0], u'done')\n"", ' \n', '         # this would crash for the same reason\n', ""-        np.array([np.array(u'\\xe5\\xe4\\xf6')])\n"", ' \n', '     def test_stringlike_empty_list(self):\n', '         # gh-8902\n', ""-        u = np.array([u'done'])\n"", ""         b = np.array([b'done'])\n"", ' \n', '         class bad_sequence:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestZeroRank:\n', '+    def setup_method(self):\n', ""         self.d = np.array(0), np.array('x', object)\n"", ' \n', '     def test_ellipsis_subscript(self):\n']","[' \n', ' \n', ' class TestZeroRank:\n', '-    def setup(self):\n', ""         self.d = np.array(0), np.array('x', object)\n"", ' \n', '     def test_ellipsis_subscript(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestScalarIndexing:\n', '+    def setup_method(self):\n', '         self.d = np.array([0, 1])[0]\n', ' \n', '     def test_ellipsis_subscript(self):\n']","[' \n', ' \n', ' class TestScalarIndexing:\n', '-    def setup(self):\n', '         self.d = np.array([0, 1])[0]\n', ' \n', '     def test_ellipsis_subscript(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                           shape=(max_bytes//itemsize + 1,), dtype=dtype)\n', ' \n', '     def _ragged_creation(self, seq):\n', '+        # without dtype=object, the ragged object raises\n', '+        with pytest.raises(ValueError, match="".*detected shape was""):\n', '             a = np.array(seq)\n', '+\n', '+        return np.array(seq, dtype=object)\n', ' \n', '     def test_ragged_ndim_object(self):\n', '         # Lists of mismatching depths are treated as object arrays\n']","['                           shape=(max_bytes//itemsize + 1,), dtype=dtype)\n', ' \n', '     def _ragged_creation(self, seq):\n', '-        # without dtype=object, the ragged object should raise\n', '-        with assert_warns(np.VisibleDeprecationWarning):\n', '             a = np.array(seq)\n', '-        b = np.array(seq, dtype=object)\n', '-        assert_equal(a, b)\n', '-        return b\n', ' \n', '     def test_ragged_ndim_object(self):\n', '         # Lists of mismatching depths are treated as object arrays\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a = np.array([1, Decimal(1)])\n', '         a = np.array([[1], [Decimal(1)]])\n', ' \n', '+    @pytest.mark.parametrize(""dtype"", [object, ""O,O"", ""O,(3)O"", ""(2,3)O""])\n', '+    @pytest.mark.parametrize(""function"", [\n', '+            np.ndarray, np.empty,\n', '+            lambda shape, dtype: np.empty_like(np.empty(shape, dtype=dtype))])\n', '+    def test_object_initialized_to_None(self, function, dtype):\n', '+        # NumPy has support for object fields to be NULL (meaning None)\n', '+        # but generally, we should always fill with the proper None, and\n', '+        # downstream may rely on that.  (For fully initialized arrays!)\n', '+        arr = function(3, dtype=dtype)\n', '+        # We expect a fill value of None, which is not NULL:\n', '+        expected = np.array(None).tobytes()\n', '+        expected = expected * (arr.nbytes // len(expected))\n', '+        assert arr.tobytes() == expected\n', '+\n', ' class TestStructured:\n', '     def test_subarray_field_access(self):\n', ""         a = np.zeros((3, 5), dtype=[('a', ('i4', (2, 2)))])\n""]","['         a = np.array([1, Decimal(1)])\n', '         a = np.array([[1], [Decimal(1)]])\n', ' \n', ' class TestStructured:\n', '     def test_subarray_field_access(self):\n', ""         a = np.zeros((3, 5), dtype=[('a', ('i4', (2, 2)))])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with pytest.raises(TypeError):\n', '             x == y\n', ' \n', '+    def test_empty_structured_array_comparison(self):\n', '+        # Check that comparison works on empty arrays with nontrivially\n', '+        # shaped fields\n', ""+        a = np.zeros(0, [('a', '<f8', (1, 1))])\n"", '+        assert_equal(a, a)\n', ""+        a = np.zeros(0, [('a', '<f8', (1,))])\n"", '+        assert_equal(a, a)\n', ""+        a = np.zeros((0, 0), [('a', '<f8', (1, 1))])\n"", '+        assert_equal(a, a)\n', ""+        a = np.zeros((1, 0, 1), [('a', '<f8', (1, 1))])\n"", '+        assert_equal(a, a)\n', '+\n', '     def test_structured_comparisons_with_promotion(self):\n', '         # Check that structured arrays can be compared so long as their\n', '         # dtypes promote fine:\n']","['         with pytest.raises(TypeError):\n', '             x == y\n', ' \n', '     def test_structured_comparisons_with_promotion(self):\n', '         # Check that structured arrays can be compared so long as their\n', '         # dtypes promote fine:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         assert_fortran(a.copy('F'))\n"", ""         assert_c(a.copy('A'))\n"", ' \n', '+    @pytest.mark.parametrize(""dtype"", [\'O\', np.int32, \'i,O\'])\n', '+    def test__deepcopy__(self, dtype):\n', '+        # Force the entry of NULLs into array\n', '+        a = np.empty(4, dtype=dtype)\n', '+        ctypes.memset(a.ctypes.data, 0, a.nbytes)\n', '+\n', '+        # Ensure no error is raised, see gh-21833\n', '+        b = a.__deepcopy__({})\n', '+\n', '+        a[0] = 42\n', '+        with pytest.raises(AssertionError):\n', '+            assert_array_equal(a, b)\n', '+\n', '+    def test__deepcopy__catches_failure(self):\n', '+        class MyObj:\n', '+            def __deepcopy__(self, *args, **kwargs):\n', '+                raise RuntimeError\n', '+\n', ""+        arr = np.array([1, MyObj(), 3], dtype='O')\n"", '+        with pytest.raises(RuntimeError):\n', '+            arr.__deepcopy__({})\n', '+\n', '     def test_sort_order(self):\n', '         # Test sorting an array with fields\n', '         x1 = np.array([21, 32, 14])\n']","[""         assert_fortran(a.copy('F'))\n"", ""         assert_c(a.copy('A'))\n"", ' \n', '     def test_sort_order(self):\n', '         # Test sorting an array with fields\n', '         x1 = np.array([21, 32, 14])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_raises(ValueError, d.sort, kind=k)\n', '         assert_raises(ValueError, d.argsort, kind=k)\n', ' \n', ""+    @pytest.mark.parametrize('a', [\n"", '+        np.array([0, 1, np.nan], dtype=np.float16),\n', '+        np.array([0, 1, np.nan], dtype=np.float32),\n', '+        np.array([0, 1, np.nan]),\n', '+    ])\n', '+    def test_searchsorted_floats(self, a):\n', '+        # test for floats arrays containing nans. Explicitly test\n', '+        # half, single, and double precision floats to verify that\n', '+        # the NaN-handling is correct.\n', '+        msg = ""Test real (%s) searchsorted with nans, side=\'l\'"" % a.dtype\n', ""         b = a.searchsorted(a, side='left')\n"", '         assert_equal(b, np.arange(3), msg)\n', '+        msg = ""Test real (%s) searchsorted with nans, side=\'r\'"" % a.dtype\n', ""         b = a.searchsorted(a, side='right')\n"", '         assert_equal(b, np.arange(1, 4), msg)\n', '         # check keyword arguments\n', '         a.searchsorted(v=1)\n', ""+        x = np.array([0, 1, np.nan], dtype='float32')\n"", '+        y = np.searchsorted(x, x[-1])\n', '+        assert_equal(y, 2)\n', '+\n', '+    def test_searchsorted_complex(self):\n', '+        # test for complex arrays containing nans.\n', '+        # The search sorted routines use the compare functions for the\n', '+        # array type, so this checks if that is consistent with the sort\n', '+        # order.\n', '         # check double complex\n', '         a = np.zeros(9, dtype=np.complex128)\n', '         a.real += [0, 0, 1, 1, 0, 1, np.nan, np.nan, np.nan]\n']","['         assert_raises(ValueError, d.sort, kind=k)\n', '         assert_raises(ValueError, d.argsort, kind=k)\n', ' \n', '-    def test_searchsorted(self):\n', '-        # test for floats and complex containing nans. The logic is the\n', '-        # same for all float types so only test double types for now.\n', '-        # The search sorted routines use the compare functions for the\n', '-        # array type, so this checks if that is consistent with the sort\n', '-        # order.\n', '-\n', '-        # check double\n', '-        a = np.array([0, 1, np.nan])\n', '-        msg = ""Test real searchsorted with nans, side=\'l\'""\n', ""         b = a.searchsorted(a, side='left')\n"", '         assert_equal(b, np.arange(3), msg)\n', '-        msg = ""Test real searchsorted with nans, side=\'r\'""\n', ""         b = a.searchsorted(a, side='right')\n"", '         assert_equal(b, np.arange(1, 4), msg)\n', '         # check keyword arguments\n', '         a.searchsorted(v=1)\n', '         # check double complex\n', '         a = np.zeros(9, dtype=np.complex128)\n', '         a.real += [0, 0, 1, 1, 0, 1, np.nan, np.nan, np.nan]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         b = a.searchsorted(np.array(128, dtype='>i4'))\n"", '         assert_equal(b, 1, msg)\n', ' \n', '+    def test_searchsorted_n_elements(self):\n', '         # Check 0 elements\n', '         a = np.ones(0)\n', ""         b = a.searchsorted([0, 1, 2], 'left')\n""]","[""         b = a.searchsorted(np.array(128, dtype='>i4'))\n"", '         assert_equal(b, 1, msg)\n', ' \n', '         # Check 0 elements\n', '         a = np.ones(0)\n', ""         b = a.searchsorted([0, 1, 2], 'left')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         b = a.searchsorted([0, 1, 2], 'right')\n"", '         assert_equal(b, [0, 2, 2])\n', ' \n', '+    def test_searchsorted_unaligned_array(self):\n', '         # Test searching unaligned array\n', '         a = np.arange(10)\n', ""         aligned = np.empty(a.itemsize * a.size + 1, 'uint8')\n""]","[""         b = a.searchsorted([0, 1, 2], 'right')\n"", '         assert_equal(b, [0, 2, 2])\n', ' \n', '         # Test searching unaligned array\n', '         a = np.arange(10)\n', ""         aligned = np.empty(a.itemsize * a.size + 1, 'uint8')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         b = a.searchsorted(unaligned, 'right')\n"", '         assert_equal(b, a + 1)\n', ' \n', '+    def test_searchsorted_resetting(self):\n', '         # Test smart resetting of binsearch indices\n', '         a = np.arange(5)\n', ""         b = a.searchsorted([6, 5, 4], 'left')\n""]","[""         b = a.searchsorted(unaligned, 'right')\n"", '         assert_equal(b, a + 1)\n', ' \n', '         # Test smart resetting of binsearch indices\n', '         a = np.arange(5)\n', ""         b = a.searchsorted([6, 5, 4], 'left')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         b = a.searchsorted([6, 5, 4], 'right')\n"", '         assert_equal(b, [5, 5, 5])\n', ' \n', '+    def test_searchsorted_type_specific(self):\n', '         # Test all type specific binary search functions\n', ""         types = ''.join((np.typecodes['AllInteger'], np.typecodes['AllFloat'],\n"", ""                          np.typecodes['Datetime'], '?O'))\n""]","[""         b = a.searchsorted([6, 5, 4], 'right')\n"", '         assert_equal(b, [5, 5, 5])\n', ' \n', '         # Test all type specific binary search functions\n', ""         types = ''.join((np.typecodes['AllInteger'], np.typecodes['AllFloat'],\n"", ""                          np.typecodes['Datetime'], '?O'))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_array_equal(g1 >= g2, [x >= g2 for x in g1])\n', ' \n', '     def test_unicode(self):\n', '+        g1 = np.array([""This"", ""is"", ""example""])\n', '+        g2 = np.array([""This"", ""was"", ""example""])\n', '         assert_array_equal(g1 == g2, [g1[i] == g2[i] for i in [0, 1, 2]])\n', '         assert_array_equal(g1 != g2, [g1[i] != g2[i] for i in [0, 1, 2]])\n', '         assert_array_equal(g1 <= g2, [g1[i] <= g2[i] for i in [0, 1, 2]])\n']","['         assert_array_equal(g1 >= g2, [x >= g2 for x in g1])\n', ' \n', '     def test_unicode(self):\n', '-        g1 = np.array([u""This"", u""is"", u""example""])\n', '-        g2 = np.array([u""This"", u""was"", u""example""])\n', '         assert_array_equal(g1 == g2, [g1[i] == g2[i] for i in [0, 1, 2]])\n', '         assert_array_equal(g1 != g2, [g1[i] != g2[i] for i in [0, 1, 2]])\n', '         assert_array_equal(g1 <= g2, [g1[i] <= g2[i] for i in [0, 1, 2]])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             ([np.nan, 0, 1, 2, 3], 0),\n', '             ([np.nan, 0, np.nan, 2, 3], 0),\n', '             # To hit the tail of SIMD multi-level(x4, x1) inner loops\n', '+            # on variant SIMD widthes\n', '             ([1] * (2*5-1) + [np.nan], 2*5-1),\n', '             ([1] * (4*5-1) + [np.nan], 4*5-1),\n', '             ([1] * (8*5-1) + [np.nan], 8*5-1),\n']","['             ([np.nan, 0, 1, 2, 3], 0),\n', '             ([np.nan, 0, np.nan, 2, 3], 0),\n', '             # To hit the tail of SIMD multi-level(x4, x1) inner loops\n', '-            # on varient SIMD widthes\n', '             ([1] * (2*5-1) + [np.nan], 2*5-1),\n', '             ([1] * (4*5-1) + [np.nan], 4*5-1),\n', '             ([1] * (8*5-1) + [np.nan], 8*5-1),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             ([np.nan, 0, 1, 2, 3], 0),\n', '             ([np.nan, 0, np.nan, 2, 3], 0),\n', '             # To hit the tail of SIMD multi-level(x4, x1) inner loops\n', '+            # on variant SIMD widthes\n', '             ([1] * (2*5-1) + [np.nan], 2*5-1),\n', '             ([1] * (4*5-1) + [np.nan], 4*5-1),\n', '             ([1] * (8*5-1) + [np.nan], 8*5-1),\n']","['             ([np.nan, 0, 1, 2, 3], 0),\n', '             ([np.nan, 0, np.nan, 2, 3], 0),\n', '             # To hit the tail of SIMD multi-level(x4, x1) inner loops\n', '-            # on varient SIMD widthes\n', '             ([1] * (2*5-1) + [np.nan], 2*5-1),\n', '             ([1] * (4*5-1) + [np.nan], 4*5-1),\n', '             ([1] * (8*5-1) + [np.nan], 8*5-1),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             for types in np.sctypes.values():\n', '                 for T in types:\n', '                     if T not in unchecked_types:\n', '+                        if val < 0 and np.dtype(T).kind == ""u"":\n', '+                            val = np.iinfo(T).max - 99\n', '                         self.tst_basic(x.copy().astype(T), T, mask, val)\n', ' \n', '             # Also test string of a length which uses an untypical length\n']","['             for types in np.sctypes.values():\n', '                 for T in types:\n', '                     if T not in unchecked_types:\n', '                         self.tst_basic(x.copy().astype(T), T, mask, val)\n', ' \n', '             # Also test string of a length which uses an untypical length\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     @pytest.mark.slow  # takes > 1 minute on mechanical hard drive\n', '     def test_big_binary(self):\n', '+        """"""Test workarounds for 32-bit limit for MSVC fwrite, fseek, and ftell\n', '+\n', '+        These normally would hang doing something like this.\n', '+        See : https://github.com/numpy/numpy/issues/2256\n', '+        """"""\n', ""+        if sys.platform != 'win32' or '[GCC ' in sys.version:\n"", '             return\n', '         try:\n', '             # before workarounds, only up to 2**32-1 worked\n']","[' \n', '     @pytest.mark.slow  # takes > 1 minute on mechanical hard drive\n', '     def test_big_binary(self):\n', '-        """"""Test workarounds for 32-bit limited fwrite, fseek, and ftell\n', '-        calls in windows. These normally would hang doing something like this.\n', '-        See http://projects.scipy.org/numpy/ticket/1660""""""\n', ""-        if sys.platform != 'win32':\n"", '             return\n', '         try:\n', '             # before workarounds, only up to 2**32-1 worked\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         buf = x.tobytes()\n', '         assert_array_equal(np.frombuffer(buf, dtype=dt), x.flat)\n', ' \n', '+    @pytest.mark.parametrize(""obj"", [np.arange(10), b""12345678""])\n', '+    def test_array_base(self, obj):\n', '+        # Objects (including NumPy arrays), which do not use the\n', '+        # `release_buffer` slot should be directly used as a base object.\n', '+        # See also gh-21612\n', '+        new = np.frombuffer(obj)\n', '+        assert new.base is obj\n', ' \n', '     def test_empty(self):\n', ""         assert_array_equal(np.frombuffer(b''), np.array([]))\n""]","['         buf = x.tobytes()\n', '         assert_array_equal(np.frombuffer(buf, dtype=dt), x.flat)\n', ' \n', '-    def test_array_base(self):\n', '-        arr = np.arange(10)\n', '-        new = np.frombuffer(arr)\n', '-        # We currently special case arrays to ensure they are used as a base.\n', '-        # This could probably be changed (removing the test).\n', '-        assert new.base is arr\n', ' \n', '     def test_empty(self):\n', ""         assert_array_equal(np.frombuffer(b''), np.array([]))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             mm.close()\n', ' \n', ' class TestFlat:\n', '+    def setup_method(self):\n', '         a0 = np.arange(20.0)\n', '         a = a0.reshape(4, 5)\n', '         a0.shape = (4, 5)\n']","['             mm.close()\n', ' \n', ' class TestFlat:\n', '-    def setup(self):\n', '         a0 = np.arange(20.0)\n', '         a = a0.reshape(4, 5)\n', '         a0.shape = (4, 5)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_fromarrays_unicode(self):\n', '         # A single name string provided to fromarrays() is allowed to be unicode\n', '         # on both Python 2 and 3:\n', '+        x = np.core.records.fromarrays(\n', ""+            [[0], [1]], names='a,b', formats='i4,i4')\n"", ""         assert_equal(x['a'][0], 0)\n"", ""         assert_equal(x['b'][0], 1)\n"", ' \n', '     def test_unicode_order(self):\n', '         # Test that we can sort with order as a unicode field name in both Python 2 and\n', '         # 3:\n', ""+        name = 'b'\n"", '         x = np.array([1, 3, 2], dtype=[(name, int)])\n', '         x.sort(order=name)\n', ""+        assert_equal(x['b'], np.array([1, 2, 3]))\n"", ' \n', '     def test_field_names(self):\n', '         # Test unicode and 8-bit / byte strings can be used\n']","['     def test_fromarrays_unicode(self):\n', '         # A single name string provided to fromarrays() is allowed to be unicode\n', '         # on both Python 2 and 3:\n', ""-        x = np.core.records.fromarrays([[0], [1]], names=u'a,b', formats=u'i4,i4')\n"", ""         assert_equal(x['a'][0], 0)\n"", ""         assert_equal(x['b'][0], 1)\n"", ' \n', '     def test_unicode_order(self):\n', '         # Test that we can sort with order as a unicode field name in both Python 2 and\n', '         # 3:\n', ""-        name = u'b'\n"", '         x = np.array([1, 3, 2], dtype=[(name, int)])\n', '         x.sort(order=name)\n', ""-        assert_equal(x[u'b'], np.array([1, 2, 3]))\n"", ' \n', '     def test_field_names(self):\n', '         # Test unicode and 8-bit / byte strings can be used\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         assert_equal(b[['f1', 'f3']][0].tolist(), (2, (1,)))\n"", ' \n', '         # non-ascii unicode field indexing is well behaved\n', ""+        assert_raises(ValueError, a.__setitem__, '\\u03e0', 1)\n"", ""+        assert_raises(ValueError, a.__getitem__, '\\u03e0')\n"", ' \n', '     def test_record_hash(self):\n', ""         a = np.array([(1, 2), (1, 2)], dtype='i1,i2')\n""]","[""         assert_equal(b[['f1', 'f3']][0].tolist(), (2, (1,)))\n"", ' \n', '         # non-ascii unicode field indexing is well behaved\n', ""-        assert_raises(ValueError, a.__setitem__, u'\\u03e0', 1)\n"", ""-        assert_raises(ValueError, a.__getitem__, u'\\u03e0')\n"", ' \n', '     def test_record_hash(self):\n', ""         a = np.array([(1, 2), (1, 2)], dtype='i1,i2')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     funcs = [_mean, _var, _std]\n', ' \n', '+    def setup_method(self):\n', '         np.random.seed(range(3))\n', '         self.rmat = np.random.random((4, 5))\n', '         self.cmat = self.rmat + 1j * self.rmat\n']","[' \n', '     funcs = [_mean, _var, _std]\n', ' \n', '-    def setup(self):\n', '         np.random.seed(range(3))\n', '         self.rmat = np.random.random((4, 5))\n', '         self.cmat = self.rmat + 1j * self.rmat\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestDot:\n', '+    def setup_method(self):\n', '         np.random.seed(128)\n', '         self.A = np.random.rand(4, 2)\n', '         self.b1 = np.random.rand(2, 1)\n']","[' \n', ' \n', ' class TestDot:\n', '-    def setup(self):\n', '         np.random.seed(128)\n', '         self.A = np.random.rand(4, 2)\n', '         self.b1 = np.random.rand(2, 1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # Strides in A cols and X\n', '             assert_dot_close(A_f_12, X_f_2, desired)\n', ' \n', '+    @pytest.mark.slow\n', '+    @pytest.mark.parametrize(""dtype"", [np.float64, np.complex128])\n', '+    @requires_memory(free_bytes=18e9)  # complex case needs 18GiB+\n', '+    def test_huge_vectordot(self, dtype):\n', '+        # Large vector multiplications are chunked with 32bit BLAS\n', '+        # Test that the chunking does the right thing, see also gh-22262\n', '+        data = np.ones(2**30+100, dtype=dtype)\n', '+        res = np.dot(data, data)\n', '+        assert res == 2**30+100\n', '+\n', '+    def test_dtype_discovery_fails(self):\n', '+        # See gh-14247, error checking was missing for failed dtype discovery\n', '+        class BadObject(object):\n', '+            def __array__(self):\n', '+                raise TypeError(""just this tiny mint leaf"")\n', '+\n', '+        with pytest.raises(TypeError):\n', '+            np.dot(BadObject(), BadObject())\n', '+\n', '+        with pytest.raises(TypeError):\n', '+            np.dot(3.0, BadObject())\n', ' \n', ' \n', ' class MatmulCommon:\n']","['             # Strides in A cols and X\n', '             assert_dot_close(A_f_12, X_f_2, desired)\n', ' \n', ' \n', ' \n', ' class MatmulCommon:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                    [2630, 2910, 3190]],\n', ' \n', '                   [[2198, 2542, 2886],\n', '+                   [3230, 3574, 3918]]]]\n', '+            ).astype(dt)\n', '             assert_equal(np.inner(a, b), desired)\n', '             assert_equal(np.inner(b, a).transpose(2,3,0,1), desired)\n', ' \n', ' \n', ' class TestChoose:\n', '+    def setup_method(self):\n', '         self.x = 2*np.ones((3,), dtype=int)\n', '         self.y = 3*np.ones((3,), dtype=int)\n', '         self.x2 = 2*np.ones((2, 3), dtype=int)\n']","['                    [2630, 2910, 3190]],\n', ' \n', '                   [[2198, 2542, 2886],\n', '-                   [3230, 3574, 3918]]]],\n', '-                dtype=dt\n', '-            )\n', '             assert_equal(np.inner(a, b), desired)\n', '             assert_equal(np.inner(b, a).transpose(2,3,0,1), desired)\n', ' \n', ' \n', ' class TestChoose:\n', '-    def setup(self):\n', '         self.x = 2*np.ones((3,), dtype=int)\n', '         self.y = 3*np.ones((3,), dtype=int)\n', '         self.x2 = 2*np.ones((2, 3), dtype=int)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestRepeat:\n', '+    def setup_method(self):\n', '         self.m = np.array([1, 2, 3, 4, 5, 6])\n', '         self.m_rect = self.m.reshape((2, 3))\n', ' \n']","[' \n', ' \n', ' class TestRepeat:\n', '-    def setup(self):\n', '         self.m = np.array([1, 2, 3, 4, 5, 6])\n', '         self.m_rect = self.m.reshape((2, 3))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # gh-9972\n', ""             assert_equal(4, int_func(np.array('4')))\n"", ""             assert_equal(5, int_func(np.bytes_(b'5')))\n"", ""+            assert_equal(6, int_func(np.unicode_('6')))\n"", '+\n', '+            # The delegation of int() to __trunc__ was deprecated in\n', '+            # Python 3.11.\n', '+            if sys.version_info < (3, 11):\n', '+                class HasTrunc:\n', '+                    def __trunc__(self):\n', '+                        return 3\n', '+                assert_equal(3, int_func(np.array(HasTrunc())))\n', '+                assert_equal(3, int_func(np.array([HasTrunc()])))\n', '+            else:\n', '+                pass\n', ' \n', '             class NotConvertible:\n', '                 def __int__(self):\n']","['             # gh-9972\n', ""             assert_equal(4, int_func(np.array('4')))\n"", ""             assert_equal(5, int_func(np.bytes_(b'5')))\n"", ""-            assert_equal(6, int_func(np.unicode_(u'6')))\n"", '-\n', '-            class HasTrunc:\n', '-                def __trunc__(self):\n', '-                    return 3\n', '-            assert_equal(3, int_func(np.array(HasTrunc())))\n', '-            assert_equal(3, int_func(np.array([HasTrunc()])))\n', ' \n', '             class NotConvertible:\n', '                 def __int__(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert len(keyword_start_stop) == 6\n', '         assert_array_equal(keyword_stop, keyword_zerotostop)\n', ' \n', '+    def test_arange_booleans(self):\n', '+        # Arange makes some sense for booleans and works up to length 2.\n', '+        # But it is weird since `arange(2, 4, dtype=bool)` works.\n', '+        # Arguably, much or all of this could be deprecated/removed.\n', '+        res = np.arange(False, dtype=bool)\n', '+        assert_array_equal(res, np.array([], dtype=""bool""))\n', '+\n', '+        res = np.arange(True, dtype=""bool"")\n', '+        assert_array_equal(res, [False])\n', '+\n', '+        res = np.arange(2, dtype=""bool"")\n', '+        assert_array_equal(res, [False, True])\n', '+\n', '+        # This case is especially weird, but drops out without special case:\n', '+        res = np.arange(6, 8, dtype=""bool"")\n', '+        assert_array_equal(res, [True, True])\n', '+\n', '+        with pytest.raises(TypeError):\n', '+            np.arange(3, dtype=""bool"")\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", [""S3"", ""U"", ""5i""])\n', '+    def test_rejects_bad_dtypes(self, dtype):\n', '+        dtype = np.dtype(dtype)\n', '+        DType_name = re.escape(str(type(dtype)))\n', '+        with pytest.raises(TypeError,\n', '+                match=rf""arange\\(\\) not supported for inputs .* {DType_name}""):\n', '+            np.arange(2, dtype=dtype)\n', '+\n', '+    def test_rejects_strings(self):\n', '+        # Explicitly test error for strings which may call ""b"" - ""a"":\n', '+        DType_name = re.escape(str(type(np.array(""a"").dtype)))\n', '+        with pytest.raises(TypeError,\n', '+                match=rf""arange\\(\\) not supported for inputs .* {DType_name}""):\n', '+            np.arange(""a"", ""b"")\n', '+\n', '+    def test_byteswapped(self):\n', '+        res_be = np.arange(1, 1000, dtype="">i4"")\n', '+        res_le = np.arange(1, 1000, dtype=""<i4"")\n', '+        assert res_be.dtype == "">i4""\n', '+        assert res_le.dtype == ""<i4""\n', '+        assert_array_equal(res_le, res_be)\n', '+\n', '+    @pytest.mark.parametrize(""which"", [0, 1, 2])\n', '+    def test_error_paths_and_promotion(self, which):\n', '+        args = [0, 1, 2]  # start, stop, and step\n', '+        args[which] = np.float64(2.)  # should ensure float64 output\n', '+\n', '+        assert np.arange(*args).dtype == np.float64\n', '+\n', '+        # Cover stranger error path, test only to achieve code coverage!\n', '+        args[which] = [None, []]\n', '+        with pytest.raises(ValueError):\n', '+            # Fails discovering start dtype\n', '+            np.arange(*args)\n', '+\n', ' \n', ' class TestArrayFinalize:\n', '     """""" Tests __array_finalize__ """"""\n']","['         assert len(keyword_start_stop) == 6\n', '         assert_array_equal(keyword_stop, keyword_zerotostop)\n', ' \n', ' \n', ' class TestArrayFinalize:\n', '     """""" Tests __array_finalize__ """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' def test_orderconverter_with_nonASCII_unicode_ordering():\n', '     # gh-7475\n', '     a = np.arange(5)\n', ""+    assert_raises(ValueError, a.flatten, order='\\xe2')\n"", ' \n', ' \n', ' def test_equal_override():\n']","[' def test_orderconverter_with_nonASCII_unicode_ordering():\n', '     # gh-7475\n', '     a = np.arange(5)\n', ""-    assert_raises(ValueError, a.flatten, order=u'\\xe2')\n"", ' \n', ' \n', ' def test_equal_override():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy import array, arange, nditer, all\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_array_equal, assert_raises,\n', '+    IS_WASM, HAS_REFCOUNT, suppress_warnings, break_cycles\n', '     )\n', ' \n', ' \n']","[' from numpy import array, arange, nditer, all\n', ' from numpy.testing import (\n', '     assert_, assert_equal, assert_array_equal, assert_raises,\n', '-    HAS_REFCOUNT, suppress_warnings, break_cycles\n', '     )\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     # Allocated output can't have buffering without delayed bufalloc\n"", ""     assert_raises(ValueError, nditer, [a, None], ['buffered'],\n"", ""                                             ['allocate', 'readwrite'])\n"", '+    # Must specify dtype if there are no inputs (cannot promote existing ones;\n', ""+    # maybe this should use the 'f4' here, but it does not historically.)\n"", '+    assert_raises(TypeError, nditer, [None, None], [],\n', ""                         [['writeonly', 'allocate'],\n"", ""                          ['writeonly', 'allocate']],\n"", ""+                        op_dtypes=[None, np.dtype('f4')])\n"", '     # If using op_axes, must specify all the axes\n', ""     a = arange(24, dtype='i4').reshape(2, 3, 4)\n"", '     assert_raises(ValueError, nditer, [a, None], [],\n']","[""     # Allocated output can't have buffering without delayed bufalloc\n"", ""     assert_raises(ValueError, nditer, [a, None], ['buffered'],\n"", ""                                             ['allocate', 'readwrite'])\n"", '-    # Must specify at least one input\n', '-    assert_raises(ValueError, nditer, [None, None], [],\n', ""                         [['writeonly', 'allocate'],\n"", ""                          ['writeonly', 'allocate']],\n"", ""-                        op_dtypes=[np.dtype('f4'), np.dtype('f4')])\n"", '     # If using op_axes, must specify all the axes\n', ""     a = arange(24, dtype='i4').reshape(2, 3, 4)\n"", '     assert_raises(ValueError, nditer, [a, None], [],\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                         op_dtypes=[None, np.dtype('f4')],\n"", '                         op_axes=[None, [0, np.newaxis, 2]])\n', ' \n', '+def test_all_allocated():\n', '+    # When no output and no shape is given, `()` is used as shape.\n', '+    i = np.nditer([None], op_dtypes=[""int64""])\n', '+    assert i.operands[0].shape == ()\n', '+    assert i.dtypes == (np.dtype(""int64""),)\n', '+\n', '+    i = np.nditer([None], op_dtypes=[""int64""], itershape=(2, 3, 4))\n', '+    assert i.operands[0].shape == (2, 3, 4)\n', '+\n', ' def test_iter_remove_axis():\n', '     a = arange(24).reshape(2, 3, 4)\n', ' \n']","[""                         op_dtypes=[None, np.dtype('f4')],\n"", '                         op_axes=[None, [0, np.newaxis, 2]])\n', ' \n', ' def test_iter_remove_axis():\n', '     a = arange(24).reshape(2, 3, 4)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             buf = next(it)\n', '             buf[...] = ""a""  # cannot be converted to int.\n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""PyPy seems to not hit this."")\n', ' def test_buffered_cast_error_paths_unraisable():\n', '     # The following gives an unraisable error. Pytest sometimes captures that\n']","['             buf = next(it)\n', '             buf[...] = ""a""  # cannot be converted to int.\n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""PyPy seems to not hit this."")\n', ' def test_buffered_cast_error_paths_unraisable():\n', '     # The following gives an unraisable error. Pytest sometimes captures that\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     assert_raises(TypeError, nditer, a, ['buffered'], ['readonly'],\n"", ""                     op_dtypes='U2')\n"", ""     i = nditer(a, ['buffered'], ['readonly'], op_dtypes='U6')\n"", ""+    assert_equal(i[0], 'abc')\n"", ""     assert_equal(i[0].dtype, np.dtype('U6'))\n"", ' \n', ' def test_iter_buffering_growinner():\n']","[""     assert_raises(TypeError, nditer, a, ['buffered'], ['readonly'],\n"", ""                     op_dtypes='U2')\n"", ""     i = nditer(a, ['buffered'], ['readonly'], op_dtypes='U6')\n"", ""-    assert_equal(i[0], u'abc')\n"", ""     assert_equal(i[0].dtype, np.dtype('U6'))\n"", ' \n', ' def test_iter_buffering_growinner():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                     op_dtypes=['f4', None],\n"", ""                     casting='same_kind')\n"", ' \n', '+\n', ' def _is_buffered(iterator):\n', '     try:\n', '         iterator.itviews\n']","[""                     op_dtypes=['f4', None],\n"", ""                     casting='same_kind')\n"", ' \n', ' def _is_buffered(iterator):\n', '     try:\n', '         iterator.itviews\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # were copied back\n', '     assert_equal(a, np.broadcast_to([3, 3, 2.5] * reps, shape))\n', ' \n', '+\n', '+@pytest.mark.parametrize([""mask"", ""mask_axes""], [\n', '+        # Allocated operand (only broadcasts with -1)\n', '+        (None, [-1, 0]),\n', '+        # Reduction along the first dimension (with and without op_axes)\n', '+        (np.zeros((1, 4), dtype=""bool""), [0, 1]),\n', '+        (np.zeros((1, 4), dtype=""bool""), None),\n', '+        # Test 0-D and -1 op_axes\n', '+        (np.zeros(4, dtype=""bool""), [-1, 0]),\n', '+        (np.zeros((), dtype=""bool""), [-1, -1]),\n', '+        (np.zeros((), dtype=""bool""), None)])\n', '+def test_iter_writemasked_broadcast_error(mask, mask_axes):\n', '+    # This assumes that a readwrite mask makes sense. This is likely not the\n', '+    # case and should simply be deprecated.\n', '+    arr = np.zeros((3, 4))\n', '+    itflags = [""reduce_ok""]\n', '+    mask_flags = [""arraymask"", ""readwrite"", ""allocate""]\n', '+    a_flags = [""writeonly"", ""writemasked""]\n', '+    if mask_axes is None:\n', '+        op_axes = None\n', '+    else:\n', '+        op_axes = [mask_axes, [0, 1]]\n', '+\n', '+    with assert_raises(ValueError):\n', '+        np.nditer((mask, arr), flags=itflags, op_flags=[mask_flags, a_flags],\n', '+                  op_axes=op_axes)\n', '+\n', '+\n', ' def test_iter_writemasked_decref():\n', '     # force casting (to make it interesting) by using a structured dtype.\n', '     arr = np.arange(10000).astype("">i,O"")\n']","['     # were copied back\n', '     assert_equal(a, np.broadcast_to([3, 3, 2.5] * reps, shape))\n', ' \n', ' def test_iter_writemasked_decref():\n', '     # force casting (to make it interesting) by using a structured dtype.\n', '     arr = np.arange(10000).astype("">i,O"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' @pytest.mark.skipif(sys.version_info[:2] == (3, 9) and sys.platform == ""win32"",\n', '                     reason=""Errors with Python 3.9 on Windows"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n', '         [(""i"", ""O""), (""O"", ""i""),  # most simple cases\n', '          (""i,O"", ""O,O""),  # structured partially only copying O\n']","[' \n', ' @pytest.mark.skipif(sys.version_info[:2] == (3, 9) and sys.platform == ""win32"",\n', '                     reason=""Errors with Python 3.9 on Windows"")\n', '-@pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n', '         [(""i"", ""O""), (""O"", ""i""),  # most simple cases\n', '          (""i,O"", ""O,O""),  # structured partially only copying O\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['          ])\n', ' @pytest.mark.parametrize(""steps"", [1, 2, 3])\n', ' def test_partial_iteration_cleanup(in_dtype, buf_dtype, steps):\n', '+    """"""\n', '+    Checks for reference counting leaks during cleanup.  Using explicit\n', '+    reference counts lead to occasional false positives (at least in parallel\n', '+    test setups).  This test now should still test leaks correctly when\n', '+    run e.g. with pytest-valgrind or pytest-leaks\n', '+    """"""\n', ""+    value = 2**30 + 1  # just a random value that Python won't intern\n"", '     arr = np.full(int(np.BUFSIZE * 2.5), value).astype(in_dtype)\n', ' \n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n', '             flags=[""buffered"", ""external_loop"", ""refs_ok""], casting=""unsafe"")\n']","['          ])\n', ' @pytest.mark.parametrize(""steps"", [1, 2, 3])\n', ' def test_partial_iteration_cleanup(in_dtype, buf_dtype, steps):\n', '-    value = 123  # relies on python cache (leak-check will still find it)\n', '     arr = np.full(int(np.BUFSIZE * 2.5), value).astype(in_dtype)\n', '-    count = sys.getrefcount(value)\n', ' \n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n', '             flags=[""buffered"", ""external_loop"", ""refs_ok""], casting=""unsafe"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # The iteration finishes in 3 steps, the first two are partial\n', '         next(it)\n', ' \n', '+    del it  # not necessary, but we test the cleanup\n', ' \n', '     # Repeat the test with `iternext`\n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n']","['         # The iteration finishes in 3 steps, the first two are partial\n', '         next(it)\n', ' \n', '-    # Note that resetting does not free references\n', '-    del it\n', '-    break_cycles()\n', '-    break_cycles()\n', '-    assert count == sys.getrefcount(value)\n', ' \n', '     # Repeat the test with `iternext`\n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     for step in range(steps):\n', '         it.iternext()\n', ' \n', '+    del it  # not necessary, but we test the cleanup\n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n']","['     for step in range(steps):\n', '         it.iternext()\n', ' \n', '-    del it  # should ensure cleanup\n', '-    break_cycles()\n', '-    break_cycles()\n', '-    assert count == sys.getrefcount(value)\n', '-\n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+""""""\n', '+This file adds basic tests to test the NEP 50 style promotion compatibility\n', '+mode.  Most of these test are likely to be simply deleted again once NEP 50\n', '+is adopted in the main test suite.  A few may be moved elsewhere.\n', '+""""""\n', '+\n', '+import operator\n', '+\n', '+import numpy as np\n', '+\n', '+import pytest\n', '+from numpy.testing import IS_WASM\n', '+\n', '+\n', '+@pytest.fixture(scope=""module"", autouse=True)\n', '+def _weak_promotion_enabled():\n', '+    state = np._get_promotion_state()\n', '+    np._set_promotion_state(""weak_and_warn"")\n', '+    yield\n', '+    np._set_promotion_state(state)\n', '+\n', '+\n', '+@pytest.mark.skipif(IS_WASM, reason=""wasm doesn\'t have support for fp errors"")\n', '+def test_nep50_examples():\n', '+    with pytest.warns(UserWarning, match=""result dtype changed""):\n', '+        res = np.uint8(1) + 2\n', '+    assert res.dtype == np.uint8\n', '+\n', '+    with pytest.warns(UserWarning, match=""result dtype changed""):\n', '+        res = np.array([1], np.uint8) + np.int64(1)\n', '+    assert res.dtype == np.int64\n', '+\n', '+    with pytest.warns(UserWarning, match=""result dtype changed""):\n', '+        res = np.array([1], np.uint8) + np.array(1, dtype=np.int64)\n', '+    assert res.dtype == np.int64\n', '+\n', '+    with pytest.warns(UserWarning, match=""result dtype changed""):\n', '+        # Note: For ""weak_and_warn"" promotion state the overflow warning is\n', '+        #       unfortunately not given (because we use the full array path).\n', '+        with np.errstate(over=""raise""):\n', '+            res = np.uint8(100) + 200\n', '+    assert res.dtype == np.uint8\n', '+\n', '+    with pytest.warns(Warning) as recwarn:\n', '+        res = np.float32(1) + 3e100\n', '+\n', '+    # Check that both warnings were given in the one call:\n', '+    warning = str(recwarn.pop(UserWarning).message)\n', '+    assert warning.startswith(""result dtype changed"")\n', '+    warning = str(recwarn.pop(RuntimeWarning).message)\n', '+    assert warning.startswith(""overflow"")\n', '+    assert len(recwarn) == 0  # no further warnings\n', '+    assert np.isinf(res)\n', '+    assert res.dtype == np.float32\n', '+\n', ""+    # Changes, but we don't warn for it (too noisy)\n"", '+    res = np.array([0.1], np.float32) == np.float64(0.1)\n', '+    assert res[0] == False\n', '+\n', '+    # Additional test, since the above silences the warning:\n', '+    with pytest.warns(UserWarning, match=""result dtype changed""):\n', '+        res = np.array([0.1], np.float32) + np.float64(0.1)\n', '+    assert res.dtype == np.float64\n', '+\n', '+    with pytest.warns(UserWarning, match=""result dtype changed""):\n', '+        res = np.array([1.], np.float32) + np.int64(3)\n', '+    assert res.dtype == np.float64\n', '+\n', '+\n', '+@pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+def test_nep50_weak_integers(dtype):\n', '+    # Avoids warning (different code path for scalars)\n', '+    np._set_promotion_state(""weak"")\n', '+    scalar_type = np.dtype(dtype).type\n', '+\n', '+    maxint = int(np.iinfo(dtype).max)\n', '+\n', '+    with np.errstate(over=""warn""):\n', '+        with pytest.warns(RuntimeWarning):\n', '+            res = scalar_type(100) + maxint\n', '+    assert res.dtype == dtype\n', '+\n', '+    # Array operations are not expected to warn, but should give the same\n', '+    # result dtype.\n', '+    res = np.array(100, dtype=dtype) + maxint\n', '+    assert res.dtype == dtype\n', '+\n', '+\n', '+@pytest.mark.parametrize(""dtype"", np.typecodes[""AllFloat""])\n', '+def test_nep50_weak_integers_with_inexact(dtype):\n', '+    # Avoids warning (different code path for scalars)\n', '+    np._set_promotion_state(""weak"")\n', '+    scalar_type = np.dtype(dtype).type\n', '+\n', '+    too_big_int = int(np.finfo(dtype).max) * 2\n', '+\n', '+    if dtype in ""dDG"":\n', '+        # These dtypes currently convert to Python float internally, which\n', '+        # raises an OverflowError, while the other dtypes overflow to inf.\n', '+        # NOTE: It may make sense to normalize the behavior!\n', '+        with pytest.raises(OverflowError):\n', '+            scalar_type(1) + too_big_int\n', '+\n', '+        with pytest.raises(OverflowError):\n', '+            np.array(1, dtype=dtype) + too_big_int\n', '+    else:\n', '+        # NumPy uses (or used) `int -> string -> longdouble` for the\n', '+        # conversion.  But Python may refuse `str(int)` for huge ints.\n', '+        # In that case, RuntimeWarning would be correct, but conversion\n', '+        # fails earlier (seems to happen on 32bit linux, possibly only debug).\n', '+        if dtype in ""gG"":\n', '+            try:\n', '+                str(too_big_int)\n', '+            except ValueError:\n', '+                pytest.skip(""`huge_int -> string -> longdouble` failed"")\n', '+\n', '+        # Otherwise, we overflow to infinity:\n', '+        with pytest.warns(RuntimeWarning):\n', '+            res = scalar_type(1) + too_big_int\n', '+        assert res.dtype == dtype\n', '+        assert res == np.inf\n', '+\n', '+        with pytest.warns(RuntimeWarning):\n', '+            # We force the dtype here, since windows may otherwise pick the\n', '+            # double instead of the longdouble loop.  That leads to slightly\n', '+            # different results (conversion of the int fails as above).\n', '+            res = np.add(np.array(1, dtype=dtype), too_big_int, dtype=dtype)\n', '+        assert res.dtype == dtype\n', '+        assert res == np.inf\n', '+\n', '+\n', '+@pytest.mark.parametrize(""op"", [operator.add, operator.pow, operator.eq])\n', '+def test_weak_promotion_scalar_path(op):\n', '+    # Some additional paths excercising the weak scalars.\n', '+    np._set_promotion_state(""weak"")\n', '+\n', '+    # Integer path:\n', '+    res = op(np.uint8(3), 5)\n', '+    assert res == op(3, 5)\n', '+    assert res.dtype == np.uint8 or res.dtype == bool\n', '+\n', '+    with pytest.raises(OverflowError):\n', '+        op(np.uint8(3), 1000)\n', '+\n', '+    # Float path:\n', '+    res = op(np.float32(3), 5.)\n', '+    assert res == op(3., 5.)\n', '+    assert res.dtype == np.float32 or res.dtype == bool\n', '+\n', '+\n', '+def test_nep50_complex_promotion():\n', '+    np._set_promotion_state(""weak"")\n', '+\n', '+    with pytest.warns(RuntimeWarning, match="".*overflow""):\n', '+        res = np.complex64(3) + complex(2**300)\n', '+\n', '+    assert type(res) == np.complex64\n', '+\n', '+\n', '+def test_nep50_integer_conversion_errors():\n', '+    # Do not worry about warnings here (auto-fixture will reset).\n', '+    np._set_promotion_state(""weak"")\n', '+    # Implementation for error paths is mostly missing (as of writing)\n', '+    with pytest.raises(OverflowError, match="".*uint8""):\n', '+        np.array([1], np.uint8) + 300\n', '+\n', '+    with pytest.raises(OverflowError, match="".*uint8""):\n', '+        np.uint8(1) + 300\n', '+\n', '+    # Error message depends on platform (maybe unsigned int or unsigned long)\n', '+    with pytest.raises(OverflowError,\n', '+            match=""Python integer -1 out of bounds for uint8""):\n', '+        np.uint8(1) + -1\n', '+\n', '+\n', '+def test_nep50_integer_regression():\n', '+    # Test the old integer promotion rules.  When the integer is too large,\n', '+    # we need to keep using the old-style promotion.\n', '+    np._set_promotion_state(""legacy"")\n', '+    arr = np.array(1)\n', '+    assert (arr + 2**63).dtype == np.float64\n', '+    assert (arr[()] + 2**63).dtype == np.float64\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_raises_regex,\n', '     assert_array_equal, assert_almost_equal, assert_array_almost_equal,\n', '+    assert_warns, assert_array_max_ulp, HAS_REFCOUNT, IS_WASM\n', '     )\n', ' from numpy.core._rational_tests import rational\n', ' \n']","[' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_raises_regex,\n', '     assert_array_equal, assert_almost_equal, assert_array_almost_equal,\n', '-    assert_warns, assert_array_max_ulp, HAS_REFCOUNT\n', '     )\n', ' from numpy.core._rational_tests import rational\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestBoolArray:\n', '+    def setup_method(self):\n', '         # offset for simd tests\n', '         self.t = np.array([True] * 41, dtype=bool)[1::]\n', '         self.f = np.array([False] * 41, dtype=bool)[1::]\n']","[' \n', ' \n', ' class TestBoolArray:\n', '-    def setup(self):\n', '         # offset for simd tests\n', '         self.t = np.array([True] * 41, dtype=bool)[1::]\n', '         self.f = np.array([False] * 41, dtype=bool)[1::]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestBoolCmp:\n', '+    def setup_method(self):\n', '         self.f = np.ones(256, dtype=np.float32)\n', '         self.ef = np.ones(self.f.size, dtype=bool)\n', '         self.d = np.ones(128, dtype=np.float64)\n']","[' \n', ' \n', ' class TestBoolCmp:\n', '-    def setup(self):\n', '         self.f = np.ones(256, dtype=np.float32)\n', '         self.ef = np.ones(self.f.size, dtype=bool)\n', '         self.d = np.ones(128, dtype=np.float64)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             np.seterr(**old)\n', '             assert_(np.geterr() == old)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""no wasm fp exception support"")\n', '     @pytest.mark.skipif(platform.machine() == ""armv5tel"", reason=""See gh-413."")\n', '     def test_divide_err(self):\n', ""         with np.errstate(divide='raise'):\n""]","['             np.seterr(**old)\n', '             assert_(np.geterr() == old)\n', ' \n', '     @pytest.mark.skipif(platform.machine() == ""armv5tel"", reason=""See gh-413."")\n', '     def test_divide_err(self):\n', ""         with np.errstate(divide='raise'):\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             np.seterr(divide='ignore')\n"", '             np.array([1.]) / np.array([0.])\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""no wasm fp exception support"")\n', '     def test_errobj(self):\n', '         olderrobj = np.geterrobj()\n', '         self.called = 0\n']","[""             np.seterr(divide='ignore')\n"", '             np.array([1.]) / np.array([0.])\n', ' \n', '     def test_errobj(self):\n', '         olderrobj = np.geterrobj()\n', '         self.called = 0\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.assert_raises_fpe(fpeerr, flop, sc1[()], sc2[()])\n', ' \n', '     # Test for all real and complex float types\n', '+    @pytest.mark.skipif(IS_WASM, reason=""no wasm fp exception support"")\n', '     @pytest.mark.parametrize(""typecode"", np.typecodes[""AllFloat""])\n', '     def test_floating_exceptions(self, typecode):\n', '         # Test basic arithmetic function errors\n']","['         self.assert_raises_fpe(fpeerr, flop, sc1[()], sc2[()])\n', ' \n', '     # Test for all real and complex float types\n', '     @pytest.mark.parametrize(""typecode"", np.typecodes[""AllFloat""])\n', '     def test_floating_exceptions(self, typecode):\n', '         # Test basic arithmetic function errors\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             self.assert_raises_fpe(invalid,\n', '                                    lambda a, b: a*b, ftype(0), ftype(np.inf))\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""no wasm fp exception support"")\n', '     def test_warnings(self):\n', '         # test warning code path\n', '         with warnings.catch_warnings(record=True) as w:\n']","['             self.assert_raises_fpe(invalid,\n', '                                    lambda a, b: a*b, ftype(0), ftype(np.inf))\n', ' \n', '     def test_warnings(self):\n', '         # test warning code path\n', '         with warnings.catch_warnings(record=True) as w:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a = np.array([[ThrowsAfter(15)]]*10)\n', '         assert_raises(ValueError, np.nonzero, a)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""wasm doesn\'t have threads"")\n', '     def test_structured_threadsafety(self):\n', '         # Nonzero (and some other functions) should be threadsafe for\n', '         # structured datatypes, see gh-15387. This test can behave randomly.\n']","['         a = np.array([[ThrowsAfter(15)]]*10)\n', '         assert_raises(ValueError, np.nonzero, a)\n', ' \n', '     def test_structured_threadsafety(self):\n', '         # Nonzero (and some other functions) should be threadsafe for\n', '         # structured datatypes, see gh-15387. This test can behave randomly.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestClip:\n', '+    def setup_method(self):\n', '         self.nr = 5\n', '         self.nc = 3\n', ' \n']","[' \n', ' \n', ' class TestClip:\n', '-    def setup(self):\n', '         self.nr = 5\n', '         self.nc = 3\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def tst_allclose(self, x, y):\n']","['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def tst_allclose(self, x, y):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '+    def _setup(self):\n', '         atol = self.atol\n', '         rtol = self.rtol\n', '         arr = np.array([100, 1000])\n']","['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '-    def setup(self):\n', '         atol = self.atol\n', '         rtol = self.rtol\n', '         arr = np.array([100, 1000])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 ]\n', ' \n', '     def test_ip_isclose(self):\n', '+        self._setup()\n', '         tests = self.some_close_tests\n', '         results = self.some_close_results\n', '         for (x, y), result in zip(tests, results):\n']","['                 ]\n', ' \n', '     def test_ip_isclose(self):\n', '-        self.setup()\n', '         tests = self.some_close_tests\n', '         results = self.some_close_results\n', '         for (x, y), result in zip(tests, results):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             assert_array_equal(np.isclose(x, y).all(), np.allclose(x, y), msg % (x, y))\n', ' \n', '     def test_ip_all_isclose(self):\n', '+        self._setup()\n', '         for (x, y) in self.all_close_tests:\n', '             self.tst_all_isclose(x, y)\n', ' \n', '     def test_ip_none_isclose(self):\n', '+        self._setup()\n', '         for (x, y) in self.none_close_tests:\n', '             self.tst_none_isclose(x, y)\n', ' \n', '     def test_ip_isclose_allclose(self):\n', '+        self._setup()\n', '         tests = (self.all_close_tests + self.none_close_tests +\n', '                  self.some_close_tests)\n', '         for (x, y) in tests:\n']","['             assert_array_equal(np.isclose(x, y).all(), np.allclose(x, y), msg % (x, y))\n', ' \n', '     def test_ip_all_isclose(self):\n', '-        self.setup()\n', '         for (x, y) in self.all_close_tests:\n', '             self.tst_all_isclose(x, y)\n', ' \n', '     def test_ip_none_isclose(self):\n', '-        self.setup()\n', '         for (x, y) in self.none_close_tests:\n', '             self.tst_none_isclose(x, y)\n', ' \n', '     def test_ip_isclose_allclose(self):\n', '-        self.setup()\n', '         tests = (self.all_close_tests + self.none_close_tests +\n', '                  self.some_close_tests)\n', '         for (x, y) in tests:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestStdVar:\n', '+    def setup_method(self):\n', '         self.A = np.array([1, -1, 1, -1])\n', '         self.real_var = 1\n', ' \n']","[' \n', ' \n', ' class TestStdVar:\n', '-    def setup(self):\n', '         self.A = np.array([1, -1, 1, -1])\n', '         self.real_var = 1\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestCreationFuncs:\n', '     # Test ones, zeros, empty and full.\n', ' \n', '+    def setup_method(self):\n', '         dtypes = {np.dtype(tp) for tp in itertools.chain(*np.sctypes.values())}\n', '         # void, bytes, str\n', ""         variable_sized = {tp for tp in dtypes if tp.str.endswith('0')}\n""]","[' class TestCreationFuncs:\n', '     # Test ones, zeros, empty and full.\n', ' \n', '-    def setup(self):\n', '         dtypes = {np.dtype(tp) for tp in itertools.chain(*np.sctypes.values())}\n', '         # void, bytes, str\n', ""         variable_sized = {tp for tp in dtypes if tp.str.endswith('0')}\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestLikeFuncs:\n', ""     '''Test ones_like, zeros_like, empty_like and full_like'''\n"", ' \n', '+    def setup_method(self):\n', '         self.data = [\n', '                 # Array scalars\n', '                 (np.array(3.), None),\n']","[' class TestLikeFuncs:\n', ""     '''Test ones_like, zeros_like, empty_like and full_like'''\n"", ' \n', '-    def setup(self):\n', '         self.data = [\n', '                 # Array scalars\n', '                 (np.array(3.), None),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def compare_array_value(self, dz, value, fill_value):\n', '         if value is not None:\n', '             if fill_value:\n', '+                # Conversion is close to what np.full_like uses\n', '+                # but we  may want to convert directly in the future\n', '+                # which may result in errors (where this does not).\n', '+                z = np.array(value).astype(dz.dtype)\n', '+                assert_(np.all(dz == z))\n', '             else:\n', '                 assert_(np.all(dz == value))\n', ' \n']","['     def compare_array_value(self, dz, value, fill_value):\n', '         if value is not None:\n', '             if fill_value:\n', '-                try:\n', '-                    z = dz.dtype.type(value)\n', '-                except OverflowError:\n', '-                    pass\n', '-                else:\n', '-                    assert_(np.all(dz == z))\n', '             else:\n', '                 assert_(np.all(dz == value))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.check_like_function(np.full_like, 1, True)\n', '         self.check_like_function(np.full_like, 1000, True)\n', '         self.check_like_function(np.full_like, 123.456, True)\n', '+        # Inf to integer casts cause invalid-value errors: ignore them.\n', '+        with np.errstate(invalid=""ignore""):\n', '+            self.check_like_function(np.full_like, np.inf, True)\n', ' \n', ""     @pytest.mark.parametrize('likefunc', [np.empty_like, np.full_like,\n"", '                                           np.zeros_like, np.ones_like])\n']","['         self.check_like_function(np.full_like, 1, True)\n', '         self.check_like_function(np.full_like, 1000, True)\n', '         self.check_like_function(np.full_like, 123.456, True)\n', '-        self.check_like_function(np.full_like, np.inf, True)\n', ' \n', ""     @pytest.mark.parametrize('likefunc', [np.empty_like, np.full_like,\n"", '                                           np.zeros_like, np.ones_like])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         for axisc in range(-2, 2):\n', '             assert_equal(np.cross(u, u, axisc=axisc).shape, (3, 4))\n', ' \n', '+    def test_uint8_int32_mixed_dtypes(self):\n', '+        # regression test for gh-19138\n', '+        u = np.array([[195, 8, 9]], np.uint8)\n', '+        v = np.array([250, 166, 68], np.int32)\n', '+        z = np.array([[950, 11010, -30370]], dtype=np.int32)\n', '+        assert_equal(np.cross(v, u), z)\n', '+        assert_equal(np.cross(u, v), -z)\n', '+\n', ' \n', ' def test_outer_out_param():\n', '     arr1 = np.ones((5,))\n']","['         for axisc in range(-2, 2):\n', '             assert_equal(np.cross(u, u, axisc=axisc).shape, (3, 4))\n', ' \n', ' \n', ' def test_outer_out_param():\n', '     arr1 = np.ones((5,))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # x     Info                                                color info        y                  z\n', '     #       value y2 Info2                            name z2         Name Value\n', '     #                name   value    y3       z3\n', ""+    ([3, 2], (6j, 6., (b'nn', [6j, 4j], [6., 4.], [1, 2]), b'NN', True),\n"", ""+     b'cc', ('NN', 6j), [[6., 4.], [6., 4.]], 8),\n"", ""+    ([4, 3], (7j, 7., (b'oo', [7j, 5j], [7., 5.], [2, 1]), b'OO', False),\n"", ""+     b'dd', ('OO', 7j), [[7., 5.], [7., 5.]], 9),\n"", '     ]\n', ' \n', ' \n']","['     # x     Info                                                color info        y                  z\n', '     #       value y2 Info2                            name z2         Name Value\n', '     #                name   value    y3       z3\n', ""-    ([3, 2], (6j, 6., (b'nn', [6j, 4j], [6., 4.], [1, 2]), b'NN', True), b'cc', (u'NN', 6j), [[6., 4.], [6., 4.]], 8),\n"", ""-    ([4, 3], (7j, 7., (b'oo', [7j, 5j], [7., 5.], [2, 1]), b'OO', False), b'dd', (u'OO', 7j), [[7., 5.], [7., 5.]], 9),\n"", '     ]\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         assert_(res == 'f8')\n"", ' \n', ' class TestMultipleFields:\n', '+    def setup_method(self):\n', ""         self.ary = np.array([(1, 2, 3, 4), (5, 6, 7, 8)], dtype='i4,f4,i2,c8')\n"", ' \n', '     def _bad_call(self):\n']","[""         assert_(res == 'f8')\n"", ' \n', ' class TestMultipleFields:\n', '-    def setup(self):\n', ""         self.ary = np.array([(1, 2, 3, 4), (5, 6, 7, 8)], dtype='i4,f4,i2,c8')\n"", ' \n', '     def _bad_call(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # alias for np.int_, but np.long is not supported for historical\n', '         # reasons (gh-21063)\n', ""         assert_(np.sctypeDict['ulong'] is np.uint)\n"", '+        with pytest.warns(FutureWarning):\n', '+            # We will probably allow this in the future:\n', ""+            assert not hasattr(np, 'ulong')\n"", ' \n', ' class TestBitName:\n', '     def test_abstract(self):\n']","['         # alias for np.int_, but np.long is not supported for historical\n', '         # reasons (gh-21063)\n', ""         assert_(np.sctypeDict['ulong'] is np.uint)\n"", ""-        assert_(not hasattr(np, 'ulong'))\n"", '-\n', ' \n', ' class TestBitName:\n', '     def test_abstract(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 TypeError, ""no implementation found for \'my.func\'""):\n', '             func(MyArray())\n', ' \n', '+    def test_signature_error_message(self):\n', '+        # The lambda function will be named ""<lambda>"", but the TypeError\n', '+        # should show the name as ""func""\n', '+        def _dispatcher():\n', '+            return ()\n', '+\n', '+        @array_function_dispatch(_dispatcher)\n', '+        def func():\n', '+            pass\n', '+\n', '+        try:\n', '+            func(bad_arg=3)\n', '+        except TypeError as e:\n', '+            expected_exception = e\n', '+\n', '+        try:\n', '+            func(bad_arg=3)\n', '+            raise AssertionError(""must fail"")\n', '+        except TypeError as exc:\n', '+            assert exc.args == expected_exception.args\n', '+\n', '+    @pytest.mark.parametrize(""value"", [234, ""this func is not replaced""])\n', '+    def test_dispatcher_error(self, value):\n', '+        # If the dispatcher raises an error, we must not attempt to mutate it\n', '+        error = TypeError(value)\n', '+\n', '+        def dispatcher():\n', '+            raise error\n', '+\n', '+        @array_function_dispatch(dispatcher)\n', '+        def func():\n', '+            return 3\n', '+\n', '+        try:\n', '+            func()\n', '+            raise AssertionError(""must fail"")\n', '+        except TypeError as exc:\n', '+            assert exc is error  # unmodified exception\n', '+\n', ' \n', ' class TestNDArrayMethods:\n', ' \n']","['                 TypeError, ""no implementation found for \'my.func\'""):\n', '             func(MyArray())\n', ' \n', ' \n', ' class TestNDArrayMethods:\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestArrayLike:\n', '+    def setup_method(self):\n', '         class MyArray():\n', '             def __init__(self, function=None):\n', '                 self.function = function\n']","[' \n', ' \n', ' class TestArrayLike:\n', '-    def setup(self):\n', '         class MyArray():\n', '             def __init__(self, function=None):\n', '                 self.function = function\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         ('fromiter', *func_args(range(3), dtype=int)),\n"", ""         ('fromstring', *func_args('1,2', dtype=int, sep=',')),\n"", ""         ('loadtxt', *func_args(lambda: StringIO('0 1\\n2 3'))),\n"", ""+        ('genfromtxt', *func_args(lambda: StringIO('1,2.1'),\n"", ""                                   dtype=[('int', 'i8'), ('float', 'f8')],\n"", ""                                   delimiter=',')),\n"", '     ]\n']","[""         ('fromiter', *func_args(range(3), dtype=int)),\n"", ""         ('fromstring', *func_args('1,2', dtype=int, sep=',')),\n"", ""         ('loadtxt', *func_args(lambda: StringIO('0 1\\n2 3'))),\n"", ""-        ('genfromtxt', *func_args(lambda: StringIO(u'1,2.1'),\n"", ""                                   dtype=[('int', 'i8'), ('float', 'f8')],\n"", ""                                   delimiter=',')),\n"", '     ]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with assert_raises(TypeError):\n', '             # Raises the error about `value_error` being invalid first\n', '             np.array(1, value_error=True, like=ref)\n', '+\n', ""+    @pytest.mark.parametrize('function, args, kwargs', _array_tests)\n"", '+    def test_like_as_none(self, function, args, kwargs):\n', ""+        self.add_method('array', self.MyArray)\n"", '+        self.add_method(function, self.MyArray)\n', '+        np_func = getattr(np, function)\n', '+\n', '+        like_args = tuple(a() if callable(a) else a for a in args)\n', '+        # required for loadtxt and genfromtxt to init w/o error.\n', '+        like_args_exp = tuple(a() if callable(a) else a for a in args)\n', '+\n', '+        array_like = np_func(*like_args, **kwargs, like=None)\n', '+        expected = np_func(*like_args_exp, **kwargs)\n', '+        # Special-case np.empty to ensure values match\n', '+        if function == ""empty"":\n', '+            array_like.fill(1)\n', '+            expected.fill(1)\n', '+        assert_equal(array_like, expected)\n']","['         with assert_raises(TypeError):\n', '             # Raises the error about `value_error` being invalid first\n', '             np.array(1, value_error=True, like=ref)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestRecord:\n', '+    def setup_method(self):\n', '         self.data = np.rec.fromrecords([(1, 2, 3), (4, 5, 6)],\n', '                             dtype=[(""col1"", ""<i4""),\n', '                                    (""col2"", ""<i4""),\n']","[' \n', ' \n', ' class TestRecord:\n', '-    def setup(self):\n', '         self.data = np.rec.fromrecords([(1, 2, 3), (4, 5, 6)],\n', '                             dtype=[(""col1"", ""<i4""),\n', '                                    (""col2"", ""<i4""),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_, assert_equal, IS_PYPY, assert_almost_equal,\n', '         assert_array_equal, assert_array_almost_equal, assert_raises,\n', '         assert_raises_regex, assert_warns, suppress_warnings,\n', '+        _assert_valid_refcount, HAS_REFCOUNT, IS_PYSTON, IS_WASM\n', '         )\n', ' from numpy.testing._private.utils import _no_tracing, requires_memory\n', ' from numpy.compat import asbytes, asunicode, pickle\n']","['         assert_, assert_equal, IS_PYPY, assert_almost_equal,\n', '         assert_array_equal, assert_array_almost_equal, assert_raises,\n', '         assert_raises_regex, assert_warns, suppress_warnings,\n', '-        _assert_valid_refcount, HAS_REFCOUNT, IS_PYSTON\n', '         )\n', ' from numpy.testing._private.utils import _no_tracing, requires_memory\n', ' from numpy.compat import asbytes, asunicode, pickle\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_unicode_swapping(self):\n', '         # Ticket #79\n', '         ulen = 1\n', ""+        ucs_value = '\\U0010FFFF'\n"", ""         ua = np.array([[[ucs_value*ulen]*2]*3]*4, dtype='U%s' % ulen)\n"", '         ua.newbyteorder()  # Should succeed.\n', ' \n']","['     def test_unicode_swapping(self):\n', '         # Ticket #79\n', '         ulen = 1\n', ""-        ucs_value = u'\\U0010FFFF'\n"", ""         ua = np.array([[[ucs_value*ulen]*2]*3]*4, dtype='U%s' % ulen)\n"", '         ua.newbyteorder()  # Should succeed.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_raises(ValueError, bfa)\n', '         assert_raises(ValueError, bfb)\n', ' \n', '+    @pytest.mark.xfail(IS_WASM, reason=""not sure why"")\n', '+    @pytest.mark.parametrize(""index"",\n', '+            [np.ones(10, dtype=bool), np.arange(10)],\n', '+            ids=[""boolean-arr-index"", ""integer-arr-index""])\n', '+    def test_nonarray_assignment(self, index):\n', '         # See also Issue gh-2870, test for non-array assignment\n', '         # and equivalent unsafe casted array assignment\n', '         a = np.arange(10)\n', ' \n', '+        with pytest.raises(ValueError):\n', '+            a[index] = np.nan\n', ' \n', '+        with np.errstate(invalid=""warn""):\n', '+            with pytest.warns(RuntimeWarning, match=""invalid value""):\n', '+                a[index] = np.array(np.nan)  # Only warns\n', ' \n', '     def test_unpickle_dtype_with_object(self):\n', '         # Implemented in r2840\n']","['         assert_raises(ValueError, bfa)\n', '         assert_raises(ValueError, bfb)\n', ' \n', '-    def test_nonarray_assignment(self):\n', '         # See also Issue gh-2870, test for non-array assignment\n', '         # and equivalent unsafe casted array assignment\n', '         a = np.arange(10)\n', '-        b = np.ones(10, dtype=bool)\n', '-        r = np.arange(10)\n', ' \n', '-        def assign(a, b, c):\n', '-            a[b] = c\n', ' \n', '-        assert_raises(ValueError, assign, a, b, np.nan)\n', '-        a[b] = np.array(np.nan)  # but not this.\n', '-        assert_raises(ValueError, assign, a, r, np.nan)\n', '-        a[r] = np.array(np.nan)\n', ' \n', '     def test_unpickle_dtype_with_object(self):\n', '         # Implemented in r2840\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         for i in range(1, 9):\n', ""             msg = 'unicode offset: %d chars' % i\n"", ""             t = np.dtype([('a', 'S%d' % i), ('b', 'U2')])\n"", ""+            x = np.array([(b'a', 'b')], dtype=t)\n"", '             assert_equal(str(x), ""[(b\'a\', \'b\')]"", err_msg=msg)\n', ' \n', '     def test_sign_for_complex_nan(self):\n']","['         for i in range(1, 9):\n', ""             msg = 'unicode offset: %d chars' % i\n"", ""             t = np.dtype([('a', 'S%d' % i), ('b', 'U2')])\n"", ""-            x = np.array([(b'a', u'b')], dtype=t)\n"", '             assert_equal(str(x), ""[(b\'a\', \'b\')]"", err_msg=msg)\n', ' \n', '     def test_sign_for_complex_nan(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_unicode_to_string_cast(self):\n', '         # Ticket #1240.\n', ""+        a = np.array([['abc', '\\u03a3'],\n"", ""+                      ['asdf', 'erw']],\n"", ""                      dtype='U')\n"", ""         assert_raises(UnicodeEncodeError, np.array, a, 'S4')\n"", ' \n', '     def test_unicode_to_string_cast_error(self):\n', '         # gh-15790\n', ""+        a = np.array(['\\x80'] * 129, dtype='U3')\n"", ""         assert_raises(UnicodeEncodeError, np.array, a, 'S')\n"", '         b = a.reshape(3, 43)[:-1, :-1]\n', ""         assert_raises(UnicodeEncodeError, np.array, b, 'S')\n"", ' \n', '+    def test_mixed_string_byte_array_creation(self):\n', ""+        a = np.array(['1234', b'123'])\n"", '         assert_(a.itemsize == 16)\n', ""+        a = np.array([b'123', '1234'])\n"", '         assert_(a.itemsize == 16)\n', ""+        a = np.array(['1234', b'123', '12345'])\n"", '         assert_(a.itemsize == 20)\n', ""+        a = np.array([b'123', '1234', b'12345'])\n"", '         assert_(a.itemsize == 20)\n', ""+        a = np.array([b'123', '1234', b'1234'])\n"", '         assert_(a.itemsize == 16)\n', ' \n', '     def test_misaligned_objects_segfault(self):\n']","[' \n', '     def test_unicode_to_string_cast(self):\n', '         # Ticket #1240.\n', ""-        a = np.array([[u'abc', u'\\u03a3'],\n"", ""-                      [u'asdf', u'erw']],\n"", ""                      dtype='U')\n"", ""         assert_raises(UnicodeEncodeError, np.array, a, 'S4')\n"", ' \n', '     def test_unicode_to_string_cast_error(self):\n', '         # gh-15790\n', ""-        a = np.array([u'\\x80'] * 129, dtype='U3')\n"", ""         assert_raises(UnicodeEncodeError, np.array, a, 'S')\n"", '         b = a.reshape(3, 43)[:-1, :-1]\n', ""         assert_raises(UnicodeEncodeError, np.array, b, 'S')\n"", ' \n', '-    def test_mixed_string_unicode_array_creation(self):\n', ""-        a = np.array(['1234', u'123'])\n"", '         assert_(a.itemsize == 16)\n', ""-        a = np.array([u'123', '1234'])\n"", '         assert_(a.itemsize == 16)\n', ""-        a = np.array(['1234', u'123', '12345'])\n"", '         assert_(a.itemsize == 20)\n', ""-        a = np.array([u'123', '1234', u'12345'])\n"", '         assert_(a.itemsize == 20)\n', ""-        a = np.array([u'123', '1234', u'1234'])\n"", '         assert_(a.itemsize == 16)\n', ' \n', '     def test_misaligned_objects_segfault(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             min = np.array([np.iinfo(t).min])\n', '             min //= -1\n', ' \n', '+        with np.errstate(over=""ignore""):\n', '             for t in (np.int8, np.int16, np.int32, np.int64, int):\n', '                 test_type(t)\n', ' \n']","['             min = np.array([np.iinfo(t).min])\n', '             min //= -1\n', ' \n', '-        with np.errstate(divide=""ignore""):\n', '             for t in (np.int8, np.int16, np.int32, np.int64, int):\n', '                 test_type(t)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # Check that loads does not clobber interned strings\n', '         s = re.sub(""a(.)"", ""\\x01\\\\1"", ""a_"")\n', '         assert_equal(s[0], ""\\x01"")\n', '+        data[0] = 0x6a\n', '         s = re.sub(""a(.)"", ""\\x01\\\\1"", ""a_"")\n', '         assert_equal(s[0], ""\\x01"")\n', ' \n']","['         # Check that loads does not clobber interned strings\n', '         s = re.sub(""a(.)"", ""\\x01\\\\1"", ""a_"")\n', '         assert_equal(s[0], ""\\x01"")\n', '-        data[0] = 0xbb\n', '         s = re.sub(""a(.)"", ""\\x01\\\\1"", ""a_"")\n', '         assert_equal(s[0], ""\\x01"")\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n', ""             data = np.array([1], dtype='b')\n"", '             data = pickle.loads(pickle.dumps(data, protocol=proto))\n', '+            data[0] = 0x7d\n', '             bytestring = ""\\x01  "".encode(\'ascii\')\n', ""             assert_equal(bytestring[0:1], '\\x01'.encode('ascii'))\n"", ' \n']","['         for proto in range(2, pickle.HIGHEST_PROTOCOL + 1):\n', ""             data = np.array([1], dtype='b')\n"", '             data = pickle.loads(pickle.dumps(data, protocol=proto))\n', '-            data[0] = 0xdd\n', '             bytestring = ""\\x01  "".encode(\'ascii\')\n', ""             assert_equal(bytestring[0:1], '\\x01'.encode('ascii'))\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 b""p13\\ntp14\\nb."")\n', '         # This should work:\n', ""         result = pickle.loads(data, encoding='latin1')\n"", ""+        assert_array_equal(result, np.array([129]).astype('b'))\n"", '         # Should not segfault:\n', ""         assert_raises(Exception, pickle.loads, data, encoding='koi8-r')\n"", ' \n']","['                 b""p13\\ntp14\\nb."")\n', '         # This should work:\n', ""         result = pickle.loads(data, encoding='latin1')\n"", ""-        assert_array_equal(result, np.array([129], dtype='b'))\n"", '         # Should not segfault:\n', ""         assert_raises(Exception, pickle.loads, data, encoding='koi8-r')\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         import numpy as np\n', ""         a = np.array([['Hello', 'Foob']], dtype='U5', order='F')\n"", ""         arr = np.ndarray(shape=[1, 2, 5], dtype='U1', buffer=a)\n"", ""+        arr2 = np.array([[['H', 'e', 'l', 'l', 'o'],\n"", ""+                          ['F', 'o', 'o', 'b', '']]])\n"", '         assert_array_equal(arr, arr2)\n', ' \n', '     def test_assign_from_sequence_error(self):\n']","['         import numpy as np\n', ""         a = np.array([['Hello', 'Foob']], dtype='U5', order='F')\n"", ""         arr = np.ndarray(shape=[1, 2, 5], dtype='U1', buffer=a)\n"", ""-        arr2 = np.array([[[u'H', u'e', u'l', u'l', u'o'],\n"", ""-                          [u'F', u'o', u'o', u'b', u'']]])\n"", '         assert_array_equal(arr, arr2)\n', ' \n', '     def test_assign_from_sequence_error(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(1024, np.intp(1024))\n', ' \n', '     def test_uint64_from_negative(self):\n', '+        with pytest.warns(DeprecationWarning):\n', '+            assert_equal(np.uint64(-2), np.uint64(18446744073709551614))\n', ' \n', ' \n', ' int_types = [np.byte, np.short, np.intc, np.int_, np.longlong]\n']","['         assert_equal(1024, np.intp(1024))\n', ' \n', '     def test_uint64_from_negative(self):\n', '-        assert_equal(np.uint64(-2), np.uint64(18446744073709551614))\n', ' \n', ' \n', ' int_types = [np.byte, np.short, np.intc, np.int_, np.longlong]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     @pytest.mark.parametrize('t2', cfloat_types + [None])\n"", '     def test_complex(self, t1, t2):\n', '         return self._do_test(t1, t2)\n', '+\n', '+\n', '+@pytest.mark.parametrize(""length"",\n', '+        [5, np.int8(5), np.array(5, dtype=np.uint16)])\n', '+def test_void_via_length(length):\n', '+    res = np.void(length)\n', '+    assert type(res) is np.void\n', '+    assert res.item() == b""\\0"" * 5\n', '+    assert res.dtype == ""V5""\n', '+\n', '+@pytest.mark.parametrize(""bytes_"",\n', '+        [b""spam"", np.array(567.)])\n', '+def test_void_from_byteslike(bytes_):\n', '+    res = np.void(bytes_)\n', '+    expected = bytes(bytes_)\n', '+    assert type(res) is np.void\n', '+    assert res.item() == expected\n', '+\n', '+    # Passing dtype can extend it (this is how filling works)\n', '+    res = np.void(bytes_, dtype=""V100"")\n', '+    assert type(res) is np.void\n', '+    assert res.item()[:len(expected)] == expected\n', '+    assert res.item()[len(expected):] == b""\\0"" * (res.nbytes - len(expected))\n', '+    # As well as shorten:\n', '+    res = np.void(bytes_, dtype=""V4"")\n', '+    assert type(res) is np.void\n', '+    assert res.item() == expected[:4]\n', '+\n', '+def test_void_arraylike_trumps_byteslike():\n', '+    # The memoryview is converted as an array-like of shape (18,)\n', '+    # rather than a single bytes-like of that length.\n', '+    m = memoryview(b""just one mintleaf?"")\n', '+    res = np.void(m)\n', '+    assert type(res) is np.ndarray\n', '+    assert res.dtype == ""V1""\n', '+    assert res.shape == (18,)\n', '+\n', '+def test_void_dtype_arg():\n', '+    # Basic test for the dtype argument (positional and keyword)\n', '+    res = np.void((1, 2), dtype=""i,i"")\n', '+    assert res.item() == (1, 2)\n', '+    res = np.void((2, 3), ""i,i"")\n', '+    assert res.item() == (2, 3)\n', '+\n', '+@pytest.mark.parametrize(""data"",\n', '+        [5, np.int8(5), np.array(5, dtype=np.uint16)])\n', '+def test_void_from_integer_with_dtype(data):\n', '+    # The ""length"" meaning is ignored, rather data is used:\n', '+    res = np.void(data, dtype=""i,i"")\n', '+    assert type(res) is np.void\n', '+    assert res.dtype == ""i,i""\n', '+    assert res[""f0""] == 5 and res[""f1""] == 5\n', '+\n', '+def test_void_from_structure():\n', ""+    dtype = np.dtype([('s', [('f', 'f8'), ('u', 'U1')]), ('i', 'i2')])\n"", ""+    data = np.array(((1., 'a'), 2), dtype=dtype)\n"", '+    res = np.void(data[()], dtype=dtype)\n', '+    assert type(res) is np.void\n', '+    assert res.dtype == dtype\n', '+    assert res == data[()]\n', '+\n', '+def test_void_bad_dtype():\n', '+    with pytest.raises(TypeError,\n', '+            match=""void: descr must be a `void.*int64""):\n', '+        np.void(4, dtype=""i8"")\n', '+\n', '+    # Subarray dtype (with shape `(4,)` is rejected):\n', '+    with pytest.raises(TypeError,\n', '+            match=r""void: descr must be a `void.*\\(4,\\)""):\n', '+        np.void(4, dtype=""4i"")\n']","[""     @pytest.mark.parametrize('t2', cfloat_types + [None])\n"", '     def test_complex(self, t1, t2):\n', '         return self._do_test(t1, t2)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             n, d = f.as_integer_ratio()\n', ' \n', '             try:\n', '+                nf = np.longdouble(n)\n', '+                df = np.longdouble(d)\n', '             except (OverflowError, RuntimeWarning):\n', '                 # the values may not fit in any float type\n', '                 pytest.skip(""longdouble too small on this platform"")\n']","['             n, d = f.as_integer_ratio()\n', ' \n', '             try:\n', '-                # workaround for gh-9968\n', '-                nf = np.longdouble(str(n))\n', '-                df = np.longdouble(str(d))\n', '             except (OverflowError, RuntimeWarning):\n', '                 # the values may not fit in any float type\n', '                 pytest.skip(""longdouble too small on this platform"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is np.complexfloating\n', ' \n', '+    @pytest.mark.parametrize(""arg_len"", range(4))\n', '+    def test_abc_complexfloating_subscript_tuple(self, arg_len: int) -> None:\n', '+        arg_tup = (Any,) * arg_len\n', '+        if arg_len in (1, 2):\n', '+            assert np.complexfloating[arg_tup]\n', '+        else:\n', '+            match = f""Too {\'few\' if arg_len == 0 else \'many\'} arguments""\n', '+            with pytest.raises(TypeError, match=match):\n', '+                np.complexfloating[arg_tup]\n', '+\n', '     @pytest.mark.parametrize(""cls"", [np.generic, np.flexible, np.character])\n', '     def test_abc_non_numeric(self, cls: Type[np.generic]) -> None:\n', '         with pytest.raises(TypeError):\n']","['         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is np.complexfloating\n', ' \n', '     @pytest.mark.parametrize(""cls"", [np.generic, np.flexible, np.character])\n', '     def test_abc_non_numeric(self, cls: Type[np.generic]) -> None:\n', '         with pytest.raises(TypeError):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         np_s = np.string_('abc')\n"", ""         np_u = np.unicode_('abc')\n"", ""         s = b'def'\n"", ""+        u = 'def'\n"", '         assert_(np_s.__radd__(np_s) is NotImplemented)\n', '         assert_(np_s.__radd__(np_u) is NotImplemented)\n', '         assert_(np_s.__radd__(s) is NotImplemented)\n']","[""         np_s = np.string_('abc')\n"", ""         np_u = np.unicode_('abc')\n"", ""         s = b'def'\n"", ""-        u = u'def'\n"", '         assert_(np_s.__radd__(np_s) is NotImplemented)\n', '         assert_(np_s.__radd__(np_u) is NotImplemented)\n', '         assert_(np_s.__radd__(s) is NotImplemented)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(np_u.__radd__(s) is NotImplemented)\n', '         assert_(np_u.__radd__(u) is NotImplemented)\n', ""         assert_(s + np_s == b'defabc')\n"", ""+        assert_(u + np_u == 'defabc')\n"", ' \n', '         class MyStr(str, np.generic):\n', '             # would segfault\n']","['         assert_(np_u.__radd__(s) is NotImplemented)\n', '         assert_(np_u.__radd__(u) is NotImplemented)\n', ""         assert_(s + np_s == b'defabc')\n"", ""-        assert_(u + np_u == u'defabc')\n"", ' \n', '         class MyStr(str, np.generic):\n', '             # would segfault\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         np_s = np.string_('abc')\n"", ""         np_u = np.unicode_('abc')\n"", ""         res_s = b'abc' * 5\n"", ""+        res_u = 'abc' * 5\n"", '         assert_(np_s * 5 == res_s)\n', '         assert_(np_u * 5 == res_u)\n']","[""         np_s = np.string_('abc')\n"", ""         np_u = np.unicode_('abc')\n"", ""         res_s = b'abc' * 5\n"", ""-        res_u = u'abc' * 5\n"", '         assert_(np_s * 5 == res_s)\n', '         assert_(np_u * 5 == res_u)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_iinfo_long_values(self):\n', ""         for code in 'bBhH':\n"", '+            with pytest.warns(DeprecationWarning):\n', '+                res = np.array(np.iinfo(code).max + 1, dtype=code)\n', '             tgt = np.iinfo(code).min\n', '             assert_(res == tgt)\n', ' \n']","[' \n', '     def test_iinfo_long_values(self):\n', ""         for code in 'bBhH':\n"", '-            res = np.array(np.iinfo(code).max + 1, dtype=code)\n', '             tgt = np.iinfo(code).min\n', '             assert_(res == tgt)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             sup.filter(RuntimeWarning)\n', '             for dt in types:\n', '                 a = np.ones((), dtype=dt)[()]\n', ""+                if dt in np.typecodes['UnsignedInteger']:\n"", '+                    st = np.dtype(dt).type\n', '+                    max = st(np.iinfo(dt).max)\n', '+                    assert_equal(operator.neg(a), max)\n', '+                else:\n', '+                    assert_equal(operator.neg(a) + a, 0)\n', ' \n', ' class TestSubtract:\n', '     def test_exceptions(self):\n']","['             sup.filter(RuntimeWarning)\n', '             for dt in types:\n', '                 a = np.ones((), dtype=dt)[()]\n', '-                assert_equal(operator.neg(a) + a, 0)\n', '-\n', ' \n', ' class TestSubtract:\n', '     def test_exceptions(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         nbits = dt.itemsize * 8\n', '         for val in [5, -5]:\n', '             for shift in [nbits, nbits + 4]:\n', '+                val_scl = np.array(val).astype(dt)[()]\n', '                 shift_scl = dt.type(shift)\n', '                 res_scl = op(val_scl, shift_scl)\n', '                 if val_scl < 0 and op is operator.rshift:\n']","['         nbits = dt.itemsize * 8\n', '         for val in [5, -5]:\n', '             for shift in [nbits, nbits + 4]:\n', '-                val_scl = dt.type(val)\n', '                 shift_scl = dt.type(shift)\n', '                 res_scl = op(val_scl, shift_scl)\n', '                 if val_scl < 0 and op is operator.rshift:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     assert_equal(res_scl, 0)\n', ' \n', '                 # Result on scalars should be the same as on arrays\n', '+                val_arr = np.array([val_scl]*32, dtype=dt)\n', '                 shift_arr = np.array([shift]*32, dtype=dt)\n', '                 res_arr = op(val_arr, shift_arr)\n', '                 assert_equal(res_arr, res_scl)\n']","['                     assert_equal(res_scl, 0)\n', ' \n', '                 # Result on scalars should be the same as on arrays\n', '-                val_arr = np.array([val]*32, dtype=dt)\n', '                 shift_arr = np.array([shift]*32, dtype=dt)\n', '                 res_arr = op(val_arr, shift_arr)\n', '                 assert_equal(res_arr, res_scl)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             assert hash(val) == hash(numpy_val)\n', ' \n', '         if hash(float(np.nan)) != hash(float(np.nan)):\n', '+            # If Python distinguishes different NaNs we do so too (gh-18833)\n', '             assert hash(scalar(np.nan)) != hash(scalar(np.nan))\n', ' \n', '     @pytest.mark.parametrize(""type_code"", np.typecodes[\'Complex\'])\n']","['             assert hash(val) == hash(numpy_val)\n', ' \n', '         if hash(float(np.nan)) != hash(float(np.nan)):\n', '-            # If Python distinguises different NaNs we do so too (gh-18833)\n', '             assert hash(scalar(np.nan)) != hash(scalar(np.nan))\n', ' \n', '     @pytest.mark.parametrize(""type_code"", np.typecodes[\'Complex\'])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""Integer""])\n', ' @pytest.mark.parametrize(""operation"", [\n', '+        lambda min, neg_1: -min,\n', '         lambda min, neg_1: abs(min),\n', '         lambda min, neg_1: min * neg_1,\n', '+        pytest.param(lambda min, neg_1: min // neg_1,\n', '+            marks=pytest.mark.skip(reason=""broken on some platforms""))],\n', '+        ids=[""neg"", ""abs"", ""*"", ""//""])\n', ' def test_scalar_signed_integer_overflow(dtype, operation):\n', '     # The minimum signed integer can ""overflow"" for some additional operations\n', '     st = np.dtype(dtype).type\n']","[' \n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""Integer""])\n', ' @pytest.mark.parametrize(""operation"", [\n', '         lambda min, neg_1: abs(min),\n', '         lambda min, neg_1: min * neg_1,\n', '-        lambda min, neg_1: min // neg_1], ids=[""abs"", ""*"", ""//""])\n', ' def test_scalar_signed_integer_overflow(dtype, operation):\n', '     # The minimum signed integer can ""overflow"" for some additional operations\n', '     st = np.dtype(dtype).type\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""UnsignedInteger""])\n', '+def test_scalar_unsigned_integer_overflow(dtype):\n', '     val = np.dtype(dtype).type(8)\n', '     with pytest.warns(RuntimeWarning, match=""overflow encountered""):\n', '         -val\n', ' \n', '+    zero = np.dtype(dtype).type(0)\n', '+    -zero  # does not warn\n', ' \n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', ' @pytest.mark.parametrize(""operation"", [\n']","[' \n', ' \n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""UnsignedInteger""])\n', '-@pytest.mark.xfail  # TODO: the check is quite simply missing!\n', '-def test_scalar_signed_integer_overflow(dtype):\n', '     val = np.dtype(dtype).type(8)\n', '     with pytest.warns(RuntimeWarning, match=""overflow encountered""):\n', '         -val\n', ' \n', ' \n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', ' @pytest.mark.parametrize(""operation"", [\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' @pytest.mark.parametrize([""__op__"", ""__rop__"", ""op"", ""cmp""], ops_with_names)\n', ' @pytest.mark.parametrize(""subtype"", [float, int, complex, np.float16])\n', '+@np._no_nep50_warning()\n', ' def test_pyscalar_subclasses(subtype, __op__, __rop__, op, cmp):\n', '     def op_func(self, other):\n', '         return __op__\n']","[' \n', ' @pytest.mark.parametrize([""__op__"", ""__rop__"", ""op"", ""cmp""], ops_with_names)\n', ' @pytest.mark.parametrize(""subtype"", [float, int, complex, np.float16])\n', ' def test_pyscalar_subclasses(subtype, __op__, __rop__, op, cmp):\n', '     def op_func(self, other):\n', '         return __op__\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with assert_warns(FutureWarning):\n', '             hstack(map(lambda x: x, np.ones((3, 2))))\n', ' \n', '+    def test_casting_and_dtype(self):\n', '+        a = np.array([1, 2, 3])\n', '+        b = np.array([2.5, 3.5, 4.5])\n', '+        res = np.hstack((a, b), casting=""unsafe"", dtype=np.int64)\n', '+        expected_res = np.array([1, 2, 3, 2, 3, 4])\n', '+        assert_array_equal(res, expected_res)\n', '+    \n', '+    def test_casting_and_dtype_type_error(self):\n', '+        a = np.array([1, 2, 3])\n', '+        b = np.array([2.5, 3.5, 4.5])\n', '+        with pytest.raises(TypeError):\n', '+            hstack((a, b), casting=""safe"", dtype=np.int64)\n', '+\n', ' \n', ' class TestVstack:\n', '     def test_non_iterable(self):\n']","['         with assert_warns(FutureWarning):\n', '             hstack(map(lambda x: x, np.ones((3, 2))))\n', ' \n', ' \n', ' class TestVstack:\n', '     def test_non_iterable(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with assert_warns(FutureWarning):\n', '             vstack((np.arange(3) for _ in range(2)))\n', ' \n', '+    def test_casting_and_dtype(self):\n', '+        a = np.array([1, 2, 3])\n', '+        b = np.array([2.5, 3.5, 4.5])\n', '+        res = np.vstack((a, b), casting=""unsafe"", dtype=np.int64)\n', '+        expected_res = np.array([[1, 2, 3], [2, 3, 4]])\n', '+        assert_array_equal(res, expected_res)\n', '+    \n', '+    def test_casting_and_dtype_type_error(self):\n', '+        a = np.array([1, 2, 3])\n', '+        b = np.array([2.5, 3.5, 4.5])\n', '+        with pytest.raises(TypeError):\n', '+            vstack((a, b), casting=""safe"", dtype=np.int64)\n', '+        \n', '+\n', ' \n', ' class TestConcatenate:\n', '     def test_returns_copy(self):\n']","['         with assert_warns(FutureWarning):\n', '             vstack((np.arange(3) for _ in range(2)))\n', ' \n', ' \n', ' class TestConcatenate:\n', '     def test_returns_copy(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             np.concatenate((a, b), axis=axis[0])  # OK\n', '             assert_raises_regex(\n', '                 ValueError,\n', '+                ""all the input array dimensions except for the concatenation axis ""\n', '                 ""must match exactly, but along dimension {}, the array at ""\n', '                 ""index 0 has size 1 and the array at index 1 has size 2""\n', '                 .format(i),\n']","['             np.concatenate((a, b), axis=axis[0])  # OK\n', '             assert_raises_regex(\n', '                 ValueError,\n', '-                ""all the input array dimensions for the concatenation axis ""\n', '                 ""must match exactly, but along dimension {}, the array at ""\n', '                 ""index 0 has size 1 and the array at index 1 has size 2""\n', '                 .format(i),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     with assert_warns(FutureWarning):\n', '         result = stack((x for x in range(3)))\n', '     assert_array_equal(result, np.array([0, 1, 2]))\n', '+    #casting and dtype test\n', '+    a = np.array([1, 2, 3])\n', '+    b = np.array([2.5, 3.5, 4.5])\n', '+    res = np.stack((a, b), axis=1, casting=""unsafe"", dtype=np.int64)\n', '+    expected_res = np.array([[1, 2], [2, 3], [3, 4]])\n', '+    assert_array_equal(res, expected_res)\n', '+    #casting and dtype with TypeError\n', '+    with assert_raises(TypeError):\n', '+        stack((a, b), dtype=np.int64, axis=1, casting=""safe"")\n', '+\n', '+\n', '+@pytest.mark.parametrize(""axis"", [0])\n', '+@pytest.mark.parametrize(""out_dtype"", [""c8"", ""f4"", ""f8"", "">f8"", ""i8""])\n', '+@pytest.mark.parametrize(""casting"",\n', ""+                         ['no', 'equiv', 'safe', 'same_kind', 'unsafe'])\n"", '+def test_stack_out_and_dtype(axis, out_dtype, casting):\n', '+    to_concat = (array([1, 2]), array([3, 4]))\n', '+    res = array([[1, 2], [3, 4]])\n', '+    out = np.zeros_like(res)\n', '+\n', '+    if not np.can_cast(to_concat[0], out_dtype, casting=casting):\n', '+        with assert_raises(TypeError):\n', '+            stack(to_concat, dtype=out_dtype,\n', '+                  axis=axis, casting=casting)\n', '+    else:\n', '+        res_out = stack(to_concat, out=out,\n', '+                        axis=axis, casting=casting)\n', '+        res_dtype = stack(to_concat, dtype=out_dtype,\n', '+                          axis=axis, casting=casting)\n', '+        assert res_out is out\n', '+        assert_array_equal(out, res_dtype)\n', '+        assert res_dtype.dtype == out_dtype\n', '+\n', '+    with assert_raises(TypeError):\n', '+        stack(to_concat, out=out, dtype=out_dtype, axis=axis)\n', ' \n', ' \n', ' class TestBlock:\n']","['     with assert_warns(FutureWarning):\n', '         result = stack((x for x in range(3)))\n', '     assert_array_equal(result, np.array([0, 1, 2]))\n', ' \n', ' \n', ' class TestBlock:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             return getattr(self.npyv, cvt_intrin.format(sfx[1:], sfx))(vector)\n', ' \n', '     def _pinfinity(self):\n', '+        return float(""inf"")\n', ' \n', '     def _ninfinity(self):\n', '+        return -float(""inf"")\n', ' \n', '     def _nan(self):\n', '+        return float(""nan"")\n', ' \n', '     def _cpu_features(self):\n', '         target = self.target_name\n']","['             return getattr(self.npyv, cvt_intrin.format(sfx[1:], sfx))(vector)\n', ' \n', '     def _pinfinity(self):\n', '-        v = self.npyv.setall_u32(0x7f800000)\n', '-        return self.npyv.reinterpret_f32_u32(v)[0]\n', ' \n', '     def _ninfinity(self):\n', '-        v = self.npyv.setall_u32(0xff800000)\n', '-        return self.npyv.reinterpret_f32_u32(v)[0]\n', ' \n', '     def _nan(self):\n', '-        v = self.npyv.setall_u32(0x7fc00000)\n', '-        return self.npyv.reinterpret_f32_u32(v)[0]\n', ' \n', '     def _cpu_features(self):\n', '         target = self.target_name\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     To test all boolean vector types at once\n', '     """"""\n', '+    def _nlanes(self):\n', '+        return getattr(self.npyv, ""nlanes_u"" + self.sfx[1:])\n', '+\n', '     def _data(self, start=None, count=None, reverse=False):\n', '         true_mask = self._true_mask()\n', '+        rng = range(self._nlanes())\n', '         if reverse:\n', '             rng = reversed(rng)\n', '         return [true_mask if x % 2 else 0 for x in rng]\n']","['     """"""\n', '     To test all boolean vector types at once\n', '     """"""\n', '     def _data(self, start=None, count=None, reverse=False):\n', '-        nlanes = getattr(self.npyv, ""nlanes_u"" + self.sfx[1:])\n', '         true_mask = self._true_mask()\n', '-        rng = range(nlanes)\n', '         if reverse:\n', '             rng = reversed(rng)\n', '         return [true_mask if x % 2 else 0 for x in rng]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         """"""\n', '         Logical operations for boolean types.\n', '         Test intrinsics:\n', '+            npyv_xor_##SFX, npyv_and_##SFX, npyv_or_##SFX, npyv_not_##SFX,\n', '+            npyv_andc_b8, npvy_orc_b8, nvpy_xnor_b8\n', '         """"""\n', '         data_a = self._data()\n', '         data_b = self._data(reverse=True)\n']","['         """"""\n', '         Logical operations for boolean types.\n', '         Test intrinsics:\n', '-            npyv_xor_##SFX, npyv_and_##SFX, npyv_or_##SFX, npyv_not_##SFX\n', '         """"""\n', '         data_a = self._data()\n', '         data_b = self._data(reverse=True)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         vnot = getattr(self, ""not"")(vdata_a)\n', '         assert vnot == data_b\n', ' \n', '+        # among the boolean types, andc, orc and xnor only support b8\n', '+        if self.sfx not in (""b8""):\n', '+            return\n', '+\n', '+        data_andc = [(a & ~b) & 0xFF for a, b in zip(data_a, data_b)]\n', '+        vandc = getattr(self, ""andc"")(vdata_a, vdata_b)\n', '+        assert data_andc == vandc\n', '+\n', '+        data_orc = [(a | ~b) & 0xFF for a, b in zip(data_a, data_b)]\n', '+        vorc = getattr(self, ""orc"")(vdata_a, vdata_b)\n', '+        assert data_orc == vorc\n', '+\n', '+        data_xnor = [~(a ^ b) & 0xFF for a, b in zip(data_a, data_b)]\n', '+        vxnor = getattr(self, ""xnor"")(vdata_a, vdata_b)\n', '+        assert data_xnor == vxnor\n', '+\n', '     def test_tobits(self):\n', '         data2bits = lambda data: sum([int(x != 0) << i for i, x in enumerate(data, 0)])\n', '         for data in (self._data(), self._data(reverse=True)):\n', '             vdata = self._load_b(data)\n', '             data_bits = data2bits(data)\n', '+            tobits = self.tobits(vdata)\n', '+            bin_tobits = bin(tobits)\n', '+            assert bin_tobits == bin(data_bits)\n', '+\n', '+    def test_pack(self):\n', '+        """"""\n', '+        Pack multiple vectors into one\n', '+        Test intrinsics:\n', '+            npyv_pack_b8_b16\n', '+            npyv_pack_b8_b32\n', '+            npyv_pack_b8_b64\n', '+        """"""\n', '+        if self.sfx not in (""b16"", ""b32"", ""b64""):\n', '+            return\n', '+        # create the vectors\n', '+        data = self._data()\n', '+        rdata = self._data(reverse=True)\n', '+        vdata = self._load_b(data)\n', '+        vrdata = self._load_b(rdata)\n', '+        pack_simd = getattr(self.npyv, f""pack_b8_{self.sfx}"")\n', '+        # for scalar execution, concatenate the elements of the multiple lists\n', '+        # into a single list (spack) and then iterate over the elements of\n', '+        # the created list applying a mask to capture the first byte of them.\n', '+        if self.sfx == ""b16"":\n', '+            spack = [(i & 0xFF) for i in (list(rdata) + list(data))]\n', '+            vpack = pack_simd(vrdata, vdata)\n', '+        elif self.sfx == ""b32"":\n', '+            spack = [(i & 0xFF) for i in (2*list(rdata) + 2*list(data))]\n', '+            vpack = pack_simd(vrdata, vrdata, vdata, vdata)\n', '+        elif self.sfx == ""b64"":\n', '+            spack = [(i & 0xFF) for i in (4*list(rdata) + 4*list(data))]\n', '+            vpack = pack_simd(vrdata, vrdata, vrdata, vrdata,\n', '+                               vdata,  vdata,  vdata,  vdata)\n', '+        assert vpack == spack\n', '+\n', '+    @pytest.mark.parametrize(""intrin"", [""any"", ""all""])\n', '+    @pytest.mark.parametrize(""data"", (\n', '+        [-1, 0],\n', '+        [0, -1],\n', '+        [-1],\n', '+        [0]\n', '+    ))\n', '+    def test_operators_crosstest(self, intrin, data):\n', '+        """"""\n', '+        Test intrinsics:\n', '+            npyv_any_##SFX\n', '+            npyv_all_##SFX\n', '+        """"""\n', '+        data_a = self._load_b(data * self._nlanes())\n', '+        func = eval(intrin)\n', '+        intrin = getattr(self, intrin)\n', '+        desired = func(data_a)\n', '+        simd = intrin(data_a)\n', '+        assert not not simd == desired\n', ' \n', ' class _SIMD_INT(_Test_Utility):\n', '     """"""\n']","['         vnot = getattr(self, ""not"")(vdata_a)\n', '         assert vnot == data_b\n', ' \n', '     def test_tobits(self):\n', '         data2bits = lambda data: sum([int(x != 0) << i for i, x in enumerate(data, 0)])\n', '         for data in (self._data(), self._data(reverse=True)):\n', '             vdata = self._load_b(data)\n', '             data_bits = data2bits(data)\n', '-            tobits = bin(self.tobits(vdata))\n', '-            assert tobits == bin(data_bits)\n', ' \n', ' class _SIMD_INT(_Test_Utility):\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         simd_min = self.min(vdata_a, vdata_b)\n', '         assert simd_min == data_min\n', ' \n', '+    @pytest.mark.parametrize(""start"", [-100, -10000, 0, 100, 10000])\n', '+    def test_reduce_max_min(self, start):\n', '+        """"""\n', '+        Test intrinsics:\n', '+            npyv_reduce_max_##sfx\n', '+            npyv_reduce_min_##sfx\n', '+        """"""\n', '+        vdata_a = self.load(self._data(start))\n', '+        assert self.reduce_max(vdata_a) == max(vdata_a)\n', '+        assert self.reduce_min(vdata_a) == min(vdata_a)\n', '+\n', '+\n', ' class _SIMD_FP32(_Test_Utility):\n', '     """"""\n', '     To only test single precision\n']","['         simd_min = self.min(vdata_a, vdata_b)\n', '         assert simd_min == data_min\n', ' \n', ' class _SIMD_FP32(_Test_Utility):\n', '     """"""\n', '     To only test single precision\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             data_round = self._to_unsigned(self.setall(-0.0))\n', '             assert _round == data_round\n', ' \n', '+    @pytest.mark.parametrize(""intrin"", [\n', '+        ""max"", ""maxp"", ""maxn"", ""min"", ""minp"", ""minn""\n', '+    ])\n', '+    def test_max_min(self, intrin):\n', '         """"""\n', '         Test intrinsics:\n', '+            npyv_max_##sfx\n', '+            npyv_maxp_##sfx\n', '+            npyv_maxn_##sfx\n', '+            npyv_min_##sfx\n', '+            npyv_minp_##sfx\n', '+            npyv_minn_##sfx\n', '+            npyv_reduce_max_##sfx\n', '+            npyv_reduce_maxp_##sfx\n', '+            npyv_reduce_maxn_##sfx\n', '+            npyv_reduce_min_##sfx\n', '+            npyv_reduce_minp_##sfx\n', '+            npyv_reduce_minn_##sfx\n', '         """"""\n', '         pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()\n', '+        chk_nan = {""xp"": 1, ""np"": 1, ""nn"": 2, ""xn"": 2}.get(intrin[-2:], 0)\n', '+        func = eval(intrin[:3])\n', '+        reduce_intrin = getattr(self, ""reduce_"" + intrin)\n', '+        intrin = getattr(self, intrin)\n', '+        hf_nlanes = self.nlanes//2\n', '+\n', '+        cases = (\n', '+            ([0.0, -0.0], [-0.0, 0.0]),\n', '+            ([10, -10],  [10, -10]),\n', '+            ([pinf, 10], [10, ninf]),\n', '+            ([10, pinf], [ninf, 10]),\n', '+            ([10, -10], [10, -10]),\n', '+            ([-10, 10], [-10, 10])\n', '+        )\n', '+        for op1, op2 in cases:\n', '+            vdata_a = self.load(op1*hf_nlanes)\n', '+            vdata_b = self.load(op2*hf_nlanes)\n', '+            data = func(vdata_a, vdata_b)\n', '+            simd = intrin(vdata_a, vdata_b)\n', '+            assert simd == data\n', '+            data = func(vdata_a)\n', '+            simd = reduce_intrin(vdata_a)\n', '+            assert simd == data\n', '+\n', '+        if not chk_nan:\n', '+            return\n', '+        if chk_nan == 1:\n', '+            test_nan = lambda a, b: (\n', '+                b if math.isnan(a) else a if math.isnan(b) else b\n', '+            )\n', '+        else:\n', '+            test_nan = lambda a, b: (\n', '+                nan if math.isnan(a) or math.isnan(b) else b\n', '+            )\n', '+        cases = (\n', '+            (nan, 10),\n', '+            (10, nan),\n', '+            (nan, pinf),\n', '+            (pinf, nan),\n', '+            (nan, nan)\n', '+        )\n', '+        for op1, op2 in cases:\n', '+            vdata_ab = self.load([op1, op2]*hf_nlanes)\n', '+            data = test_nan(op1, op2)\n', '+            simd = reduce_intrin(vdata_ab)\n', '+            assert simd == pytest.approx(data, nan_ok=True)\n', '+            vdata_a = self.setall(op1)\n', '+            vdata_b = self.setall(op2)\n', '+            data = [data] * self.nlanes\n', '+            simd = intrin(vdata_a, vdata_b)\n', '+            assert simd == pytest.approx(data, nan_ok=True)\n', ' \n', '     def test_reciprocal(self):\n', '         pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()\n']","['             data_round = self._to_unsigned(self.setall(-0.0))\n', '             assert _round == data_round\n', ' \n', '-    def test_max(self):\n', '         """"""\n', '         Test intrinsics:\n', '-            npyv_max_##SFX\n', '-            npyv_maxp_##SFX\n', '         """"""\n', '-        data_a = self._data()\n', '-        data_b = self._data(self.nlanes)\n', '-        vdata_a, vdata_b = self.load(data_a), self.load(data_b)\n', '-        data_max = [max(a, b) for a, b in zip(data_a, data_b)]\n', '-        _max = self.max(vdata_a, vdata_b)\n', '-        assert _max == data_max\n', '-        maxp = self.maxp(vdata_a, vdata_b)\n', '-        assert maxp == data_max\n', '-        # test IEEE standards\n', '         pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()\n', '-        max_cases = ((nan, nan, nan), (nan, 10, 10), (10, nan, 10),\n', '-                     (pinf, pinf, pinf), (pinf, 10, pinf), (10, pinf, pinf),\n', '-                     (ninf, ninf, ninf), (ninf, 10, 10), (10, ninf, 10),\n', '-                     (10, 0, 10), (10, -10, 10))\n', '-        for case_operand1, case_operand2, desired in max_cases:\n', '-            data_max = [desired]*self.nlanes\n', '-            vdata_a = self.setall(case_operand1)\n', '-            vdata_b = self.setall(case_operand2)\n', '-            maxp = self.maxp(vdata_a, vdata_b)\n', '-            assert maxp == pytest.approx(data_max, nan_ok=True)\n', '-            if nan in (case_operand1, case_operand2, desired):\n', '-                continue\n', '-            _max = self.max(vdata_a, vdata_b)\n', '-            assert _max == data_max\n', '-\n', '-    def test_min(self):\n', '-        """"""\n', '-        Test intrinsics:\n', '-            npyv_min_##SFX\n', '-            npyv_minp_##SFX\n', '-        """"""\n', '-        data_a = self._data()\n', '-        data_b = self._data(self.nlanes)\n', '-        vdata_a, vdata_b = self.load(data_a), self.load(data_b)\n', '-        data_min = [min(a, b) for a, b in zip(data_a, data_b)]\n', '-        _min = self.min(vdata_a, vdata_b)\n', '-        assert _min == data_min\n', '-        minp = self.minp(vdata_a, vdata_b)\n', '-        assert minp == data_min\n', '-        # test IEEE standards\n', '-        pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()\n', '-        min_cases = ((nan, nan, nan), (nan, 10, 10), (10, nan, 10),\n', '-                     (pinf, pinf, pinf), (pinf, 10, 10), (10, pinf, 10),\n', '-                     (ninf, ninf, ninf), (ninf, 10, ninf), (10, ninf, ninf),\n', '-                     (10, 0, 0), (10, -10, -10))\n', '-        for case_operand1, case_operand2, desired in min_cases:\n', '-            data_min = [desired]*self.nlanes\n', '-            vdata_a = self.setall(case_operand1)\n', '-            vdata_b = self.setall(case_operand2)\n', '-            minp = self.minp(vdata_a, vdata_b)\n', '-            assert minp == pytest.approx(data_min, nan_ok=True)\n', '-            if nan in (case_operand1, case_operand2, desired):\n', '-                continue\n', '-            _min = self.min(vdata_a, vdata_b)\n', '-            assert _min == data_min\n', ' \n', '     def test_reciprocal(self):\n', '         pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         nnan = self.notnan(self.setall(self._nan()))\n', '         assert nnan == [0]*self.nlanes\n', ' \n', '+    import operator\n', '+\n', ""+    @pytest.mark.parametrize('py_comp,np_comp', [\n"", '+        (operator.lt, ""cmplt""),\n', '+        (operator.le, ""cmple""),\n', '+        (operator.gt, ""cmpgt""),\n', '+        (operator.ge, ""cmpge""),\n', '+        (operator.eq, ""cmpeq""),\n', '+        (operator.ne, ""cmpneq"")\n', '+    ])\n', '+    def test_comparison_with_nan(self, py_comp, np_comp):\n', '+        pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()\n', '+        mask_true = self._true_mask()\n', '+\n', '+        def to_bool(vector):\n', '+            return [lane == mask_true for lane in vector]\n', '+\n', '+        intrin = getattr(self, np_comp)\n', '+        cmp_cases = ((0, nan), (nan, 0), (nan, nan), (pinf, nan), (ninf, nan))\n', '+        for case_operand1, case_operand2 in cmp_cases:\n', '+            data_a = [case_operand1]*self.nlanes\n', '+            data_b = [case_operand2]*self.nlanes\n', '+            vdata_a = self.setall(case_operand1)\n', '+            vdata_b = self.setall(case_operand2)\n', '+            vcmp = to_bool(intrin(vdata_a, vdata_b))\n', '+            data_cmp = [py_comp(a, b) for a, b in zip(data_a, data_b)]\n', '+            assert vcmp == data_cmp\n', '+\n', '+    @pytest.mark.parametrize(""intrin"", [""any"", ""all""])\n', '+    @pytest.mark.parametrize(""data"", (\n', '+        [float(""nan""), 0],\n', '+        [0, float(""nan"")],\n', '+        [float(""nan""), 1],\n', '+        [1, float(""nan"")],\n', '+        [float(""nan""), float(""nan"")],\n', '+        [0.0, -0.0],\n', '+        [-0.0, 0.0],\n', '+        [1.0, -0.0]\n', '+    ))\n', '+    def test_operators_crosstest(self, intrin, data):\n', '+        """"""\n', '+        Test intrinsics:\n', '+            npyv_any_##SFX\n', '+            npyv_all_##SFX\n', '+        """"""\n', '+        data_a = self.load(data * self.nlanes)\n', '+        func = eval(intrin)\n', '+        intrin = getattr(self, intrin)\n', '+        desired = func(data_a)\n', '+        simd = intrin(data_a)\n', '+        assert not not simd == desired\n', '+\n', ' class _SIMD_ALL(_Test_Utility):\n', '     """"""\n', '     To test all vector types at once\n']","['         nnan = self.notnan(self.setall(self._nan()))\n', '         assert nnan == [0]*self.nlanes\n', ' \n', ' class _SIMD_ALL(_Test_Utility):\n', '     """"""\n', '     To test all vector types at once\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         # We're testing the sanity of _simd's type-vector,\n"", '         # reinterpret* intrinsics itself are tested via compiler\n', '         # during the build of _simd module\n', '+        sfxes = [""u8"", ""s8"", ""u16"", ""s16"", ""u32"", ""s32"", ""u64"", ""s64""]\n', '         if self.npyv.simd_f64:\n', '             sfxes.append(""f64"")\n', '+        if self.npyv.simd_f32:\n', '+            sfxes.append(""f32"")\n', '         for sfx in sfxes:\n', '             vec_name = getattr(self, ""reinterpret_"" + sfx)(vdata_a).__name__\n', '             assert vec_name == ""npyv_"" + sfx\n']","[""         # We're testing the sanity of _simd's type-vector,\n"", '         # reinterpret* intrinsics itself are tested via compiler\n', '         # during the build of _simd module\n', '-        sfxes = [""u8"", ""s8"", ""u16"", ""s16"", ""u32"", ""s32"", ""u64"", ""s64"", ""f32""]\n', '         if self.npyv.simd_f64:\n', '             sfxes.append(""f64"")\n', '         for sfx in sfxes:\n', '             vec_name = getattr(self, ""reinterpret_"" + sfx)(vdata_a).__name__\n', '             assert vec_name == ""npyv_"" + sfx\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         select_b = self.select(self.cmpneq(self.zero(), self.zero()), vdata_a, vdata_b)\n', '         assert select_b == data_b\n', ' \n', '+        # test extract elements\n', '+        assert self.extract0(vdata_b) == vdata_b[0]\n', '+\n', '         # cleanup intrinsic is only used with AVX for\n', '         # zeroing registers to avoid the AVX-SSE transition penalty,\n', '         # so nothing to test here\n']","['         select_b = self.select(self.cmpneq(self.zero(), self.zero()), vdata_a, vdata_b)\n', '         assert select_b == data_b\n', ' \n', '         # cleanup intrinsic is only used with AVX for\n', '         # zeroing registers to avoid the AVX-SSE transition penalty,\n', '         # so nothing to test here\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         vnot = cast(getattr(self, ""not"")(vdata_a))\n', '         assert vnot == data_not\n', ' \n', '+        if self.sfx not in (""u8""):\n', '+            return\n', '+        data_andc = [a & ~b for a, b in zip(data_cast_a, data_cast_b)]\n', '+        vandc = cast(getattr(self, ""andc"")(vdata_a, vdata_b))\n', '+        assert vandc == data_andc\n', '+\n', '+    @pytest.mark.parametrize(""intrin"", [""any"", ""all""])\n', '+    @pytest.mark.parametrize(""data"", (\n', '+        [1, 2, 3, 4],\n', '+        [-1, -2, -3, -4],\n', '+        [0, 1, 2, 3, 4],\n', '+        [0x7f, 0x7fff, 0x7fffffff, 0x7fffffffffffffff],\n', '+        [0, -1, -2, -3, 4],\n', '+        [0],\n', '+        [1],\n', '+        [-1]\n', '+    ))\n', '+    def test_operators_crosstest(self, intrin, data):\n', '+        """"""\n', '+        Test intrinsics:\n', '+            npyv_any_##SFX\n', '+            npyv_all_##SFX\n', '+        """"""\n', '+        data_a = self.load(data * self.nlanes)\n', '+        func = eval(intrin)\n', '+        intrin = getattr(self, intrin)\n', '+        desired = func(data_a)\n', '+        simd = intrin(data_a)\n', '+        assert not not simd == desired\n', '+\n', '     def test_conversion_boolean(self):\n', '         bsfx = ""b"" + self.sfx[1:]\n', '         to_boolean = getattr(self.npyv, ""cvt_%s_%s"" % (bsfx, self.sfx))\n']","['         vnot = cast(getattr(self, ""not"")(vdata_a))\n', '         assert vnot == data_not\n', ' \n', '     def test_conversion_boolean(self):\n', '         bsfx = ""b"" + self.sfx[1:]\n', '         to_boolean = getattr(self.npyv, ""cvt_%s_%s"" % (bsfx, self.sfx))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         skip = f""target \'{pretty_name}\' isn\'t supported by current machine""\n', '     elif not npyv.simd:\n', '         skip = f""target \'{pretty_name}\' isn\'t supported by NPYV""\n', '+    else:\n', '+        if not npyv.simd_f32:\n', '+            skip_sfx[""f32""] = f""target \'{pretty_name}\' ""\\\n', '+                               ""doesn\'t support single-precision""\n', '+        if not npyv.simd_f64:\n', '+            skip_sfx[""f64""] = f""target \'{pretty_name}\' doesn\'t""\\\n', '+                               ""support double-precision""\n', ' \n', '     for sfxes, cls in tests_registry.items():\n', '         for sfx in sfxes:\n']","['         skip = f""target \'{pretty_name}\' isn\'t supported by current machine""\n', '     elif not npyv.simd:\n', '         skip = f""target \'{pretty_name}\' isn\'t supported by NPYV""\n', '-    elif not npyv.simd_f64:\n', '-        skip_sfx[""f64""] = f""target \'{pretty_name}\' doesn\'t support double-precision""\n', ' \n', '     for sfxes, cls in tests_registry.items():\n', '         for sfx in sfxes:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' unsigned_sfx = [""u8"", ""u16"", ""u32"", ""u64""]\n', ' signed_sfx = [""s8"", ""s16"", ""s32"", ""s64""]\n', '+fp_sfx = []\n', '+if npyv and npyv.simd_f32:\n', '+    fp_sfx.append(""f32"")\n', ' if npyv and npyv.simd_f64:\n', '     fp_sfx.append(""f64"")\n', ' \n']","[' \n', ' unsigned_sfx = [""u8"", ""u16"", ""u32"", ""u64""]\n', ' signed_sfx = [""s8"", ""s16"", ""s32"", ""s64""]\n', '-fp_sfx = [""f32""]\n', ' if npyv and npyv.simd_f64:\n', '     fp_sfx.append(""f64"")\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import pytest\n', '+\n', '+import operator\n', '+import numpy as np\n', '+\n', '+from numpy.testing import assert_array_equal\n', '+\n', '+\n', '+COMPARISONS = [\n', '+    (operator.eq, np.equal, ""==""),\n', '+    (operator.ne, np.not_equal, ""!=""),\n', '+    (operator.lt, np.less, ""<""),\n', '+    (operator.le, np.less_equal, ""<=""),\n', '+    (operator.gt, np.greater, "">""),\n', '+    (operator.ge, np.greater_equal, "">=""),\n', '+]\n', '+\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+def test_mixed_string_comparison_ufuncs_fail(op, ufunc, sym):\n', '+    arr_string = np.array([""a"", ""b""], dtype=""S"")\n', '+    arr_unicode = np.array([""a"", ""c""], dtype=""U"")\n', '+\n', '+    with pytest.raises(TypeError, match=""did not contain a loop""):\n', '+        ufunc(arr_string, arr_unicode)\n', '+\n', '+    with pytest.raises(TypeError, match=""did not contain a loop""):\n', '+        ufunc(arr_unicode, arr_string)\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+def test_mixed_string_comparisons_ufuncs_with_cast(op, ufunc, sym):\n', '+    arr_string = np.array([""a"", ""b""], dtype=""S"")\n', '+    arr_unicode = np.array([""a"", ""c""], dtype=""U"")\n', '+\n', '+    # While there is no loop, manual casting is acceptable:\n', '+    res1 = ufunc(arr_string, arr_unicode, signature=""UU->?"", casting=""unsafe"")\n', '+    res2 = ufunc(arr_string, arr_unicode, signature=""SS->?"", casting=""unsafe"")\n', '+\n', ""+    expected = op(arr_string.astype('U'), arr_unicode)\n"", '+    assert_array_equal(res1, expected)\n', '+    assert_array_equal(res2, expected)\n', '+\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+@pytest.mark.parametrize(""dtypes"", [\n', '+        (""S2"", ""S2""), (""S2"", ""S10""),\n', '+        (""<U1"", ""<U1""), (""<U1"", "">U1""), ("">U1"", "">U1""),\n', '+        (""<U1"", ""<U10""), (""<U1"", "">U10"")])\n', '+@pytest.mark.parametrize(""aligned"", [True, False])\n', '+def test_string_comparisons(op, ufunc, sym, dtypes, aligned):\n', '+    # ensure native byte-order for the first view to stay within unicode range\n', '+    native_dt = np.dtype(dtypes[0]).newbyteorder(""="")\n', '+    arr = np.arange(2**15).view(native_dt).astype(dtypes[0])\n', '+    if not aligned:\n', '+        # Make `arr` unaligned:\n', '+        new = np.zeros(arr.nbytes + 1, dtype=np.uint8)[1:].view(dtypes[0])\n', '+        new[...] = arr\n', '+        arr = new\n', '+\n', '+    arr2 = arr.astype(dtypes[1], copy=True)\n', '+    np.random.shuffle(arr2)\n', '+    arr[0] = arr2[0]  # make sure one matches\n', '+\n', '+    expected = [op(d1, d2) for d1, d2 in zip(arr.tolist(), arr2.tolist())]\n', '+    assert_array_equal(op(arr, arr2), expected)\n', '+    assert_array_equal(ufunc(arr, arr2), expected)\n', '+    assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n', '+\n', '+    expected = [op(d2, d1) for d1, d2 in zip(arr.tolist(), arr2.tolist())]\n', '+    assert_array_equal(op(arr2, arr), expected)\n', '+    assert_array_equal(ufunc(arr2, arr), expected)\n', '+    assert_array_equal(np.compare_chararrays(arr2, arr, sym, False), expected)\n', '+\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+@pytest.mark.parametrize(""dtypes"", [\n', '+        (""S2"", ""S2""), (""S2"", ""S10""), (""<U1"", ""<U1""), (""<U1"", "">U10"")])\n', '+def test_string_comparisons_empty(op, ufunc, sym, dtypes):\n', '+    arr = np.empty((1, 0, 1, 5), dtype=dtypes[0])\n', '+    arr2 = np.empty((100, 1, 0, 1), dtype=dtypes[1])\n', '+\n', '+    expected = np.empty(np.broadcast_shapes(arr.shape, arr2.shape), dtype=bool)\n', '+    assert_array_equal(op(arr, arr2), expected)\n', '+    assert_array_equal(ufunc(arr, arr2), expected)\n', '+    assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import warnings\n', ' import itertools\n', ' import sys\n', '+import ctypes as ct\n', ' \n', ' import pytest\n', '+from pytest import param\n', ' \n', ' import numpy as np\n', ' import numpy.core._umath_tests as umt\n']","[' import warnings\n', ' import itertools\n', ' import sys\n', ' \n', ' import pytest\n', ' \n', ' import numpy as np\n', ' import numpy.core._umath_tests as umt\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_array_equal,\n', '     assert_almost_equal, assert_array_almost_equal, assert_no_warnings,\n', '+    assert_allclose, HAS_REFCOUNT, suppress_warnings, IS_WASM\n', '     )\n', ' from numpy.testing._private.utils import requires_memory\n', ' from numpy.compat import pickle\n']","[' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_array_equal,\n', '     assert_almost_equal, assert_array_almost_equal, assert_no_warnings,\n', '-    assert_allclose, HAS_REFCOUNT, suppress_warnings\n', '     )\n', ' from numpy.testing._private.utils import requires_memory\n', ' from numpy.compat import pickle\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_signature3(self):\n', '         enabled, num_dims, ixs, flags, sizes = umt.test_signature(\n', '+            2, 1, ""(i1, i12),   (J_1)->(i12, i2)"")\n', '         assert_equal(enabled, 1)\n', '         assert_equal(num_dims, (2, 1, 2))\n', '         assert_equal(ixs, (0, 1, 2, 1, 3))\n']","[' \n', '     def test_signature3(self):\n', '         enabled, num_dims, ixs, flags, sizes = umt.test_signature(\n', '-            2, 1, u""(i1, i12),   (J_1)->(i12, i2)"")\n', '         assert_equal(enabled, 1)\n', '         assert_equal(num_dims, (2, 1, 2))\n', '         assert_equal(ixs, (0, 1, 2, 1, 3))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         float_dtype = type(np.dtype(np.float64))\n', '         np.add(3, 4, signature=(float_dtype, float_dtype, None))\n', ' \n', '+    @pytest.mark.parametrize(""get_kwarg"", [\n', '+            lambda dt: dict(dtype=x),\n', '+            lambda dt: dict(signature=(x, None, None))])\n', '+    def test_signature_dtype_instances_allowed(self, get_kwarg):\n', '+        # We allow certain dtype instances when there is a clear singleton\n', '+        # and the given one is equivalent; mainly for backcompat.\n', '+        int64 = np.dtype(""int64"")\n', '+        int64_2 = pickle.loads(pickle.dumps(int64))\n', '+        # Relies on pickling behavior, if assert fails just remove test...\n', '+        assert int64 is not int64_2\n', '+\n', '+        assert np.add(1, 2, **get_kwarg(int64_2)).dtype == int64\n', '+        td = np.timedelta(2, ""s"")\n', '+        assert np.add(td, td, **get_kwarg(""m8"")).dtype == ""m8[s]""\n', '+\n', '+    @pytest.mark.parametrize(""get_kwarg"", [\n', '+            param(lambda x: dict(dtype=x), id=""dtype""),\n', '+            param(lambda x: dict(signature=(x, None, None)), id=""signature"")])\n', '+    def test_signature_dtype_instances_allowed(self, get_kwarg):\n', '+        msg = ""The `dtype` and `signature` arguments to ufuncs""\n', '+\n', '+        with pytest.raises(TypeError, match=msg):\n', '+            np.add(3, 5, **get_kwarg(np.dtype(""int64"").newbyteorder()))\n', '+        with pytest.raises(TypeError, match=msg):\n', '+            np.add(3, 5, **get_kwarg(np.dtype(""m8[ns]"")))\n', '+        with pytest.raises(TypeError, match=msg):\n', '+            np.add(3, 5, **get_kwarg(""m8[ns]""))\n', '+\n', '     @pytest.mark.parametrize(""casting"", [""unsafe"", ""same_kind"", ""safe""])\n', '     def test_partial_signature_mismatch(self, casting):\n', '         # If the second argument matches already, no need to specify it:\n']","['         float_dtype = type(np.dtype(np.float64))\n', '         np.add(3, 4, signature=(float_dtype, float_dtype, None))\n', ' \n', '     @pytest.mark.parametrize(""casting"", [""unsafe"", ""same_kind"", ""safe""])\n', '     def test_partial_signature_mismatch(self, casting):\n', '         # If the second argument matches already, no need to specify it:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with pytest.raises(TypeError):\n', '             np.ldexp(1., np.uint64(3), signature=(None, None, ""d""))\n', ' \n', '+    def test_partial_signature_mismatch_with_cache(self):\n', '+        with pytest.raises(TypeError):\n', '+            np.add(np.float16(1), np.uint64(2), sig=(""e"", ""d"", None))\n', '+        # Ensure e,d->None is in the dispatching cache (double loop)\n', '+        np.add(np.float16(1), np.float64(2))\n', '+        # The error must still be raised:\n', '+        with pytest.raises(TypeError):\n', '+            np.add(np.float16(1), np.uint64(2), sig=(""e"", ""d"", None))\n', '+\n', '     def test_use_output_signature_for_all_arguments(self):\n', '         # Test that providing only `dtype=` or `signature=(None, None, dtype)`\n', '         # is sufficient if falling back to a homogeneous signature works.\n']","['         with pytest.raises(TypeError):\n', '             np.ldexp(1., np.uint64(3), signature=(None, None, ""d""))\n', ' \n', '     def test_use_output_signature_for_all_arguments(self):\n', '         # Test that providing only `dtype=` or `signature=(None, None, dtype)`\n', '         # is sufficient if falling back to a homogeneous signature works.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                                 atol = max(np.finfo(dtout).tiny, 3e-308)\n', '                             else:\n', '                                 atol = 3e-308\n', '+                        # Some test values result in invalid for float16\n', '+                        # and the cast to it may overflow to inf.\n', ""+                        with np.errstate(invalid='ignore', over='ignore'):\n"", '                             res = np.true_divide(x, y, dtype=dtout)\n', ""                         if not np.isfinite(res) and tcout == 'e':\n"", '                             continue\n']","['                                 atol = max(np.finfo(dtout).tiny, 3e-308)\n', '                             else:\n', '                                 atol = 3e-308\n', '-                        # Some test values result in invalid for float16.\n', ""-                        with np.errstate(invalid='ignore'):\n"", '                             res = np.true_divide(x, y, dtype=dtout)\n', ""                         if not np.isfinite(res) and tcout == 'e':\n"", '                             continue\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a = np.ones(500, dtype=np.float64)\n', '         assert_almost_equal((a / 10.).sum() - a.size / 10., 0, 13)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_sum(self):\n', '         for dt in (int, np.float16, np.float32, np.float64, np.longdouble):\n', '             for v in (0, 1, 2, 7, 8, 9, 15, 16, 19, 127,\n', '                       128, 1024, 1235):\n', '                 # warning if sum overflows, which it does in float16\n', '                 with warnings.catch_warnings(record=True) as w:\n', '+                    warnings.simplefilter(""always"", RuntimeWarning)\n', '+\n', '+                    tgt = dt(v * (v + 1) / 2)\n', '+                    overflow = not np.isfinite(tgt)\n', '                     assert_equal(len(w), 1 * overflow)\n', ' \n', '+                    d = np.arange(1, v + 1, dtype=dt)\n', '+\n', '+                    assert_almost_equal(np.sum(d), tgt)\n', '                     assert_equal(len(w), 2 * overflow)\n', ' \n', '+                    assert_almost_equal(np.sum(d[::-1]), tgt)\n', '+                    assert_equal(len(w), 3 * overflow)\n', '+\n', '             d = np.ones(500, dtype=dt)\n', '             assert_almost_equal(np.sum(d[::2]), 250.)\n', '             assert_almost_equal(np.sum(d[1::2]), 250.)\n']","['         a = np.ones(500, dtype=np.float64)\n', '         assert_almost_equal((a / 10.).sum() - a.size / 10., 0, 13)\n', ' \n', '     def test_sum(self):\n', '         for dt in (int, np.float16, np.float32, np.float64, np.longdouble):\n', '             for v in (0, 1, 2, 7, 8, 9, 15, 16, 19, 127,\n', '                       128, 1024, 1235):\n', '-                tgt = dt(v * (v + 1) / 2)\n', '-                d = np.arange(1, v + 1, dtype=dt)\n', '-\n', '                 # warning if sum overflows, which it does in float16\n', '-                overflow = not np.isfinite(tgt)\n', '-\n', '                 with warnings.catch_warnings(record=True) as w:\n', '-                    warnings.simplefilter(""always"")\n', '-                    assert_almost_equal(np.sum(d), tgt)\n', '                     assert_equal(len(w), 1 * overflow)\n', ' \n', '-                    assert_almost_equal(np.sum(d[::-1]), tgt)\n', '                     assert_equal(len(w), 2 * overflow)\n', ' \n', '             d = np.ones(500, dtype=dt)\n', '             assert_almost_equal(np.sum(d[::2]), 250.)\n', '             assert_almost_equal(np.sum(d[1::2]), 250.)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # the result would be just a scalar `5`, but is broadcast fully:\n', '         assert (out == 5).all()\n', ' \n', '+    @pytest.mark.parametrize([""arr"", ""out""], [\n', '+                ([2], np.empty(())),\n', '+                ([1, 2], np.empty(1)),\n', '+                (np.ones((4, 3)), np.empty((4, 1)))],\n', '+            ids=[""(1,)->()"", ""(2,)->(1,)"", ""(4, 3)->(4, 1)""])\n', '+    def test_out_broadcast_errors(self, arr, out):\n', '+        # Output is (currently) allowed to broadcast inputs, but it cannot be\n', '+        # smaller than the actual result.\n', '+        with pytest.raises(ValueError, match=""non-broadcastable""):\n', '+            np.positive(arr, out=out)\n', '+\n', '+        with pytest.raises(ValueError, match=""non-broadcastable""):\n', '+            np.add(np.ones(()), arr, out=out)\n', '+\n', '     def test_type_cast(self):\n', '         msg = ""type cast""\n', ""         a = np.arange(6, dtype='short').reshape((2, 3))\n""]","['         # the result would be just a scalar `5`, but is broadcast fully:\n', '         assert (out == 5).all()\n', ' \n', '     def test_type_cast(self):\n', '         msg = ""type cast""\n', ""         a = np.arange(6, dtype='short').reshape((2, 3))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" @pytest.mark.parametrize('ufunc', [getattr(np, x) for x in dir(np)\n"", '                                 if isinstance(getattr(np, x), np.ufunc)])\n', '+@np._no_nep50_warning()\n', ' def test_ufunc_noncontiguous(ufunc):\n', ""     '''\n"", '     Check that contiguous and non-contiguous calls to ufuncs\n']","[' \n', "" @pytest.mark.parametrize('ufunc', [getattr(np, x) for x in dir(np)\n"", '                                 if isinstance(getattr(np, x), np.ufunc)])\n', ' def test_ufunc_noncontiguous(ufunc):\n', ""     '''\n"", '     Check that contiguous and non-contiguous calls to ufuncs\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', '+def test_ufunc_out_casterrors():\n', '     # Tests that casting errors are correctly reported and buffers are\n', '     # cleared.\n', '     # The following array can be added to itself as an object array, but\n']","[' \n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', '-def test_ufunc_casterrors():\n', '     # Tests that casting errors are correctly reported and buffers are\n', '     # cleared.\n', '     # The following array can be added to itself as an object array, but\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert out[-1] == 1\n', ' \n', ' \n', '+@pytest.mark.parametrize(""bad_offset"", [0, int(np.BUFSIZE * 1.5)])\n', '+def test_ufunc_input_casterrors(bad_offset):\n', '+    value = 123\n', '+    arr = np.array([value] * bad_offset +\n', '+                   [""string""] +\n', '+                   [value] * int(1.5 * np.BUFSIZE), dtype=object)\n', '+    with pytest.raises(ValueError):\n', '+        # Force cast inputs, but the buffered cast of `arr` to intp fails:\n', '+        np.add(arr, arr, dtype=np.intp, casting=""unsafe"")\n', '+\n', '+\n', '+@pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '+@pytest.mark.parametrize(""bad_offset"", [0, int(np.BUFSIZE * 1.5)])\n', '+def test_ufunc_input_floatingpoint_error(bad_offset):\n', '+    value = 123\n', '+    arr = np.array([value] * bad_offset +\n', '+                   [np.nan] +\n', '+                   [value] * int(1.5 * np.BUFSIZE))\n', '+    with np.errstate(invalid=""raise""), pytest.raises(FloatingPointError):\n', '+        # Force cast inputs, but the buffered cast of `arr` to intp fails:\n', '+        np.add(arr, arr, dtype=np.intp, casting=""unsafe"")\n', '+\n', '+\n', ' def test_trivial_loop_invalid_cast():\n', '     # This tests the fast-path ""invalid cast"", see gh-19904.\n', '     with pytest.raises(TypeError,\n']","['     assert out[-1] == 1\n', ' \n', ' \n', ' def test_trivial_loop_invalid_cast():\n', '     # This tests the fast-path ""invalid cast"", see gh-19904.\n', '     with pytest.raises(TypeError,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert out[()] < value * offset\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', ' @pytest.mark.parametrize(""method"",\n', '         [np.add.accumulate, np.add.reduce,\n', '          pytest.param(lambda x: np.add.reduceat(x, [0]), id=""reduceat""),\n']","['     assert out[()] < value * offset\n', ' \n', ' \n', ' @pytest.mark.parametrize(""method"",\n', '         [np.add.accumulate, np.add.reduce,\n', '          pytest.param(lambda x: np.add.reduceat(x, [0]), id=""reduceat""),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # `sum([])` should probably be 0.0 and not -0.0 like `sum([-0.0])`\n', '             assert not np.signbit(res.real)\n', '             assert not np.signbit(res.imag)\n', '+\n', '+class TestLowlevelAPIAccess:\n', '+    def test_resolve_dtypes_basic(self):\n', '+        # Basic test for dtype resolution:\n', '+        i4 = np.dtype(""i4"")\n', '+        f4 = np.dtype(""f4"")\n', '+        f8 = np.dtype(""f8"")\n', '+\n', '+        r = np.add.resolve_dtypes((i4, f4, None))\n', '+        assert r == (f8, f8, f8)\n', '+\n', '+        # Signature uses the same logic to parse as ufunc (less strict)\n', '+        # the following is ""same-kind"" casting so works:\n', '+        r = np.add.resolve_dtypes((\n', '+                i4, i4, None), signature=(None, None, ""f4""))\n', '+        assert r == (f4, f4, f4)\n', '+\n', '+        # Check NEP 50 ""weak"" promotion also:\n', '+        r = np.add.resolve_dtypes((f4, int, None))\n', '+        assert r == (f4, f4, f4)\n', '+\n', '+        with pytest.raises(TypeError):\n', '+            np.add.resolve_dtypes((i4, f4, None), casting=""no"")\n', '+\n', '+    def test_weird_dtypes(self):\n', '+        S0 = np.dtype(""S0"")\n', '+        # S0 is often converted by NumPy to S1, but not here:\n', '+        r = np.equal.resolve_dtypes((S0, S0, None))\n', '+        assert r == (S0, S0, np.dtype(bool))\n', '+\n', '+        # Subarray dtypes are weird and only really exist nested, they need\n', '+        # the shift to full NEP 50 to be implemented nicely:\n', '+        dts = np.dtype(""10i"")\n', '+        with pytest.raises(NotImplementedError):\n', '+            np.equal.resolve_dtypes((dts, dts, None))\n', '+\n', '+    def test_resolve_dtypes_reduction(self):\n', '+        i4 = np.dtype(""i4"")\n', '+        with pytest.raises(NotImplementedError):\n', '+            np.add.resolve_dtypes((i4, i4, i4), reduction=True)\n', '+\n', '+    @pytest.mark.parametrize(""dtypes"", [\n', '+            (np.dtype(""i""), np.dtype(""i"")),\n', '+            (None, np.dtype(""i""), np.dtype(""f"")),\n', '+            (np.dtype(""i""), None, np.dtype(""f"")),\n', '+            (""i4"", ""i4"", None)])\n', '+    def test_resolve_dtypes_errors(self, dtypes):\n', '+        with pytest.raises(TypeError):\n', '+            np.add.resolve_dtypes(dtypes)\n', '+\n', '+    def test_resolve_dtypes_reduction(self):\n', '+        i2 = np.dtype(""i2"")\n', '+        long_ = np.dtype(""long"")\n', '+        # Check special addition resolution:\n', '+        res = np.add.resolve_dtypes((None, i2, None), reduction=True)\n', '+        assert res == (long_, long_, long_)\n', '+\n', '+    def test_resolve_dtypes_reduction_errors(self):\n', '+        i2 = np.dtype(""i2"")\n', '+\n', '+        with pytest.raises(TypeError):\n', '+            np.add.resolve_dtypes((None, i2, i2))\n', '+\n', '+        with pytest.raises(TypeError):\n', '+            np.add.signature((None, None, ""i4""))\n', '+\n', '+    @pytest.mark.skipif(not hasattr(ct, ""pythonapi""),\n', '+            reason=""`ctypes.pythonapi` required for capsule unpacking."")\n', '+    def test_loop_access(self):\n', '+        # This is a basic test for the full strided loop access\n', '+        data_t = ct.ARRAY(ct.c_char_p, 2)\n', '+        dim_t = ct.ARRAY(ct.c_ssize_t, 1)\n', '+        strides_t = ct.ARRAY(ct.c_ssize_t, 2)\n', '+        strided_loop_t = ct.CFUNCTYPE(\n', '+                ct.c_int, ct.c_void_p, data_t, dim_t, strides_t, ct.c_void_p)\n', '+\n', '+        class call_info_t(ct.Structure):\n', '+            _fields_ = [\n', '+                (""strided_loop"", strided_loop_t),\n', '+                (""context"", ct.c_void_p),\n', '+                (""auxdata"", ct.c_void_p),\n', '+                (""requires_pyapi"", ct.c_byte),\n', '+                (""no_floatingpoint_errors"", ct.c_byte),\n', '+            ]\n', '+\n', '+        i4 = np.dtype(""i4"")\n', '+        dt, call_info_obj = np.negative._resolve_dtypes_and_context((i4, i4))\n', '+        assert dt == (i4, i4)  # can be used without casting\n', '+\n', '+        # Fill in the rest of the information:\n', '+        np.negative._get_strided_loop(call_info_obj)\n', '+\n', '+        ct.pythonapi.PyCapsule_GetPointer.restype = ct.c_void_p\n', '+        call_info = ct.pythonapi.PyCapsule_GetPointer(\n', '+                ct.py_object(call_info_obj),\n', '+                ct.c_char_p(b""numpy_1.24_ufunc_call_info""))\n', '+\n', '+        call_info = ct.cast(call_info, ct.POINTER(call_info_t)).contents\n', '+\n', '+        arr = np.arange(10, dtype=i4)\n', '+        call_info.strided_loop(\n', '+                call_info.context,\n', '+                data_t(arr.ctypes.data, arr.ctypes.data),\n', '+                arr.ctypes.shape,  # is a C-array with 10 here\n', '+                strides_t(arr.ctypes.strides[0], arr.ctypes.strides[0]),\n', '+                call_info.auxdata)\n', '+\n', '+        # We just directly called the negative inner-loop in-place:\n', '+        assert_array_equal(arr, -np.arange(10, dtype=i4))\n', '+\n', '+    @pytest.mark.parametrize(""strides"", [1, (1, 2, 3), (1, ""2"")])\n', '+    def test__get_strided_loop_errors_bad_strides(self, strides):\n', '+        i4 = np.dtype(""i4"")\n', '+        dt, call_info = np.negative._resolve_dtypes_and_context((i4, i4))\n', '+\n', '+        with pytest.raises(TypeError, match=""fixed_strides.*tuple.*or None""):\n', '+            np.negative._get_strided_loop(call_info, fixed_strides=strides)\n', '+\n', '+    def test__get_strided_loop_errors_bad_call_info(self):\n', '+        i4 = np.dtype(""i4"")\n', '+        dt, call_info = np.negative._resolve_dtypes_and_context((i4, i4))\n', '+\n', '+        with pytest.raises(ValueError, match=""PyCapsule""):\n', '+            np.negative._get_strided_loop(""not the capsule!"")\n', '+\n', '+        with pytest.raises(TypeError, match="".*incompatible context""):\n', '+            np.add._get_strided_loop(call_info)\n', '+\n', '+        np.negative._get_strided_loop(call_info)\n', '+        with pytest.raises(TypeError):\n', '+            # cannot call it a second time:\n', '+            np.negative._get_strided_loop(call_info)\n']","['             # `sum([])` should probably be 0.0 and not -0.0 like `sum([-0.0])`\n', '             assert not np.signbit(res.real)\n', '             assert not np.signbit(res.imag)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import pytest\n', ' import sys\n', ' import os\n', '+import operator\n', ' from fractions import Fraction\n', ' from functools import reduce\n', '+from collections import namedtuple\n', ' \n', ' import numpy.core.umath as ncu\n', ' from numpy.core import _umath_tests as ncu_tests\n']","[' import pytest\n', ' import sys\n', ' import os\n', ' from fractions import Fraction\n', ' from functools import reduce\n', ' \n', ' import numpy.core.umath as ncu\n', ' from numpy.core import _umath_tests as ncu_tests\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_, assert_equal, assert_raises, assert_raises_regex,\n', '     assert_array_equal, assert_almost_equal, assert_array_almost_equal,\n', '     assert_array_max_ulp, assert_allclose, assert_no_warnings, suppress_warnings,\n', '+    _gen_alignment_data, assert_array_almost_equal_nulp, IS_WASM\n', '     )\n', ' from numpy.testing._private.utils import _glibc_older_than\n', ' \n', ' \n', '+def interesting_binop_operands(val1, val2, dtype):\n', '+    """"""\n', '+    Helper to create ""interesting"" operands to cover common code paths:\n', '+    * scalar inputs\n', '+    * only first ""values"" is an array (e.g. scalar division fast-paths)\n', '+    * Longer array (SIMD) placing the value of interest at different positions\n', '+    * Oddly strided arrays which may not be SIMD compatible\n', '+\n', '+    It does not attempt to cover unaligned access or mixed dtypes.\n', '+    These are normally handled by the casting/buffering machinery.\n', '+\n', '+    This is not a fixture (currently), since I believe a fixture normally\n', '+    only yields once?\n', '+    """"""\n', '+    fill_value = 1  # could be a parameter, but maybe not an optional one?\n', '+\n', '+    arr1 = np.full(10003, dtype=dtype, fill_value=fill_value)\n', '+    arr2 = np.full(10003, dtype=dtype, fill_value=fill_value)\n', '+\n', '+    arr1[0] = val1\n', '+    arr2[0] = val2\n', '+\n', '+    extractor = lambda res: res\n', '+    yield arr1[0], arr2[0], extractor, ""scalars""\n', '+\n', '+    extractor = lambda res: res\n', '+    yield arr1[0, ...], arr2[0, ...], extractor, ""scalar-arrays""\n', '+\n', '+    # reset array values to fill_value:\n', '+    arr1[0] = fill_value\n', '+    arr2[0] = fill_value\n', '+\n', '+    for pos in [0, 1, 2, 3, 4, 5, -1, -2, -3, -4]:\n', '+        arr1[pos] = val1\n', '+        arr2[pos] = val2\n', '+\n', '+        extractor = lambda res: res[pos]\n', '+        yield arr1, arr2, extractor, f""off-{pos}""\n', '+        yield arr1, arr2[pos], extractor, f""off-{pos}-with-scalar""\n', '+\n', '+        arr1[pos] = fill_value\n', '+        arr2[pos] = fill_value\n', '+\n', '+    for stride in [-1, 113]:\n', '+        op1 = arr1[::stride]\n', '+        op2 = arr2[::stride]\n', '+        op1[10] = val1\n', '+        op2[10] = val2\n', '+\n', '+        extractor = lambda res: res[10]\n', '+        yield op1, op2, extractor, f""stride-{stride}""\n', '+\n', '+        op1[10] = fill_value\n', '+        op2[10] = fill_value\n', '+\n', '+\n', ' def on_powerpc():\n', '     """""" True if we are running on a Power PC platform.""""""\n', ""     return platform.processor() == 'powerpc' or \\\n""]","['     assert_, assert_equal, assert_raises, assert_raises_regex,\n', '     assert_array_equal, assert_almost_equal, assert_array_almost_equal,\n', '     assert_array_max_ulp, assert_allclose, assert_no_warnings, suppress_warnings,\n', '-    _gen_alignment_data, assert_array_almost_equal_nulp\n', '     )\n', ' from numpy.testing._private.utils import _glibc_older_than\n', ' \n', ' \n', ' def on_powerpc():\n', '     """""" True if we are running on a Power PC platform.""""""\n', ""     return platform.processor() == 'powerpc' or \\\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def bad_arcsinh():\n', '+    """"""The blocklisted trig functions are not accurate on aarch64/PPC for\n', '     complex256. Rather than dig through the actual problem skip the\n', '     test. This should be fixed when we can move past glibc2.17\n', '     which is the version in manylinux2014\n', '     """"""\n', ""+    if platform.machine() == 'aarch64':\n"", '+        x = 1.78e-10\n', '+    elif on_powerpc():\n', '+        x = 2.16e-10\n', '+    else:\n', '+        return False\n', '     v1 = np.arcsinh(np.float128(x))\n', '     v2 = np.arcsinh(np.complex256(x)).real\n', '     # The eps for float128 is 1-e33, so this is way bigger\n']","[' \n', ' \n', ' def bad_arcsinh():\n', '-    """"""The blocklisted trig functions are not accurate on aarch64 for\n', '     complex256. Rather than dig through the actual problem skip the\n', '     test. This should be fixed when we can move past glibc2.17\n', '     which is the version in manylinux2014\n', '     """"""\n', '-    x = 1.78e-10\n', '     v1 = np.arcsinh(np.float128(x))\n', '     v2 = np.arcsinh(np.complex256(x)).real\n', '     # The eps for float128 is 1-e33, so this is way bigger\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class _FilterInvalids:\n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', ' \n']","[' \n', ' \n', ' class _FilterInvalids:\n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestComparisons:\n', '+    import operator\n', '+\n', ""+    @pytest.mark.parametrize('dtype', np.sctypes['uint'] + np.sctypes['int'] +\n"", ""+                             np.sctypes['float'] + [np.bool_])\n"", ""+    @pytest.mark.parametrize('py_comp,np_comp', [\n"", '+        (operator.lt, np.less),\n', '+        (operator.le, np.less_equal),\n', '+        (operator.gt, np.greater),\n', '+        (operator.ge, np.greater_equal),\n', '+        (operator.eq, np.equal),\n', '+        (operator.ne, np.not_equal)\n', '+    ])\n', '+    def test_comparison_functions(self, dtype, py_comp, np_comp):\n', '+        # Initialize input arrays\n', '+        if dtype == np.bool_:\n', '+            a = np.random.choice(a=[False, True], size=1000)\n', '+            b = np.random.choice(a=[False, True], size=1000)\n', '+            scalar = True\n', '+        else:\n', '+            a = np.random.randint(low=1, high=10, size=1000).astype(dtype)\n', '+            b = np.random.randint(low=1, high=10, size=1000).astype(dtype)\n', '+            scalar = 5\n', '+        np_scalar = np.dtype(dtype).type(scalar)\n', '+        a_lst = a.tolist()\n', '+        b_lst = b.tolist()\n', '+\n', '+        # (Binary) Comparison (x1=array, x2=array)\n', '+        comp_b = np_comp(a, b)\n', '+        comp_b_list = [py_comp(x, y) for x, y in zip(a_lst, b_lst)]\n', '+\n', '+        # (Scalar1) Comparison (x1=scalar, x2=array)\n', '+        comp_s1 = np_comp(np_scalar, b)\n', '+        comp_s1_list = [py_comp(scalar, x) for x in b_lst]\n', '+\n', '+        # (Scalar2) Comparison (x1=array, x2=scalar)\n', '+        comp_s2 = np_comp(a, np_scalar)\n', '+        comp_s2_list = [py_comp(x, scalar) for x in a_lst]\n', '+\n', '+        # Sequence: Binary, Scalar1 and Scalar2\n', '+        assert_(comp_b.tolist() == comp_b_list,\n', '+            f""Failed comparison ({py_comp.__name__})"")\n', '+        assert_(comp_s1.tolist() == comp_s1_list,\n', '+            f""Failed comparison ({py_comp.__name__})"")\n', '+        assert_(comp_s2.tolist() == comp_s2_list,\n', '+            f""Failed comparison ({py_comp.__name__})"")\n', '+\n', '     def test_ignore_object_identity_in_equal(self):\n', '         # Check comparing identical objects whose comparison\n', '         # is not a simple boolean, e.g., arrays that are compared elementwise.\n']","[' \n', ' \n', ' class TestComparisons:\n', '     def test_ignore_object_identity_in_equal(self):\n', '         # Check comparing identical objects whose comparison\n', '         # is not a simple boolean, e.g., arrays that are compared elementwise.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a = np.array([np.nan], dtype=object)\n', '         assert_equal(np.not_equal(a, a), [True])\n', ' \n', '+    def test_error_in_equal_reduce(self):\n', '+        # gh-20929\n', '+        # make sure np.equal.reduce raises a TypeError if an array is passed\n', '+        # without specifying the dtype\n', '+        a = np.array([0, 0])\n', '+        assert_equal(np.equal.reduce(a, dtype=bool), True)\n', '+        assert_raises(TypeError, np.equal.reduce, a)\n', '+\n', '+    def test_object_dtype(self):\n', '+        assert np.equal(1, [1], dtype=object).dtype == object\n', '+        assert np.equal(1, [1], signature=(None, None, ""O"")).dtype == object\n', '+\n', '+    def test_object_nonbool_dtype_error(self):\n', '+        # bool output dtype is fine of course:\n', '+        assert np.equal(1, [1], dtype=bool).dtype == bool\n', '+\n', '+        # but the following are examples do not have a loop:\n', '+        with pytest.raises(TypeError, match=""No loop matching""):\n', '+            np.equal(1, 1, dtype=np.int64)\n', '+\n', '+        with pytest.raises(TypeError, match=""No loop matching""):\n', '+            np.equal(1, 1, sig=(None, None, ""l""))\n', '+\n', ' \n', ' class TestAdd:\n', '     def test_reduce_alignment(self):\n']","['         a = np.array([np.nan], dtype=object)\n', '         assert_equal(np.not_equal(a, a), [True])\n', ' \n', ' \n', ' class TestAdd:\n', '     def test_reduce_alignment(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(x // 100, [0, 0, 0, 1, -1, -1, -1, -1, -2])\n', '         assert_equal(x % 100, [5, 10, 90, 0, 95, 90, 10, 0, 80])\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.parametrize(""dtype,ex_val"", itertools.product(\n', ""         np.sctypes['int'] + np.sctypes['uint'], (\n"", '             (\n', '                 # dividend\n', '+                ""np.array(range(fo.max-lsize, fo.max)).astype(dtype),""\n', '                 # divisors\n', '+                ""np.arange(lsize).astype(dtype),""\n', '                 # scalar divisors\n', '                 ""range(15)""\n', '             ),\n', '             (\n', '                 # dividend\n', '+                ""np.arange(fo.min, fo.min+lsize).astype(dtype),""\n', '                 # divisors\n', '+                ""np.arange(lsize//-2, lsize//2).astype(dtype),""\n', '                 # scalar divisors\n', '                 ""range(fo.min, fo.min + 15)""\n', '             ), (\n', '                 # dividend\n', '+                ""np.array(range(fo.max-lsize, fo.max)).astype(dtype),""\n', '                 # divisors\n', '+                ""np.arange(lsize).astype(dtype),""\n', '                 # scalar divisors\n', '                 ""[1,3,9,13,neg, fo.min+1, fo.min//2, fo.max//3, fo.max//4]""\n', '             )\n']","['         assert_equal(x // 100, [0, 0, 0, 1, -1, -1, -1, -1, -2])\n', '         assert_equal(x % 100, [5, 10, 90, 0, 95, 90, 10, 0, 80])\n', ' \n', '     @pytest.mark.parametrize(""dtype,ex_val"", itertools.product(\n', ""         np.sctypes['int'] + np.sctypes['uint'], (\n"", '             (\n', '                 # dividend\n', '-                ""np.arange(fo.max-lsize, fo.max, dtype=dtype),""\n', '                 # divisors\n', '-                ""np.arange(lsize, dtype=dtype),""\n', '                 # scalar divisors\n', '                 ""range(15)""\n', '             ),\n', '             (\n', '                 # dividend\n', '-                ""np.arange(fo.min, fo.min+lsize, dtype=dtype),""\n', '                 # divisors\n', '-                ""np.arange(lsize//-2, lsize//2, dtype=dtype),""\n', '                 # scalar divisors\n', '                 ""range(fo.min, fo.min + 15)""\n', '             ), (\n', '                 # dividend\n', '-                ""np.arange(fo.max-lsize, fo.max, dtype=dtype),""\n', '                 # divisors\n', '-                ""np.arange(lsize, dtype=dtype),""\n', '                 # scalar divisors\n', '                 ""[1,3,9,13,neg, fo.min+1, fo.min//2, fo.max//3, fo.max//4]""\n', '             )\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a_lst, b_lst = a.tolist(), b.tolist()\n', ' \n', '         c_div = lambda n, d: (\n', '+            0 if d == 0 else (\n', '+                fo.min if (n and n == fo.min and d == -1) else n//d\n', '+            )\n', '         )\n', ""         with np.errstate(divide='ignore'):\n"", '             ac = a.copy()\n']","['         a_lst, b_lst = a.tolist(), b.tolist()\n', ' \n', '         c_div = lambda n, d: (\n', '-            0 if d == 0 or (n and n == fo.min and d == -1) else n//d\n', '         )\n', ""         with np.errstate(divide='ignore'):\n"", '             ac = a.copy()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         for divisor in divisors:\n', '             ac = a.copy()\n', ""+            with np.errstate(divide='ignore', over='ignore'):\n"", '                 div_a = a // divisor\n', '                 ac //= divisor\n', '             div_lst = [c_div(i, divisor) for i in a_lst]\n']","[' \n', '         for divisor in divisors:\n', '             ac = a.copy()\n', ""-            with np.errstate(divide='ignore'):\n"", '                 div_a = a // divisor\n', '                 ac //= divisor\n', '             div_lst = [c_div(i, divisor) for i in a_lst]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             assert all(div_a == div_lst), msg\n', '             assert all(ac == div_lst), msg_eq\n', ' \n', ""+        with np.errstate(divide='raise', over='raise'):\n"", '+            if 0 in b:\n', '                 # Verify overflow case\n', '+                with pytest.raises(FloatingPointError,\n', '+                        match=""divide by zero encountered in floor_divide""):\n', '                     a // b\n', '             else:\n', '                 a // b\n', '             if fo.min and fo.min in a:\n', '+                with pytest.raises(FloatingPointError,\n', ""+                        match='overflow encountered in floor_divide'):\n"", '                     a // -1\n', '             elif fo.min:\n', '                 a // -1\n', '+            with pytest.raises(FloatingPointError,\n', '+                    match=""divide by zero encountered in floor_divide""):\n', '                 a // 0\n', '+            with pytest.raises(FloatingPointError,\n', '+                    match=""divide by zero encountered in floor_divide""):\n', '                 ac = a.copy()\n', '                 ac //= 0\n', ' \n', '             np.array([], dtype=dtype) // 0\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.parametrize(""dtype,ex_val"", itertools.product(\n', ""         np.sctypes['int'] + np.sctypes['uint'], (\n"", '             ""np.array([fo.max, 1, 2, 1, 1, 2, 3], dtype=dtype)"",\n', '+            ""np.array([fo.min, 1, -2, 1, 1, 2, -3]).astype(dtype)"",\n', '             ""np.arange(fo.min, fo.min+(100*10), 10, dtype=dtype)"",\n', '+            ""np.array(range(fo.max-(100*7), fo.max, 7)).astype(dtype)"",\n', '         )\n', '     ))\n', '     def test_division_int_reduce(self, dtype, ex_val):\n']","['             assert all(div_a == div_lst), msg\n', '             assert all(ac == div_lst), msg_eq\n', ' \n', ""-        with np.errstate(divide='raise'):\n"", '-            if 0 in b or (fo.min and -1 in b and fo.min in a):\n', '                 # Verify overflow case\n', '-                with pytest.raises(FloatingPointError):\n', '                     a // b\n', '             else:\n', '                 a // b\n', '             if fo.min and fo.min in a:\n', '-                with pytest.raises(FloatingPointError):\n', '                     a // -1\n', '             elif fo.min:\n', '                 a // -1\n', '-            with pytest.raises(FloatingPointError):\n', '                 a // 0\n', '-            with pytest.raises(FloatingPointError):\n', '                 ac = a.copy()\n', '                 ac //= 0\n', ' \n', '             np.array([], dtype=dtype) // 0\n', ' \n', '     @pytest.mark.parametrize(""dtype,ex_val"", itertools.product(\n', ""         np.sctypes['int'] + np.sctypes['uint'], (\n"", '             ""np.array([fo.max, 1, 2, 1, 1, 2, 3], dtype=dtype)"",\n', '-            ""np.array([fo.min, 1, -2, 1, 1, 2, -3], dtype=dtype)"",\n', '             ""np.arange(fo.min, fo.min+(100*10), 10, dtype=dtype)"",\n', '-            ""np.arange(fo.max-(100*7), fo.max, 7, dtype=dtype)"",\n', '         )\n', '     ))\n', '     def test_division_int_reduce(self, dtype, ex_val):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         msg = ""Reduce floor integer division check""\n', '         assert div_a == div_lst, msg\n', ' \n', ""+        with np.errstate(divide='raise', over='raise'):\n"", '+            with pytest.raises(FloatingPointError,\n', '+                    match=""divide by zero encountered in reduce""):\n', '+                np.floor_divide.reduce(np.arange(-100, 100).astype(dtype))\n', '             if fo.min:\n', '+                with pytest.raises(FloatingPointError,\n', ""+                        match='overflow encountered in reduce'):\n"", '                     np.floor_divide.reduce(\n', '                         np.array([fo.min, 1, -1], dtype=dtype)\n', '                     )\n']","['         msg = ""Reduce floor integer division check""\n', '         assert div_a == div_lst, msg\n', ' \n', ""-        with np.errstate(divide='raise'):\n"", '-            with pytest.raises(FloatingPointError):\n', '-                np.floor_divide.reduce(np.arange(-100, 100, dtype=dtype))\n', '             if fo.min:\n', '-                with pytest.raises(FloatingPointError):\n', '                     np.floor_divide.reduce(\n', '                         np.array([fo.min, 1, -1], dtype=dtype)\n', '                     )\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             quotient_array = np.array([quotient]*5)\n', '             assert all(dividend_array // divisor == quotient_array), msg\n', '         else:\n', '+            if IS_WASM:\n', '+                pytest.skip(""fp errors don\'t work in wasm"")\n', ""             with np.errstate(divide='raise', invalid='raise'):\n"", '                 with pytest.raises(FloatingPointError):\n', '                     dividend // divisor\n']","['             quotient_array = np.array([quotient]*5)\n', '             assert all(dividend_array // divisor == quotient_array), msg\n', '         else:\n', ""             with np.errstate(divide='raise', invalid='raise'):\n"", '                 with pytest.raises(FloatingPointError):\n', '                     dividend // divisor\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(np.signbit(x//1), 0)\n', '         assert_equal(np.signbit((-x)//1), 1)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', ""     @pytest.mark.parametrize('dtype', np.typecodes['Float'])\n"", '     def test_floor_division_errors(self, dtype):\n', '         fnan = np.array(np.nan, dtype=dtype)\n']","['         assert_equal(np.signbit(x//1), 0)\n', '         assert_equal(np.signbit((-x)//1), 1)\n', ' \n', ""     @pytest.mark.parametrize('dtype', np.typecodes['Float'])\n"", '     def test_floor_division_errors(self, dtype):\n', '         fnan = np.array(np.nan, dtype=dtype)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     else:\n', '                         assert_(b > rem >= 0, msg)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.xfail(sys.platform.startswith(""darwin""),\n', '             reason=""MacOS seems to not give the correct \'invalid\' warning for ""\n', '                    ""`fmod`.  Hopefully, others always do."")\n']","['                     else:\n', '                         assert_(b > rem >= 0, msg)\n', ' \n', '     @pytest.mark.xfail(sys.platform.startswith(""darwin""),\n', '             reason=""MacOS seems to not give the correct \'invalid\' warning for ""\n', '                    ""`fmod`.  Hopefully, others always do."")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # inf / 0 does not set any flags, only the modulo creates a NaN\n', '             np.divmod(finf, fzero)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.xfail(sys.platform.startswith(""darwin""),\n', '            reason=""MacOS seems to not give the correct \'invalid\' warning for ""\n', '                   ""`fmod`.  Hopefully, others always do."")\n']","['             # inf / 0 does not set any flags, only the modulo creates a NaN\n', '             np.divmod(finf, fzero)\n', ' \n', '     @pytest.mark.xfail(sys.platform.startswith(""darwin""),\n', '            reason=""MacOS seems to not give the correct \'invalid\' warning for ""\n', '                   ""`fmod`.  Hopefully, others always do."")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             fn(fone, fnan)\n', '             fn(fnan, fone)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_float_remainder_overflow(self):\n', '         a = np.finfo(np.float64).tiny\n', ""         with np.errstate(over='ignore', invalid='ignore'):\n""]","['             fn(fone, fnan)\n', '             fn(fnan, fone)\n', ' \n', '     def test_float_remainder_overflow(self):\n', '         a = np.finfo(np.float64).tiny\n', ""         with np.errstate(over='ignore', invalid='ignore'):\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                 assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, rem))\n"", ' \n', ' \n', '+class TestDivisionIntegerOverflowsAndDivideByZero:\n', ""+    result_type = namedtuple('result_type',\n"", ""+            ['nocast', 'casted'])\n"", '+    helper_lambdas = {\n', ""+        'zero': lambda dtype: 0,\n"", ""+        'min': lambda dtype: np.iinfo(dtype).min,\n"", ""+        'neg_min': lambda dtype: -np.iinfo(dtype).min,\n"", ""+        'min-zero': lambda dtype: (np.iinfo(dtype).min, 0),\n"", ""+        'neg_min-zero': lambda dtype: (-np.iinfo(dtype).min, 0),\n"", '+    }\n', '+    overflow_results = {\n', '+        np.remainder: result_type(\n', ""+            helper_lambdas['zero'], helper_lambdas['zero']),\n"", '+        np.fmod: result_type(\n', ""+            helper_lambdas['zero'], helper_lambdas['zero']),\n"", '+        operator.mod: result_type(\n', ""+            helper_lambdas['zero'], helper_lambdas['zero']),\n"", '+        operator.floordiv: result_type(\n', ""+            helper_lambdas['min'], helper_lambdas['neg_min']),\n"", '+        np.floor_divide: result_type(\n', ""+            helper_lambdas['min'], helper_lambdas['neg_min']),\n"", '+        np.divmod: result_type(\n', ""+            helper_lambdas['min-zero'], helper_lambdas['neg_min-zero'])\n"", '+    }\n', '+\n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""Integer""])\n', '+    def test_signed_division_overflow(self, dtype):\n', '+        to_check = interesting_binop_operands(np.iinfo(dtype).min, -1, dtype)\n', '+        for op1, op2, extractor, operand_identifier in to_check:\n', '+            with pytest.warns(RuntimeWarning, match=""overflow encountered""):\n', '+                res = op1 // op2\n', '+\n', '+            assert res.dtype == op1.dtype\n', '+            assert extractor(res) == np.iinfo(op1.dtype).min\n', '+\n', '+            # Remainder is well defined though, and does not warn:\n', '+            res = op1 % op2\n', '+            assert res.dtype == op1.dtype\n', '+            assert extractor(res) == 0\n', '+            # Check fmod as well:\n', '+            res = np.fmod(op1, op2)\n', '+            assert extractor(res) == 0\n', '+\n', '+            # Divmod warns for the division part:\n', '+            with pytest.warns(RuntimeWarning, match=""overflow encountered""):\n', '+                res1, res2 = np.divmod(op1, op2)\n', '+\n', '+            assert res1.dtype == res2.dtype == op1.dtype\n', '+            assert extractor(res1) == np.iinfo(op1.dtype).min\n', '+            assert extractor(res2) == 0\n', '+\n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_divide_by_zero(self, dtype):\n', '+        # Note that the return value cannot be well defined here, but NumPy\n', '+        # currently uses 0 consistently.  This could be changed.\n', '+        to_check = interesting_binop_operands(1, 0, dtype)\n', '+        for op1, op2, extractor, operand_identifier in to_check:\n', '+            with pytest.warns(RuntimeWarning, match=""divide by zero""):\n', '+                res = op1 // op2\n', '+\n', '+            assert res.dtype == op1.dtype\n', '+            assert extractor(res) == 0\n', '+\n', '+            with pytest.warns(RuntimeWarning, match=""divide by zero""):\n', '+                res1, res2 = np.divmod(op1, op2)\n', '+\n', '+            assert res1.dtype == res2.dtype == op1.dtype\n', '+            assert extractor(res1) == 0\n', '+            assert extractor(res2) == 0\n', '+\n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '+    @pytest.mark.parametrize(""dividend_dtype"",\n', ""+            np.sctypes['int'])\n"", '+    @pytest.mark.parametrize(""divisor_dtype"",\n', ""+            np.sctypes['int'])\n"", '+    @pytest.mark.parametrize(""operation"",\n', '+            [np.remainder, np.fmod, np.divmod, np.floor_divide,\n', '+             operator.mod, operator.floordiv])\n', ""+    @np.errstate(divide='warn', over='warn')\n"", '+    def test_overflows(self, dividend_dtype, divisor_dtype, operation):\n', '+        # SIMD tries to perform the operation on as many elements as possible\n', ""+        # that is a multiple of the register's size. We resort to the\n"", '+        # default implementation for the leftover elements.\n', '+        # We try to cover all paths here.\n', '+        arrays = [np.array([np.iinfo(dividend_dtype).min]*i,\n', '+                           dtype=dividend_dtype) for i in range(1, 129)]\n', '+        divisor = np.array([-1], dtype=divisor_dtype)\n', '+        # If dividend is a larger type than the divisor (`else` case),\n', '+        # then, result will be a larger type than dividend and will not\n', '+        # result in an overflow for `divmod` and `floor_divide`.\n', '+        if np.dtype(dividend_dtype).itemsize >= np.dtype(\n', '+                divisor_dtype).itemsize and operation in (\n', '+                        np.divmod, np.floor_divide, operator.floordiv):\n', '+            with pytest.warns(\n', '+                    RuntimeWarning,\n', '+                    match=""overflow encountered in""):\n', '+                result = operation(\n', '+                            dividend_dtype(np.iinfo(dividend_dtype).min),\n', '+                            divisor_dtype(-1)\n', '+                        )\n', '+                assert result == self.overflow_results[operation].nocast(\n', '+                        dividend_dtype)\n', '+\n', '+            # Arrays\n', '+            for a in arrays:\n', '+                # In case of divmod, we need to flatten the result\n', '+                # column first as we get a column vector of quotient and\n', '+                # remainder and a normal flatten of the expected result.\n', '+                with pytest.warns(\n', '+                        RuntimeWarning,\n', '+                        match=""overflow encountered in""):\n', ""+                    result = np.array(operation(a, divisor)).flatten('f')\n"", '+                    expected_array = np.array(\n', '+                            [self.overflow_results[operation].nocast(\n', '+                                dividend_dtype)]*len(a)).flatten()\n', '+                    assert_array_equal(result, expected_array)\n', '+        else:\n', '+            # Scalars\n', '+            result = operation(\n', '+                        dividend_dtype(np.iinfo(dividend_dtype).min),\n', '+                        divisor_dtype(-1)\n', '+                    )\n', '+            assert result == self.overflow_results[operation].casted(\n', '+                    dividend_dtype)\n', '+\n', '+            # Arrays\n', '+            for a in arrays:\n', '+                # See above comment on flatten\n', ""+                result = np.array(operation(a, divisor)).flatten('f')\n"", '+                expected_array = np.array(\n', '+                        [self.overflow_results[operation].casted(\n', '+                            dividend_dtype)]*len(a)).flatten()\n', '+                assert_array_equal(result, expected_array)\n', '+\n', '+\n', ' class TestCbrt:\n', '     def test_cbrt_scalar(self):\n', '         assert_almost_equal((np.cbrt(np.float32(-2.5)**3)), -2.5)\n']","[""                 assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, rem))\n"", ' \n', ' \n', ' class TestCbrt:\n', '     def test_cbrt_scalar(self):\n', '         assert_almost_equal((np.cbrt(np.float32(-2.5)**3)), -2.5)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             assert_raises(ValueError, np.power, one, b)\n', '             assert_raises(ValueError, np.power, one, minusone)\n', ' \n', '+    def test_float_to_inf_power(self):\n', '+        for dt in [np.float32, np.float64]:\n', '+            a = np.array([1, 1, 2, 2, -2, -2, np.inf, -np.inf], dt)\n', '+            b = np.array([np.inf, -np.inf, np.inf, -np.inf,\n', '+                                np.inf, -np.inf, np.inf, -np.inf], dt)\n', '+            r = np.array([1, 1, np.inf, 0, np.inf, 0, np.inf, 0], dt)\n', '+            assert_equal(np.power(a, b), r)\n', '+\n', ' \n', ' class TestFloat_power:\n', '     def test_type_conversion(self):\n']","['             assert_raises(ValueError, np.power, one, b)\n', '             assert_raises(ValueError, np.power, one, minusone)\n', ' \n', ' \n', ' class TestFloat_power:\n', '     def test_type_conversion(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         v = np.log2(2.**i)\n', ""         assert_equal(v, float(i), err_msg='at exponent %d' % i)\n"", ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_log2_special(self):\n', '         assert_equal(np.log2(1.), 0.)\n', '         assert_equal(np.log2(np.inf), np.inf)\n']","['         v = np.log2(2.**i)\n', ""         assert_equal(v, float(i), err_msg='at exponent %d' % i)\n"", ' \n', '     def test_log2_special(self):\n', '         assert_equal(np.log2(1.), 0.)\n', '         assert_equal(np.log2(np.inf), np.inf)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         with np.errstate(under='raise', over='raise'):\n"", '             x = [np.nan,  np.nan, np.inf, 0.]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf]\n', ""+            for dt in ['e', 'f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.exp(yf), xf)\n']","[""         with np.errstate(under='raise', over='raise'):\n"", '             x = [np.nan,  np.nan, np.inf, 0.]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf]\n', ""-            for dt in ['f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.exp(yf), xf)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     )\n', '     def test_exp_exceptions(self):\n', ""         with np.errstate(over='raise'):\n"", '+            assert_raises(FloatingPointError, np.exp, np.float16(11.0899))\n', '             assert_raises(FloatingPointError, np.exp, np.float32(100.))\n', '             assert_raises(FloatingPointError, np.exp, np.float32(1E19))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(800.))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(1E19))\n', ' \n', ""         with np.errstate(under='raise'):\n"", '+            assert_raises(FloatingPointError, np.exp, np.float16(-17.5))\n', '             assert_raises(FloatingPointError, np.exp, np.float32(-1000.))\n', '             assert_raises(FloatingPointError, np.exp, np.float32(-1E19))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(-1000.))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(-1E19))\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_log_values(self):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan, np.nan, np.inf, np.nan, -np.inf, np.nan]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf, 0.0, -1.0]\n', '             y1p = [np.nan, -np.nan, np.inf, -np.inf, -1.0, -2.0]\n', ""+            for dt in ['e', 'f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 yf1p = np.array(y1p, dtype=dt)\n']","['     )\n', '     def test_exp_exceptions(self):\n', ""         with np.errstate(over='raise'):\n"", '             assert_raises(FloatingPointError, np.exp, np.float32(100.))\n', '             assert_raises(FloatingPointError, np.exp, np.float32(1E19))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(800.))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(1E19))\n', ' \n', ""         with np.errstate(under='raise'):\n"", '             assert_raises(FloatingPointError, np.exp, np.float32(-1000.))\n', '             assert_raises(FloatingPointError, np.exp, np.float32(-1E19))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(-1000.))\n', '             assert_raises(FloatingPointError, np.exp, np.float64(-1E19))\n', ' \n', '     def test_log_values(self):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan, np.nan, np.inf, np.nan, -np.inf, np.nan]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf, 0.0, -1.0]\n', '             y1p = [np.nan, -np.nan, np.inf, -np.inf, -1.0, -2.0]\n', ""-            for dt in ['f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 yf1p = np.array(y1p, dtype=dt)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 assert_equal(np.log1p(yf1p), xf)\n', ' \n', ""         with np.errstate(divide='raise'):\n"", ""+            for dt in ['e', 'f', 'd']:\n"", '                 assert_raises(FloatingPointError, np.log,\n', '                               np.array(0.0, dtype=dt))\n', '                 assert_raises(FloatingPointError, np.log2,\n']","['                 assert_equal(np.log1p(yf1p), xf)\n', ' \n', ""         with np.errstate(divide='raise'):\n"", ""-            for dt in ['f', 'd']:\n"", '                 assert_raises(FloatingPointError, np.log,\n', '                               np.array(0.0, dtype=dt))\n', '                 assert_raises(FloatingPointError, np.log2,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                               np.array(-1.0, dtype=dt))\n', ' \n', ""         with np.errstate(invalid='raise'):\n"", ""+            for dt in ['e', 'f', 'd']:\n"", '                 assert_raises(FloatingPointError, np.log,\n', '                               np.array(-np.inf, dtype=dt))\n', '                 assert_raises(FloatingPointError, np.log,\n']","['                               np.array(-1.0, dtype=dt))\n', ' \n', ""         with np.errstate(invalid='raise'):\n"", ""-            for dt in ['f', 'd']:\n"", '                 assert_raises(FloatingPointError, np.log,\n', '                               np.array(-np.inf, dtype=dt))\n', '                 assert_raises(FloatingPointError, np.log,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             a = np.array(1e9, dtype='float32')\n"", '             np.log(a)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_sincos_values(self):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan, np.nan, np.nan, np.nan]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf]\n', ""+            for dt in ['e', 'f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.sin(yf), xf)\n', '                 assert_equal(np.cos(yf), xf)\n', ' \n', '+\n', ""         with np.errstate(invalid='raise'):\n"", '+            for callable in [np.sin, np.cos]:\n', '+                for value in [np.inf, -np.inf]:\n', ""+                    for dt in ['e', 'f', 'd']:\n"", '+                        assert_raises(FloatingPointError, callable,\n', '+                                np.array([value], dtype=dt))\n', ' \n', ""+    @pytest.mark.parametrize('dt', ['e', 'f', 'd', 'g'])\n"", '     def test_sqrt_values(self, dt):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan, np.nan, np.inf, np.nan, 0.]\n']","[""             a = np.array(1e9, dtype='float32')\n"", '             np.log(a)\n', ' \n', '     def test_sincos_values(self):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan, np.nan, np.nan, np.nan]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf]\n', ""-            for dt in ['f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.sin(yf), xf)\n', '                 assert_equal(np.cos(yf), xf)\n', ' \n', ""         with np.errstate(invalid='raise'):\n"", '-            assert_raises(FloatingPointError, np.sin, np.float32(-np.inf))\n', '-            assert_raises(FloatingPointError, np.sin, np.float32(np.inf))\n', '-            assert_raises(FloatingPointError, np.cos, np.float32(-np.inf))\n', '-            assert_raises(FloatingPointError, np.cos, np.float32(np.inf))\n', ' \n', ""-    @pytest.mark.parametrize('dt', ['f', 'd', 'g'])\n"", '     def test_sqrt_values(self, dt):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan, np.nan, np.inf, np.nan, 0.]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_abs_values(self):\n', '         x = [np.nan,  np.nan, np.inf, np.inf, 0., 0., 1.0, 1.0]\n', '         y = [np.nan, -np.nan, np.inf, -np.inf, 0., -0., -1.0, 1.0]\n', ""+        for dt in ['e', 'f', 'd', 'g']:\n"", '             xf = np.array(x, dtype=dt)\n', '             yf = np.array(y, dtype=dt)\n', '             assert_equal(np.abs(yf), xf)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_square_values(self):\n', '         x = [np.nan,  np.nan, np.inf, np.inf]\n', '         y = [np.nan, -np.nan, np.inf, -np.inf]\n', ""         with np.errstate(all='ignore'):\n"", ""+            for dt in ['e', 'f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.square(yf), xf)\n', ' \n', ""         with np.errstate(over='raise'):\n"", '+            assert_raises(FloatingPointError, np.square,\n', ""+                          np.array(1E3, dtype='e'))\n"", '             assert_raises(FloatingPointError, np.square,\n', ""                           np.array(1E32, dtype='f'))\n"", '             assert_raises(FloatingPointError, np.square,\n', ""                           np.array(1E200, dtype='d'))\n"", ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_reciprocal_values(self):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan,  np.nan, 0.0, -0.0, np.inf, -np.inf]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf, 0., -0.]\n', ""+            for dt in ['e', 'f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.reciprocal(yf), xf)\n', ' \n', ""         with np.errstate(divide='raise'):\n"", ""+            for dt in ['e', 'f', 'd', 'g']:\n"", '                 assert_raises(FloatingPointError, np.reciprocal,\n', '                               np.array(-0.0, dtype=dt))\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_tan(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, 0.0, -0.0, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, 0.0, -0.0, np.nan, np.nan]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.tan(in_arr), out_arr)\n', ' \n', ""         with np.errstate(invalid='raise'):\n"", ""+            for dt in ['e', 'f', 'd']:\n"", '                 assert_raises(FloatingPointError, np.tan,\n', '                               np.array(np.inf, dtype=dt))\n', '                 assert_raises(FloatingPointError, np.tan,\n', '                               np.array(-np.inf, dtype=dt))\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_arcsincos(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, np.nan, np.nan]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arcsin(in_arr), out_arr)\n']","['     def test_abs_values(self):\n', '         x = [np.nan,  np.nan, np.inf, np.inf, 0., 0., 1.0, 1.0]\n', '         y = [np.nan, -np.nan, np.inf, -np.inf, 0., -0., -1.0, 1.0]\n', ""-        for dt in ['f', 'd', 'g']:\n"", '             xf = np.array(x, dtype=dt)\n', '             yf = np.array(y, dtype=dt)\n', '             assert_equal(np.abs(yf), xf)\n', ' \n', '     def test_square_values(self):\n', '         x = [np.nan,  np.nan, np.inf, np.inf]\n', '         y = [np.nan, -np.nan, np.inf, -np.inf]\n', ""         with np.errstate(all='ignore'):\n"", ""-            for dt in ['f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.square(yf), xf)\n', ' \n', ""         with np.errstate(over='raise'):\n"", '             assert_raises(FloatingPointError, np.square,\n', ""                           np.array(1E32, dtype='f'))\n"", '             assert_raises(FloatingPointError, np.square,\n', ""                           np.array(1E200, dtype='d'))\n"", ' \n', '     def test_reciprocal_values(self):\n', ""         with np.errstate(all='ignore'):\n"", '             x = [np.nan,  np.nan, 0.0, -0.0, np.inf, -np.inf]\n', '             y = [np.nan, -np.nan, np.inf, -np.inf, 0., -0.]\n', ""-            for dt in ['f', 'd', 'g']:\n"", '                 xf = np.array(x, dtype=dt)\n', '                 yf = np.array(y, dtype=dt)\n', '                 assert_equal(np.reciprocal(yf), xf)\n', ' \n', ""         with np.errstate(divide='raise'):\n"", ""-            for dt in ['f', 'd', 'g']:\n"", '                 assert_raises(FloatingPointError, np.reciprocal,\n', '                               np.array(-0.0, dtype=dt))\n', ' \n', '     def test_tan(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, 0.0, -0.0, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, 0.0, -0.0, np.nan, np.nan]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.tan(in_arr), out_arr)\n', ' \n', ""         with np.errstate(invalid='raise'):\n"", ""-            for dt in ['f', 'd']:\n"", '                 assert_raises(FloatingPointError, np.tan,\n', '                               np.array(np.inf, dtype=dt))\n', '                 assert_raises(FloatingPointError, np.tan,\n', '                               np.array(-np.inf, dtype=dt))\n', ' \n', '     def test_arcsincos(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, np.nan, np.nan]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arcsin(in_arr), out_arr)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         for callable in [np.arcsin, np.arccos]:\n', '             for value in [np.inf, -np.inf, 2.0, -2.0]:\n', ""+                for dt in ['e', 'f', 'd']:\n"", ""                     with np.errstate(invalid='raise'):\n"", '                         assert_raises(FloatingPointError, callable,\n', '                                       np.array(value, dtype=dt))\n']","[' \n', '         for callable in [np.arcsin, np.arccos]:\n', '             for value in [np.inf, -np.inf, 2.0, -2.0]:\n', ""-                for dt in ['f', 'd']:\n"", ""                     with np.errstate(invalid='raise'):\n"", '                         assert_raises(FloatingPointError, callable,\n', '                                       np.array(value, dtype=dt))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan]\n', '             out = [np.nan, np.nan]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arctan(in_arr), out_arr)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_sinh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, np.inf, -np.inf]\n', ""+        for dt in ['e', 'f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.sinh(in_arr), out_arr)\n', ' \n', ""         with np.errstate(over='raise'):\n"", '+            assert_raises(FloatingPointError, np.sinh,\n', ""+                          np.array(12.0, dtype='e'))\n"", '             assert_raises(FloatingPointError, np.sinh,\n', ""                           np.array(120.0, dtype='f'))\n"", '             assert_raises(FloatingPointError, np.sinh,\n', ""                           np.array(1200.0, dtype='d'))\n"", ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_cosh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, np.inf, np.inf]\n', ""+        for dt in ['e', 'f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.cosh(in_arr), out_arr)\n', ' \n', ""         with np.errstate(over='raise'):\n"", '+            assert_raises(FloatingPointError, np.cosh,\n', ""+                          np.array(12.0, dtype='e'))\n"", '             assert_raises(FloatingPointError, np.cosh,\n', ""                           np.array(120.0, dtype='f'))\n"", '             assert_raises(FloatingPointError, np.cosh,\n']","[""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan]\n', '             out = [np.nan, np.nan]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arctan(in_arr), out_arr)\n', ' \n', '     def test_sinh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, np.inf, -np.inf]\n', ""-        for dt in ['f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.sinh(in_arr), out_arr)\n', ' \n', ""         with np.errstate(over='raise'):\n"", '             assert_raises(FloatingPointError, np.sinh,\n', ""                           np.array(120.0, dtype='f'))\n"", '             assert_raises(FloatingPointError, np.sinh,\n', ""                           np.array(1200.0, dtype='d'))\n"", ' \n', '     def test_cosh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, np.inf, np.inf]\n', ""-        for dt in ['f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.cosh(in_arr), out_arr)\n', ' \n', ""         with np.errstate(over='raise'):\n"", '             assert_raises(FloatingPointError, np.cosh,\n', ""                           np.array(120.0, dtype='f'))\n"", '             assert_raises(FloatingPointError, np.cosh,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_tanh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, 1.0, -1.0]\n', ""+        for dt in ['e', 'f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.tanh(in_arr), out_arr)\n']","['     def test_tanh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, 1.0, -1.0]\n', ""-        for dt in ['f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.tanh(in_arr), out_arr)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_arcsinh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, np.inf, -np.inf]\n', ""+        for dt in ['e', 'f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.arcsinh(in_arr), out_arr)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_arccosh(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf, 1.0, 0.0]\n', '             out = [np.nan, np.nan, np.inf, np.nan, 0.0, np.nan]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arccosh(in_arr), out_arr)\n', ' \n', '         for value in [0.0, -np.inf]:\n', ""             with np.errstate(invalid='raise'):\n"", ""+                for dt in ['e', 'f', 'd']:\n"", '                     assert_raises(FloatingPointError, np.arccosh,\n', '                                   np.array(value, dtype=dt))\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_arctanh(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf, 1.0, -1.0, 2.0]\n', '             out = [np.nan, np.nan, np.nan, np.nan, np.inf, -np.inf, np.nan]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arctanh(in_arr), out_arr)\n', ' \n', '         for value in [1.01, np.inf, -np.inf, 1.0, -1.0]:\n', ""             with np.errstate(invalid='raise', divide='raise'):\n"", ""+                for dt in ['e', 'f', 'd']:\n"", '                     assert_raises(FloatingPointError, np.arctanh,\n', '                                   np.array(value, dtype=dt))\n', ' \n']","['     def test_arcsinh(self):\n', '         in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '         out = [np.nan, np.nan, np.inf, -np.inf]\n', ""-        for dt in ['f', 'd']:\n"", '             in_arr = np.array(in_, dtype=dt)\n', '             out_arr = np.array(out, dtype=dt)\n', '             assert_equal(np.arcsinh(in_arr), out_arr)\n', ' \n', '     def test_arccosh(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf, 1.0, 0.0]\n', '             out = [np.nan, np.nan, np.inf, np.nan, 0.0, np.nan]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arccosh(in_arr), out_arr)\n', ' \n', '         for value in [0.0, -np.inf]:\n', ""             with np.errstate(invalid='raise'):\n"", ""-                for dt in ['f', 'd']:\n"", '                     assert_raises(FloatingPointError, np.arccosh,\n', '                                   np.array(value, dtype=dt))\n', ' \n', '     def test_arctanh(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf, 1.0, -1.0, 2.0]\n', '             out = [np.nan, np.nan, np.nan, np.nan, np.inf, -np.inf, np.nan]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.arctanh(in_arr), out_arr)\n', ' \n', '         for value in [1.01, np.inf, -np.inf, 1.0, -1.0]:\n', ""             with np.errstate(invalid='raise', divide='raise'):\n"", ""-                for dt in ['f', 'd']:\n"", '                     assert_raises(FloatingPointError, np.arctanh,\n', '                                   np.array(value, dtype=dt))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, np.inf, 0.0]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.exp2(in_arr), out_arr)\n', ' \n', '         for value in [2000.0, -2000.0]:\n', ""             with np.errstate(over='raise', under='raise'):\n"", ""+                for dt in ['e', 'f', 'd']:\n"", '                     assert_raises(FloatingPointError, np.exp2,\n', '                                   np.array(value, dtype=dt))\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_expm1(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, np.inf, -1.0]\n', ""+            for dt in ['e', 'f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.expm1(in_arr), out_arr)\n', ' \n', '         for value in [200.0, 2000.0]:\n', ""             with np.errstate(over='raise'):\n"", ""+                for dt in ['e', 'f']:\n"", '+                    assert_raises(FloatingPointError, np.expm1,\n', '+                                  np.array(value, dtype=dt))\n', '+\n', '+    # test to ensure no spurious FP exceptions are raised due to SIMD\n', '+    def test_spurious_fpexception(self):\n', ""+        for dt in ['e', 'f', 'd']:\n"", '+            arr = np.array([1.0, 2.0], dtype=dt)\n', '+            with assert_no_warnings():\n', '+                np.log(arr)\n', '+                np.log2(arr)\n', '+                np.log10(arr)\n', '+                np.arccosh(arr)\n', '+\n', ' \n', ' class TestFPClass:\n', '     @pytest.mark.parametrize(""stride"", [-4,-2,-1,1,2,4])\n']","[""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, np.inf, 0.0]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.exp2(in_arr), out_arr)\n', ' \n', '         for value in [2000.0, -2000.0]:\n', ""             with np.errstate(over='raise', under='raise'):\n"", ""-                for dt in ['f', 'd']:\n"", '                     assert_raises(FloatingPointError, np.exp2,\n', '                                   np.array(value, dtype=dt))\n', ' \n', '     def test_expm1(self):\n', ""         with np.errstate(all='ignore'):\n"", '             in_ = [np.nan, -np.nan, np.inf, -np.inf]\n', '             out = [np.nan, np.nan, np.inf, -1.0]\n', ""-            for dt in ['f', 'd']:\n"", '                 in_arr = np.array(in_, dtype=dt)\n', '                 out_arr = np.array(out, dtype=dt)\n', '                 assert_equal(np.expm1(in_arr), out_arr)\n', ' \n', '         for value in [200.0, 2000.0]:\n', ""             with np.errstate(over='raise'):\n"", '-                assert_raises(FloatingPointError, np.expm1,\n', ""-                              np.array(value, dtype='f'))\n"", ' \n', ' class TestFPClass:\n', '     @pytest.mark.parametrize(""stride"", [-4,-2,-1,1,2,4])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_values(self):\n', '         for dt in self.bitwise_types:\n', '             zeros = np.array([0], dtype=dt)\n', '+            ones = np.array([-1]).astype(dt)\n', '             msg = ""dt = \'%s\'"" % dt.char\n', ' \n', '             assert_equal(np.bitwise_not(zeros), ones, err_msg=msg)\n']","['     def test_values(self):\n', '         for dt in self.bitwise_types:\n', '             zeros = np.array([0], dtype=dt)\n', '-            ones = np.array([-1], dtype=dt)\n', '             msg = ""dt = \'%s\'"" % dt.char\n', ' \n', '             assert_equal(np.bitwise_not(zeros), ones, err_msg=msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_types(self):\n', '         for dt in self.bitwise_types:\n', '             zeros = np.array([0], dtype=dt)\n', '+            ones = np.array([-1]).astype(dt)\n', '             msg = ""dt = \'%s\'"" % dt.char\n', ' \n', '             assert_(np.bitwise_not(zeros).dtype == dt, msg)\n']","['     def test_types(self):\n', '         for dt in self.bitwise_types:\n', '             zeros = np.array([0], dtype=dt)\n', '-            ones = np.array([-1], dtype=dt)\n', '             msg = ""dt = \'%s\'"" % dt.char\n', ' \n', '             assert_(np.bitwise_not(zeros).dtype == dt, msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         for dt in self.bitwise_types:\n', '             zeros = np.array([0], dtype=dt)\n', '+            ones = np.array([-1]).astype(dt)\n', '             for f in binary_funcs:\n', '                 msg = ""dt: \'%s\', f: \'%s\'"" % (dt, f)\n', '                 assert_equal(f.reduce(zeros), zeros, err_msg=msg)\n']","[' \n', '         for dt in self.bitwise_types:\n', '             zeros = np.array([0], dtype=dt)\n', '-            ones = np.array([-1], dtype=dt)\n', '             for f in binary_funcs:\n', '                 msg = ""dt: \'%s\', f: \'%s\'"" % (dt, f)\n', '                 assert_equal(f.reduce(zeros), zeros, err_msg=msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             empty = np.array([], dtype=dt)\n', '             for f in binary_funcs:\n', '                 msg = ""dt: \'%s\', f: \'%s\'"" % (dt, f)\n', '+                tgt = np.array(f.identity).astype(dt)\n', '                 res = f.reduce(empty)\n', '                 assert_equal(res, tgt, err_msg=msg)\n', '                 assert_(res.dtype == tgt.dtype, msg)\n']","['             empty = np.array([], dtype=dt)\n', '             for f in binary_funcs:\n', '                 msg = ""dt: \'%s\', f: \'%s\'"" % (dt, f)\n', '-                tgt = np.array(f.identity, dtype=dt)\n', '                 res = f.reduce(empty)\n', '                 assert_equal(res, tgt, err_msg=msg)\n', '                 assert_(res.dtype == tgt.dtype, msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             assert_almost_equal(fz.real, fr, err_msg='real part %s' % f)\n"", ""             assert_almost_equal(fz.imag, 0., err_msg='imag part %s' % f)\n"", ' \n', '+    @pytest.mark.xfail(IS_WASM, reason=""doesn\'t work"")\n', '     def test_precisions_consistent(self):\n', '         z = 1 + 1j\n', '         for f in self.funcs:\n']","[""             assert_almost_equal(fz.real, fr, err_msg='real part %s' % f)\n"", ""             assert_almost_equal(fz.imag, 0., err_msg='imag part %s' % f)\n"", ' \n', '     def test_precisions_consistent(self):\n', '         z = 1 + 1j\n', '         for f in self.funcs:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             assert_almost_equal(fcf, fcd, decimal=6, err_msg='fch-fcd %s' % f)\n"", ""             assert_almost_equal(fcl, fcd, decimal=15, err_msg='fch-fcl %s' % f)\n"", ' \n', '+    @pytest.mark.xfail(IS_WASM, reason=""doesn\'t work"")\n', '     def test_branch_cuts(self):\n', '         # check branch cuts and continuity on them\n', '         _check_branch_cut(np.log,   -0.5, 1j, 1, -1, True)\n']","[""             assert_almost_equal(fcf, fcd, decimal=6, err_msg='fch-fcd %s' % f)\n"", ""             assert_almost_equal(fcl, fcd, decimal=15, err_msg='fch-fcl %s' % f)\n"", ' \n', '     def test_branch_cuts(self):\n', '         # check branch cuts and continuity on them\n', '         _check_branch_cut(np.log,   -0.5, 1j, 1, -1, True)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         _check_branch_cut(np.arccosh, [0-2j, 2j, 2], [1,  1,  1j], 1, 1)\n', '         _check_branch_cut(np.arctanh, [0-2j, 2j, 0], [1,  1,  1j], 1, 1)\n', ' \n', '+    @pytest.mark.xfail(IS_WASM, reason=""doesn\'t work"")\n', '     def test_branch_cuts_complex64(self):\n', '         # check branch cuts and continuity on them\n', '         _check_branch_cut(np.log,   -0.5, 1j, 1, -1, True, np.complex64)\n']","['         _check_branch_cut(np.arccosh, [0-2j, 2j, 2], [1,  1,  1j], 1, 1)\n', '         _check_branch_cut(np.arctanh, [0-2j, 2j, 0], [1,  1,  1j], 1, 1)\n', ' \n', '     def test_branch_cuts_complex64(self):\n', '         # check branch cuts and continuity on them\n', '         _check_branch_cut(np.log,   -0.5, 1j, 1, -1, True, np.complex64)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 b = cfunc(p)\n', '                 assert_(abs(a - b) < atol, ""%s %s: %s; cmath: %s"" % (fname, p, a, b))\n', ' \n', '+    @pytest.mark.xfail(IS_WASM, reason=""doesn\'t work"")\n', ""     @pytest.mark.parametrize('dtype', [np.complex64, np.complex_, np.longcomplex])\n"", '     def test_loss_of_precision(self, dtype):\n', '         """"""Check loss of precision in complex arc* functions""""""\n']","['                 b = cfunc(p)\n', '                 assert_(abs(a - b) < atol, ""%s %s: %s; cmath: %s"" % (fname, p, a, b))\n', ' \n', ""     @pytest.mark.parametrize('dtype', [np.complex64, np.complex_, np.longcomplex])\n"", '     def test_loss_of_precision(self, dtype):\n', '         """"""Check loss of precision in complex arc* functions""""""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         x_basic = np.logspace(-2.999, 0, 10, endpoint=False)\n', ' \n', '         if dtype is np.longcomplex:\n', '+            if bad_arcsinh():\n', '                 pytest.skip(""Trig functions of np.longcomplex values known ""\n', '+                            ""to be inaccurate on aarch64 and PPC for some ""\n', '+                            ""compilation configurations."")\n', ""             # It's not guaranteed that the system-provided arc functions\n"", '             # are accurate down to a few epsilons. (Eg. on Linux 64-bit)\n', '             # So, give more leeway for long complex tests here:\n']","['         x_basic = np.logspace(-2.999, 0, 10, endpoint=False)\n', ' \n', '         if dtype is np.longcomplex:\n', ""-            if (platform.machine() == 'aarch64' and bad_arcsinh()):\n"", '                 pytest.skip(""Trig functions of np.longcomplex values known ""\n', '-                            ""to be inaccurate on aarch64 for some compilation ""\n', '-                            ""configurations."")\n', ""             # It's not guaranteed that the system-provided arc functions\n"", '             # are accurate down to a few epsilons. (Eg. on Linux 64-bit)\n', '             # So, give more leeway for long complex tests here:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing._private.utils import _glibc_older_than\n', ' from numpy.core._multiarray_umath import __cpu_features__\n', ' \n', '+UNARY_UFUNCS = [obj for obj in np.core.umath.__dict__.values() if\n', '+        isinstance(obj, np.ufunc)]\n', '+UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if ""O->O"" in uf.types]\n', ""+UNARY_OBJECT_UFUNCS.remove(getattr(np, 'invert'))\n"", '+\n', "" IS_AVX = __cpu_features__.get('AVX512F', False) or \\\n"", ""         (__cpu_features__.get('FMA3', False) and __cpu_features__.get('AVX2', False))\n"", ' # only run on linux with AVX, also avoid old glibc (numpy/numpy#20448).\n']","[' from numpy.testing._private.utils import _glibc_older_than\n', ' from numpy.core._multiarray_umath import __cpu_features__\n', ' \n', "" IS_AVX = __cpu_features__.get('AVX512F', False) or \\\n"", ""         (__cpu_features__.get('FMA3', False) and __cpu_features__.get('AVX2', False))\n"", ' # only run on linux with AVX, also avoid old glibc (numpy/numpy#20448).\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                         outval = outval[perm]\n', ""                         maxulperr = data_subset['ulperr'].max()\n"", '                         assert_array_max_ulp(npfunc(inval), outval, maxulperr)\n', '+\n', '+    @pytest.mark.parametrize(""ufunc"", UNARY_OBJECT_UFUNCS)\n', '+    def test_validate_fp16_transcendentals(self, ufunc):\n', ""+        with np.errstate(all='ignore'):\n"", '+            arr = np.arange(65536, dtype=np.int16)\n', '+            datafp16 = np.frombuffer(arr.tobytes(), dtype=np.float16)\n', '+            datafp32 = datafp16.astype(np.float32)\n', '+            assert_array_max_ulp(ufunc(datafp16), ufunc(datafp32),\n', '+                    maxulp=1, dtype=np.float16)\n']","['                         outval = outval[perm]\n', ""                         maxulperr = data_subset['ulperr'].max()\n"", '                         assert_array_max_ulp(npfunc(inval), outval, maxulperr)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # cuts first)\n', ' \n', ' class TestCpow:\n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']","['         # cuts first)\n', ' \n', ' class TestCpow:\n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)\n"", ' \n', ' class TestCabs:\n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']","[""             assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)\n"", ' \n', ' class TestCabs:\n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import pytest\n', '+\n', ' import numpy as np\n', ' from numpy.testing import assert_, assert_equal, assert_array_equal\n', ' \n']","[' import numpy as np\n', ' from numpy.testing import assert_, assert_equal, assert_array_equal\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', '         return np.prod(v.shape) * v.itemsize\n', ' \n', '+\n', ' # In both cases below we need to make sure that the byte swapped value (as\n', ' # UCS4) is still a valid unicode:\n', ' # Value that can be represented in UCS2 interpreters\n', ""+ucs2_value = '\\u0900'\n"", ' # Value that cannot be represented in UCS2 interpreters (but can in UCS4)\n', ""+ucs4_value = '\\U00100900'\n"", ' \n', ' \n', ' def test_string_cast():\n']","['     else:\n', '         return np.prod(v.shape) * v.itemsize\n', ' \n', ' # In both cases below we need to make sure that the byte swapped value (as\n', ' # UCS4) is still a valid unicode:\n', ' # Value that can be represented in UCS2 interpreters\n', ""-ucs2_value = u'\\u0900'\n"", ' # Value that cannot be represented in UCS2 interpreters (but can in UCS4)\n', ""-ucs4_value = u'\\U00100900'\n"", ' \n', ' \n', ' def test_string_cast():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     uni_arr1 = str_arr.astype('>U')\n"", ""     uni_arr2 = str_arr.astype('<U')\n"", ' \n', '+    with pytest.warns(FutureWarning):\n', '+        assert str_arr != uni_arr1\n', '+    with pytest.warns(FutureWarning):\n', '+        assert str_arr != uni_arr2\n', '+\n', '     assert_array_equal(uni_arr1, uni_arr2)\n', ' \n', ' \n']","[""     uni_arr1 = str_arr.astype('>U')\n"", ""     uni_arr2 = str_arr.astype('<U')\n"", ' \n', '-    assert_(str_arr != uni_arr1)\n', '-    assert_(str_arr != uni_arr2)\n', '     assert_array_equal(uni_arr1, uni_arr2)\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # Check the length of the data buffer\n', '         assert_(buffer_length(ua) == nbytes)\n', '         # Small check that data in array element is ok\n', ""+        assert_(ua_scalar == '')\n"", '         # Encode to ascii and double check\n', ""         assert_(ua_scalar.encode('ascii') == b'')\n"", '         # Check buffer lengths for scalars\n']","['         # Check the length of the data buffer\n', '         assert_(buffer_length(ua) == nbytes)\n', '         # Small check that data in array element is ok\n', ""-        assert_(ua_scalar == u'')\n"", '         # Encode to ascii and double check\n', ""         assert_(ua_scalar.encode('ascii') == b'')\n"", '         # Check buffer lengths for scalars\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from distutils.unixccompiler import UnixCCompiler                              \n', ' \n', ' class ArmCCompiler(UnixCCompiler):\n']","['-from __future__ import division, absolute_import, print_function               \n', '-\n', ' from distutils.unixccompiler import UnixCCompiler                              \n', ' \n', ' class ArmCCompiler(UnixCCompiler):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     cxx.compiler_cxx = cxx.compiler_cxx\n', '     cxx.compiler_so = [cxx.compiler_cxx[0]] + \\\n', '                       sanitize_cxx_flags(cxx.compiler_so[1:])\n', ""+    if (sys.platform.startswith(('aix', 'os400')) and\n"", ""+            'ld_so_aix' in cxx.linker_so[0]):\n"", '         # AIX needs the ld_so_aix script included with Python\n', '         cxx.linker_so = [cxx.linker_so[0], cxx.compiler_cxx[0]] \\\n', '                         + cxx.linker_so[2:]\n', ""+    if sys.platform.startswith('os400'):\n"", '+        #This is required by i 7.4 and prievous for PRId64 in printf() call.\n', ""+        cxx.compiler_so.append('-D__STDC_FORMAT_MACROS')\n"", '+        #This a bug of gcc10.3, which failed to handle the TLS init.\n', ""+        cxx.compiler_so.append('-fno-extern-tls-init')\n"", ""+        cxx.linker_so.append('-fno-extern-tls-init')\n"", '     else:\n', '         cxx.linker_so = [cxx.compiler_cxx[0]] + cxx.linker_so[1:]\n', '     return cxx\n']","['     cxx.compiler_cxx = cxx.compiler_cxx\n', '     cxx.compiler_so = [cxx.compiler_cxx[0]] + \\\n', '                       sanitize_cxx_flags(cxx.compiler_so[1:])\n', ""-    if sys.platform.startswith('aix') and 'ld_so_aix' in cxx.linker_so[0]:\n"", '         # AIX needs the ld_so_aix script included with Python\n', '         cxx.linker_so = [cxx.linker_so[0], cxx.compiler_cxx[0]] \\\n', '                         + cxx.linker_so[2:]\n', '     else:\n', '         cxx.linker_so = [cxx.compiler_cxx[0]] + cxx.linker_so[1:]\n', '     return cxx\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def _dist_test_spawn(cmd, display=None):\n', '         try:\n', '             o = subprocess.check_output(cmd, stderr=subprocess.STDOUT,\n', '+                                        text=True)\n', '             if o and re.match(_Distutils._dist_warn_regex, o):\n', '                 _Distutils.dist_error(\n', '                     ""Flags in command"", cmd ,""aren\'t supported by the compiler""\n']","['     def _dist_test_spawn(cmd, display=None):\n', '         try:\n', '             o = subprocess.check_output(cmd, stderr=subprocess.STDOUT,\n', '-                                        universal_newlines=True)\n', '             if o and re.match(_Distutils._dist_warn_regex, o):\n', '                 _Distutils.dist_error(\n', '                     ""Flags in command"", cmd ,""aren\'t supported by the compiler""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def __init__(self):\n', '         if hasattr(self, ""cc_is_cached""):\n', '             return\n', '+        #      attr            regex        compiler-expression\n', '         detect_arch = (\n', '+            (""cc_on_x64"",      "".*(x|x86_|amd)64.*"", """"),\n', '+            (""cc_on_x86"",      "".*(win32|x86|i386|i686).*"", """"),\n', '+            (""cc_on_ppc64le"",  "".*(powerpc|ppc)64(el|le).*"", """"),\n', '+            (""cc_on_ppc64"",    "".*(powerpc|ppc)64.*"", """"),\n', '+            (""cc_on_aarch64"",  "".*(aarch64|arm64).*"", """"),\n', '+            (""cc_on_armhf"",    "".*arm.*"", ""defined(__ARM_ARCH_7__) || ""\n', '+                                          ""defined(__ARM_ARCH_7A__)""),\n', '+            (""cc_on_s390x"",    "".*s390x.*"", """"),\n', '             # undefined platform\n', '+            (""cc_on_noarch"",   """", """"),\n', '         )\n', '         detect_compiler = (\n', '+            (""cc_is_gcc"",     r"".*(gcc|gnu\\-g).*"", """"),\n', '+            (""cc_is_clang"",    "".*clang.*"", """"),\n', '+            # intel msvc like\n', '+            (""cc_is_iccw"",     "".*(intelw|intelemw|iccw).*"", """"),\n', '+            (""cc_is_icc"",      "".*(intel|icc).*"", """"),  # intel unix like\n', '+            (""cc_is_msvc"",     "".*msvc.*"", """"),\n', '             # undefined compiler will be treat it as gcc\n', '+            (""cc_is_nocc"",     """", """"),\n', '         )\n', '         detect_args = (\n', '+           (""cc_has_debug"",  "".*(O0|Od|ggdb|coverage|debug:full).*"", """"),\n', '+           (""cc_has_native"", "".*(-march=native|-xHost|/QxHost).*"", """"),\n', '            # in case if the class run with -DNPY_DISABLE_OPTIMIZATION\n', '+           (""cc_noopt"", "".*DISABLE_OPT.*"", """"),\n', '         )\n', ' \n', '         dist_info = self.dist_info()\n', '         platform, compiler_info, extra_args = dist_info\n', '         # set False to all attrs\n', '         for section in (detect_arch, detect_compiler, detect_args):\n', '+            for attr, rgex, cexpr in section:\n', '                 setattr(self, attr, False)\n', ' \n', '         for detect, searchin in ((detect_arch, platform), (detect_compiler, compiler_info)):\n', '+            for attr, rgex, cexpr in detect:\n', '                 if rgex and not re.match(rgex, searchin, re.IGNORECASE):\n', '                     continue\n', '+                if cexpr and not self.cc_test_cexpr(cexpr):\n', '+                    continue\n', '                 setattr(self, attr, True)\n', '                 break\n', ' \n', '+        for attr, rgex, cexpr in detect_args:\n', '             if rgex and not re.match(rgex, extra_args, re.IGNORECASE):\n', '                 continue\n', '+            if cexpr and not self.cc_test_cexpr(cexpr):\n', '+                continue\n', '             setattr(self, attr, True)\n', ' \n', '         if self.cc_on_noarch:\n']","['     def __init__(self):\n', '         if hasattr(self, ""cc_is_cached""):\n', '             return\n', '-        #      attr                regex\n', '         detect_arch = (\n', '-            (""cc_on_x64"",      "".*(x|x86_|amd)64.*""),\n', '-            (""cc_on_x86"",      "".*(win32|x86|i386|i686).*""),\n', '-            (""cc_on_ppc64le"",  "".*(powerpc|ppc)64(el|le).*""),\n', '-            (""cc_on_ppc64"",    "".*(powerpc|ppc)64.*""),\n', '-            (""cc_on_aarch64"",  "".*(aarch64|arm64).*""),\n', '-            (""cc_on_armhf"",    "".*arm.*""),\n', '-            (""cc_on_s390x"",    "".*s390x.*""),\n', '             # undefined platform\n', '-            (""cc_on_noarch"",    """"),\n', '         )\n', '         detect_compiler = (\n', '-            (""cc_is_gcc"",     r"".*(gcc|gnu\\-g).*""),\n', '-            (""cc_is_clang"",    "".*clang.*""),\n', '-            (""cc_is_iccw"",     "".*(intelw|intelemw|iccw).*""), # intel msvc like\n', '-            (""cc_is_icc"",      "".*(intel|icc).*""), # intel unix like\n', '-            (""cc_is_msvc"",     "".*msvc.*""),\n', '             # undefined compiler will be treat it as gcc\n', '-            (""cc_is_nocc"",     """"),\n', '         )\n', '         detect_args = (\n', '-           (""cc_has_debug"",  "".*(O0|Od|ggdb|coverage|debug:full).*""),\n', '-           (""cc_has_native"", "".*(-march=native|-xHost|/QxHost).*""),\n', '            # in case if the class run with -DNPY_DISABLE_OPTIMIZATION\n', '-           (""cc_noopt"", "".*DISABLE_OPT.*""),\n', '         )\n', ' \n', '         dist_info = self.dist_info()\n', '         platform, compiler_info, extra_args = dist_info\n', '         # set False to all attrs\n', '         for section in (detect_arch, detect_compiler, detect_args):\n', '-            for attr, rgex in section:\n', '                 setattr(self, attr, False)\n', ' \n', '         for detect, searchin in ((detect_arch, platform), (detect_compiler, compiler_info)):\n', '-            for attr, rgex in detect:\n', '                 if rgex and not re.match(rgex, searchin, re.IGNORECASE):\n', '                     continue\n', '                 setattr(self, attr, True)\n', '                 break\n', ' \n', '-        for attr, rgex in detect_args:\n', '             if rgex and not re.match(rgex, extra_args, re.IGNORECASE):\n', '                 continue\n', '             setattr(self, attr, True)\n', ' \n', '         if self.cc_on_noarch:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             self.dist_log(""testing failed"", stderr=True)\n', '         return test\n', ' \n', '+    @_Cache.me\n', '+    def cc_test_cexpr(self, cexpr, flags=[]):\n', '+        """"""\n', '+        Same as the above but supports compile-time expressions.\n', '+        """"""\n', '+        self.dist_log(""testing compiler expression"", cexpr)\n', '+        test_path = os.path.join(self.conf_tmp_path, ""npy_dist_test_cexpr.c"")\n', '+        with open(test_path, ""w"") as fd:\n', '+            fd.write(textwrap.dedent(f""""""\\\n', '+               #if !({cexpr})\n', '+                   #error ""unsupported expression""\n', '+               #endif\n', '+               int dummy;\n', '+            """"""))\n', '+        test = self.dist_test(test_path, flags)\n', '+        if not test:\n', '+            self.dist_log(""testing failed"", stderr=True)\n', '+        return test\n', '+\n', '     def cc_normalize_flags(self, flags):\n', '         """"""\n', '         Remove the conflicts that caused due gathering implied features flags.\n']","['             self.dist_log(""testing failed"", stderr=True)\n', '         return test\n', ' \n', '     def cc_normalize_flags(self, flags):\n', '         """"""\n', '         Remove the conflicts that caused due gathering implied features flags.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # not using fcompiler linker\n', '             self._libs_with_msvc_and_fortran(\n', '                 fcompiler, libraries, library_dirs)\n', '+            if ext.runtime_library_dirs:\n', '+                # gcc adds RPATH to the link. On windows, copy the dll into\n', '+                # self.extra_dll_dir instead.\n', '+                for d in ext.runtime_library_dirs:\n', ""+                    for f in glob(d + '/*.dll'):\n"", '+                        copy_file(f, self.extra_dll_dir)\n', '+                ext.runtime_library_dirs = []\n', ' \n', ""         elif ext.language in ['f77', 'f90'] and fcompiler is not None:\n"", '             linker = fcompiler.link_shared_object\n']","['             # not using fcompiler linker\n', '             self._libs_with_msvc_and_fortran(\n', '                 fcompiler, libraries, library_dirs)\n', ' \n', ""         elif ext.language in ['f77', 'f90'] and fcompiler is not None:\n"", '             linker = fcompiler.link_shared_object\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # XXX: hack to circumvent a python 2.6 bug with msvc9compiler:\n', '             # initialize call query_vcvarsall, which throws an IOError, and\n', '             # causes an error along the way without much information. We try to\n', '+            # catch it here, hoping it is early enough, and print a helpful\n', '             # message instead of Error: None.\n', '             if not self.compiler.initialized:\n', '                 try:\n']","['             # XXX: hack to circumvent a python 2.6 bug with msvc9compiler:\n', '             # initialize call query_vcvarsall, which throws an IOError, and\n', '             # causes an error along the way without much information. We try to\n', '-            # catch it here, hoping it is early enough, and print an helpful\n', '             # message instead of Error: None.\n', '             if not self.compiler.initialized:\n', '                 try:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                         Could not initialize compiler instance: do you have Visual Studio\n', '                         installed?  If you are trying to build with MinGW, please use ""python setup.py\n', '                         build -c mingw32"" instead.  If you have Visual Studio installed, check it is\n', '+                        correctly installed, and the right version (VS 2015 as of this writing).\n', ' \n', '                         Original exception was: %s, and the Compiler class was %s\n', '                         ============================================================================"""""") \\\n']","['                         Could not initialize compiler instance: do you have Visual Studio\n', '                         installed?  If you are trying to build with MinGW, please use ""python setup.py\n', '                         build -c mingw32"" instead.  If you have Visual Studio installed, check it is\n', '-                        correctly installed, and the right version (VS 2008 for python 2.6, 2.7 and 3.2,\n', '-                        VS 2010 for >= 3.3).\n', ' \n', '                         Original exception was: %s, and the Compiler class was %s\n', '                         ============================================================================"""""") \\\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Inherit environment by default\n', '     env = env or None\n', '     try:\n', '+        # text is set to False so that communicate()\n', '         # will return bytes. We need to decode the output ourselves\n', '         # so that Python will not raise a UnicodeDecodeError when\n', '         # it encounters an invalid character; rather, we simply replace it\n', '+        proc = subprocess.Popen(command, shell=use_shell, env=env, text=False,\n', '                                 stdout=subprocess.PIPE,\n', '+                                stderr=subprocess.STDOUT)\n', '     except OSError:\n', '         # Return 127, as os.spawn*() and /bin/sh do\n', ""         return 127, ''\n""]","['     # Inherit environment by default\n', '     env = env or None\n', '     try:\n', '-        # universal_newlines is set to False so that communicate()\n', '         # will return bytes. We need to decode the output ourselves\n', '         # so that Python will not raise a UnicodeDecodeError when\n', '         # it encounters an invalid character; rather, we simply replace it\n', '-        proc = subprocess.Popen(command, shell=use_shell, env=env,\n', '                                 stdout=subprocess.PIPE,\n', '-                                stderr=subprocess.STDOUT,\n', '-                                universal_newlines=False)\n', '     except OSError:\n', '         # Return 127, as os.spawn*() and /bin/sh do\n', ""         return 127, ''\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import sys                                                                     \n', '                                                                                \n', ' from numpy.distutils.fcompiler import FCompiler, dummy_fortran_file\n']","['-from __future__ import division, absolute_import, print_function\n', '-                                                                               \n', ' import sys                                                                     \n', '                                                                                \n', ' from numpy.distutils.fcompiler import FCompiler, dummy_fortran_file\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ""         if sys.platform == 'darwin':\n"", ""             return f'-Wl,-rpath,{dir}'\n"", ""+        elif sys.platform.startswith(('aix', 'os400')):\n"", '             # AIX RPATH is called LIBPATH\n', ""             return f'-Wl,-blibpath:{dir}'\n"", '         else:\n']","[' \n', ""         if sys.platform == 'darwin':\n"", ""             return f'-Wl,-rpath,{dir}'\n"", ""-        elif sys.platform[:3] == 'aix':\n"", '             # AIX RPATH is called LIBPATH\n', ""             return f'-Wl,-blibpath:{dir}'\n"", '         else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     module_dir_switch = '-J'\n"", ""     module_include_switch = '-I'\n"", ' \n', ""+    if sys.platform.startswith(('aix', 'os400')):\n"", ""         executables['linker_so'].append('-lpthread')\n"", ""         if platform.architecture()[0][:2] == '64':\n"", ""             for key in ['compiler_f77', 'compiler_f90','compiler_fix','linker_so', 'linker_exe']:\n""]","[""     module_dir_switch = '-J'\n"", ""     module_include_switch = '-I'\n"", ' \n', ""-    if sys.platform[:3] == 'aix':\n"", ""         executables['linker_so'].append('-lpthread')\n"", ""         if platform.architecture()[0][:2] == '64':\n"", ""             for key in ['compiler_f77', 'compiler_f90','compiler_fix','linker_so', 'linker_exe']:\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def get_target(self):\n', '         try:\n', '+            p = subprocess.Popen(\n', ""+                self.compiler_f77 + ['-v'],\n"", '+                stdin=subprocess.PIPE,\n', '+                stderr=subprocess.PIPE,\n', '+            )\n', '+            stdout, stderr = p.communicate()\n', '+            output = (stdout or b"""") + (stderr or b"""")\n', '         except (OSError, subprocess.CalledProcessError):\n', '             pass\n', '         else:\n']","[' \n', '     def get_target(self):\n', '         try:\n', ""-            output = subprocess.check_output(self.compiler_f77 + ['-v'])\n"", '         except (OSError, subprocess.CalledProcessError):\n', '             pass\n', '         else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     module_include_switch = '/I'\n"", ' \n', '     def get_flags(self):\n', ""+        opt = ['/nologo', '/MD', '/nbs', '/names:lowercase', \n"", ""+               '/assume:underscore', '/fpp']\n"", '         return opt\n', ' \n', '     def get_flags_free(self):\n']","[""     module_include_switch = '/I'\n"", ' \n', '     def get_flags(self):\n', ""-        opt = ['/nologo', '/MD', '/nbs', '/names:lowercase', '/assume:underscore']\n"", '         return opt\n', ' \n', '     def get_flags_free(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' nm_output = getnm(nm_cmd = \'nm -Cs py_lib\')""""""\n', '     p = subprocess.Popen(nm_cmd, shell=shell, stdout=subprocess.PIPE,\n', '+                         stderr=subprocess.PIPE, text=True)\n', '     nm_output, nm_err = p.communicate()\n', '     if p.returncode != 0:\n', '         raise RuntimeError(\'failed to run ""%s"": ""%s""\' % (\n']","[' \n', ' nm_output = getnm(nm_cmd = \'nm -Cs py_lib\')""""""\n', '     p = subprocess.Popen(nm_cmd, shell=shell, stdout=subprocess.PIPE,\n', '-                         stderr=subprocess.PIPE, universal_newlines=True)\n', '     nm_output, nm_err = p.communicate()\n', '     if p.returncode != 0:\n', '         raise RuntimeError(\'failed to run ""%s"": ""%s""\' % (\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     # We can't do much here:\n"", '     # - find it in the virtualenv (sys.prefix)\n', '     # - find it in python main dir (sys.base_prefix, if in a virtualenv)\n', '     # - in system32,\n', ""     # - ortherwise (Sxs), I don't know how to get it.\n"", '     stems = [sys.prefix]\n', '+    if sys.base_prefix != sys.prefix:\n', '         stems.append(sys.base_prefix)\n', ' \n', ""     sub_dirs = ['', 'lib', 'bin']\n"", '     # generate possible combinations of directory trees and sub-directories\n']","[""     # We can't do much here:\n"", '     # - find it in the virtualenv (sys.prefix)\n', '     # - find it in python main dir (sys.base_prefix, if in a virtualenv)\n', '-    # - sys.real_prefix is main dir for virtualenvs in Python 2.7\n', '     # - in system32,\n', ""     # - ortherwise (Sxs), I don't know how to get it.\n"", '     stems = [sys.prefix]\n', ""-    if hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix:\n"", '         stems.append(sys.base_prefix)\n', ""-    elif hasattr(sys, 'real_prefix') and sys.real_prefix != sys.prefix:\n"", '-        stems.append(sys.real_prefix)\n', ' \n', ""     sub_dirs = ['', 'lib', 'bin']\n"", '     # generate possible combinations of directory trees and sub-directories\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             fgcode = 30 + _colour_codes.get(fg.lower(), 0)\n', '             seq.append(str(fgcode))\n', '         if bg:\n', '+            bgcode = 40 + _colour_codes.get(bg.lower(), 7)\n', '             seq.append(str(bgcode))\n', '         if seq:\n', ""             return '\\x1b[%sm%s\\x1b[0m' % (';'.join(seq), s)\n""]","['             fgcode = 30 + _colour_codes.get(fg.lower(), 0)\n', '             seq.append(str(fgcode))\n', '         if bg:\n', '-            bgcode = 40 + _colour_codes.get(fg.lower(), 7)\n', '             seq.append(str(bgcode))\n', '         if seq:\n', ""             return '\\x1b[%sm%s\\x1b[0m' % (';'.join(seq), s)\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if sys.platform != ""cygwin"":\n', '         return path\n', '     return subprocess.check_output(\n', '+        [""/usr/bin/cygpath"", ""--windows"", path], text=True\n', '     )\n', ' \n', ' \n']","['     if sys.platform != ""cygwin"":\n', '         return path\n', '     return subprocess.check_output(\n', '-        [""/usr/bin/cygpath"", ""--windows"", path], universal_newlines=True\n', '     )\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if platform_bits == 32:\n', ""             self.compile_options += ['/arch:SSE2']\n"", ""             self.compile_options_debug += ['/arch:SSE2']\n"", '+\n', '+\n', '+def lib_opts_if_msvc(build_cmd):\n', '+    """""" Add flags if we are using MSVC compiler\n', '+\n', ""+    We can't see `build_cmd` in our scope, because we have not initialized\n"", '+    the distutils build command, so use this deferred calculation to run\n', '+    when we are building the library.\n', '+    """"""\n', ""+    if build_cmd.compiler.compiler_type != 'msvc':\n"", '+        return []\n', '+    # Explicitly disable whole-program optimization.\n', ""+    flags = ['/GL-']\n"", '+    # Disable voltbl section for vc142 to allow link using mingw-w64; see:\n', '+    # https://github.com/matthew-brett/dll_investigation/issues/1#issuecomment-1100468171\n', ""+    if build_cmd.compiler_opt.cc_test_flags(['-d2VolatileMetadata-']):\n"", ""+        flags.append('-d2VolatileMetadata-')\n"", '+    return flags\n']","['         if platform_bits == 32:\n', ""             self.compile_options += ['/arch:SSE2']\n"", ""             self.compile_options_debug += ['/arch:SSE2']\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import sys\n', ' from textwrap import indent, dedent\n', ' import pytest\n', '+from numpy.testing import IS_WASM\n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""cannot start subprocess in wasm"")\n', ' @pytest.mark.slow\n', ' def test_multi_fortran_libs_link(tmp_path):\n', ""     '''\n""]","[' import sys\n', ' from textwrap import indent, dedent\n', ' import pytest\n', ' \n', ' @pytest.mark.slow\n', ' def test_multi_fortran_libs_link(tmp_path):\n', ""     '''\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     arch = None # x86_64\n', '     cc   = None # gcc\n', ' \n', '+    def setup_class(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', '         self._opt = None\n', ' \n']","['     arch = None # x86_64\n', '     cc   = None # gcc\n', ' \n', '-    def setup(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', '         self._opt = None\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         cc   = '{cc}'\n"", '         def __init__(self, methodName=""runTest""):\n', '             unittest.TestCase.__init__(self, methodName)\n', '+            self.setup_class()\n', '     """""").format(\n', ""         class_name=arch + '_' + cc, arch=arch, cc=cc\n"", '     )\n']","[""         cc   = '{cc}'\n"", '         def __init__(self, methodName=""runTest""):\n', '             unittest.TestCase.__init__(self, methodName)\n', '-            self.setup()\n', '     """""").format(\n', ""         class_name=arch + '_' + cc, arch=arch, cc=cc\n"", '     )\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestConfFeatures(unittest.TestCase):\n', '     def __init__(self, methodName=""runTest""):\n', '         unittest.TestCase.__init__(self, methodName)\n', '+        self._setup()\n', ' \n', '+    def _setup(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', ' \n', '     def test_features(self):\n']","[' class TestConfFeatures(unittest.TestCase):\n', '     def __init__(self, methodName=""runTest""):\n', '         unittest.TestCase.__init__(self, methodName)\n', '-        self.setup()\n', ' \n', '-    def setup(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', ' \n', '     def test_features(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import os\n', '+import pytest\n', ' import sys\n', ' from tempfile import TemporaryFile\n', ' \n', ' from numpy.distutils import exec_command\n', ' from numpy.distutils.exec_command import get_pythonexe\n', '+from numpy.testing import tempdir, assert_, assert_warns, IS_WASM\n', '+\n', ' \n', ' # In python 3 stdout, stderr are text (unicode compliant) devices, so to\n', ' # emulate them import StringIO from the io module.\n']","[' import os\n', ' import sys\n', ' from tempfile import TemporaryFile\n', ' \n', ' from numpy.distutils import exec_command\n', ' from numpy.distutils.exec_command import get_pythonexe\n', '-from numpy.testing import tempdir, assert_, assert_warns\n', ' \n', ' # In python 3 stdout, stderr are text (unicode compliant) devices, so to\n', ' # emulate them import StringIO from the io module.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                         exec_command.exec_command(""cd \'.\'"")\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', ' class TestExecCommand:\n', '+    def setup_method(self):\n', '         self.pyexe = get_pythonexe()\n', ' \n', '     def check_nt(self, **kws):\n']","['                         exec_command.exec_command(""cd \'.\'"")\n', ' \n', ' \n', ' class TestExecCommand:\n', '-    def setup(self):\n', '         self.pyexe = get_pythonexe()\n', ' \n', '     def check_nt(self, **kws):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import sys\n', ' \n', ' from numpy.distutils import _shell_utils\n', '+from numpy.testing import IS_WASM\n', ' \n', ' argv_cases = [\n', ""     [r'exe'],\n""]","[' import sys\n', ' \n', ' from numpy.distutils import _shell_utils\n', ' \n', ' argv_cases = [\n', ""     [r'exe'],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         raise NotImplementedError\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', "" @pytest.mark.parametrize('argv', argv_cases)\n"", ' def test_join_matches_subprocess(Parser, runner, argv):\n', '     """"""\n']","['         raise NotImplementedError\n', ' \n', ' \n', "" @pytest.mark.parametrize('argv', argv_cases)\n"", ' def test_join_matches_subprocess(Parser, runner, argv):\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert json.loads(json_out) == argv\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', "" @pytest.mark.parametrize('argv', argv_cases)\n"", ' def test_roundtrip(Parser, argv):\n', '     """"""\n']","['     assert json.loads(json_out) == argv\n', ' \n', ' \n', "" @pytest.mark.parametrize('argv', argv_cases)\n"", ' def test_roundtrip(Parser, argv):\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestSystemInfoReading:\n', ' \n', '+    def setup_method(self):\n', '         """""" Create the libraries """"""\n', '         # Create 2 sources and 2 libraries\n', '         self._dir1 = mkdtemp()\n']","[' \n', ' class TestSystemInfoReading:\n', ' \n', '-    def setup(self):\n', '         """""" Create the libraries """"""\n', '         # Create 2 sources and 2 libraries\n', '         self._dir1 = mkdtemp()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         self.c_dup_options = site_and_parse(get_class('duplicate_options'),\n"", '                                             self._sitecfg)\n', ' \n', '+    def teardown_method(self):\n', '         # Do each removal separately\n', '         try:\n', '             shutil.rmtree(self._dir1)\n']","[""         self.c_dup_options = site_and_parse(get_class('duplicate_options'),\n"", '                                             self._sitecfg)\n', ' \n', '-\n', '-    def teardown(self):\n', '         # Do each removal separately\n', '         try:\n', '             shutil.rmtree(self._dir1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     'getfortranname', 'getpymethoddef', 'getrestdoc', 'getusercode',\n"", ""     'getusercode1', 'hasbody', 'hascallstatement', 'hascommon',\n"", ""     'hasexternals', 'hasinitvalue', 'hasnote', 'hasresultnote',\n"", ""+    'isallocatable', 'isarray', 'isarrayofstrings',\n"", ""+    'ischaracter', 'ischaracterarray', 'ischaracter_or_characterarray',\n"", ""+    'iscomplex',\n"", ""     'iscomplexarray', 'iscomplexfunction', 'iscomplexfunction_warn',\n"", ""     'isdouble', 'isdummyroutine', 'isexternal', 'isfunction',\n"", ""+    'isfunction_wrap', 'isint1', 'isint1array', 'isinteger', 'isintent_aux',\n"", ""     'isintent_c', 'isintent_callback', 'isintent_copy', 'isintent_dict',\n"", ""     'isintent_hide', 'isintent_in', 'isintent_inout', 'isintent_inplace',\n"", ""     'isintent_nothide', 'isintent_out', 'isintent_overwrite', 'islogical',\n""]","[""     'getfortranname', 'getpymethoddef', 'getrestdoc', 'getusercode',\n"", ""     'getusercode1', 'hasbody', 'hascallstatement', 'hascommon',\n"", ""     'hasexternals', 'hasinitvalue', 'hasnote', 'hasresultnote',\n"", ""-    'isallocatable', 'isarray', 'isarrayofstrings', 'iscomplex',\n"", ""     'iscomplexarray', 'iscomplexfunction', 'iscomplexfunction_warn',\n"", ""     'isdouble', 'isdummyroutine', 'isexternal', 'isfunction',\n"", ""-    'isfunction_wrap', 'isint1array', 'isinteger', 'isintent_aux',\n"", ""     'isintent_c', 'isintent_callback', 'isintent_copy', 'isintent_dict',\n"", ""     'isintent_hide', 'isintent_in', 'isintent_inout', 'isintent_inplace',\n"", ""     'isintent_nothide', 'isintent_out', 'isintent_overwrite', 'islogical',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     'islong_doublefunction', 'islong_long', 'islong_longfunction',\n"", ""     'ismodule', 'ismoduleroutine', 'isoptional', 'isprivate', 'isrequired',\n"", ""     'isroutine', 'isscalar', 'issigned_long_longarray', 'isstring',\n"", ""+    'isstringarray', 'isstring_or_stringarray', 'isstringfunction',\n"", ""+    'issubroutine',\n"", ""     'issubroutine_wrap', 'isthreadsafe', 'isunsigned', 'isunsigned_char',\n"", ""     'isunsigned_chararray', 'isunsigned_long_long',\n"", ""     'isunsigned_long_longarray', 'isunsigned_short',\n"", ""     'isunsigned_shortarray', 'l_and', 'l_not', 'l_or', 'outmess',\n"", ""+    'replace', 'show', 'stripcomma', 'throw_error', 'isattr_value'\n"", ' ]\n', ' \n', ' \n']","[""     'islong_doublefunction', 'islong_long', 'islong_longfunction',\n"", ""     'ismodule', 'ismoduleroutine', 'isoptional', 'isprivate', 'isrequired',\n"", ""     'isroutine', 'isscalar', 'issigned_long_longarray', 'isstring',\n"", ""-    'isstringarray', 'isstringfunction', 'issubroutine',\n"", ""     'issubroutine_wrap', 'isthreadsafe', 'isunsigned', 'isunsigned_char',\n"", ""     'isunsigned_chararray', 'isunsigned_long_long',\n"", ""     'isunsigned_long_longarray', 'isunsigned_short',\n"", ""     'isunsigned_shortarray', 'l_and', 'l_not', 'l_or', 'outmess',\n"", ""-    'replace', 'show', 'stripcomma', 'throw_error',\n"", ' ]\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     return 'capi' in debugoptions\n"", ' \n', ' \n', '+def _ischaracter(var):\n', ""+    return 'typespec' in var and var['typespec'] == 'character' and \\\n"", '+           not isexternal(var)\n', '+\n', '+\n', ' def _isstring(var):\n', ""     return 'typespec' in var and var['typespec'] == 'character' and \\\n"", '            not isexternal(var)\n', ' \n', ' \n', '+def ischaracter_or_characterarray(var):\n', ""+    return _ischaracter(var) and 'charselector' not in var\n"", ' \n', ' \n', ' def ischaracter(var):\n', '+    return ischaracter_or_characterarray(var) and not isarray(var)\n', '+\n', '+\n', '+def ischaracterarray(var):\n', '+    return ischaracter_or_characterarray(var) and isarray(var)\n', '+\n', '+\n', '+def isstring_or_stringarray(var):\n', ""+    return _ischaracter(var) and 'charselector' in var\n"", '+\n', '+\n', '+def isstring(var):\n', '+    return isstring_or_stringarray(var) and not isarray(var)\n', ' \n', ' \n', ' def isstringarray(var):\n', '+    return isstring_or_stringarray(var) and isarray(var)\n', ' \n', ' \n', '+def isarrayofstrings(var):  # obsolete?\n', ""     # leaving out '*' for now so that `character*(*) a(m)` and `character\n"", '     # a(m,*)` are treated differently. Luckily `character**` is illegal.\n', ""     return isstringarray(var) and var['dimension'][-1] == '(*)'\n""]","[""     return 'capi' in debugoptions\n"", ' \n', ' \n', ' def _isstring(var):\n', ""     return 'typespec' in var and var['typespec'] == 'character' and \\\n"", '            not isexternal(var)\n', ' \n', ' \n', '-def isstring(var):\n', '-    return _isstring(var) and not isarray(var)\n', ' \n', ' \n', ' def ischaracter(var):\n', ""-    return isstring(var) and 'charselector' not in var\n"", ' \n', ' \n', ' def isstringarray(var):\n', '-    return isarray(var) and _isstring(var)\n', ' \n', ' \n', '-def isarrayofstrings(var):\n', ""     # leaving out '*' for now so that `character*(*) a(m)` and `character\n"", '     # a(m,*)` are treated differently. Luckily `character**` is illegal.\n', ""     return isstringarray(var) and var['dimension'][-1] == '(*)'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             pass\n', ' \n', ' \n', '+def isint1(var):\n', ""+    return var.get('typespec') == 'integer' \\\n"", ""+        and get_kind(var) == '1' and not isarray(var)\n"", '+\n', '+\n', ' def islong_long(var):\n', '     if not isscalar(var):\n', '         return 0\n']","['             pass\n', ' \n', ' \n', ' def islong_long(var):\n', '     if not isscalar(var):\n', '         return 0\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return 0\n', '     return issubroutine(rout) and hasassumedshape(rout)\n', ' \n', '+def isattr_value(var):\n', ""+    return 'value' in var.get('attrspec', [])\n"", '+\n', ' \n', ' def hasassumedshape(rout):\n', ""     if rout.get('hasassumedshape'):\n""]","['         return 0\n', '     return issubroutine(rout) and hasassumedshape(rout)\n', ' \n', ' \n', ' def hasassumedshape(rout):\n', ""     if rout.get('hasassumedshape'):\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             ('out' in var['intent'] and 'in' not in var['intent'] and\n"", '                 (not l_or(isintent_inout, isintent_inplace)(var)))))\n', ' \n', '+\n', ' def isintent_nothide(var):\n', '     return not isintent_hide(var)\n', ' \n']","[""             ('out' in var['intent'] and 'in' not in var['intent'] and\n"", '                 (not l_or(isintent_inout, isintent_inplace)(var)))))\n', ' \n', ' def isintent_nothide(var):\n', '     return not isintent_hide(var)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' def isintent_aligned16(var):\n', ""     return 'aligned16' in var.get('intent', [])\n"", ' \n', '+\n', "" isintent_dict = {isintent_in: 'INTENT_IN', isintent_inout: 'INTENT_INOUT',\n"", ""                  isintent_out: 'INTENT_OUT', isintent_hide: 'INTENT_HIDE',\n"", ""                  isintent_cache: 'INTENT_CACHE',\n""]","[' def isintent_aligned16(var):\n', ""     return 'aligned16' in var.get('intent', [])\n"", ' \n', "" isintent_dict = {isintent_in: 'INTENT_IN', isintent_inout: 'INTENT_INOUT',\n"", ""                  isintent_out: 'INTENT_OUT', isintent_hide: 'INTENT_HIDE',\n"", ""                  isintent_cache: 'INTENT_CACHE',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def l_and(*f):\n', ""+    l1, l2 = 'lambda v', []\n"", '     for i in range(len(f)):\n', ""+        l1 = '%s,f%d=f[%d]' % (l1, i, i)\n"", ""         l2.append('f%d(v)' % (i))\n"", ""+    return eval('%s:%s' % (l1, ' and '.join(l2)))\n"", ' \n', ' \n', ' def l_or(*f):\n', ""+    l1, l2 = 'lambda v', []\n"", '     for i in range(len(f)):\n', ""+        l1 = '%s,f%d=f[%d]' % (l1, i, i)\n"", ""         l2.append('f%d(v)' % (i))\n"", ""+    return eval('%s:%s' % (l1, ' or '.join(l2)))\n"", ' \n', ' \n', ' def l_not(f):\n']","[' \n', ' \n', ' def l_and(*f):\n', ""-    l, l2 = 'lambda v', []\n"", '     for i in range(len(f)):\n', ""-        l = '%s,f%d=f[%d]' % (l, i, i)\n"", ""         l2.append('f%d(v)' % (i))\n"", ""-    return eval('%s:%s' % (l, ' and '.join(l2)))\n"", ' \n', ' \n', ' def l_or(*f):\n', ""-    l, l2 = 'lambda v', []\n"", '     for i in range(len(f)):\n', ""-        l = '%s,f%d=f[%d]' % (l, i, i)\n"", ""         l2.append('f%d(v)' % (i))\n"", ""-    return eval('%s:%s' % (l, ' or '.join(l2)))\n"", ' \n', ' \n', ' def l_not(f):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             elif isstring(var):\n', '                 pass\n', '             else:\n', '+                if not isattr_value(var):\n', ""+                    ctype = ctype + '*'\n"", '+            if ((isstring(var)\n', '+                 or isarrayofstrings(var)  # obsolete?\n', '+                 or isstringarray(var))):\n', ""                 arg_types2.append('size_t')\n"", '         arg_types.append(ctype)\n', ' \n']","['             elif isstring(var):\n', '                 pass\n', '             else:\n', ""-                ctype = ctype + '*'\n"", '-            if isstring(var) or isarrayofstrings(var):\n', ""                 arg_types2.append('size_t')\n"", '         arg_types.append(ctype)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def gentitle(name):\n', '+    ln = (80 - len(name) - 6) // 2\n', ""+    return '/*%s %s %s*/' % (ln * '*', name, ln * '*')\n"", ' \n', ' \n', '+def flatlist(lst):\n', '+    if isinstance(lst, list):\n', '+        return reduce(lambda x, y, f=flatlist: x + f(y), lst, [])\n', '+    return [lst]\n', ' \n', ' \n', ' def stripcomma(s):\n']","[' \n', ' \n', ' def gentitle(name):\n', '-    l = (80 - len(name) - 6) // 2\n', ""-    return '/*%s %s %s*/' % (l * '*', name, l * '*')\n"", ' \n', ' \n', '-def flatlist(l):\n', '-    if isinstance(l, list):\n', '-        return reduce(lambda x, y, f=flatlist: x + f(y), l, [])\n', '-    return [l]\n', ' \n', ' \n', ' def stripcomma(s):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             'complex_double': 'complex',\n"", ""             'complex_long_double': 'complex',          # forced casting\n"", ""             'string': 'string',\n"", ""+            'character': 'bytes',\n"", '             }\n', "" c2capi_map = {'double': 'NPY_DOUBLE',\n"", ""               'float': 'NPY_FLOAT',\n""]","[""             'complex_double': 'complex',\n"", ""             'complex_long_double': 'complex',          # forced casting\n"", ""             'string': 'string',\n"", '             }\n', "" c2capi_map = {'double': 'NPY_DOUBLE',\n"", ""               'float': 'NPY_FLOAT',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""               'complex_float': 'NPY_CFLOAT',\n"", ""               'complex_double': 'NPY_CDOUBLE',\n"", ""               'complex_long_double': 'NPY_CDOUBLE',   # forced casting\n"", ""+              'string': 'NPY_STRING',\n"", ""+              'character': 'NPY_CHAR'}\n"", ' \n', "" # These new maps aren't used anywhere yet, but should be by default\n"", ' #  unless building numeric or numarray extensions.\n']","[""               'complex_float': 'NPY_CFLOAT',\n"", ""               'complex_double': 'NPY_CDOUBLE',\n"", ""               'complex_long_double': 'NPY_CDOUBLE',   # forced casting\n"", ""-              'string': 'NPY_STRING'}\n"", ' \n', "" # These new maps aren't used anywhere yet, but should be by default\n"", ' #  unless building numeric or numarray extensions.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                   'complex_float': 'NPY_CFLOAT',\n"", ""                   'complex_double': 'NPY_CDOUBLE',\n"", ""                   'complex_long_double': 'NPY_CDOUBLE',\n"", ""+                  'string': 'NPY_STRING',\n"", ""+                  'character': 'NPY_STRING'}\n"", ' \n', "" c2pycode_map = {'double': 'd',\n"", ""                 'float': 'f',\n""]","[""                   'complex_float': 'NPY_CFLOAT',\n"", ""                   'complex_double': 'NPY_CDOUBLE',\n"", ""                   'complex_long_double': 'NPY_CDOUBLE',\n"", ""-                  'string':'NPY_STRING'\n"", '-                  }\n', ' \n', "" c2pycode_map = {'double': 'd',\n"", ""                 'float': 'f',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                 'complex_float': 'F',\n"", ""                 'complex_double': 'D',\n"", ""                 'complex_long_double': 'D',               # forced casting\n"", ""+                'string': 'c',\n"", ""+                'character': 'c'\n"", '                 }\n', ' \n', ' if using_newcore:\n']","[""                 'complex_float': 'F',\n"", ""                 'complex_double': 'D',\n"", ""                 'complex_long_double': 'D',               # forced casting\n"", ""-                'string': 'c'\n"", '                 }\n', ' \n', ' if using_newcore:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                     'complex_float': 'F',\n"", ""                     'complex_double': 'D',\n"", ""                     'complex_long_double': 'G',\n"", ""+                    'string': 'S',\n"", ""+                    'character': 'c'}\n"", ' \n', '+# https://docs.python.org/3/c-api/arg.html#building-values\n', '+# c2buildvalue_map is NumPy agnostic, so no need to bother with using_newcore\n', "" c2buildvalue_map = {'double': 'd',\n"", ""                     'float': 'f',\n"", ""                     'char': 'b',\n""]","[""                     'complex_float': 'F',\n"", ""                     'complex_double': 'D',\n"", ""                     'complex_long_double': 'G',\n"", ""-                    'string': 'S'}\n"", ' \n', "" c2buildvalue_map = {'double': 'd',\n"", ""                     'float': 'f',\n"", ""                     'char': 'b',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                     'complex_float': 'N',\n"", ""                     'complex_double': 'N',\n"", ""                     'complex_long_double': 'N',\n"", ""+                    'string': 'y',\n"", ""+                    'character': 'c'}\n"", ' \n', "" f2cmap_all = {'real': {'': 'float', '4': 'float', '8': 'double',\n"", ""                        '12': 'long_double', '16': 'long_double'},\n""]","[""                     'complex_float': 'N',\n"", ""                     'complex_double': 'N',\n"", ""                     'complex_long_double': 'N',\n"", ""-                    'string': 'y'}\n"", ' \n', "" f2cmap_all = {'real': {'': 'float', '4': 'float', '8': 'double',\n"", ""                        '12': 'long_double', '16': 'long_double'},\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""               'double complex': {'': 'complex_double'},\n"", ""               'double precision': {'': 'double'},\n"", ""               'byte': {'': 'char'},\n"", '               }\n', ' \n', ' f2cmap_default = copy.deepcopy(f2cmap_all)\n', ' \n', '+f2cmap_mapped = []\n', ' \n', ' def load_f2cmap_file(f2cmap_file):\n', '     global f2cmap_all\n']","[""               'double complex': {'': 'complex_double'},\n"", ""               'double precision': {'': 'double'},\n"", ""               'byte': {'': 'char'},\n"", ""-              'character': {'': 'string'}\n"", '               }\n', ' \n', ' f2cmap_default = copy.deepcopy(f2cmap_all)\n', ' \n', ' \n', ' def load_f2cmap_file(f2cmap_file):\n', '     global f2cmap_all\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     f2cmap_all[k][k1] = d[k][k1]\n', '                     outmess(\'\\tMapping ""%s(kind=%s)"" to ""%s""\\n\' %\n', '                             (k, k1, d[k][k1]))\n', '+                    f2cmap_mapped.append(d[k][k1])\n', '                 else:\n', '                     errmess(""\\tIgnoring map {\'%s\':{\'%s\':\'%s\'}}: \'%s\' must be in %s\\n"" % (\n', '                         k, k1, d[k][k1], d[k][k1], list(c2py_map.keys())))\n']","['                     f2cmap_all[k][k1] = d[k][k1]\n', '                     outmess(\'\\tMapping ""%s(kind=%s)"" to ""%s""\\n\' %\n', '                             (k, k1, d[k][k1]))\n', '                 else:\n', '                     errmess(""\\tIgnoring map {\'%s\':{\'%s\':\'%s\'}}: \'%s\' must be in %s\\n"" % (\n', '                         k, k1, d[k][k1], d[k][k1], list(c2py_map.keys())))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                'complex_float': '(%g,%g)',\n"", ""                'complex_double': '(%g,%g)',\n"", ""                'complex_long_double': '(%Lg,%Lg)',\n"", '+               \'string\': \'\\\\""%s\\\\""\',\n', '+               \'character\': ""\'%c\'"",\n', '                }\n', ' \n', ' # Auxiliary functions\n']","[""                'complex_float': '(%g,%g)',\n"", ""                'complex_double': '(%g,%g)',\n"", ""                'complex_long_double': '(%Lg,%Lg)',\n"", ""-               'string': '%s',\n"", '                }\n', ' \n', ' # Auxiliary functions\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             errmess('getctype: function %s has no return value?!\\n' % a)\n"", '     elif issubroutine(var):\n', '         return ctype\n', '+    elif ischaracter_or_characterarray(var):\n', ""+        return 'character'\n"", '+    elif isstring_or_stringarray(var):\n', ""+        return 'string'\n"", ""     elif 'typespec' in var and var['typespec'].lower() in f2cmap_all:\n"", ""         typespec = var['typespec'].lower()\n"", '         f2cmap = f2cmap_all[typespec]\n']","[""             errmess('getctype: function %s has no return value?!\\n' % a)\n"", '     elif issubroutine(var):\n', '         return ctype\n', ""     elif 'typespec' in var and var['typespec'].lower() in f2cmap_all:\n"", ""         typespec = var['typespec'].lower()\n"", '         f2cmap = f2cmap_all[typespec]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return ctype\n', ' \n', ' \n', '+def f2cexpr(expr):\n', '+    """"""Rewrite Fortran expression as f2py supported C expression.\n', '+\n', '+    Due to the lack of a proper expression parser in f2py, this\n', '+    function uses a heuristic approach that assumes that Fortran\n', '+    arithmetic expressions are valid C arithmetic expressions when\n', '+    mapping Fortran function calls to the corresponding C function/CPP\n', '+    macros calls.\n', '+\n', '+    """"""\n', '+    # TODO: support Fortran `len` function with optional kind parameter\n', ""+    expr = re.sub(r'\\blen\\b', 'f2py_slen', expr)\n"", '+    return expr\n', '+\n', '+\n', ' def getstrlength(var):\n', '     if isstringfunction(var):\n', ""         if 'result' in var:\n""]","['     return ctype\n', ' \n', ' \n', ' def getstrlength(var):\n', '     if isstringfunction(var):\n', ""         if 'result' in var:\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         if '*' in a:\n"", ""             len = a['*']\n"", ""         elif 'len' in a:\n"", ""+            len = f2cexpr(a['len'])\n"", ""     if re.match(r'\\(\\s*(\\*|:)\\s*\\)', len) or re.match(r'(\\*|:)', len):\n"", '         if isintent_hide(var):\n', ""             errmess('getstrlength:intent(hide): expected a string with defined length but got: %s\\n' % (\n""]","[""         if '*' in a:\n"", ""             len = a['*']\n"", ""         elif 'len' in a:\n"", ""-            len = a['len']\n"", ""     if re.match(r'\\(\\s*(\\*|:)\\s*\\)', len) or re.match(r'(\\*|:)', len):\n"", '         if isintent_hide(var):\n', ""             errmess('getstrlength:intent(hide): expected a string with defined length but got: %s\\n' % (\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return init, showinit\n', ' \n', ' \n', '+def get_elsize(var):\n', '+    if isstring(var) or isstringarray(var):\n', '+        elsize = getstrlength(var)\n', '+        # override with user-specified length when available:\n', ""+        elsize = var['charselector'].get('f2py_len', elsize)\n"", '+        return elsize\n', '+    if ischaracter(var) or ischaracterarray(var):\n', ""+        return '1'\n"", '+    # for numerical types, PyArray_New* functions ignore specified\n', '+    # elsize, so we just return 1 and let elsize be determined at\n', '+    # runtime, see fortranobject.c\n', ""+    return '1'\n"", '+\n', '+\n', ' def sign2map(a, var):\n', '     """"""\n', '     varname,ctype,atype\n']","['     return init, showinit\n', ' \n', ' \n', ' def sign2map(a, var):\n', '     """"""\n', '     varname,ctype,atype\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         dim = copy.copy(var['dimension'])\n"", ""     if ret['ctype'] in c2capi_map:\n"", ""         ret['atype'] = c2capi_map[ret['ctype']]\n"", ""+        ret['elsize'] = get_elsize(var)\n"", '     # Debug info\n', '     if debugcapi(var):\n', ""         il = [isintent_in, 'input', isintent_out, 'output',\n""]","[""         dim = copy.copy(var['dimension'])\n"", ""     if ret['ctype'] in c2capi_map:\n"", ""         ret['atype'] = c2capi_map[ret['ctype']]\n"", '     # Debug info\n', '     if debugcapi(var):\n', ""         il = [isintent_in, 'input', isintent_out, 'output',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     ret['ctype'] = getctype(var)\n"", ""     if ret['ctype'] in c2capi_map:\n"", ""         ret['atype'] = c2capi_map[ret['ctype']]\n"", ""+        ret['elsize'] = get_elsize(var)\n"", ""     if ret['ctype'] in cformat_map:\n"", ""         ret['showvalueformat'] = '%s' % (cformat_map[ret['ctype']])\n"", '     if isarray(var):\n']","[""     ret['ctype'] = getctype(var)\n"", ""     if ret['ctype'] in c2capi_map:\n"", ""         ret['atype'] = c2capi_map[ret['ctype']]\n"", ""     if ret['ctype'] in cformat_map:\n"", ""         ret['showvalueformat'] = '%s' % (cformat_map[ret['ctype']])\n"", '     if isarray(var):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         ret['ctype'] = 'char'\n"", ""     if ret['ctype'] in c2capi_map:\n"", ""         ret['atype'] = c2capi_map[ret['ctype']]\n"", ""+        ret['elsize'] = get_elsize(var)\n"", ""     if ret['ctype'] in cformat_map:\n"", ""         ret['showvalueformat'] = '%s' % (cformat_map[ret['ctype']])\n"", '     if isarray(var):\n']","[""         ret['ctype'] = 'char'\n"", ""     if ret['ctype'] in c2capi_map:\n"", ""         ret['atype'] = c2capi_map[ret['ctype']]\n"", ""     if ret['ctype'] in cformat_map:\n"", ""         ret['showvalueformat'] = '%s' % (cformat_map[ret['ctype']])\n"", '     if isarray(var):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                  {debugcapi: 'CFUNCSMESS'}, 'string.h'],\n"", ""         '_check': l_and(isstring, isintent_out)\n"", '     }, {\n', ""+        'pyobjfrom': [\n"", '+            {debugcapi:\n', '+             (\'    fprintf(stderr,""debug-capi:cb:#varname#=#showvalueformat#:\'\n', '+              \'%d:\\\\n"",#varname_i#,#varname_i#_cb_len);\')},\n', '+            {isintent_in: """"""\\\n', '     if (cb->nofargs>capi_i)\n', '         if (CAPI_ARGLIST_SETITEM(capi_i++,pyobj_from_#ctype#1size(#varname_i#,#varname_i#_cb_len)))\n', '             goto capi_fail;""""""},\n']","[""                  {debugcapi: 'CFUNCSMESS'}, 'string.h'],\n"", ""         '_check': l_and(isstring, isintent_out)\n"", '     }, {\n', '-        \'pyobjfrom\': [{debugcapi: \'    fprintf(stderr,""debug-capi:cb:#varname#=\\\\""#showvalueformat#\\\\"":%d:\\\\n"",#varname_i#,#varname_i#_cb_len);\'},\n', '-                      {isintent_in: """"""\\\n', '     if (cb->nofargs>capi_i)\n', '         if (CAPI_ARGLIST_SETITEM(capi_i++,pyobj_from_#ctype#1size(#varname_i#,#varname_i#_cb_len)))\n', '             goto capi_fail;""""""},\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         \'pyobjfrom\': [{debugcapi: \'    fprintf(stderr,""debug-capi:cb:#varname#\\\\n"");\'},\n', '                       {isintent_c: """"""\\\n', '     if (cb->nofargs>capi_i) {\n', '+        /* tmp_arr will be inserted to capi_arglist_list that will be\n', '+           destroyed when leaving callback function wrapper together\n', '+           with tmp_arr. */\n', '+        PyArrayObject *tmp_arr = (PyArrayObject *)PyArray_New(&PyArray_Type,\n', '+          #rank#,#varname_i#_Dims,#atype#,NULL,(char*)#varname_i#,#elsize#,\n', '+          NPY_ARRAY_CARRAY,NULL);\n', ' """""",\n', '                        l_not(isintent_c): """"""\\\n', '     if (cb->nofargs>capi_i) {\n', '+        /* tmp_arr will be inserted to capi_arglist_list that will be\n', '+           destroyed when leaving callback function wrapper together\n', '+           with tmp_arr. */\n', '+        PyArrayObject *tmp_arr = (PyArrayObject *)PyArray_New(&PyArray_Type,\n', '+          #rank#,#varname_i#_Dims,#atype#,NULL,(char*)#varname_i#,#elsize#,\n', '+          NPY_ARRAY_FARRAY,NULL);\n', ' """""",\n', '                        },\n', '                       """"""\n']","['         \'pyobjfrom\': [{debugcapi: \'    fprintf(stderr,""debug-capi:cb:#varname#\\\\n"");\'},\n', '                       {isintent_c: """"""\\\n', '     if (cb->nofargs>capi_i) {\n', '-        int itemsize_ = #atype# == NPY_STRING ? 1 : 0;\n', '-        /*XXX: Hmm, what will destroy this array??? */\n', '-        PyArrayObject *tmp_arr = (PyArrayObject *)PyArray_New(&PyArray_Type,#rank#,#varname_i#_Dims,#atype#,NULL,(char*)#varname_i#,itemsize_,NPY_ARRAY_CARRAY,NULL);\n', ' """""",\n', '                        l_not(isintent_c): """"""\\\n', '     if (cb->nofargs>capi_i) {\n', '-        int itemsize_ = #atype# == NPY_STRING ? 1 : 0;\n', '-        /*XXX: Hmm, what will destroy this array??? */\n', '-        PyArrayObject *tmp_arr = (PyArrayObject *)PyArray_New(&PyArray_Type,#rank#,#varname_i#_Dims,#atype#,NULL,(char*)#varname_i#,itemsize_,NPY_ARRAY_FARRAY,NULL);\n', ' """""",\n', '                        },\n', '                       """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" typedefs['complex_float'] = 'typedef struct {float r,i;} complex_float;'\n"", "" typedefs['complex_double'] = 'typedef struct {double r,i;} complex_double;'\n"", ' typedefs[\'string\'] = """"""typedef char * string;""""""\n', '+typedefs[\'character\'] = """"""typedef char character;""""""\n', ' \n', ' \n', ' ############### CPP macros ####################\n']","["" typedefs['complex_float'] = 'typedef struct {float r,i;} complex_float;'\n"", "" typedefs['complex_double'] = 'typedef struct {double r,i;} complex_double;'\n"", ' typedefs[\'string\'] = """"""typedef char * string;""""""\n', ' \n', ' \n', ' ############### CPP macros ####################\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' #define MIN(a,b) ((a < b) ? (a) : (b))\n', ' #endif\n', ' """"""\n', ' cppmacros[\'len..\'] = """"""\\\n', '+/* See fortranobject.h for definitions. The macros here are provided for BC. */\n', '+#define rank f2py_rank\n', '+#define shape f2py_shape\n', '+#define fshape f2py_shape\n', '+#define len f2py_len\n', '+#define flen f2py_flen\n', '+#define slen f2py_slen\n', '+#define size f2py_size\n', ' """"""\n', ' cppmacros[\n', ""     'pyobj_from_char1'] = '#define pyobj_from_char1(v) (PyLong_FromLong(v))'\n"", ' cppmacros[\n']","[' #define MIN(a,b) ((a < b) ? (a) : (b))\n', ' #endif\n', ' """"""\n', ""-needs['len..'] = ['f2py_size']\n"", ' cppmacros[\'len..\'] = """"""\\\n', '-#define rank(var) var ## _Rank\n', '-#define shape(var,dim) var ## _Dims[dim]\n', '-#define old_rank(var) (PyArray_NDIM((PyArrayObject *)(capi_ ## var ## _tmp)))\n', '-#define old_shape(var,dim) PyArray_DIM(((PyArrayObject *)(capi_ ## var ## _tmp)),dim)\n', '-#define fshape(var,dim) shape(var,rank(var)-dim-1)\n', '-#define len(var) shape(var,0)\n', '-#define flen(var) fshape(var,0)\n', '-#define old_size(var) PyArray_SIZE((PyArrayObject *)(capi_ ## var ## _tmp))\n', '-/* #define index(i) capi_i ## i */\n', '-#define slen(var) capi_ ## var ## _len\n', '-#define size(var, ...) f2py_size((PyArrayObject *)(capi_ ## var ## _tmp), ## __VA_ARGS__, -1)\n', ' """"""\n', ""-needs['f2py_size'] = ['stdarg.h']\n"", '-cfuncs[\'f2py_size\'] = """"""\\\n', '-static int f2py_size(PyArrayObject* var, ...)\n', '-{\n', '-  npy_int sz = 0;\n', '-  npy_int dim;\n', '-  npy_int rank;\n', '-  va_list argp;\n', '-  va_start(argp, var);\n', '-  dim = va_arg(argp, npy_int);\n', '-  if (dim==-1)\n', '-    {\n', '-      sz = PyArray_SIZE(var);\n', '-    }\n', '-  else\n', '-    {\n', '-      rank = PyArray_NDIM(var);\n', '-      if (dim>=1 && dim<=rank)\n', '-        sz = PyArray_DIM(var, dim-1);\n', '-      else\n', '-        fprintf(stderr, \\""f2py_size: 2nd argument value=%d fails to satisfy 1<=value<=%d. Result will be 0.\\\\n\\"", dim, rank);\n', '-    }\n', '-  va_end(argp);\n', '-  return sz;\n', '-}\n', '-""""""\n', '-\n', ' cppmacros[\n', ""     'pyobj_from_char1'] = '#define pyobj_from_char1(v) (PyLong_FromLong(v))'\n"", ' cppmacros[\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['       && (__STDC_VERSION__ >= 201112L) \\\\\n', '       && !defined(__STDC_NO_THREADS__) \\\\\n', '       && (!defined(__GLIBC__) || __GLIBC__ > 2 || (__GLIBC__ == 2 && __GLIBC_MINOR__ > 12)) \\\\\n', '+      && !defined(NPY_OS_OPENBSD) && !defined(NPY_OS_HAIKU)\n', ' /* __STDC_NO_THREADS__ was first defined in a maintenance release of glibc 2.12,\n', '    see https://lists.gnu.org/archive/html/commit-hurd/2012-07/msg00180.html,\n', '    so `!defined(__STDC_NO_THREADS__)` may give false positive for the existence\n']","['       && (__STDC_VERSION__ >= 201112L) \\\\\n', '       && !defined(__STDC_NO_THREADS__) \\\\\n', '       && (!defined(__GLIBC__) || __GLIBC__ > 2 || (__GLIBC__ == 2 && __GLIBC_MINOR__ > 12)) \\\\\n', '-      && !defined(NPY_OS_OPENBSD)\n', ' /* __STDC_NO_THREADS__ was first defined in a maintenance release of glibc 2.12,\n', '    see https://lists.gnu.org/archive/html/commit-hurd/2012-07/msg00180.html,\n', '    so `!defined(__STDC_NO_THREADS__)` may give false positive for the existence\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' }\n', ' """"""\n', ' \n', '+cfuncs[\'character_from_pyobj\'] = """"""\\\n', '+static int\n', '+character_from_pyobj(character* v, PyObject *obj, const char *errmess) {\n', '+    if (PyBytes_Check(obj)) {\n', '+        /* empty bytes has trailing null, so dereferencing is always safe */\n', '+        *v = PyBytes_AS_STRING(obj)[0];\n', '+        return 1;\n', '+    } else if (PyUnicode_Check(obj)) {\n', '+        PyObject* tmp = PyUnicode_AsASCIIString(obj);\n', '+        if (tmp != NULL) {\n', '+            *v = PyBytes_AS_STRING(tmp)[0];\n', '+            Py_DECREF(tmp);\n', '+            return 1;\n', '+        }\n', '+    } else if (PyArray_Check(obj)) {\n', '+        PyArrayObject* arr = (PyArrayObject*)obj;\n', '+        if (F2PY_ARRAY_IS_CHARACTER_COMPATIBLE(arr)) {\n', '+            *v = PyArray_BYTES(arr)[0];\n', '+            return 1;\n', '+        } else if (F2PY_IS_UNICODE_ARRAY(arr)) {\n', '+            // TODO: update when numpy will support 1-byte and\n', '+            // 2-byte unicode dtypes\n', '+            PyObject* tmp = PyUnicode_FromKindAndData(\n', '+                              PyUnicode_4BYTE_KIND,\n', '+                              PyArray_BYTES(arr),\n', '+                              (PyArray_NBYTES(arr)>0?1:0));\n', '+            if (tmp != NULL) {\n', '+                if (character_from_pyobj(v, tmp, errmess)) {\n', '+                    Py_DECREF(tmp);\n', '+                    return 1;\n', '+                }\n', '+                Py_DECREF(tmp);\n', '+            }\n', '+        }\n', '+    } else if (PySequence_Check(obj)) {\n', '+        PyObject* tmp = PySequence_GetItem(obj,0);\n', '+        if (tmp != NULL) {\n', '+            if (character_from_pyobj(v, tmp, errmess)) {\n', '+                Py_DECREF(tmp);\n', '+                return 1;\n', '+            }\n', '+            Py_DECREF(tmp);\n', '+        }\n', '+    }\n', '+    {\n', '+        char mess[F2PY_MESSAGE_BUFFER_SIZE];\n', '+        strcpy(mess, errmess);\n', '+        PyObject* err = PyErr_Occurred();\n', '+        if (err == NULL) {\n', '+            err = PyExc_TypeError;\n', '+        }\n', '+        sprintf(mess + strlen(mess),\n', '+                "" -- expected str|bytes|sequence-of-str-or-bytes, got "");\n', '+        f2py_describe(obj, mess + strlen(mess));\n', '+        PyErr_SetString(err, mess);\n', '+    }\n', '+    return 0;\n', '+}\n', '+""""""\n', '+\n', "" needs['char_from_pyobj'] = ['int_from_pyobj']\n"", ' cfuncs[\'char_from_pyobj\'] = """"""\\\n', ' static int\n']","[' }\n', ' """"""\n', ' \n', "" needs['char_from_pyobj'] = ['int_from_pyobj']\n"", ' cfuncs[\'char_from_pyobj\'] = """"""\\\n', ' static int\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return 1;\n', '     }\n', '     if (PyArray_CheckScalar(obj)) { /* 0-dim array or still array scalar */\n', '+        PyArrayObject *arr;\n', '         if (PyArray_Check(obj)) {\n', '+            arr = (PyArrayObject *)PyArray_Cast((PyArrayObject *)obj, NPY_CDOUBLE);\n', '         }\n', '         else {\n', '+            arr = (PyArrayObject *)PyArray_FromScalar(obj, PyArray_DescrFromType(NPY_CDOUBLE));\n', '         }\n', '         if (arr == NULL) {\n', '             return 0;\n']","['         return 1;\n', '     }\n', '     if (PyArray_CheckScalar(obj)) { /* 0-dim array or still array scalar */\n', '-        PyObject *arr;\n', '         if (PyArray_Check(obj)) {\n', '-            arr = PyArray_Cast((PyArrayObject *)obj, NPY_CDOUBLE);\n', '         }\n', '         else {\n', '-            arr = PyArray_FromScalar(obj, PyArray_DescrFromType(NPY_CDOUBLE));\n', '         }\n', '         if (arr == NULL) {\n', '             return 0;\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' """"""\n', ' \n', ' \n', '+cfuncs[\'try_pyarr_from_character\'] = """"""\\\n', '+static int try_pyarr_from_character(PyObject* obj, character* v) {\n', '+    PyArrayObject *arr = (PyArrayObject*)obj;\n', '+    if (!obj) return -2;\n', '+    if (PyArray_Check(obj)) {\n', '+        if (F2PY_ARRAY_IS_CHARACTER_COMPATIBLE(arr))  {\n', '+            *(character *)(PyArray_DATA(arr)) = *v;\n', '+            return 1;\n', '+        }\n', '+    }\n', '+    {\n', '+        char mess[F2PY_MESSAGE_BUFFER_SIZE];\n', '+        PyObject* err = PyErr_Occurred();\n', '+        if (err == NULL) {\n', '+            err = PyExc_ValueError;\n', '+            strcpy(mess, ""try_pyarr_from_character failed""\n', '+                         "" -- expected bytes array-scalar|array, got "");\n', '+            f2py_describe(obj, mess + strlen(mess));\n', '+        }\n', '+        PyErr_SetString(err, mess);\n', '+    }\n', '+    return 0;\n', '+}\n', '+""""""\n', '+\n', "" needs['try_pyarr_from_char'] = ['pyobj_from_char1', 'TRYPYARRAYTEMPLATE']\n"", ' cfuncs[\n', ""     'try_pyarr_from_char'] = 'static int try_pyarr_from_char(PyObject* obj,char* v) {\\n    TRYPYARRAYTEMPLATE(char,\\'c\\');\\n}\\n'\n""]","[' """"""\n', ' \n', ' \n', "" needs['try_pyarr_from_char'] = ['pyobj_from_char1', 'TRYPYARRAYTEMPLATE']\n"", ' cfuncs[\n', ""     'try_pyarr_from_char'] = 'static int try_pyarr_from_char(PyObject* obj,char* v) {\\n    TRYPYARRAYTEMPLATE(char,\\'c\\');\\n}\\n'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             if (xa != NULL)\n', '                 ext = PyTuple_Size((PyObject *)xa);\n', '             if(ext>0) {\n', '+                fprintf(stderr,\\""extra arguments tuple cannot be used with PyCapsule call-back\\\\n\\"");\n', '                 goto capi_fail;\n', '             }\n', '             tmp_fun = fun;\n']","['             if (xa != NULL)\n', '                 ext = PyTuple_Size((PyObject *)xa);\n', '             if(ext>0) {\n', '-                fprintf(stderr,\\""extra arguments tuple cannot be used with CObject call-back\\\\n\\"");\n', '                 goto capi_fail;\n', '             }\n', '             tmp_fun = fun;\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         idims = []\n', '         for n in inames:\n', '             ct = capi_maps.getctype(vars[n])\n', '+            elsize = capi_maps.get_elsize(vars[n])\n', '             at = capi_maps.c2capi_map[ct]\n', '             dm = capi_maps.getarrdims(n, vars[n])\n', ""             if dm['dims']:\n""]","['         idims = []\n', '         for n in inames:\n', '             ct = capi_maps.getctype(vars[n])\n', '             at = capi_maps.c2capi_map[ct]\n', '             dm = capi_maps.getarrdims(n, vars[n])\n', ""             if dm['dims']:\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             dms = dm['dims'].strip()\n"", '             if not dms:\n', ""                 dms = '-1'\n"", '+            cadd(\'\\t{\\""%s\\"",%s,{{%s}},%s, %s},\'\n', ""+                 % (n, dm['rank'], dms, at, elsize))\n"", ""         cadd('\\t{NULL}\\n};')\n"", '         inames1 = rmbadname(inames)\n', ""         inames1_tps = ','.join(['char *' + s for s in inames1])\n""]","[""             dms = dm['dims'].strip()\n"", '             if not dms:\n', ""                 dms = '-1'\n"", '-            cadd(\'\\t{\\""%s\\"",%s,{{%s}},%s},\' % (n, dm[\'rank\'], dms, at))\n', ""         cadd('\\t{NULL}\\n};')\n"", '         inames1 = rmbadname(inames)\n', ""         inames1_tps = ','.join(['char *' + s for s in inames1])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['              % (F_FUNC, lower_name, name.upper(), name))\n', ""         cadd('}\\n')\n"", ""         iadd('\\ttmp = PyFortranObject_New(f2py_%s_def,f2py_init_%s);' % (name, name))\n"", ""+        iadd('\\tif (tmp == NULL) return NULL;')\n"", '+        iadd(\'\\tif (F2PyDict_SetItemString(d, \\""%s\\"", tmp) == -1) return NULL;\'\n', '+             % name)\n', ""         iadd('\\tPy_DECREF(tmp);')\n"", ""         tname = name.replace('_', '\\\\_')\n"", ""         dadd('\\\\subsection{Common block \\\\texttt{%s}}\\n' % (tname))\n""]","['              % (F_FUNC, lower_name, name.upper(), name))\n', ""         cadd('}\\n')\n"", ""         iadd('\\ttmp = PyFortranObject_New(f2py_%s_def,f2py_init_%s);' % (name, name))\n"", '-        iadd(\'\\tF2PyDict_SetItemString(d, \\""%s\\"", tmp);\' % name)\n', ""         iadd('\\tPy_DECREF(tmp);')\n"", ""         tname = name.replace('_', '\\\\_')\n"", ""         dadd('\\\\subsection{Common block \\\\texttt{%s}}\\n' % (tname))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                        'optional','required', etc)\n"", ""      K = D['kindselector'] = {['*','kind']} (only if D['typespec'] =\n"", ""                          'complex' | 'integer' | 'logical' | 'real' )\n"", ""+     C = D['charselector'] = {['*','len','kind','f2py_len']}\n"", ""                              (only if D['typespec']=='character')\n"", ""      D['='] --- initialization expression string\n"", ""      D['typename'] --- name of the type if D['typespec']=='type'\n""]","[""                        'optional','required', etc)\n"", ""      K = D['kindselector'] = {['*','kind']} (only if D['typespec'] =\n"", ""                          'complex' | 'integer' | 'logical' | 'real' )\n"", ""-     C = D['charselector'] = {['*','len','kind']}\n"", ""                              (only if D['typespec']=='character')\n"", ""      D['='] --- initialization expression string\n"", ""      D['typename'] --- name of the type if D['typespec']=='type'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""      D['typespec>']*K['*']\n"", ""      D['typespec'](kind=K['kind'])\n"", ""      character*C['*']\n"", ""+     character(len=C['len'],kind=C['kind'], f2py_len=C['f2py_len'])\n"", '      (see also fortran type declaration statement formats below)\n', ' \n', ' Fortran 90 type declaration statement format (F77 is subset of F90)\n']","[""      D['typespec>']*K['*']\n"", ""      D['typespec'](kind=K['kind'])\n"", ""      character*C['*']\n"", ""-     character(len=C['len'],kind=C['kind'])\n"", '      (see also fortran type declaration statement formats below)\n', ' \n', ' Fortran 90 type declaration statement format (F77 is subset of F90)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import os\n', ' import copy\n', ' import platform\n', '+import codecs\n', '+try:\n', '+    import chardet\n', '+except ImportError:\n', '+    chardet = None\n', ' \n', ' from . import __version__\n', ' \n']","[' import os\n', ' import copy\n', ' import platform\n', ' \n', ' from . import __version__\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"["" _free_f90_start = re.compile(r'[^c*]\\s*[^\\s\\d\\t]', re.I).match\n"", ' \n', ' \n', '+def openhook(filename, mode):\n', '+    """"""Ensures that filename is opened with correct encoding parameter.\n', '+\n', '+    This function uses chardet package, when available, for\n', '+    determining the encoding of the file to be opened. When chardet is\n', '+    not available, the function detects only UTF encodings, otherwise,\n', '+    ASCII encoding is used as fallback.\n', '+    """"""\n', '+    bytes = min(32, os.path.getsize(filename))\n', ""+    with open(filename, 'rb') as f:\n"", '+        raw = f.read(bytes)\n', '+    if raw.startswith(codecs.BOM_UTF8):\n', ""+        encoding = 'UTF-8-SIG'\n"", '+    elif raw.startswith((codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE)):\n', ""+        encoding = 'UTF-32'\n"", '+    elif raw.startswith((codecs.BOM_LE, codecs.BOM_BE)):\n', ""+        encoding = 'UTF-16'\n"", '+    else:\n', '+        if chardet is not None:\n', ""+            encoding = chardet.detect(raw)['encoding']\n"", '+        else:\n', '+            # hint: install chardet to ensure correct encoding handling\n', ""+            encoding = 'ascii'\n"", '+    return open(filename, mode, encoding=encoding)\n', '+\n', '+\n', ' def is_free_format(file):\n', '     """"""Check if file is in free format Fortran.""""""\n', '     # f90 allows both fixed and free format, assuming fixed unless\n', '     # signs of free format are detected.\n', '     result = 0\n', ""+    with openhook(file, 'r') as f:\n"", '         line = f.readline()\n', '         n = 15  # the number of non-comment lines to scan for hints\n', '         if _has_f_header(line):\n']","["" _free_f90_start = re.compile(r'[^c*]\\s*[^\\s\\d\\t]', re.I).match\n"", ' \n', ' \n', ' def is_free_format(file):\n', '     """"""Check if file is in free format Fortran.""""""\n', '     # f90 allows both fixed and free format, assuming fixed unless\n', '     # signs of free format are detected.\n', '     result = 0\n', ""-    with open(file, 'r') as f:\n"", '         line = f.readline()\n', '         n = 15  # the number of non-comment lines to scan for hints\n', '         if _has_f_header(line):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     ll, l1 = '', ''\n"", ""     spacedigits = [' '] + [str(_m) for _m in range(10)]\n"", ""     filepositiontext = ''\n"", '+    fin = fileinput.FileInput(ffile, openhook=openhook)\n', '     while True:\n', '+        try:\n', '+            l = fin.readline()\n', '+        except UnicodeDecodeError as msg:\n', '+            raise Exception(\n', ""+                f'readfortrancode: reading {fin.filename()}#{fin.lineno()}'\n"", ""+                f' failed with\\n{msg}.\\nIt is likely that installing chardet'\n"", ""+                ' package will help f2py determine the input file encoding'\n"", ""+                ' correctly.')\n"", '         if not l:\n', '             break\n', '         if fin.isfirstline():\n']","[""     ll, l1 = '', ''\n"", ""     spacedigits = [' '] + [str(_m) for _m in range(10)]\n"", ""     filepositiontext = ''\n"", '-    fin = fileinput.FileInput(ffile)\n', '     while True:\n', '-        l = fin.readline()\n', '         if not l:\n', '             break\n', '         if fin.isfirstline():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' charselector = re.compile(\n', ""     r'\\s*(\\((?P<lenkind>.*)\\)|\\*\\s*(?P<charlen>.*))\\s*\\Z', re.I)\n"", ' lenkindpattern = re.compile(\n', ""+    r'\\s*(kind\\s*=\\s*(?P<kind>.*?)\\s*(@,@\\s*len\\s*=\\s*(?P<len>.*)|)'\n"", ""+    r'|(len\\s*=\\s*|)(?P<len2>.*?)\\s*(@,@\\s*(kind\\s*=\\s*|)(?P<kind2>.*)'\n"", ""+    r'|(f2py_len\\s*=\\s*(?P<f2py_len>.*))|))\\s*\\Z', re.I)\n"", ' lenarraypattern = re.compile(\n', ""     r'\\s*(@\\(@\\s*(?!/)\\s*(?P<array>.*?)\\s*@\\)@\\s*\\*\\s*(?P<len>.*?)|(\\*\\s*(?P<len2>.*?)|)\\s*(@\\(@\\s*(?!/)\\s*(?P<array2>.*?)\\s*@\\)@|))\\s*(=\\s*(?P<init>.*?)|(@\\(@|)/\\s*(?P<init2>.*?)\\s*/(@\\)@|)|)\\s*\\Z', re.I)\n"", ' \n']","[' charselector = re.compile(\n', ""     r'\\s*(\\((?P<lenkind>.*)\\)|\\*\\s*(?P<charlen>.*))\\s*\\Z', re.I)\n"", ' lenkindpattern = re.compile(\n', ""-    r'\\s*(kind\\s*=\\s*(?P<kind>.*?)\\s*(@,@\\s*len\\s*=\\s*(?P<len>.*)|)|(len\\s*=\\s*|)(?P<len2>.*?)\\s*(@,@\\s*(kind\\s*=\\s*|)(?P<kind2>.*)|))\\s*\\Z', re.I)\n"", ' lenarraypattern = re.compile(\n', ""     r'\\s*(@\\(@\\s*(?!/)\\s*(?P<array>.*?)\\s*@\\)@\\s*\\*\\s*(?P<len>.*?)|(\\*\\s*(?P<len2>.*?)|)\\s*(@\\(@\\s*(?!/)\\s*(?P<array2>.*?)\\s*@\\)@|))\\s*(=\\s*(?P<init>.*?)|(@\\(@|)/\\s*(?P<init2>.*?)\\s*/(@\\)@|)|)\\s*\\Z', re.I)\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                         lenkind[lk] = lenkind[lk + '2']\n"", '                     charselect[lk] = lenkind[lk]\n', ""                     del lenkind[lk + '2']\n"", ""+                if lenkind['f2py_len'] is not None:\n"", '+                    # used to specify the length of assumed length strings\n', ""+                    charselect['f2py_len'] = lenkind['f2py_len']\n"", ""             del charselect['lenkind']\n"", '             for k in list(charselect.keys()):\n', '                 if not charselect[k]:\n']","[""                         lenkind[lk] = lenkind[lk + '2']\n"", '                     charselect[lk] = lenkind[lk]\n', ""                     del lenkind[lk + '2']\n"", ""             del charselect['lenkind']\n"", '             for k in list(charselect.keys()):\n', '                 if not charselect[k]:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     if 'charselector' not in decl:\n"", ""         decl['charselector'] = sel\n"", '         return decl\n', '+\n', '     for k in list(sel.keys()):\n', ""         if force or k not in decl['charselector']:\n"", ""             decl['charselector'][k] = sel[k]\n""]","[""     if 'charselector' not in decl:\n"", ""         decl['charselector'] = sel\n"", '         return decl\n', '     for k in list(sel.keys()):\n', ""         if force or k not in decl['charselector']:\n"", ""             decl['charselector'][k] = sel[k]\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             as_ = args\n', ""         b = postcrack(b, as_, tab=tab + '\\t')\n"", ""         if b['block'] in ['interface', 'abstract interface'] and \\\n"", ""+           not b['body'] and not b.get('implementedby'):\n"", ""             if 'f2pyenhancements' not in b:\n"", '                 continue\n', ""         if b['block'].replace(' ', '') == 'pythonmodule':\n""]","['             as_ = args\n', ""         b = postcrack(b, as_, tab=tab + '\\t')\n"", ""         if b['block'] in ['interface', 'abstract interface'] and \\\n"", ""-           not b['body'] and not b['implementedby']:\n"", ""             if 'f2pyenhancements' not in b:\n"", '                 continue\n', ""         if b['block'].replace(' ', '') == 'pythonmodule':\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if _is_kind_number(value):\n', ""         value = value.split('_')[0]\n"", '     try:\n', '+        # TODO: use symbolic from PR #19805\n', '         value = eval(value, {}, params)\n', '         value = (repr if isinstance(value, str) else str)(value)\n', '     except (NameError, SyntaxError, TypeError):\n']","['     if _is_kind_number(value):\n', ""         value = value.split('_')[0]\n"", '     try:\n', '         value = eval(value, {}, params)\n', '         value = (repr if isinstance(value, str) else str)(value)\n', '     except (NameError, SyntaxError, TypeError):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         del vars['']\n"", ""         if 'attrspec' in block['vars']['']:\n"", ""             gen = block['vars']['']['attrspec']\n"", ""+            for n in set(vars) | set(b['name'] for b in block['body']):\n"", ""                 for k in ['public', 'private']:\n"", '                     if k in gen:\n', '+                        vars[n] = setattrspec(vars.get(n, {}), k)\n', '     svars = []\n', ""     args = block['args']\n"", '     for a in args:\n']","[""         del vars['']\n"", ""         if 'attrspec' in block['vars']['']:\n"", ""             gen = block['vars']['']['attrspec']\n"", '-            for n in list(vars.keys()):\n', ""                 for k in ['public', 'private']:\n"", '                     if k in gen:\n', '-                        vars[n] = setattrspec(vars[n], k)\n', '     svars = []\n', ""     args = block['args']\n"", '     for a in args:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                 elif n in block['args']:\n"", ""                     outmess('analyzevars: typespec of variable %s is not defined in routine %s.\\n' % (\n"", ""                         repr(n), block['name']))\n"", ""         if 'charselector' in vars[n]:\n"", ""             if 'len' in vars[n]['charselector']:\n"", ""                 l = vars[n]['charselector']['len']\n""]","[""                 elif n in block['args']:\n"", ""                     outmess('analyzevars: typespec of variable %s is not defined in routine %s.\\n' % (\n"", ""                         repr(n), block['name']))\n"", '-\n', ""         if 'charselector' in vars[n]:\n"", ""             if 'len' in vars[n]['charselector']:\n"", ""                 l = vars[n]['charselector']['len']\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                         dimension_exprs[d] = solver_and_deps\n', ""                     vars[n]['dimension'].append(d)\n"", ' \n', ""         if 'check' not in vars[n] and 'args' in block and n in block['args']:\n"", '             # n is an argument that has no checks defined. Here we\n', '             # generate some consistency checks for n, and when n is an\n']","['                         dimension_exprs[d] = solver_and_deps\n', ""                     vars[n]['dimension'].append(d)\n"", ' \n', ""-        if 'dimension' in vars[n]:\n"", '-            if isstringarray(vars[n]):\n', ""-                if 'charselector' in vars[n]:\n"", ""-                    d = vars[n]['charselector']\n"", ""-                    if '*' in d:\n"", ""-                        d = d['*']\n"", '-                        errmess(\'analyzevars: character array ""character*%s %s(%s)"" is considered as ""character %s(%s)""; ""intent(c)"" is forced.\\n\'\n', '-                                % (d, n,\n', ""-                                   ','.join(vars[n]['dimension']),\n"", ""-                                   n, ','.join(vars[n]['dimension'] + [d])))\n"", ""-                        vars[n]['dimension'].append(d)\n"", ""-                        del vars[n]['charselector']\n"", ""-                        if 'intent' not in vars[n]:\n"", ""-                            vars[n]['intent'] = []\n"", ""-                        if 'c' not in vars[n]['intent']:\n"", ""-                            vars[n]['intent'].append('c')\n"", '-                    else:\n', '-                        errmess(\n', '-                            ""analyzevars: charselector=%r unhandled.\\n"" % (d))\n', '-\n', ""         if 'check' not in vars[n] and 'args' in block and n in block['args']:\n"", '             # n is an argument that has no checks defined. Here we\n', '             # generate some consistency checks for n, and when n is an\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         if 'attrspec' in vars[a]:\n"", ""             attr = [l for l in vars[a]['attrspec']\n"", ""                     if l not in ['external']]\n"", ""+            if as_interface and 'intent(in)' in attr and 'intent(out)' in attr:\n"", '+                # In Fortran, intent(in, out) are conflicting while\n', '+                # intent(in, out) can be specified only via\n', '+                # `!f2py intent(out) ..`.\n', ""+                # So, for the Fortran interface, we'll drop\n"", '+                # intent(out) to resolve the conflict.\n', ""+                attr.remove('intent(out)')\n"", '             if attr:\n', ""                 vardef = '%s, %s' % (vardef, ','.join(attr))\n"", ""                 c = ','\n""]","[""         if 'attrspec' in vars[a]:\n"", ""             attr = [l for l in vars[a]['attrspec']\n"", ""                     if l not in ['external']]\n"", '             if attr:\n', ""                 vardef = '%s, %s' % (vardef, ','.join(attr))\n"", ""                 c = ','\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' ######\n', ' \n', ' \n', '+# We expose post_processing_hooks as global variable so that\n', '+# user-libraries could register their own hooks to f2py.\n', '+post_processing_hooks = []\n', '+\n', '+\n', ' def crackfortran(files):\n', '+    global usermodules, post_processing_hooks\n', ' \n', ""     outmess('Reading fortran codes...\\n', 0)\n"", '     readfortrancode(files, crackline)\n', ""     outmess('Post-processing...\\n', 0)\n"", '     usermodules = []\n', '     postlist = postcrack(grouplist[0])\n', ""+    outmess('Applying post-processing hooks...\\n', 0)\n"", '+    for hook in post_processing_hooks:\n', ""+        outmess(f'  {hook.__name__}\\n', 0)\n"", '+        postlist = traverse(postlist, hook)\n', ""     outmess('Post-processing (stage 2)...\\n', 0)\n"", '     postlist = postcrack2(postlist)\n', '     return usermodules + postlist\n']","[' ######\n', ' \n', ' \n', ' def crackfortran(files):\n', '-    global usermodules\n', ' \n', ""     outmess('Reading fortran codes...\\n', 0)\n"", '     readfortrancode(files, crackline)\n', ""     outmess('Post-processing...\\n', 0)\n"", '     usermodules = []\n', '     postlist = postcrack(grouplist[0])\n', ""     outmess('Post-processing (stage 2)...\\n', 0)\n"", '     postlist = postcrack2(postlist)\n', '     return usermodules + postlist\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' """""" % (f2py_version)\n', '     return header + pyf + footer\n', ' \n', '+\n', '+def _is_visit_pair(obj):\n', '+    return (isinstance(obj, tuple)\n', '+            and len(obj) == 2\n', '+            and isinstance(obj[0], (int, str)))\n', '+\n', '+\n', '+def traverse(obj, visit, parents=[], result=None, *args, **kwargs):\n', ""+    '''Traverse f2py data structure with the following visit function:\n"", '+\n', '+    def visit(item, parents, result, *args, **kwargs):\n', '+        """"""\n', '+\n', '+        parents is a list of key-""f2py data structure"" pairs from which\n', '+        items are taken from.\n', '+\n', '+        result is a f2py data structure that is filled with the\n', '+        return value of the visit function.\n', '+\n', '+        item is 2-tuple (index, value) if parents[-1][1] is a list\n', '+        item is 2-tuple (key, value) if parents[-1][1] is a dict\n', '+\n', '+        The return value of visit must be None, or of the same kind as\n', '+        item, that is, if parents[-1] is a list, the return value must\n', '+        be 2-tuple (new_index, new_value), or if parents[-1] is a\n', '+        dict, the return value must be 2-tuple (new_key, new_value).\n', '+\n', '+        If new_index or new_value is None, the return value of visit\n', '+        is ignored, that is, it will not be added to the result.\n', '+\n', '+        If the return value is None, the content of obj will be\n', '+        traversed, otherwise not.\n', '+        """"""\n', ""+    '''\n"", '+\n', '+    if _is_visit_pair(obj):\n', ""+        if obj[0] == 'parent_block':\n"", '+            # avoid infinite recursion\n', '+            return obj\n', '+        new_result = visit(obj, parents, result, *args, **kwargs)\n', '+        if new_result is not None:\n', '+            assert _is_visit_pair(new_result)\n', '+            return new_result\n', '+        parent = obj\n', '+        result_key, obj = obj\n', '+    else:\n', '+        parent = (None, obj)\n', '+        result_key = None\n', '+\n', '+    if isinstance(obj, list):\n', '+        new_result = []\n', '+        for index, value in enumerate(obj):\n', '+            new_index, new_item = traverse((index, value), visit,\n', '+                                           parents=parents + [parent],\n', '+                                           result=result, *args, **kwargs)\n', '+            if new_index is not None:\n', '+                new_result.append(new_item)\n', '+    elif isinstance(obj, dict):\n', '+        new_result = dict()\n', '+        for key, value in obj.items():\n', '+            new_key, new_value = traverse((key, value), visit,\n', '+                                          parents=parents + [parent],\n', '+                                          result=result, *args, **kwargs)\n', '+            if new_key is not None:\n', '+                new_result[new_key] = new_value\n', '+    else:\n', '+        new_result = obj\n', '+\n', '+    if result_key is None:\n', '+        return new_result\n', '+    return result_key, new_result\n', '+\n', '+\n', '+def character_backward_compatibility_hook(item, parents, result,\n', '+                                          *args, **kwargs):\n', '+    """"""Previously, Fortran character was incorrectly treated as\n', '+    character*1. This hook fixes the usage of the corresponding\n', '+    variables in `check`, `dimension`, `=`, and `callstatement`\n', '+    expressions.\n', '+\n', '+    The usage of `char*` in `callprotoargument` expression can be left\n', '+    unchanged because C `character` is C typedef of `char`, although,\n', '+    new implementations should use `character*` in the corresponding\n', '+    expressions.\n', '+\n', '+    See https://github.com/numpy/numpy/pull/19388 for more information.\n', '+\n', '+    """"""\n', '+    parent_key, parent_value = parents[-1]\n', '+    key, value = item\n', '+\n', '+    def fix_usage(varname, value):\n', ""+        value = re.sub(r'[*]\\s*\\b' + varname + r'\\b', varname, value)\n"", ""+        value = re.sub(r'\\b' + varname + r'\\b\\s*[\\[]\\s*0\\s*[\\]]',\n"", '+                       varname, value)\n', '+        return value\n', '+\n', ""+    if parent_key in ['dimension', 'check']:\n"", ""+        assert parents[-3][0] == 'vars'\n"", '+        vars_dict = parents[-3][1]\n', ""+    elif key == '=':\n"", ""+        assert parents[-2][0] == 'vars'\n"", '+        vars_dict = parents[-2][1]\n', '+    else:\n', '+        vars_dict = None\n', '+\n', '+    new_value = None\n', '+    if vars_dict is not None:\n', '+        new_value = value\n', '+        for varname, vd in vars_dict.items():\n', '+            if ischaracter(vd):\n', '+                new_value = fix_usage(varname, new_value)\n', ""+    elif key == 'callstatement':\n"", ""+        vars_dict = parents[-2][1]['vars']\n"", '+        new_value = value\n', '+        for varname, vd in vars_dict.items():\n', '+            if ischaracter(vd):\n', '+                # replace all occurrences of `<varname>` with\n', '+                # `&<varname>` in argument passing\n', '+                new_value = re.sub(\n', ""+                    r'(?<![&])\\b' + varname + r'\\b', '&' + varname, new_value)\n"", '+\n', '+    if new_value is not None:\n', '+        if new_value != value:\n', '+            # We report the replacements here so that downstream\n', '+            # software could update their source codes\n', '+            # accordingly. However, such updates are recommended only\n', '+            # when BC with numpy 1.21 or older is not required.\n', ""+            outmess(f'character_bc_hook[{parent_key}.{key}]:'\n"", ""+                    f' replaced `{value}` -> `{new_value}`\\n', 1)\n"", '+        return (key, new_value)\n', '+\n', '+\n', '+post_processing_hooks.append(character_backward_compatibility_hook)\n', '+\n', '+\n', ' if __name__ == ""__main__"":\n', '     files = []\n', '     funcs = []\n']","[' """""" % (f2py_version)\n', '     return header + pyf + footer\n', ' \n', ' if __name__ == ""__main__"":\n', '     files = []\n', '     funcs = []\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             funcs.append(l)\n', '     if not strictf77 and f77modulename and not skipemptyends:\n', '         outmess(""""""\\\n', '+  Warning: You have specified module name for non Fortran 77 code that\n', '+  should not need one (expect if you are scanning F90 code for non\n', '+  module blocks but then you should use flag -skipemptyends and also\n', '+  be sure that the files do not contain programs without program\n', '+  statement).\n', ' """""", 0)\n', ' \n', '     postlist = crackfortran(files)\n', '     if pyffilename:\n', ""         outmess('Writing fortran code to file %s\\n' % repr(pyffilename), 0)\n"", '         pyf = crack2fortran(postlist)\n', ""+        with open(pyffilename, 'w') as f:\n"", '             f.write(pyf)\n', '     if showblocklist:\n', '         show(postlist)\n']","['             funcs.append(l)\n', '     if not strictf77 and f77modulename and not skipemptyends:\n', '         outmess(""""""\\\n', '-  Warning: You have specified module name for non Fortran 77 code\n', '-  that should not need one (expect if you are scanning F90 code\n', '-  for non module blocks but then you should use flag -skipemptyends\n', '-  and also be sure that the files do not contain programs without program statement).\n', ' """""", 0)\n', ' \n', '     postlist = crackfortran(files)\n', '     if pyffilename:\n', ""         outmess('Writing fortran code to file %s\\n' % repr(pyffilename), 0)\n"", '         pyf = crack2fortran(postlist)\n', ""-        with open(pyffilename, 'w') as f: \n"", '             f.write(pyf)\n', '     if showblocklist:\n', '         show(postlist)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 errmess(\n', ""                     'Tip: If your original code is Fortran source then you must use -m option.\\n')\n"", ""             raise TypeError('All blocks must be python module blocks but got %s' % (\n"", ""+                repr(plist['block'])))\n"", ""     auxfuncs.debugoptions = options['debug']\n"", '     f90mod_rules.options = options\n', ""     auxfuncs.wrapfuncs = options['wrapfuncs']\n""]","['                 errmess(\n', ""                     'Tip: If your original code is Fortran source then you must use -m option.\\n')\n"", ""             raise TypeError('All blocks must be python module blocks but got %s' % (\n"", ""-                repr(postlist[i]['block'])))\n"", ""     auxfuncs.debugoptions = options['debug']\n"", '     f90mod_rules.options = options\n', ""     auxfuncs.wrapfuncs = options['wrapfuncs']\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             if not dms:\n', ""                 dms = '-1'\n"", '             use_fgetdims2 = fgetdims2\n', '+            cadd(\'\\t{""%s"",%s,{{%s}},%s, %s},\' %\n', ""+                 (undo_rmbadname1(n), dm['rank'], dms, at,\n"", '+                  capi_maps.get_elsize(var)))\n', ""             dadd('\\\\item[]{{}\\\\verb@%s@{}}' %\n"", '                  (capi_maps.getarrdocsign(n, var)))\n', '             if hasnote(var):\n']","['             if not dms:\n', ""                 dms = '-1'\n"", '             use_fgetdims2 = fgetdims2\n', '-            if isstringarray(var):\n', ""-                if 'charselector' in var and 'len' in var['charselector']:\n"", '-                    cadd(\'\\t{""%s"",%s,{{%s,%s}},%s},\'\n', ""-                         % (undo_rmbadname1(n), dm['rank'], dms, var['charselector']['len'], at))\n"", '-                    use_fgetdims2 = fgetdims2_sa\n', '-                else:\n', '-                    cadd(\'\\t{""%s"",%s,{{%s}},%s},\' %\n', ""-                         (undo_rmbadname1(n), dm['rank'], dms, at))\n"", '-            else:\n', '-                cadd(\'\\t{""%s"",%s,{{%s}},%s},\' %\n', ""-                     (undo_rmbadname1(n), dm['rank'], dms, at))\n"", ""             dadd('\\\\item[]{{}\\\\verb@%s@{}}' %\n"", '                  (capi_maps.getarrdocsign(n, var)))\n', '             if hasnote(var):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                 ar['docs'] = []\n"", ""                 ar['docshort'] = []\n"", '                 ret = dictappend(ret, ar)\n', '+                cadd((\'\\t{""%s"",-1,{{-1}},0,0,NULL,(void *)\'\n', ""+                      'f2py_rout_#modulename#_%s_%s,'\n"", ""+                      'doc_f2py_rout_#modulename#_%s_%s},')\n"", ""+                     % (b['name'], m['name'], b['name'], m['name'], b['name']))\n"", ""                 sargs.append('char *%s' % (b['name']))\n"", ""                 sargsp.append('char *')\n"", ""                 iadd('\\tf2py_%s_def[i_f2py++].data = %s;' %\n""]","[""                 ar['docs'] = []\n"", ""                 ar['docshort'] = []\n"", '                 ret = dictappend(ret, ar)\n', '-                cadd(\'\\t{""%s"",-1,{{-1}},0,NULL,(void *)f2py_rout_#modulename#_%s_%s,doc_f2py_rout_#modulename#_%s_%s},\' %\n', ""-                     (b['name'], m['name'], b['name'], m['name'], b['name']))\n"", ""                 sargs.append('char *%s' % (b['name']))\n"", ""                 sargsp.append('char *')\n"", ""                 iadd('\\tf2py_%s_def[i_f2py++].data = %s;' %\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' Pearu Peterson\n', ' \n', ' """"""\n', ' import copy\n', ' \n', ' from .auxfuncs import (\n']","[' Pearu Peterson\n', ' \n', ' """"""\n', '-__version__ = ""$Revision: 1.16 $""[10:-1]\n', '-\n', ""-f2py_version = 'See `f2py -v`'\n"", '-\n', ' import copy\n', ' \n', ' from .auxfuncs import (\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', ""         args = [newname] + rout['args']\n"", ' \n', ""+    l_tmpl = var2fixfortran(vars, name, '@@@NAME@@@', f90mode)\n"", ""+    if l_tmpl[:13] == 'character*(*)':\n"", '         if f90mode:\n', ""+            l_tmpl = 'character(len=10)' + l_tmpl[13:]\n"", '         else:\n', ""+            l_tmpl = 'character*10' + l_tmpl[13:]\n"", ""         charselect = vars[name]['charselector']\n"", ""         if charselect.get('*', '') == '(*)':\n"", ""             charselect['*'] = '10'\n"", '+\n', ""+    l1 = l_tmpl.replace('@@@NAME@@@', newname)\n"", '+    rl = None\n', '+\n', ""     sargs = ', '.join(args)\n"", '     if f90mode:\n', ""         add('subroutine f2pywrap_%s_%s (%s)' %\n""]","['     else:\n', ""         args = [newname] + rout['args']\n"", ' \n', '-    l = var2fixfortran(vars, name, newname, f90mode)\n', ""-    if l[:13] == 'character*(*)':\n"", '         if f90mode:\n', ""-            l = 'character(len=10)' + l[13:]\n"", '         else:\n', ""-            l = 'character*10' + l[13:]\n"", ""         charselect = vars[name]['charselector']\n"", ""         if charselect.get('*', '') == '(*)':\n"", ""             charselect['*'] = '10'\n"", ""     sargs = ', '.join(args)\n"", '     if f90mode:\n', ""         add('subroutine f2pywrap_%s_%s (%s)' %\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         add('subroutine f2pywrap%s (%s)' % (name, sargs))\n"", '         if not need_interface:\n', ""             add('external %s' % (fortranname))\n"", ""+            rl = l_tmpl.replace('@@@NAME@@@', '') + ' ' + fortranname\n"", '+\n', '     if need_interface:\n', ""         for line in rout['saved_interface'].split('\\n'):\n"", ""             if line.lstrip().startswith('use ') and '__user__' not in line:\n""]","[""         add('subroutine f2pywrap%s (%s)' % (name, sargs))\n"", '         if not need_interface:\n', ""             add('external %s' % (fortranname))\n"", ""-            l = l + ', ' + fortranname\n"", '     if need_interface:\n', ""         for line in rout['saved_interface'].split('\\n'):\n"", ""             if line.lstrip().startswith('use ') and '__user__' not in line:\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             continue\n', '         add(var2fixfortran(vars, a, f90mode=f90mode))\n', ' \n', '+    add(l1)\n', '+    if rl is not None:\n', '+        add(rl)\n', ' \n', '     if need_interface:\n', '         if f90mode:\n']","['             continue\n', '         add(var2fixfortran(vars, a, f90mode=f90mode))\n', ' \n', '-    add(l)\n', ' \n', '     if need_interface:\n', '         if f90mode:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if issubroutine_wrap(rout):\n', '         fortranname = getfortranname(rout)\n', ""         name = rout['name']\n"", '+        outmess(\'\\t\\tCreating wrapper for Fortran subroutine ""%s""(""%s"")...\\n\'\n', '+                % (name, fortranname))\n', '         rout = copy.copy(rout)\n', '         return rout, createsubrwrapper(rout)\n', ""     return rout, ''\n""]","['     if issubroutine_wrap(rout):\n', '         fortranname = getfortranname(rout)\n', ""         name = rout['name']\n"", '-        outmess(\'\\t\\tCreating wrapper for Fortran subroutine ""%s""(""%s"")...\\n\' % (\n', '-            name, fortranname))\n', '         rout = copy.copy(rout)\n', '         return rout, createsubrwrapper(rout)\n', ""     return rout, ''\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' # __version__.version is now the same as the NumPy version\n', ' from . import __version__\n', ' \n', ' from .auxfuncs import (\n', '     applyrules, debugcapi, dictappend, errmess, gentitle, getargs2,\n', '+    hascallstatement, hasexternals, hasinitvalue, hasnote,\n', '+    hasresultnote, isarray, isarrayofstrings, ischaracter,\n', '+    ischaracterarray, ischaracter_or_characterarray, iscomplex,\n', '+    iscomplexarray, iscomplexfunction, iscomplexfunction_warn,\n', '+    isdummyroutine, isexternal, isfunction, isfunction_wrap, isint1,\n', '+    isint1array, isintent_aux, isintent_c, isintent_callback,\n', '+    isintent_copy, isintent_hide, isintent_inout, isintent_nothide,\n', '+    isintent_out, isintent_overwrite, islogical, islong_complex,\n', '+    islong_double, islong_doublefunction, islong_long,\n', '+    islong_longfunction, ismoduleroutine, isoptional, isrequired,\n', '+    isscalar, issigned_long_longarray, isstring, isstringarray,\n', '+    isstringfunction, issubroutine, isattr_value,\n', '+    issubroutine_wrap, isthreadsafe, isunsigned, isunsigned_char,\n', '+    isunsigned_chararray, isunsigned_long_long,\n', '     isunsigned_long_longarray, isunsigned_short, isunsigned_shortarray,\n', '     l_and, l_not, l_or, outmess, replace, stripcomma, requiresf90wrapper\n', ' )\n']","[' \n', ' # __version__.version is now the same as the NumPy version\n', ' from . import __version__\n', '-f2py_version = __version__.version\n', '-numpy_version = __version__.version\n', ' \n', ' from .auxfuncs import (\n', '     applyrules, debugcapi, dictappend, errmess, gentitle, getargs2,\n', '-    hascallstatement, hasexternals, hasinitvalue, hasnote, hasresultnote,\n', '-    isarray, isarrayofstrings, iscomplex, iscomplexarray,\n', '-    iscomplexfunction, iscomplexfunction_warn, isdummyroutine, isexternal,\n', '-    isfunction, isfunction_wrap, isint1array, isintent_aux, isintent_c,\n', '-    isintent_callback, isintent_copy, isintent_hide, isintent_inout,\n', '-    isintent_nothide, isintent_out, isintent_overwrite, islogical,\n', '-    islong_complex, islong_double, islong_doublefunction, islong_long,\n', '-    islong_longfunction, ismoduleroutine, isoptional, isrequired, isscalar,\n', '-    issigned_long_longarray, isstring, isstringarray, isstringfunction,\n', '-    issubroutine, issubroutine_wrap, isthreadsafe, isunsigned,\n', '-    isunsigned_char, isunsigned_chararray, isunsigned_long_long,\n', '     isunsigned_long_longarray, isunsigned_short, isunsigned_shortarray,\n', '     l_and, l_not, l_or, outmess, replace, stripcomma, requiresf90wrapper\n', ' )\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from . import f90mod_rules\n', ' from . import func2subr\n', ' \n', '+f2py_version = __version__.version\n', '+numpy_version = __version__.version\n', '+\n', ' options = {}\n', ' sepdict = {}\n', ""+# for k in ['need_cfuncs']: sepdict[k]=','\n"", "" for k in ['decl',\n"", ""           'frompyobj',\n"", ""           'cleanupfrompyobj',\n""]","[' from . import f90mod_rules\n', ' from . import func2subr\n', ' \n', ' options = {}\n', ' sepdict = {}\n', ""-#for k in ['need_cfuncs']: sepdict[k]=','\n"", "" for k in ['decl',\n"", ""           'frompyobj',\n"", ""           'cleanupfrompyobj',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                ismoduleroutine: '',\n"", ""                                isdummyroutine: ''\n"", '                                },\n', ""+        'routine_def': {\n"", '+            l_not(l_or(ismoduleroutine, isintent_c, isdummyroutine)):\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)\'\n', ""+            '  #F_FUNC#(#fortranname#,#FORTRANNAME#),'\n"", ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+            l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)):\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)#fortranname#,\'\n', ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+            l_and(l_not(ismoduleroutine), isdummyroutine):\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,NULL,\'\n', ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+        },\n', ""         'need': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): 'F_FUNC'},\n"", ""         'callfortranroutine': [\n"", '             {debugcapi: [\n']","[""                                ismoduleroutine: '',\n"", ""                                isdummyroutine: ''\n"", '                                },\n', '-        \'routine_def\': {l_not(l_or(ismoduleroutine, isintent_c, isdummyroutine)): \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#F_FUNC#(#fortranname#,#FORTRANNAME#),(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#fortranname#,(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        l_and(l_not(ismoduleroutine), isdummyroutine): \'    {\\""#name#\\"",-1,{{-1}},0,NULL,(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        },\n', ""         'need': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): 'F_FUNC'},\n"", ""         'callfortranroutine': [\n"", '             {debugcapi: [\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                isdummyroutine: '',\n"", '                                },\n', ' \n', ""+        'routine_def': {\n"", '+            l_not(l_or(ismoduleroutine, isdummyroutine)):\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)\'\n', ""+            '  #F_WRAPPEDFUNC#(#name_lower#,#NAME#),'\n"", ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+            isdummyroutine:\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,NULL,\'\n', ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+        },\n', ""         'initf2pywraphook': {l_not(l_or(ismoduleroutine, isdummyroutine)): '''\n"", '     {\n', '       extern #ctype# #F_FUNC#(#name_lower#,#NAME#)(void);\n']","[""                                isdummyroutine: '',\n"", '                                },\n', ' \n', '-        \'routine_def\': {l_not(l_or(ismoduleroutine, isdummyroutine)): \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#F_WRAPPEDFUNC#(#name_lower#,#NAME#),(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        isdummyroutine: \'    {\\""#name#\\"",-1,{{-1}},0,NULL,(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        },\n', ""         'initf2pywraphook': {l_not(l_or(ismoduleroutine, isdummyroutine)): '''\n"", '     {\n', '       extern #ctype# #F_FUNC#(#name_lower#,#NAME#)(void);\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                isdummyroutine: '',\n"", '                                },\n', ' \n', ""+        'routine_def': {\n"", '+            l_not(l_or(ismoduleroutine, isdummyroutine)):\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)\'\n', ""+            '  #F_WRAPPEDFUNC#(#name_lower#,#NAME#),'\n"", ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+            isdummyroutine:\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,NULL,\'\n', ""+            '  (f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+        },\n', ""         'initf2pywraphook': {l_not(l_or(ismoduleroutine, isdummyroutine)): '''\n"", '     {\n', '       extern void #F_FUNC#(#name_lower#,#NAME#)(void);\n']","[""                                isdummyroutine: '',\n"", '                                },\n', ' \n', '-        \'routine_def\': {l_not(l_or(ismoduleroutine, isdummyroutine)): \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#F_WRAPPEDFUNC#(#name_lower#,#NAME#),(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        isdummyroutine: \'    {\\""#name#\\"",-1,{{-1}},0,NULL,(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        },\n', ""         'initf2pywraphook': {l_not(l_or(ismoduleroutine, isdummyroutine)): '''\n"", '     {\n', '       extern void #F_FUNC#(#name_lower#,#NAME#)(void);\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): 'extern #ctype# #fortranname#(#callprotoargument#);',\n"", ""                                isdummyroutine: ''\n"", '                                },\n', ""+        'routine_def': {\n"", '+            l_and(l_not(l_or(ismoduleroutine, isintent_c)),\n', '+                  l_not(isdummyroutine)):\n', '+            (\'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)\'\n', ""+             '  #F_FUNC#(#fortranname#,#FORTRANNAME#),'\n"", ""+             '  (f2py_init_func)#apiname#,doc_#apiname#},'),\n"", '+            l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)):\n', '+            (\'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)#fortranname#,\'\n', ""+             '  (f2py_init_func)#apiname#,doc_#apiname#},'),\n"", '+            isdummyroutine:\n', '+            \'    {\\""#name#\\"",-1,{{-1}},0,0,NULL,\'\n', ""+            '(f2py_init_func)#apiname#,doc_#apiname#},',\n"", '+        },\n', ""         'decl': [{iscomplexfunction_warn: '    #ctype# #name#_return_value={0,0};',\n"", ""                   l_not(iscomplexfunction): '    #ctype# #name#_return_value=0;'},\n"", '                  {iscomplexfunction:\n']","[""                                l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): 'extern #ctype# #fortranname#(#callprotoargument#);',\n"", ""                                isdummyroutine: ''\n"", '                                },\n', '-        \'routine_def\': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#F_FUNC#(#fortranname#,#FORTRANNAME#),(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#fortranname#,(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        isdummyroutine: \'    {\\""#name#\\"",-1,{{-1}},0,NULL,(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '-                        },\n', ""         'decl': [{iscomplexfunction_warn: '    #ctype# #name#_return_value={0,0};',\n"", ""                   l_not(iscomplexfunction): '    #ctype# #name#_return_value=0;'},\n"", '                  {iscomplexfunction:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     }, {  # String function # in use for --no-wrap\n', ""         'declfortranroutine': 'extern void #F_FUNC#(#fortranname#,#FORTRANNAME#)(#callprotoargument#);',\n"", ""         'routine_def': {l_not(l_or(ismoduleroutine, isintent_c)):\n"", '+                        \'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)#F_FUNC#(#fortranname#,#FORTRANNAME#),(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '                         l_and(l_not(ismoduleroutine), isintent_c):\n', '+                        \'    {\\""#name#\\"",-1,{{-1}},0,0,(char *)#fortranname#,(f2py_init_func)#apiname#,doc_#apiname#},\'\n', '                         },\n', ""         'decl': ['    #ctype# #name#_return_value = NULL;',\n"", ""                  '    int #name#_return_value_len = 0;'],\n""]","['     }, {  # String function # in use for --no-wrap\n', ""         'declfortranroutine': 'extern void #F_FUNC#(#fortranname#,#FORTRANNAME#)(#callprotoargument#);',\n"", ""         'routine_def': {l_not(l_or(ismoduleroutine, isintent_c)):\n"", '-                        \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#F_FUNC#(#fortranname#,#FORTRANNAME#),(f2py_init_func)#apiname#,doc_#apiname#},\',\n', '                         l_and(l_not(ismoduleroutine), isintent_c):\n', '-                        \'    {\\""#name#\\"",-1,{{-1}},0,(char *)#fortranname#,(f2py_init_func)#apiname#,doc_#apiname#},\'\n', '                         },\n', ""         'decl': ['    #ctype# #name#_return_value = NULL;',\n"", ""                  '    int #name#_return_value_len = 0;'],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                      isunsigned_shortarray: 'unsigned_short',\n"", ""                      isunsigned_long_longarray: 'unsigned_long_long',\n"", ""                      issigned_long_longarray: 'long_long',\n"", ""+                     isint1: 'signed_char',\n"", ""+                     ischaracter_or_characterarray: 'character',\n"", '                      }\n', ' \n', ' aux_rules = [\n']","[""                      isunsigned_shortarray: 'unsigned_short',\n"", ""                      isunsigned_long_longarray: 'unsigned_long_long',\n"", ""                      issigned_long_longarray: 'long_long',\n"", '                      }\n', ' \n', ' aux_rules = [\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['      },\n', '     # Integer*-1 array\n', ""     {'need': '#ctype#',\n"", ""+     '_check': l_or(isunsigned_chararray, isunsigned_char),\n"", ""      '_depend': ''\n"", '      },\n', '     # Integer*-2 array\n']","['      },\n', '     # Integer*-1 array\n', ""     {'need': '#ctype#',\n"", ""-     '_check': isunsigned_chararray,\n"", ""      '_depend': ''\n"", '      },\n', '     # Integer*-2 array\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     {  # Common\n', ""         'decl': '    #ctype# #varname# = 0;',\n"", '         \'pyobjfrom\': {debugcapi: \'    fprintf(stderr,""#vardebugshowvalue#\\\\n"",#varname#);\'},\n', ""+        'callfortran': {l_or(isintent_c, isattr_value): '#varname#,', l_not(l_or(isintent_c, isattr_value)): '&#varname#,'},\n"", ""         'return': {isintent_out: ',#varname#'},\n"", ""         '_check': l_and(isscalar, l_not(iscomplex))\n"", '     }, {\n']","['     {  # Common\n', ""         'decl': '    #ctype# #varname# = 0;',\n"", '         \'pyobjfrom\': {debugcapi: \'    fprintf(stderr,""#vardebugshowvalue#\\\\n"",#varname#);\'},\n', ""-        'callfortran': {isintent_c: '#varname#,', l_not(isintent_c): '&#varname#,'},\n"", ""         'return': {isintent_out: ',#varname#'},\n"", ""         '_check': l_and(isscalar, l_not(iscomplex))\n"", '     }, {\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if (f2py_success) {""""""},\n', '         \'closepyobjfrom\': {isintent_inout: ""    } /*if (f2py_success) of #varname# pyobjfrom*/""},\n', ""         'need': {isintent_inout: 'try_pyarr_from_#ctype#'},\n"", ""+        '_check': l_and(isscalar, l_not(iscomplex), l_not(isstring),\n"", '+                        isintent_nothide)\n', '     }, {\n', ""         'frompyobj': [\n"", '             # hasinitvalue...\n']","['     if (f2py_success) {""""""},\n', '         \'closepyobjfrom\': {isintent_inout: ""    } /*if (f2py_success) of #varname# pyobjfrom*/""},\n', ""         'need': {isintent_inout: 'try_pyarr_from_#ctype#'},\n"", ""-        '_check': l_and(isscalar, l_not(iscomplex), isintent_nothide)\n"", '     }, {\n', ""         'frompyobj': [\n"", '             # hasinitvalue...\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         'return': {isintent_out: ',#varname#'},\n"", ""         'need': ['len..',\n"", ""                  {l_and(isintent_out, l_not(isintent_c)): 'STRINGPADN'}],\n"", ""+        '_check': isstring\n"", '     }, {  # Common\n', ""         'frompyobj': [\n"", '             """"""\\\n', '+    slen(#varname#) = #elsize#;\n', '     f2py_success = #ctype#_from_pyobj(&#varname#,&slen(#varname#),#init#,""""""\n', ' """"""#varname#_capi,\\""#ctype#_from_pyobj failed in converting #nth#""""""\n', ' """"""`#varname#\\\' of #pyname# to C #ctype#\\"");\n']","[""         'return': {isintent_out: ',#varname#'},\n"", ""         'need': ['len..',\n"", ""                  {l_and(isintent_out, l_not(isintent_c)): 'STRINGPADN'}],\n"", ""-        '_check':isstring\n"", '     }, {  # Common\n', ""         'frompyobj': [\n"", '             """"""\\\n', '-    slen(#varname#) = #length#;\n', '     f2py_success = #ctype#_from_pyobj(&#varname#,&slen(#varname#),#init#,""""""\n', ' """"""#varname#_capi,\\""#ctype#_from_pyobj failed in converting #nth#""""""\n', ' """"""`#varname#\\\' of #pyname# to C #ctype#\\"");\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         'decl': ['    #ctype# *#varname# = NULL;',\n"", ""                  '    npy_intp #varname#_Dims[#rank#] = {#rank*[-1]#};',\n"", ""                  '    const int #varname#_Rank = #rank#;',\n"", ""+                 '    PyArrayObject *capi_#varname#_as_array = NULL;',\n"", ""                  '    int capi_#varname#_intent = 0;',\n"", ""+                 {isstringarray: '    int slen(#varname#) = 0;'},\n"", '                  ],\n', ""         'callfortran':'#varname#,',\n"", ""+        'callfortranappend': {isstringarray: 'slen(#varname#),'},\n"", ""+        'return': {isintent_out: ',capi_#varname#_as_array'},\n"", ""         'need': 'len..',\n"", ""         '_check': isarray\n"", '     }, {  # intent(overwrite) array\n']","[""         'decl': ['    #ctype# *#varname# = NULL;',\n"", ""                  '    npy_intp #varname#_Dims[#rank#] = {#rank*[-1]#};',\n"", ""                  '    const int #varname#_Rank = #rank#;',\n"", ""-                 '    PyArrayObject *capi_#varname#_tmp = NULL;',\n"", ""                  '    int capi_#varname#_intent = 0;',\n"", '                  ],\n', ""         'callfortran':'#varname#,',\n"", ""-        'return':{isintent_out: ',capi_#varname#_tmp'},\n"", ""         'need': 'len..',\n"", ""         '_check': isarray\n"", '     }, {  # intent(overwrite) array\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         'keys_capi': {isoptional: ',&#varname#_capi'},\n"", ""         '_check': l_and(isarray, isintent_nothide)\n"", '     }, {\n', ""+        'frompyobj': [\n"", ""+            '    #setdims#;',\n"", ""+            '    capi_#varname#_intent |= #intent#;',\n"", '+            (\'    const char * capi_errmess = ""#modulename#.#pyname#:\'\n', '+             \' failed to create array from the #nth# `#varname#`"";\'),\n', '+            {isintent_hide:\n', ""+             '    capi_#varname#_as_array = ndarray_from_pyobj('\n"", ""+             '  #atype#,#elsize#,#varname#_Dims,#varname#_Rank,'\n"", ""+             '  capi_#varname#_intent,Py_None,capi_errmess);'},\n"", '+            {isintent_nothide:\n', ""+             '    capi_#varname#_as_array = ndarray_from_pyobj('\n"", ""+             '  #atype#,#elsize#,#varname#_Dims,#varname#_Rank,'\n"", ""+             '  capi_#varname#_intent,#varname#_capi,capi_errmess);'},\n"", '+            """"""\\\n', '+    if (capi_#varname#_as_array == NULL) {\n', '+        PyObject* capi_err = PyErr_Occurred();\n', '+        if (capi_err == NULL) {\n', '+            capi_err = #modulename#_error;\n', '+            PyErr_SetString(capi_err, capi_errmess);\n', '+        }\n', '     } else {\n', '+        #varname# = (#ctype# *)(PyArray_DATA(capi_#varname#_as_array));\n', ' """""",\n', '+            {isstringarray:\n', ""+             '    slen(#varname#) = f2py_itemsize(#varname#);'},\n"", '+            {hasinitvalue: [\n', '+                {isintent_nothide:\n', ""+                 '    if (#varname#_capi == Py_None) {'},\n"", ""+                {isintent_hide: '    {'},\n"", ""+                {iscomplexarray: '        #ctype# capi_c;'},\n"", '+                """"""\\\n', '         int *_i,capi_i=0;\n', '         CFUNCSMESS(\\""#name#: Initializing #varname#=#init#\\\\n\\"");\n', '+        if (initforcomb(PyArray_DIMS(capi_#varname#_as_array),\n', '+                        PyArray_NDIM(capi_#varname#_as_array),1)) {\n', '             while ((_i = nextforcomb()))\n', '                 #varname#[capi_i++] = #init#; /* fortran way */\n', '         } else {\n', '             PyObject *exc, *val, *tb;\n', '             PyErr_Fetch(&exc, &val, &tb);\n', '+            PyErr_SetString(exc ? exc : #modulename#_error,\n', '+                \\""Initialization of #nth# #varname# failed (initforcomb).\\"");\n', '             npy_PyErr_ChainExceptionsCause(exc, val, tb);\n', '             f2py_success = 0;\n', '         }\n']","[""         'keys_capi': {isoptional: ',&#varname#_capi'},\n"", ""         '_check': l_and(isarray, isintent_nothide)\n"", '     }, {\n', ""-        'frompyobj': ['    #setdims#;',\n"", ""-                      '    capi_#varname#_intent |= #intent#;',\n"", '-                      {isintent_hide:\n', ""-                       '    capi_#varname#_tmp = array_from_pyobj(#atype#,#varname#_Dims,#varname#_Rank,capi_#varname#_intent,Py_None);'},\n"", '-                      {isintent_nothide:\n', ""-                       '    capi_#varname#_tmp = array_from_pyobj(#atype#,#varname#_Dims,#varname#_Rank,capi_#varname#_intent,#varname#_capi);'},\n"", '-                      """"""\\\n', '-    if (capi_#varname#_tmp == NULL) {\n', '-        PyObject *exc, *val, *tb;\n', '-        PyErr_Fetch(&exc, &val, &tb);\n', '-        PyErr_SetString(exc ? exc : #modulename#_error,\\""failed in converting #nth# `#varname#\\\' of #pyname# to C/Fortran array\\"" );\n', '-        npy_PyErr_ChainExceptionsCause(exc, val, tb);\n', '     } else {\n', '-        #varname# = (#ctype# *)(PyArray_DATA(capi_#varname#_tmp));\n', ' """""",\n', '-                      {hasinitvalue: [\n', '-                          {isintent_nothide:\n', ""-                              '    if (#varname#_capi == Py_None) {'},\n"", ""-                          {isintent_hide: '    {'},\n"", ""-                          {iscomplexarray: '        #ctype# capi_c;'},\n"", '-                          """"""\\\n', '         int *_i,capi_i=0;\n', '         CFUNCSMESS(\\""#name#: Initializing #varname#=#init#\\\\n\\"");\n', '-        if (initforcomb(PyArray_DIMS(capi_#varname#_tmp),PyArray_NDIM(capi_#varname#_tmp),1)) {\n', '             while ((_i = nextforcomb()))\n', '                 #varname#[capi_i++] = #init#; /* fortran way */\n', '         } else {\n', '             PyObject *exc, *val, *tb;\n', '             PyErr_Fetch(&exc, &val, &tb);\n', '-            PyErr_SetString(exc ? exc : #modulename#_error,\\""Initialization of #nth# #varname# failed (initforcomb).\\"");\n', '             npy_PyErr_ChainExceptionsCause(exc, val, tb);\n', '             f2py_success = 0;\n', '         }\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if (f2py_success) {""""""]},\n', '                       ],\n', ""         'cleanupfrompyobj': [  # note that this list will be reversed\n"", ""+            '    }  '\n"", ""+            '/* if (capi_#varname#_as_array == NULL) ... else of #varname# */',\n"", '             {l_not(l_or(isintent_out, isintent_hide)): """"""\\\n', '+    if((PyObject *)capi_#varname#_as_array!=#varname#_capi) {\n', '+        Py_XDECREF(capi_#varname#_as_array); }""""""},\n', '             {l_and(isintent_hide, l_not(isintent_out))\n', '+                   : """"""        Py_XDECREF(capi_#varname#_as_array);""""""},\n', ""             {hasinitvalue: '    }  /*if (f2py_success) of #varname# init*/'},\n"", '         ],\n', ""         '_check': isarray,\n""]","['     if (f2py_success) {""""""]},\n', '                       ],\n', ""         'cleanupfrompyobj': [  # note that this list will be reversed\n"", ""-            '    }  /*if (capi_#varname#_tmp == NULL) ... else of #varname#*/',\n"", '             {l_not(l_or(isintent_out, isintent_hide)): """"""\\\n', '-    if((PyObject *)capi_#varname#_tmp!=#varname#_capi) {\n', '-        Py_XDECREF(capi_#varname#_tmp); }""""""},\n', '             {l_and(isintent_hide, l_not(isintent_out))\n', '-                   : """"""        Py_XDECREF(capi_#varname#_tmp);""""""},\n', ""             {hasinitvalue: '    }  /*if (f2py_success) of #varname# init*/'},\n"", '         ],\n', ""         '_check': isarray,\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""      '_check': iscomplexarray,\n"", ""      '_depend': ''\n"", '      },\n', '+    # Character\n', '+    {\n', ""+        'need': 'string',\n"", ""+        '_check': ischaracter,\n"", '+    },\n', '+    # Character array\n', '+    {\n', ""+        'need': 'string',\n"", ""+        '_check': ischaracterarray,\n"", '+    },\n', '     # Stringarray\n', '     {\n', ""         'callfortranappend': {isarrayofstrings: 'flen(#varname#),'},\n""]","[""      '_check': iscomplexarray,\n"", ""      '_depend': ''\n"", '      },\n', '     # Stringarray\n', '     {\n', ""         'callfortranappend': {isarrayofstrings: 'flen(#varname#),'},\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         rd = dictappend(rd, ar)\n', ' \n', '     needs = cfuncs.get_needs()\n', '+    # Add mapped definitions\n', ""+    needs['typedefs'] += [cvar for cvar in capi_maps.f2cmap_mapped #\n"", '+                          if cvar in typedef_need_dict.values()]\n', '     code = {}\n', '     for n in needs.keys():\n', '         code[n] = []\n']","['         rd = dictappend(rd, ar)\n', ' \n', '     needs = cfuncs.get_needs()\n', '     code = {}\n', '     for n in needs.keys():\n', '         code[n] = []\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from pathlib import Path\n', '+import pytest\n', ' import textwrap\n', ' from . import util\n', ' from numpy.f2py import crackfortran\n', '+from numpy.testing import IS_WASM\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', ' class TestAbstractInterface(util.F2PyTest):\n', '     sources = [util.getpath(""tests"", ""src"", ""abstract_interface"", ""foo.f90"")]\n', ' \n']","[' from pathlib import Path\n', ' import textwrap\n', ' from . import util\n', ' from numpy.f2py import crackfortran\n', ' \n', ' \n', ' class TestAbstractInterface(util.F2PyTest):\n', '     sources = [util.getpath(""tests"", ""src"", ""abstract_interface"", ""foo.f90"")]\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' import numpy as np\n', ' \n', '+from numpy.testing import assert_, assert_equal\n', '+from numpy.core.multiarray import typeinfo as _typeinfo\n', ' from . import util\n', ' \n', ' wrap = None\n', ' \n', ""+# Extend core typeinfo with CHARACTER to test dtype('c')\n"", ""+_ti = _typeinfo['STRING']\n"", '+typeinfo = dict(\n', ""+    CHARACTER=type(_ti)(('c', _ti.num, 8, _ti.alignment, _ti.type)),\n"", '+    **_typeinfo)\n', '+\n', ' \n', ' def setup_module():\n', '     """"""\n']","[' \n', ' import numpy as np\n', ' \n', '-from numpy.core.multiarray import typeinfo\n', ' from . import util\n', ' \n', ' wrap = None\n', ' \n', ' \n', ' def setup_module():\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             ""NOTSWAPPED"",\n', '             ""WRITEABLE"",\n', '             ""WRITEBACKIFCOPY"",\n', '+            ""UPDATEIFCOPY"",\n', '             ""BEHAVED"",\n', '             ""BEHAVED_RO"",\n', '             ""CARRAY"",\n']","['             ""NOTSWAPPED"",\n', '             ""WRITEABLE"",\n', '             ""WRITEBACKIFCOPY"",\n', '             ""BEHAVED"",\n', '             ""BEHAVED_RO"",\n', '             ""CARRAY"",\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ""FLOAT"",\n', '     ""DOUBLE"",\n', '     ""CFLOAT"",\n', '+    ""STRING1"",\n', '+    ""STRING5"",\n', '+    ""CHARACTER"",\n', ' ]\n', ' \n', ' _cast_dict = {""BOOL"": [""BOOL""]}\n']","['     ""FLOAT"",\n', '     ""DOUBLE"",\n', '     ""CFLOAT"",\n', ' ]\n', ' \n', ' _cast_dict = {""BOOL"": [""BOOL""]}\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' _cast_dict[""CFLOAT""] = _cast_dict[""FLOAT""] + [""CFLOAT""]\n', ' \n', ""+_cast_dict['STRING1'] = ['STRING1']\n"", ""+_cast_dict['STRING5'] = ['STRING5']\n"", ""+_cast_dict['CHARACTER'] = ['CHARACTER']\n"", '+\n', ' # 32 bit system malloc typically does not provide the alignment required by\n', ' # 16 byte long double types this means the inout intent cannot be satisfied\n', ' # and several tests fail as the alignment flag can be randomly true or fals\n']","[' \n', ' _cast_dict[""CFLOAT""] = _cast_dict[""FLOAT""] + [""CFLOAT""]\n', ' \n', ' # 32 bit system malloc typically does not provide the alignment required by\n', ' # 16 byte long double types this means the inout intent cannot be satisfied\n', ' # and several tests fail as the alignment flag can be randomly true or fals\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def _init(self, name):\n', '         self.NAME = name.upper()\n', '+\n', ""+        if self.NAME == 'CHARACTER':\n"", '+            info = typeinfo[self.NAME]\n', ""+            self.type_num = getattr(wrap, 'NPY_STRING')\n"", '+            self.elsize = 1\n', ""+            self.dtype = np.dtype('c')\n"", ""+        elif self.NAME.startswith('STRING'):\n"", '+            info = typeinfo[self.NAME[:6]]\n', ""+            self.type_num = getattr(wrap, 'NPY_STRING')\n"", '+            self.elsize = int(self.NAME[6:] or 0)\n', ""+            self.dtype = np.dtype(f'S{self.elsize}')\n"", '+        else:\n', '+            info = typeinfo[self.NAME]\n', ""+            self.type_num = getattr(wrap, 'NPY_' + self.NAME)\n"", '+            self.elsize = info.bits // 8\n', '+            self.dtype = np.dtype(info.type)\n', '+\n', '         assert self.type_num == info.num\n', '         self.type = info.type\n', '         self.dtypechar = info.char\n', ' \n', '+    def __repr__(self):\n', '+        return (f""Type({self.NAME})|type_num={self.type_num},""\n', '+                f"" dtype={self.dtype},""\n', '+                f"" type={self.type}, elsize={self.elsize},""\n', '+                f"" dtypechar={self.dtypechar}"")\n', '+\n', '     def cast_types(self):\n', '         return [self.__class__(_m) for _m in _cast_dict[self.NAME]]\n', ' \n']","[' \n', '     def _init(self, name):\n', '         self.NAME = name.upper()\n', '-        info = typeinfo[self.NAME]\n', '-        self.type_num = getattr(wrap, ""NPY_"" + self.NAME)\n', '         assert self.type_num == info.num\n', '-        self.dtype = np.dtype(info.type)\n', '         self.type = info.type\n', '-        self.elsize = info.bits / 8\n', '         self.dtypechar = info.char\n', ' \n', '     def cast_types(self):\n', '         return [self.__class__(_m) for _m in _cast_dict[self.NAME]]\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class Array:\n', '+\n', '+    def __repr__(self):\n', ""+        return (f'Array({self.type}, {self.dims}, {self.intent},'\n"", ""+                f' {self.obj})|arr={self.arr}')\n"", '+\n', '     def __init__(self, typ, dims, intent, obj):\n', '         self.type = typ\n', '         self.dims = dims\n']","[' \n', ' \n', ' class Array:\n', '     def __init__(self, typ, dims, intent, obj):\n', '         self.type = typ\n', '         self.dims = dims\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.obj = obj\n', ' \n', '         # arr.dtypechar may be different from typ.dtypechar\n', '+        self.arr = wrap.call(typ.type_num,\n', '+                             typ.elsize,\n', '+                             dims, intent.flags, obj)\n', ' \n', '         assert isinstance(self.arr, np.ndarray)\n', ' \n']","['         self.obj = obj\n', ' \n', '         # arr.dtypechar may be different from typ.dtypechar\n', '-        self.arr = wrap.call(typ.type_num, dims, intent.flags, obj)\n', ' \n', '         assert isinstance(self.arr, np.ndarray)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 self.arr.tobytes(),\n', '                 self.pyarr.tobytes(),\n', '             ))  # strides\n', '+        assert self.arr_attr[5][-2:] == self.pyarr_attr[5][-2:], repr((\n', '+            self.arr_attr[5], self.pyarr_attr[5]\n', '+            ))  # descr\n', '         assert self.arr_attr[6] == self.pyarr_attr[6], repr((\n', '             self.arr_attr[6],\n', '             self.pyarr_attr[6],\n']","['                 self.arr.tobytes(),\n', '                 self.pyarr.tobytes(),\n', '             ))  # strides\n', '-        assert self.arr_attr[5][-2:] == self.pyarr_attr[5][-2:]  # descr\n', '         assert self.arr_attr[6] == self.pyarr_attr[6], repr((\n', '             self.arr_attr[6],\n', '             self.pyarr_attr[6],\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestSharedMemory:\n', ' \n', '     @pytest.fixture(autouse=True, scope=""class"", params=_type_names)\n', '     def setup_type(self, request):\n']","[' \n', ' \n', ' class TestSharedMemory:\n', '-    num2seq = [1, 2]\n', '-    num23seq = [[1, 2, 3], [4, 5, 6]]\n', ' \n', '     @pytest.fixture(autouse=True, scope=""class"", params=_type_names)\n', '     def setup_type(self, request):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         request.cls.array = lambda self, dims, intent, obj: Array(\n', '             Type(request.param), dims, intent, obj)\n', ' \n', '+    @property\n', '+    def num2seq(self):\n', ""+        if self.type.NAME.startswith('STRING'):\n"", '+            elsize = self.type.elsize\n', ""+            return ['1' * elsize, '2' * elsize]\n"", '+        return [1, 2]\n', '+\n', '+    @property\n', '+    def num23seq(self):\n', ""+        if self.type.NAME.startswith('STRING'):\n"", '+            elsize = self.type.elsize\n', ""+            return [['1' * elsize, '2' * elsize, '3' * elsize],\n"", ""+                    ['4' * elsize, '5' * elsize, '6' * elsize]]\n"", '+        return [[1, 2, 3], [4, 5, 6]]\n', '+\n', '     def test_in_from_2seq(self):\n', '         a = self.array([2], intent.in_, self.num2seq)\n', '         assert not a.has_shared_memory()\n']","['         request.cls.array = lambda self, dims, intent, obj: Array(\n', '             Type(request.param), dims, intent, obj)\n', ' \n', '     def test_in_from_2seq(self):\n', '         a = self.array([2], intent.in_, self.num2seq)\n', '         assert not a.has_shared_memory()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         """"""Test if intent(in) array can be passed without copies""""""\n', '         seq = getattr(self, ""num"" + inp)\n', '         obj = np.array(seq, dtype=self.type.dtype, order=order)\n', ""+        obj.setflags(write=(write == 'w'))\n"", '         a = self.array(obj.shape,\n', ""+                       ((order == 'C' and intent.in_.c) or intent.in_), obj)\n"", '         assert a.has_shared_memory()\n', ' \n', '     def test_inout_2seq(self):\n']","['         """"""Test if intent(in) array can be passed without copies""""""\n', '         seq = getattr(self, ""num"" + inp)\n', '         obj = np.array(seq, dtype=self.type.dtype, order=order)\n', '-        obj.setflags(write=(write == ""w""))\n', '         a = self.array(obj.shape,\n', '-                       ((order == ""C"" and intent.in_.c) or intent.in_), obj)\n', '         assert a.has_shared_memory()\n', ' \n', '     def test_inout_2seq(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_in_cache_from_2casttype_failure(self):\n', '         for t in self.type.all_types():\n', ""+            if t.NAME == 'STRING':\n"", '+                # string elsize is 0, so skipping the test\n', '+                continue\n', '             if t.elsize >= self.type.elsize:\n', '                 continue\n', '             obj = np.array(self.num2seq, dtype=t.dtype)\n']","[' \n', '     def test_in_cache_from_2casttype_failure(self):\n', '         for t in self.type.all_types():\n', '             if t.elsize >= self.type.elsize:\n', '                 continue\n', '             obj = np.array(self.num2seq, dtype=t.dtype)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestF2cmapOption(TestAssumedShapeSumExample):\n', '+    def setup_method(self):\n', '         # Use a custom file name for .f2py_f2cmap\n', '         self.sources = list(self.sources)\n', '         f2cmap_src = self.sources.pop(-1)\n']","[' \n', ' \n', ' class TestF2cmapOption(TestAssumedShapeSumExample):\n', '-    def setup(self):\n', '         # Use a custom file name for .f2py_f2cmap\n', '         self.sources = list(self.sources)\n', '         f2cmap_src = self.sources.pop(-1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.sources.append(self.f2cmap_file.name)\n', '         self.options = [""--f2cmap"", self.f2cmap_file.name]\n', ' \n', '+        super().setup_method()\n', ' \n', '+    def teardown_method(self):\n', '         os.unlink(self.f2cmap_file.name)\n']","['         self.sources.append(self.f2cmap_file.name)\n', '         self.options = [""--f2cmap"", self.f2cmap_file.name]\n', ' \n', '-        super().setup()\n', ' \n', '-    def teardown(self):\n', '         os.unlink(self.f2cmap_file.name)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         r = t(a.mth)\n', '         assert r == 9\n', ' \n', ""+    @pytest.mark.skipif(sys.platform == 'win32',\n"", ""+                        reason='Fails with MinGW64 Gfortran (Issue #9673)')\n"", '     def test_string_callback(self):\n', '         def callback(code):\n', '             if code == ""r"":\n']","['         r = t(a.mth)\n', '         assert r == 9\n', ' \n', '-    @pytest.mark.skipif(sys.platform == ""win32"",\n', '-                        reason=""Fails with MinGW64 Gfortran (Issue #9673)"")\n', '     def test_string_callback(self):\n', '         def callback(code):\n', '             if code == ""r"":\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         r = f(callback)\n', '         assert r == 0\n', ' \n', ""+    @pytest.mark.skipif(sys.platform == 'win32',\n"", ""+                        reason='Fails with MinGW64 Gfortran (Issue #9673)')\n"", '     def test_string_callback_array(self):\n', '         # See gh-10027\n', '+        cu1 = np.zeros((1, ), ""S8"")\n', '+        cu2 = np.zeros((1, 8), ""c"")\n', '+        cu3 = np.array([""""], ""S8"")\n', ' \n', '         def callback(cu, lencu):\n', '+            if cu.shape != (lencu,):\n', '                 return 1\n', '+            if cu.dtype != ""S8"":\n', '                 return 2\n', '             if not np.all(cu == b""""):\n', '                 return 3\n', '             return 0\n', ' \n', '         f = getattr(self.module, ""string_callback_array"")\n', '+        for cu in [cu1, cu2, cu3]:\n', '+            res = f(callback, cu, cu.size)\n', '+            assert res == 0\n', ' \n', '     def test_threadsafety(self):\n', '         # Segfaults if the callback handling is not threadsafe\n']","['         r = f(callback)\n', '         assert r == 0\n', ' \n', '-    @pytest.mark.skipif(sys.platform == ""win32"",\n', '-                        reason=""Fails with MinGW64 Gfortran (Issue #9673)"")\n', '     def test_string_callback_array(self):\n', '         # See gh-10027\n', '-        cu = np.zeros((1, 8), ""S1"")\n', ' \n', '         def callback(cu, lencu):\n', '-            if cu.shape != (lencu, 8):\n', '                 return 1\n', '-            if cu.dtype != ""S1"":\n', '                 return 2\n', '             if not np.all(cu == b""""):\n', '                 return 3\n', '             return 0\n', ' \n', '         f = getattr(self.module, ""string_callback_array"")\n', '-        res = f(callback, cu, len(cu))\n', '-        assert res == 0\n', ' \n', '     def test_threadsafety(self):\n', '         # Segfaults if the callback handling is not threadsafe\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         def foo(x):\n', '             x[0] += 1\n', ' \n', '         r = self.module.gh18335(foo)\n', '         assert r == 123 + 1\n']","['         def foo(x):\n', '             x[0] += 1\n', ' \n', '-        y = np.array([1, 2, 3], dtype=np.int8)\n', '         r = self.module.gh18335(foo)\n', '         assert r == 123 + 1\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import pytest\n', '+import textwrap\n', '+from numpy.testing import assert_array_equal, assert_equal, assert_raises\n', '+import numpy as np\n', '+from numpy.f2py.tests import util\n', '+\n', '+\n', '+class TestCharacterString(util.F2PyTest):\n', ""+    # options = ['--debug-capi', '--build-dir', '/tmp/test-build-f2py']\n"", ""+    suffix = '.f90'\n"", ""+    fprefix = 'test_character_string'\n"", ""+    length_list = ['1', '3', 'star']\n"", '+\n', ""+    code = ''\n"", '+    for length in length_list:\n', '+        fsuffix = length\n', ""+        clength = dict(star='(*)').get(length, length)\n"", '+\n', '+        code += textwrap.dedent(f""""""\n', '+\n', '+        subroutine {fprefix}_input_{fsuffix}(c, o, n)\n', '+          character*{clength}, intent(in) :: c\n', '+          integer n\n', '+          !f2py integer, depend(c), intent(hide) :: n = slen(c)\n', '+          integer*1, dimension(n) :: o\n', '+          !f2py intent(out) o\n', '+          o = transfer(c, o)\n', '+        end subroutine {fprefix}_input_{fsuffix}\n', '+\n', '+        subroutine {fprefix}_output_{fsuffix}(c, o, n)\n', '+          character*{clength}, intent(out) :: c\n', '+          integer n\n', '+          integer*1, dimension(n), intent(in) :: o\n', '+          !f2py integer, depend(o), intent(hide) :: n = len(o)\n', '+          c = transfer(o, c)\n', '+        end subroutine {fprefix}_output_{fsuffix}\n', '+\n', '+        subroutine {fprefix}_array_input_{fsuffix}(c, o, m, n)\n', '+          integer m, i, n\n', '+          character*{clength}, intent(in), dimension(m) :: c\n', '+          !f2py integer, depend(c), intent(hide) :: m = len(c)\n', '+          !f2py integer, depend(c), intent(hide) :: n = f2py_itemsize(c)\n', '+          integer*1, dimension(m, n), intent(out) :: o\n', '+          do i=1,m\n', '+            o(i, :) = transfer(c(i), o(i, :))\n', '+          end do\n', '+        end subroutine {fprefix}_array_input_{fsuffix}\n', '+\n', '+        subroutine {fprefix}_array_output_{fsuffix}(c, o, m, n)\n', '+          character*{clength}, intent(out), dimension(m) :: c\n', '+          integer n\n', '+          integer*1, dimension(m, n), intent(in) :: o\n', '+          !f2py character(f2py_len=n) :: c\n', '+          !f2py integer, depend(o), intent(hide) :: m = len(o)\n', '+          !f2py integer, depend(o), intent(hide) :: n = shape(o, 1)\n', '+          do i=1,m\n', '+            c(i) = transfer(o(i, :), c(i))\n', '+          end do\n', '+        end subroutine {fprefix}_array_output_{fsuffix}\n', '+\n', '+        subroutine {fprefix}_2d_array_input_{fsuffix}(c, o, m1, m2, n)\n', '+          integer m1, m2, i, j, n\n', '+          character*{clength}, intent(in), dimension(m1, m2) :: c\n', '+          !f2py integer, depend(c), intent(hide) :: m1 = len(c)\n', '+          !f2py integer, depend(c), intent(hide) :: m2 = shape(c, 1)\n', '+          !f2py integer, depend(c), intent(hide) :: n = f2py_itemsize(c)\n', '+          integer*1, dimension(m1, m2, n), intent(out) :: o\n', '+          do i=1,m1\n', '+            do j=1,m2\n', '+              o(i, j, :) = transfer(c(i, j), o(i, j, :))\n', '+            end do\n', '+          end do\n', '+        end subroutine {fprefix}_2d_array_input_{fsuffix}\n', '+        """""")\n', '+\n', '+    @pytest.mark.parametrize(""length"", length_list)\n', '+    def test_input(self, length):\n', ""+        fsuffix = {'(*)': 'star'}.get(length, length)\n"", ""+        f = getattr(self.module, self.fprefix + '_input_' + fsuffix)\n"", '+\n', ""+        a = {'1': 'a', '3': 'abc', 'star': 'abcde' * 3}[length]\n"", '+\n', ""+        assert_array_equal(f(a), np.array(list(map(ord, a)), dtype='u1'))\n"", '+\n', '+    @pytest.mark.parametrize(""length"", length_list[:-1])\n', '+    def test_output(self, length):\n', '+        fsuffix = length\n', ""+        f = getattr(self.module, self.fprefix + '_output_' + fsuffix)\n"", '+\n', ""+        a = {'1': 'a', '3': 'abc'}[length]\n"", '+\n', ""+        assert_array_equal(f(np.array(list(map(ord, a)), dtype='u1')),\n"", '+                           a.encode())\n', '+\n', '+    @pytest.mark.parametrize(""length"", length_list)\n', '+    def test_array_input(self, length):\n', '+        fsuffix = length\n', ""+        f = getattr(self.module, self.fprefix + '_array_input_' + fsuffix)\n"", '+\n', ""+        a = np.array([{'1': 'a', '3': 'abc', 'star': 'abcde' * 3}[length],\n"", ""+                      {'1': 'A', '3': 'ABC', 'star': 'ABCDE' * 3}[length],\n"", ""+                      ], dtype='S')\n"", '+\n', ""+        expected = np.array([[c for c in s] for s in a], dtype='u1')\n"", '+        assert_array_equal(f(a), expected)\n', '+\n', '+    @pytest.mark.parametrize(""length"", length_list)\n', '+    def test_array_output(self, length):\n', '+        fsuffix = length\n', ""+        f = getattr(self.module, self.fprefix + '_array_output_' + fsuffix)\n"", '+\n', '+        expected = np.array(\n', ""+            [{'1': 'a', '3': 'abc', 'star': 'abcde' * 3}[length],\n"", ""+             {'1': 'A', '3': 'ABC', 'star': 'ABCDE' * 3}[length]], dtype='S')\n"", '+\n', ""+        a = np.array([[c for c in s] for s in expected], dtype='u1')\n"", '+        assert_array_equal(f(a), expected)\n', '+\n', '+    @pytest.mark.parametrize(""length"", length_list)\n', '+    def test_2d_array_input(self, length):\n', '+        fsuffix = length\n', ""+        f = getattr(self.module, self.fprefix + '_2d_array_input_' + fsuffix)\n"", '+\n', ""+        a = np.array([[{'1': 'a', '3': 'abc', 'star': 'abcde' * 3}[length],\n"", ""+                       {'1': 'A', '3': 'ABC', 'star': 'ABCDE' * 3}[length]],\n"", ""+                      [{'1': 'f', '3': 'fgh', 'star': 'fghij' * 3}[length],\n"", ""+                       {'1': 'F', '3': 'FGH', 'star': 'FGHIJ' * 3}[length]]],\n"", ""+                     dtype='S')\n"", '+        expected = np.array([[[c for c in item] for item in row] for row in a],\n', ""+                            dtype='u1', order='F')\n"", '+        assert_array_equal(f(a), expected)\n', '+\n', '+\n', '+class TestCharacter(util.F2PyTest):\n', ""+    # options = ['--debug-capi', '--build-dir', '/tmp/test-build-f2py']\n"", ""+    suffix = '.f90'\n"", ""+    fprefix = 'test_character'\n"", '+\n', '+    code = textwrap.dedent(f""""""\n', '+       subroutine {fprefix}_input(c, o)\n', '+          character, intent(in) :: c\n', '+          integer*1 o\n', '+          !f2py intent(out) o\n', '+          o = transfer(c, o)\n', '+       end subroutine {fprefix}_input\n', '+\n', '+       subroutine {fprefix}_output(c, o)\n', '+          character :: c\n', '+          integer*1, intent(in) :: o\n', '+          !f2py intent(out) c\n', '+          c = transfer(o, c)\n', '+       end subroutine {fprefix}_output\n', '+\n', '+       subroutine {fprefix}_input_output(c, o)\n', '+          character, intent(in) :: c\n', '+          character o\n', '+          !f2py intent(out) o\n', '+          o = c\n', '+       end subroutine {fprefix}_input_output\n', '+\n', '+       subroutine {fprefix}_inout(c, n)\n', '+          character :: c, n\n', '+          !f2py intent(in) n\n', '+          !f2py intent(inout) c\n', '+          c = n\n', '+       end subroutine {fprefix}_inout\n', '+\n', '+       function {fprefix}_return(o) result (c)\n', '+          character :: c\n', '+          character, intent(in) :: o\n', '+          c = transfer(o, c)\n', '+       end function {fprefix}_return\n', '+\n', '+       subroutine {fprefix}_array_input(c, o)\n', '+          character, intent(in) :: c(3)\n', '+          integer*1 o(3)\n', '+          !f2py intent(out) o\n', '+          integer i\n', '+          do i=1,3\n', '+            o(i) = transfer(c(i), o(i))\n', '+          end do\n', '+       end subroutine {fprefix}_array_input\n', '+\n', '+       subroutine {fprefix}_2d_array_input(c, o)\n', '+          character, intent(in) :: c(2, 3)\n', '+          integer*1 o(2, 3)\n', '+          !f2py intent(out) o\n', '+          integer i, j\n', '+          do i=1,2\n', '+            do j=1,3\n', '+              o(i, j) = transfer(c(i, j), o(i, j))\n', '+            end do\n', '+          end do\n', '+       end subroutine {fprefix}_2d_array_input\n', '+\n', '+       subroutine {fprefix}_array_output(c, o)\n', '+          character :: c(3)\n', '+          integer*1, intent(in) :: o(3)\n', '+          !f2py intent(out) c\n', '+          do i=1,3\n', '+            c(i) = transfer(o(i), c(i))\n', '+          end do\n', '+       end subroutine {fprefix}_array_output\n', '+\n', '+       subroutine {fprefix}_array_inout(c, n)\n', '+          character :: c(3), n(3)\n', '+          !f2py intent(in) n(3)\n', '+          !f2py intent(inout) c(3)\n', '+          do i=1,3\n', '+            c(i) = n(i)\n', '+          end do\n', '+       end subroutine {fprefix}_array_inout\n', '+\n', '+       subroutine {fprefix}_2d_array_inout(c, n)\n', '+          character :: c(2, 3), n(2, 3)\n', '+          !f2py intent(in) n(2, 3)\n', '+          !f2py intent(inout) c(2. 3)\n', '+          integer i, j\n', '+          do i=1,2\n', '+            do j=1,3\n', '+              c(i, j) = n(i, j)\n', '+            end do\n', '+          end do\n', '+       end subroutine {fprefix}_2d_array_inout\n', '+\n', '+       function {fprefix}_array_return(o) result (c)\n', '+          character, dimension(3) :: c\n', '+          character, intent(in) :: o(3)\n', '+          do i=1,3\n', '+            c(i) = o(i)\n', '+          end do\n', '+       end function {fprefix}_array_return\n', '+\n', '+       function {fprefix}_optional(o) result (c)\n', '+          character, intent(in) :: o\n', '+          !f2py character o = ""a""\n', '+          character :: c\n', '+          c = o\n', '+       end function {fprefix}_optional\n', '+    """""")\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", [\'c\', \'S1\'])\n', '+    def test_input(self, dtype):\n', ""+        f = getattr(self.module, self.fprefix + '_input')\n"", '+\n', ""+        assert_equal(f(np.array('a', dtype=dtype)), ord('a'))\n"", ""+        assert_equal(f(np.array(b'a', dtype=dtype)), ord('a'))\n"", ""+        assert_equal(f(np.array(['a'], dtype=dtype)), ord('a'))\n"", ""+        assert_equal(f(np.array('abc', dtype=dtype)), ord('a'))\n"", ""+        assert_equal(f(np.array([['a']], dtype=dtype)), ord('a'))\n"", '+\n', '+    def test_input_varia(self):\n', ""+        f = getattr(self.module, self.fprefix + '_input')\n"", '+\n', ""+        assert_equal(f('a'), ord('a'))\n"", ""+        assert_equal(f(b'a'), ord(b'a'))\n"", ""+        assert_equal(f(''), 0)\n"", ""+        assert_equal(f(b''), 0)\n"", ""+        assert_equal(f(b'\\0'), 0)\n"", ""+        assert_equal(f('ab'), ord('a'))\n"", ""+        assert_equal(f(b'ab'), ord('a'))\n"", ""+        assert_equal(f(['a']), ord('a'))\n"", '+\n', ""+        assert_equal(f(np.array(b'a')), ord('a'))\n"", ""+        assert_equal(f(np.array([b'a'])), ord('a'))\n"", ""+        a = np.array('a')\n"", ""+        assert_equal(f(a), ord('a'))\n"", ""+        a = np.array(['a'])\n"", ""+        assert_equal(f(a), ord('a'))\n"", '+\n', '+        try:\n', '+            f([])\n', '+        except IndexError as msg:\n', ""+            if not str(msg).endswith(' got 0-list'):\n"", '+                raise\n', '+        else:\n', ""+            raise SystemError(f'{f.__name__} should have failed on empty list')\n"", '+\n', '+        try:\n', '+            f(97)\n', '+        except TypeError as msg:\n', ""+            if not str(msg).endswith(' got int instance'):\n"", '+                raise\n', '+        else:\n', ""+            raise SystemError(f'{f.__name__} should have failed on int value')\n"", '+\n', '+    @pytest.mark.parametrize(""dtype"", [\'c\', \'S1\', \'U1\'])\n', '+    def test_array_input(self, dtype):\n', ""+        f = getattr(self.module, self.fprefix + '_array_input')\n"", '+\n', ""+        assert_array_equal(f(np.array(['a', 'b', 'c'], dtype=dtype)),\n"", ""+                           np.array(list(map(ord, 'abc')), dtype='i1'))\n"", ""+        assert_array_equal(f(np.array([b'a', b'b', b'c'], dtype=dtype)),\n"", ""+                           np.array(list(map(ord, 'abc')), dtype='i1'))\n"", '+\n', '+    def test_array_input_varia(self):\n', ""+        f = getattr(self.module, self.fprefix + '_array_input')\n"", ""+        assert_array_equal(f(['a', 'b', 'c']),\n"", ""+                           np.array(list(map(ord, 'abc')), dtype='i1'))\n"", ""+        assert_array_equal(f([b'a', b'b', b'c']),\n"", ""+                           np.array(list(map(ord, 'abc')), dtype='i1'))\n"", '+\n', '+        try:\n', ""+            f(['a', 'b', 'c', 'd'])\n"", '+        except ValueError as msg:\n', '+            if not str(msg).endswith(\n', ""+                    'th dimension must be fixed to 3 but got 4'):\n"", '+                raise\n', '+        else:\n', '+            raise SystemError(\n', ""+                f'{f.__name__} should have failed on wrong input')\n"", '+\n', '+    @pytest.mark.parametrize(""dtype"", [\'c\', \'S1\', \'U1\'])\n', '+    def test_2d_array_input(self, dtype):\n', ""+        f = getattr(self.module, self.fprefix + '_2d_array_input')\n"", '+\n', ""+        a = np.array([['a', 'b', 'c'],\n"", ""+                      ['d', 'e', 'f']], dtype=dtype, order='F')\n"", ""+        expected = a.view(np.uint32 if dtype == 'U1' else np.uint8)\n"", '+        assert_array_equal(f(a), expected)\n', '+\n', '+    def test_output(self):\n', ""+        f = getattr(self.module, self.fprefix + '_output')\n"", '+\n', ""+        assert_equal(f(ord(b'a')), b'a')\n"", ""+        assert_equal(f(0), b'\\0')\n"", '+\n', '+    def test_array_output(self):\n', ""+        f = getattr(self.module, self.fprefix + '_array_output')\n"", '+\n', ""+        assert_array_equal(f(list(map(ord, 'abc'))),\n"", ""+                           np.array(list('abc'), dtype='S1'))\n"", '+\n', '+    def test_input_output(self):\n', ""+        f = getattr(self.module, self.fprefix + '_input_output')\n"", '+\n', ""+        assert_equal(f(b'a'), b'a')\n"", ""+        assert_equal(f('a'), b'a')\n"", ""+        assert_equal(f(''), b'\\0')\n"", '+\n', '+    @pytest.mark.parametrize(""dtype"", [\'c\', \'S1\'])\n', '+    def test_inout(self, dtype):\n', ""+        f = getattr(self.module, self.fprefix + '_inout')\n"", '+\n', ""+        a = np.array(list('abc'), dtype=dtype)\n"", ""+        f(a, 'A')\n"", ""+        assert_array_equal(a, np.array(list('Abc'), dtype=a.dtype))\n"", ""+        f(a[1:], 'B')\n"", ""+        assert_array_equal(a, np.array(list('ABc'), dtype=a.dtype))\n"", '+\n', ""+        a = np.array(['abc'], dtype=dtype)\n"", ""+        f(a, 'A')\n"", ""+        assert_array_equal(a, np.array(['Abc'], dtype=a.dtype))\n"", '+\n', '+    def test_inout_varia(self):\n', ""+        f = getattr(self.module, self.fprefix + '_inout')\n"", ""+        a = np.array('abc', dtype='S3')\n"", ""+        f(a, 'A')\n"", ""+        assert_array_equal(a, np.array('Abc', dtype=a.dtype))\n"", '+\n', ""+        a = np.array(['abc'], dtype='S3')\n"", ""+        f(a, 'A')\n"", ""+        assert_array_equal(a, np.array(['Abc'], dtype=a.dtype))\n"", '+\n', '+        try:\n', ""+            f('abc', 'A')\n"", '+        except ValueError as msg:\n', ""+            if not str(msg).endswith(' got 3-str'):\n"", '+                raise\n', '+        else:\n', ""+            raise SystemError(f'{f.__name__} should have failed on str value')\n"", '+\n', '+    @pytest.mark.parametrize(""dtype"", [\'c\', \'S1\'])\n', '+    def test_array_inout(self, dtype):\n', ""+        f = getattr(self.module, self.fprefix + '_array_inout')\n"", ""+        n = np.array(['A', 'B', 'C'], dtype=dtype, order='F')\n"", '+\n', ""+        a = np.array(['a', 'b', 'c'], dtype=dtype, order='F')\n"", '+        f(a, n)\n', '+        assert_array_equal(a, n)\n', '+\n', ""+        a = np.array(['a', 'b', 'c', 'd'], dtype=dtype)\n"", '+        f(a[1:], n)\n', ""+        assert_array_equal(a, np.array(['a', 'A', 'B', 'C'], dtype=dtype))\n"", '+\n', ""+        a = np.array([['a', 'b', 'c']], dtype=dtype, order='F')\n"", '+        f(a, n)\n', ""+        assert_array_equal(a, np.array([['A', 'B', 'C']], dtype=dtype))\n"", '+\n', ""+        a = np.array(['a', 'b', 'c', 'd'], dtype=dtype, order='F')\n"", '+        try:\n', '+            f(a, n)\n', '+        except ValueError as msg:\n', '+            if not str(msg).endswith(\n', ""+                    'th dimension must be fixed to 3 but got 4'):\n"", '+                raise\n', '+        else:\n', '+            raise SystemError(\n', ""+                f'{f.__name__} should have failed on wrong input')\n"", '+\n', '+    @pytest.mark.parametrize(""dtype"", [\'c\', \'S1\'])\n', '+    def test_2d_array_inout(self, dtype):\n', ""+        f = getattr(self.module, self.fprefix + '_2d_array_inout')\n"", ""+        n = np.array([['A', 'B', 'C'],\n"", ""+                      ['D', 'E', 'F']],\n"", ""+                     dtype=dtype, order='F')\n"", ""+        a = np.array([['a', 'b', 'c'],\n"", ""+                      ['d', 'e', 'f']],\n"", ""+                     dtype=dtype, order='F')\n"", '+        f(a, n)\n', '+        assert_array_equal(a, n)\n', '+\n', '+    def test_return(self):\n', ""+        f = getattr(self.module, self.fprefix + '_return')\n"", '+\n', ""+        assert_equal(f('a'), b'a')\n"", '+\n', ""+    @pytest.mark.skip('fortran function returning array segfaults')\n"", '+    def test_array_return(self):\n', ""+        f = getattr(self.module, self.fprefix + '_array_return')\n"", '+\n', ""+        a = np.array(list('abc'), dtype='S1')\n"", '+        assert_array_equal(f(a), a)\n', '+\n', '+    def test_optional(self):\n', ""+        f = getattr(self.module, self.fprefix + '_optional')\n"", '+\n', '+        assert_equal(f(), b""a"")\n', '+        assert_equal(f(b\'B\'), b""B"")\n', '+\n', '+\n', '+class TestMiscCharacter(util.F2PyTest):\n', ""+    # options = ['--debug-capi', '--build-dir', '/tmp/test-build-f2py']\n"", ""+    suffix = '.f90'\n"", ""+    fprefix = 'test_misc_character'\n"", '+\n', '+    code = textwrap.dedent(f""""""\n', '+       subroutine {fprefix}_gh18684(x, y, m)\n', '+         character(len=5), dimension(m), intent(in) :: x\n', '+         character*5, dimension(m), intent(out) :: y\n', '+         integer i, m\n', '+         !f2py integer, intent(hide), depend(x) :: m = f2py_len(x)\n', '+         do i=1,m\n', '+           y(i) = x(i)\n', '+         end do\n', '+       end subroutine {fprefix}_gh18684\n', '+\n', '+       subroutine {fprefix}_gh6308(x, i)\n', '+         integer i\n', '+         !f2py check(i>=0 && i<12) i\n', '+         character*5 name, x\n', '+         common name(12)\n', '+         name(i + 1) = x\n', '+       end subroutine {fprefix}_gh6308\n', '+\n', '+       subroutine {fprefix}_gh4519(x)\n', '+         character(len=*), intent(in) :: x(:)\n', '+         !f2py intent(out) x\n', '+         integer :: i\n', '+         do i=1, size(x)\n', '+           print*, ""x("",i,"")="", x(i)\n', '+         end do\n', '+       end subroutine {fprefix}_gh4519\n', '+\n', '+       pure function {fprefix}_gh3425(x) result (y)\n', '+         character(len=*), intent(in) :: x\n', '+         character(len=len(x)) :: y\n', '+         integer :: i\n', '+         do i = 1, len(x)\n', '+           j = iachar(x(i:i))\n', '+           if (j>=iachar(""a"") .and. j<=iachar(""z"") ) then\n', '+             y(i:i) = achar(j-32)\n', '+           else\n', '+             y(i:i) = x(i:i)\n', '+           endif\n', '+         end do\n', '+       end function {fprefix}_gh3425\n', '+\n', '+       subroutine {fprefix}_character_bc_new(x, y, z)\n', '+         character, intent(in) :: x\n', '+         character, intent(out) :: y\n', '+         !f2py character, depend(x) :: y = x\n', ""+         !f2py character, dimension((x=='a'?1:2)), depend(x), intent(out) :: z\n"", '+         character, dimension(*) :: z\n', ""+         !f2py character, optional, check(x == 'a' || x == 'b') :: x = 'a'\n"", '+         !f2py callstatement (*f2py_func)(&x, &y, z)\n', '+         !f2py callprotoargument character*, character*, character*\n', '+         if (y.eq.x) then\n', '+           y = x\n', '+         else\n', ""+           y = 'e'\n"", '+         endif\n', ""+         z(1) = 'c'\n"", '+       end subroutine {fprefix}_character_bc_new\n', '+\n', '+       subroutine {fprefix}_character_bc_old(x, y, z)\n', '+         character, intent(in) :: x\n', '+         character, intent(out) :: y\n', '+         !f2py character, depend(x) :: y = x[0]\n', ""+         !f2py character, dimension((*x=='a'?1:2)), depend(x), intent(out) :: z\n"", '+         character, dimension(*) :: z\n', ""+         !f2py character, optional, check(*x == 'a' || x[0] == 'b') :: x = 'a'\n"", '+         !f2py callstatement (*f2py_func)(x, y, z)\n', '+         !f2py callprotoargument char*, char*, char*\n', '+          if (y.eq.x) then\n', '+           y = x\n', '+         else\n', ""+           y = 'e'\n"", '+         endif\n', ""+         z(1) = 'c'\n"", '+       end subroutine {fprefix}_character_bc_old\n', '+    """""")\n', '+\n', '+    def test_gh18684(self):\n', '+        # Test character(len=5) and character*5 usages\n', ""+        f = getattr(self.module, self.fprefix + '_gh18684')\n"", '+        x = np.array([""abcde"", ""fghij""], dtype=\'S5\')\n', '+        y = f(x)\n', '+\n', '+        assert_array_equal(x, y)\n', '+\n', '+    def test_gh6308(self):\n', '+        # Test character string array in a common block\n', ""+        f = getattr(self.module, self.fprefix + '_gh6308')\n"", '+\n', ""+        assert_equal(self.module._BLNK_.name.dtype, np.dtype('S5'))\n"", '+        assert_equal(len(self.module._BLNK_.name), 12)\n', '+        f(""abcde"", 0)\n', '+        assert_equal(self.module._BLNK_.name[0], b""abcde"")\n', '+        f(""12345"", 5)\n', '+        assert_equal(self.module._BLNK_.name[5], b""12345"")\n', '+\n', '+    def test_gh4519(self):\n', '+        # Test array of assumed length strings\n', ""+        f = getattr(self.module, self.fprefix + '_gh4519')\n"", '+\n', '+        for x, expected in [\n', ""+                ('a', dict(shape=(), dtype=np.dtype('S1'))),\n"", ""+                ('text', dict(shape=(), dtype=np.dtype('S4'))),\n"", ""+                (np.array(['1', '2', '3'], dtype='S1'),\n"", ""+                 dict(shape=(3,), dtype=np.dtype('S1'))),\n"", ""+                (['1', '2', '34'],\n"", ""+                 dict(shape=(3,), dtype=np.dtype('S2'))),\n"", ""+                (['', ''], dict(shape=(2,), dtype=np.dtype('S1')))]:\n"", '+            r = f(x)\n', '+            for k, v in expected.items():\n', '+                assert_equal(getattr(r, k), v)\n', '+\n', '+    def test_gh3425(self):\n', '+        # Test returning a copy of assumed length string\n', ""+        f = getattr(self.module, self.fprefix + '_gh3425')\n"", '+        # f is equivalent to bytes.upper\n', '+\n', ""+        assert_equal(f('abC'), b'ABC')\n"", ""+        assert_equal(f(''), b'')\n"", ""+        assert_equal(f('abC12d'), b'ABC12D')\n"", '+\n', '+    @pytest.mark.parametrize(""state"", [\'new\', \'old\'])\n', '+    def test_character_bc(self, state):\n', ""+        f = getattr(self.module, self.fprefix + '_character_bc_' + state)\n"", '+\n', '+        c, a = f()\n', ""+        assert_equal(c, b'a')\n"", '+        assert_equal(len(a), 1)\n', '+\n', ""+        c, a = f(b'b')\n"", ""+        assert_equal(c, b'b')\n"", '+        assert_equal(len(a), 2)\n', '+\n', ""+        assert_raises(Exception, lambda: f(b'c'))\n""]",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import codecs\n', ' import pytest\n', ' import numpy as np\n', ' from numpy.f2py.crackfortran import markinnerspaces\n']","[' import pytest\n', ' import numpy as np\n', ' from numpy.f2py.crackfortran import markinnerspaces\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert np.allclose(k, w + 1)\n', '         self.module.subc([w, k])\n', '         assert np.allclose(k, w + 1)\n', '+        assert self.module.t0(""23"") == b""2""\n', ' \n', ' \n', ' class TestPublicPrivate:\n']","['         assert np.allclose(k, w + 1)\n', '         self.module.subc([w, k])\n', '         assert np.allclose(k, w + 1)\n', '-        assert self.module.t0(23) == b""2""\n', ' \n', ' \n', ' class TestPublicPrivate:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert mod[""body""][3][""implementedby""] == \\\n', '             [""get_int"", ""get_real""]\n', ' \n', '+    def test_notPublicPrivate(self, tmp_path):\n', '+        fpath = util.getpath(""tests"", ""src"", ""crackfortran"", ""pubprivmod.f90"")\n', '+        mod = crackfortran.crackfortran([str(fpath)])\n', '+        assert len(mod) == 1\n', '+        mod = mod[0]\n', ""+        assert mod['vars']['a']['attrspec'] == ['private', ]\n"", ""+        assert mod['vars']['b']['attrspec'] == ['public', ]\n"", ""+        assert mod['vars']['seta']['attrspec'] == ['public', ]\n"", '+\n', ' \n', ' class TestExternal(util.F2PyTest):\n', '     # issue gh-17859: add external attribute support\n']","['         assert mod[""body""][3][""implementedby""] == \\\n', '             [""get_int"", ""get_real""]\n', ' \n', ' \n', ' class TestExternal(util.F2PyTest):\n', '     # issue gh-17859: add external attribute support\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert markinnerspaces(""a \'b c\' \'d e\'"") == ""a \'b@_@c\' \'d@_@e\'""\n', '         assert markinnerspaces(r\'a ""b c"" ""d e""\') == r\'a ""b@_@c"" ""d@_@e""\'\n', ' \n', ' class TestDimSpec(util.F2PyTest):\n', '     """"""This test suite tests various expressions that are used as dimension\n', '     specifications.\n']","['         assert markinnerspaces(""a \'b c\' \'d e\'"") == ""a \'b@_@c\' \'d@_@e\'""\n', '         assert markinnerspaces(r\'a ""b c"" ""d e""\') == r\'a ""b@_@c"" ""d@_@e""\'\n', ' \n', '-\n', ' class TestDimSpec(util.F2PyTest):\n', '     """"""This test suite tests various expressions that are used as dimension\n', '     specifications.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         mod = crackfortran.crackfortran([str(fpath)])\n', '         assert len(mod) == 1\n', '         assert mod[0][""vars""][""abar""][""=""] == ""bar(\'abar\')""\n', '+\n', '+class TestEval(util.F2PyTest):\n', '+    def test_eval_scalar(self):\n', '+        eval_scalar = crackfortran._eval_scalar\n', '+\n', ""+        assert eval_scalar('123', {}) == '123'\n"", ""+        assert eval_scalar('12 + 3', {}) == '15'\n"", ""+        assert eval_scalar('a + b', dict(a=1, b=2)) == '3'\n"", '+        assert eval_scalar(\'""123""\', {}) == ""\'123\'""\n', '+\n', '+\n', '+class TestFortranReader(util.F2PyTest):\n', '+    @pytest.mark.parametrize(""encoding"",\n', ""+                             ['ascii', 'utf-8', 'utf-16', 'utf-32'])\n"", '+    def test_input_encoding(self, tmp_path, encoding):\n', '+        # gh-635\n', '+        f_path = tmp_path / f""input_with_{encoding}_encoding.f90""\n', '+        # explicit BOM is required for UTF8\n', ""+        bom = {'utf-8': codecs.BOM_UTF8}.get(encoding, b'')\n"", ""+        with f_path.open('w', encoding=encoding) as ff:\n"", '+            ff.write(bom.decode(encoding) +\n', '+                     """"""\n', '+                     subroutine foo()\n', '+                     end subroutine foo\n', '+                     """""")\n', '+        mod = crackfortran.crackfortran([str(f_path)])\n', ""+        assert mod[0]['name'] == 'foo'\n""]","['         mod = crackfortran.crackfortran([str(fpath)])\n', '         assert len(mod) == 1\n', '         assert mod[0][""vars""][""abar""][""=""] == ""bar(\'abar\')""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import os\n', '+import pytest\n', '+import numpy as np\n', '+from numpy.testing import assert_array_equal, assert_equal\n', '+from . import util\n', '+\n', '+\n', '+def get_docdir():\n', '+    # assuming that documentation tests are run from a source\n', '+    # directory\n', '+    return os.path.abspath(os.path.join(\n', '+        os.path.dirname(__file__),\n', ""+        '..', '..', '..',\n"", ""+        'doc', 'source', 'f2py', 'code'))\n"", '+\n', '+\n', '+pytestmark = pytest.mark.skipif(\n', '+    not os.path.isdir(get_docdir()),\n', ""+    reason=('Could not find f2py documentation sources'\n"", ""+            f' ({get_docdir()} does not exists)'))\n"", '+\n', '+\n', '+def _path(*a):\n', '+    return os.path.join(*((get_docdir(),) + a))\n', '+\n', '+\n', '+class TestDocAdvanced(util.F2PyTest):\n', ""+    # options = ['--debug-capi', '--build-dir', '/tmp/build-f2py']\n"", ""+    sources = [_path('asterisk1.f90'), _path('asterisk2.f90'),\n"", ""+               _path('ftype.f')]\n"", '+\n', '+    def test_asterisk1(self):\n', ""+        foo = getattr(self.module, 'foo1')\n"", ""+        assert_equal(foo(), b'123456789A12')\n"", '+\n', '+    def test_asterisk2(self):\n', ""+        foo = getattr(self.module, 'foo2')\n"", ""+        assert_equal(foo(2), b'12')\n"", ""+        assert_equal(foo(12), b'123456789A12')\n"", ""+        assert_equal(foo(24), b'123456789A123456789B')\n"", '+\n', '+    def test_ftype(self):\n', '+        ftype = self.module\n', '+        ftype.foo()\n', '+        assert_equal(ftype.data.a, 0)\n', '+        ftype.data.a = 3\n', '+        ftype.data.x = [1, 2, 3]\n', '+        assert_equal(ftype.data.a, 3)\n', '+        assert_array_equal(ftype.data.x,\n', '+                           np.array([1, 2, 3], dtype=np.float32))\n', '+        ftype.data.x[1] = 45\n', '+        assert_array_equal(ftype.data.x,\n', '+                           np.array([1, 45, 3], dtype=np.float32))\n', '+\n', '+    # TODO: implement test methods for other example Fortran codes\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"['+from . import util\n', '+import numpy as np\n', '+\n', '+class TestF2Cmap(util.F2PyTest):\n', '+    sources = [\n', '+        util.getpath(""tests"", ""src"", ""f2cmap"", ""isoFortranEnvMap.f90""),\n', '+        util.getpath(""tests"", ""src"", ""f2cmap"", "".f2py_f2cmap"")\n', '+    ]\n', '+\n', '+    # gh-15095\n', '+    def test_long_long_map(self):\n', '+        inp = np.ones(3)\n', '+        out = self.module.func1(inp)\n', '+        exp_out = 3\n', '+        assert out == exp_out\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"['     fn.write_text(fdat, encoding=""ascii"")\n', '     return fn\n', ' \n', '+@pytest.fixture(scope=""session"")\n', '+def f2cmap_f90(tmpdir_factory):\n', '+    """"""Generates a single f90 file for testing""""""\n', '+    fdat = util.getpath(""tests"", ""src"", ""f2cmap"", ""isoFortranEnvMap.f90"").read_text()\n', '+    f2cmap = util.getpath(""tests"", ""src"", ""f2cmap"", "".f2py_f2cmap"").read_text()\n', '+    fn = tmpdir_factory.getbasetemp() / ""f2cmap.f90""\n', '+    fmap = tmpdir_factory.getbasetemp() / ""mapfile""\n', '+    fn.write_text(fdat, encoding=""ascii"")\n', '+    fmap.write_text(f2cmap, encoding=""ascii"")\n', '+    return fn\n', '+\n', ' \n', ' def test_gen_pyf(capfd, hello_world_f90, monkeypatch):\n', '     """"""Ensures that a signature file is generated via the CLI\n']","['     fn.write_text(fdat, encoding=""ascii"")\n', '     return fn\n', ' \n', ' \n', ' def test_gen_pyf(capfd, hello_world_f90, monkeypatch):\n', '     """"""Ensures that a signature file is generated via the CLI\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         f2pycli()\n', '         out, _ = capfd.readouterr()\n', '         assert ""Saving signatures to file"" in out\n', '+        assert ""function hi() ! in "" in out\n', ' \n', ' \n', ' def test_gen_pyf_no_overwrite(capfd, hello_world_f90, monkeypatch):\n']","['         f2pycli()\n', '         out, _ = capfd.readouterr()\n', '         assert ""Saving signatures to file"" in out\n', ' \n', ' \n', ' def test_gen_pyf_no_overwrite(capfd, hello_world_f90, monkeypatch):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     pass\n', ' \n', ' \n', '+def test_f2cmap(capfd, f2cmap_f90, monkeypatch):\n', '     """"""Check that Fortran-to-Python KIND specs can be passed\n', ' \n', '     CLI :: --f2cmap\n', '     """"""\n', '+    ipath = Path(f2cmap_f90)\n', '+    monkeypatch.setattr(sys, ""argv"", f\'f2py -m blah {ipath} --f2cmap mapfile\'.split())\n', '+\n', '+    with util.switchdir(ipath.parent):\n', '+        f2pycli()\n', '+        out, _ = capfd.readouterr()\n', '+        assert ""Reading f2cmap from \'mapfile\' ..."" in out\n', '+        assert ""Mapping \\""real(kind=real32)\\"" to \\""float\\"""" in out\n', '+        assert ""Mapping \\""real(kind=real64)\\"" to \\""double\\"""" in out\n', '+        assert ""Mapping \\""integer(kind=int64)\\"" to \\""long_long\\"""" in out\n', '+        assert ""Successfully applied user defined f2cmap changes"" in out\n', ' \n', ' \n', ' def test_quiet(capfd, hello_world_f90, monkeypatch):\n']","['     pass\n', ' \n', ' \n', '-def test_f2cmap():\n', '     """"""Check that Fortran-to-Python KIND specs can be passed\n', ' \n', '     CLI :: --f2cmap\n', '     """"""\n', '-    # TODO: populate\n', '-    pass\n', ' \n', ' \n', ' def test_quiet(capfd, hello_world_f90, monkeypatch):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestReturnCharacter(util.F2PyTest):\n', '     def check_function(self, t, tname):\n', '         if tname in [""t0"", ""t1"", ""s0"", ""s1""]:\n', '+            assert t(""23"") == b""2""\n', '             r = t(""ab"")\n', '             assert r == b""a""\n', '             r = t(array(""ab""))\n']","[' class TestReturnCharacter(util.F2PyTest):\n', '     def check_function(self, t, tname):\n', '         if tname in [""t0"", ""t1"", ""s0"", ""s1""]:\n', '-            assert t(23) == b""2""\n', '             r = t(""ab"")\n', '             assert r == b""a""\n', '             r = t(array(""ab""))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert abs(t(array(23 + 4j, ""F"")) - (23 + 4j)) <= err\n', '         assert abs(t(array([234])) - 234.0) <= err\n', '         assert abs(t(array([[234]])) - 234.0) <= err\n', '+        assert abs(t(array([234]).astype(""b"")) + 22.0) <= err\n', '         assert abs(t(array([234], ""h"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""i"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""l"")) - 234.0) <= err\n']","['         assert abs(t(array(23 + 4j, ""F"")) - (23 + 4j)) <= err\n', '         assert abs(t(array([234])) - 234.0) <= err\n', '         assert abs(t(array([[234]])) - 234.0) <= err\n', '-        assert abs(t(array([234], ""b"")) + 22.0) <= err\n', '         assert abs(t(array([234], ""h"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""i"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""l"")) - 234.0) <= err\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert t(array(234)) == 1\n', '         assert t(array([234])) == 1\n', '         assert t(array([[234]])) == 1\n', '+        assert t(array([127], ""b"")) == 1\n', '         assert t(array([234], ""h"")) == 1\n', '         assert t(array([234], ""i"")) == 1\n', '         assert t(array([234], ""l"")) == 1\n']","['         assert t(array(234)) == 1\n', '         assert t(array([234])) == 1\n', '         assert t(array([[234]])) == 1\n', '-        assert t(array([234], ""b"")) == 1\n', '         assert t(array([234], ""h"")) == 1\n', '         assert t(array([234], ""i"")) == 1\n', '         assert t(array([234], ""l"")) == 1\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert abs(t(array(234)) - 234.0) <= err\n', '         assert abs(t(array([234])) - 234.0) <= err\n', '         assert abs(t(array([[234]])) - 234.0) <= err\n', '+        assert abs(t(array([234]).astype(""b"")) + 22) <= err\n', '         assert abs(t(array([234], ""h"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""i"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""l"")) - 234.0) <= err\n']","['         assert abs(t(array(234)) - 234.0) <= err\n', '         assert abs(t(array([234])) - 234.0) <= err\n', '         assert abs(t(array([[234]])) - 234.0) <= err\n', '-        assert abs(t(array([234], ""b"")) + 22) <= err\n', '         assert abs(t(array([234], ""h"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""i"")) - 234.0) <= err\n', '         assert abs(t(array([234], ""l"")) - 234.0) <= err\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import os\n', '+import pytest\n', '+\n', '+from . import util\n', '+\n', '+class TestValueAttr(util.F2PyTest):\n', '+    sources = [util.getpath(""tests"", ""src"", ""value_attrspec"", ""gh21665.f90"")]\n', '+\n', '+    # gh-21665\n', '+    def test_long_long_map(self):\n', '+        inp = 2\n', '+        out = self.module.fortfuncs.square(inp)\n', '+        exp_out = 4\n', '+        assert out == exp_out\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' from pathlib import Path\n', ' from numpy.compat import asbytes, asstr\n', '+from numpy.testing import temppath, IS_WASM\n', ' from importlib import import_module\n', ' \n', ' #\n']","[' \n', ' from pathlib import Path\n', ' from numpy.compat import asbytes, asstr\n', '-from numpy.testing import temppath\n', ' from importlib import import_module\n', ' \n', ' #\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' def get_temp_module_name():\n', '     # Assume single-threaded, and the module dir usable only by this thread\n', '     global _module_num\n', '+    get_module_dir()\n', '     name = ""_test_ext_module_%d"" % _module_num\n', '     _module_num += 1\n', '     if name in sys.modules:\n']","[' def get_temp_module_name():\n', '     # Assume single-threaded, and the module dir usable only by this thread\n', '     global _module_num\n', '-    d = get_module_dir()\n', '     name = ""_test_ext_module_%d"" % _module_num\n', '     _module_num += 1\n', '     if name in sys.modules:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if ext in ("".f90"", "".f"", "".c"", "".pyf""):\n', '             f2py_sources.append(dst)\n', ' \n', '+    assert f2py_sources\n', '+\n', '     # Prepare options\n', '     if module_name is None:\n', '         module_name = get_temp_module_name()\n']","['         if ext in ("".f90"", "".f"", "".c"", "".pyf""):\n', '             f2py_sources.append(dst)\n', ' \n', '     # Prepare options\n', '     if module_name is None:\n', '         module_name = get_temp_module_name()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return _compiler_status\n', ' \n', '     _compiler_status = (False, False, False)\n', '+    if IS_WASM:\n', ""+        # Can't run compiler from inside WASM.\n"", '+        return _compiler_status\n', ' \n', ""     # XXX: this is really ugly. But I don't know how to invoke Distutils\n"", '     #      in a safer way...\n']","['         return _compiler_status\n', ' \n', '     _compiler_status = (False, False, False)\n', ' \n', ""     # XXX: this is really ugly. But I don't know how to invoke Distutils\n"", '     #      in a safer way...\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     only = []\n', '     suffix = "".f""\n', '     module = None\n', ' \n', '+    @property\n', '+    def module_name(self):\n', '+        cls = type(self)\n', '+        return f\'_{cls.__module__.rsplit(""."",1)[-1]}_{cls.__name__}_ext_module\'\n', '+\n', '+    def setup_method(self):\n', '         if sys.platform == ""win32"":\n', '             pytest.skip(""Fails with MinGW64 Gfortran (Issue #9673)"")\n', ' \n']","['     only = []\n', '     suffix = "".f""\n', '     module = None\n', '-    module_name = None\n', ' \n', '-    def setup(self):\n', '         if sys.platform == ""win32"":\n', '             pytest.skip(""Fails with MinGW64 Gfortran (Issue #9673)"")\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         needs_f77 = False\n', '         needs_f90 = False\n', '+        needs_pyf = False\n', '         for fn in codes:\n', '             if str(fn).endswith("".f""):\n', '                 needs_f77 = True\n', '             elif str(fn).endswith("".f90""):\n', '                 needs_f90 = True\n', '+            elif str(fn).endswith("".pyf""):\n', '+                needs_pyf = True\n', '         if needs_f77 and not has_f77_compiler():\n', '             pytest.skip(""No Fortran 77 compiler available"")\n', '         if needs_f90 and not has_f90_compiler():\n', '             pytest.skip(""No Fortran 90 compiler available"")\n', '+        if needs_pyf and not (has_f90_compiler() or has_f77_compiler()):\n', '+            pytest.skip(""No Fortran compiler available"")\n', ' \n', '         # Build the module\n', '         if self.code is not None:\n']","[' \n', '         needs_f77 = False\n', '         needs_f90 = False\n', '         for fn in codes:\n', '             if str(fn).endswith("".f""):\n', '                 needs_f77 = True\n', '             elif str(fn).endswith("".f90""):\n', '                 needs_f90 = True\n', '         if needs_f77 and not has_f77_compiler():\n', '             pytest.skip(""No Fortran 77 compiler available"")\n', '         if needs_f90 and not has_f90_compiler():\n', '             pytest.skip(""No Fortran 90 compiler available"")\n', ' \n', '         # Build the module\n', '         if self.code is not None:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import pytest\n', ' from numpy.random import random\n', ' from numpy.testing import (\n', '+        assert_array_equal, assert_raises, assert_allclose, IS_WASM\n', '         )\n', ' import threading\n', ' import queue\n']","[' import pytest\n', ' from numpy.random import random\n', ' from numpy.testing import (\n', '-        assert_array_equal, assert_raises, assert_allclose\n', '         )\n', ' import threading\n', ' import queue\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         raise ValueError()\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start thread"")\n', ' class TestFFTThreadSafe:\n', '     threads = 16\n', '     input_shape = (800, 200)\n']","['         raise ValueError()\n', ' \n', ' \n', ' class TestFFTThreadSafe:\n', '     threads = 16\n', '     input_shape = (800, 200)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         The array to pad.\n', '     pad_width : {sequence, array_like, int}\n', '         Number of values padded to the edges of each axis.\n', '+        ``((before_1, after_1), ... (before_N, after_N))`` unique pad widths\n', '         for each axis.\n', '+        ``(before, after)`` or ``((before, after),)`` yields same before\n', '+        and after pad for each axis.\n', '+        ``(pad,)`` or ``int`` is a shortcut for before = after = pad width\n', '+        for all axes.\n', '     mode : str or function, optional\n', '         One of the following string values or a user supplied function.\n', ' \n']","['         The array to pad.\n', '     pad_width : {sequence, array_like, int}\n', '         Number of values padded to the edges of each axis.\n', '-        ((before_1, after_1), ... (before_N, after_N)) unique pad widths\n', '         for each axis.\n', '-        ((before, after),) yields same before and after pad for each axis.\n', '-        (pad,) or int is a shortcut for before = after = pad width for all\n', '-        axes.\n', '     mode : str or function, optional\n', '         One of the following string values or a user supplied function.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of\n"", '         values at edge of each axis used to calculate the statistic value.\n', ' \n', '+        ``((before_1, after_1), ... (before_N, after_N))`` unique statistic\n', '         lengths for each axis.\n', ' \n', '+        ``(before, after)`` or ``((before, after),)`` yields same before\n', '+        and after statistic lengths for each axis.\n', ' \n', '+        ``(stat_length,)`` or ``int`` is a shortcut for\n', '+        ``before = after = statistic`` length for all axes.\n', ' \n', '         Default is ``None``, to use the entire axis.\n', '     constant_values : sequence or scalar, optional\n']","[""         Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of\n"", '         values at edge of each axis used to calculate the statistic value.\n', ' \n', '-        ((before_1, after_1), ... (before_N, after_N)) unique statistic\n', '         lengths for each axis.\n', ' \n', '-        ((before, after),) yields same before and after statistic lengths\n', '-        for each axis.\n', ' \n', '-        (stat_length,) or int is a shortcut for before = after = statistic\n', '-        length for all axes.\n', ' \n', '         Default is ``None``, to use the entire axis.\n', '     constant_values : sequence or scalar, optional\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         ``((before_1, after_1), ... (before_N, after_N))`` unique pad constants\n', '         for each axis.\n', ' \n', '+        ``(before, after)`` or ``((before, after),)`` yields same before\n', '+        and after constants for each axis.\n', ' \n', '+        ``(constant,)`` or ``constant`` is a shortcut for\n', '+        ``before = after = constant`` for all axes.\n', ' \n', '         Default is 0.\n', '     end_values : sequence or scalar, optional\n']","['         ``((before_1, after_1), ... (before_N, after_N))`` unique pad constants\n', '         for each axis.\n', ' \n', '-        ``((before, after),)`` yields same before and after constants for each\n', '-        axis.\n', ' \n', '-        ``(constant,)`` or ``constant`` is a shortcut for ``before = after = constant`` for\n', '-        all axes.\n', ' \n', '         Default is 0.\n', '     end_values : sequence or scalar, optional\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         ``((before_1, after_1), ... (before_N, after_N))`` unique end values\n', '         for each axis.\n', ' \n', '+        ``(before, after)`` or ``((before, after),)`` yields same before\n', '+        and after end values for each axis.\n', ' \n', '+        ``(constant,)`` or ``constant`` is a shortcut for\n', '+        ``before = after = constant`` for all axes.\n', ' \n', '         Default is 0.\n', ""     reflect_type : {'even', 'odd'}, optional\n""]","['         ``((before_1, after_1), ... (before_N, after_N))`` unique end values\n', '         for each axis.\n', ' \n', '-        ``((before, after),)`` yields same before and after end values for each\n', '-        axis.\n', ' \n', '-        ``(constant,)`` or ``constant`` is a shortcut for ``before = after = constant`` for\n', '-        all axes.\n', ' \n', '         Default is 0.\n', ""     reflect_type : {'even', 'odd'}, optional\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def _unique_dispatcher(ar, return_index=None, return_inverse=None,\n', '+                       return_counts=None, axis=None, *, equal_nan=None):\n', '     return (ar,)\n', ' \n', ' \n', ' @array_function_dispatch(_unique_dispatcher)\n', ' def unique(ar, return_index=False, return_inverse=False,\n', '+           return_counts=False, axis=None, *, equal_nan=True):\n', '     """"""\n', '     Find the unique elements of an array.\n', ' \n']","[' \n', ' \n', ' def _unique_dispatcher(ar, return_index=None, return_inverse=None,\n', '-                       return_counts=None, axis=None):\n', '     return (ar,)\n', ' \n', ' \n', ' @array_function_dispatch(_unique_dispatcher)\n', ' def unique(ar, return_index=False, return_inverse=False,\n', '-           return_counts=False, axis=None):\n', '     """"""\n', '     Find the unique elements of an array.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return_counts : bool, optional\n', '         If True, also return the number of times each unique item appears\n', '         in `ar`.\n', '     axis : int or None, optional\n', '         The axis to operate on. If None, `ar` will be flattened. If an integer,\n', '         the subarrays indexed by the given axis will be flattened and treated\n']","['     return_counts : bool, optional\n', '         If True, also return the number of times each unique item appears\n', '         in `ar`.\n', '-\n', '-        .. versionadded:: 1.9.0\n', '-\n', '     axis : int or None, optional\n', '         The axis to operate on. If None, `ar` will be flattened. If an integer,\n', '         the subarrays indexed by the given axis will be flattened and treated\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         .. versionadded:: 1.13.0\n', ' \n', '+    equal_nan : bool, optional\n', '+        If True, collapses multiple NaN values in the return array into one.\n', '+\n', '+        .. versionadded:: 1.24\n', '+\n', '     Returns\n', '     -------\n', '     unique : ndarray\n']","[' \n', '         .. versionadded:: 1.13.0\n', ' \n', '     Returns\n', '     -------\n', '     unique : ndarray\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     ar = np.asanyarray(ar)\n', '     if axis is None:\n', '+        ret = _unique1d(ar, return_index, return_inverse, return_counts, \n', '+                        equal_nan=equal_nan)\n', '         return _unpack_tuple(ret)\n', ' \n', '     # axis was specified and not None\n']","['     """"""\n', '     ar = np.asanyarray(ar)\n', '     if axis is None:\n', '-        ret = _unique1d(ar, return_index, return_inverse, return_counts)\n', '         return _unpack_tuple(ret)\n', ' \n', '     # axis was specified and not None\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return uniq\n', ' \n', '     output = _unique1d(consolidated, return_index,\n', '+                       return_inverse, return_counts, equal_nan=equal_nan)\n', '     output = (reshape_uniq(output[0]),) + output[1:]\n', '     return _unpack_tuple(output)\n', ' \n', ' \n', ' def _unique1d(ar, return_index=False, return_inverse=False,\n', '+              return_counts=False, *, equal_nan=True):\n', '     """"""\n', '     Find the unique elements of an array, ignoring shape.\n', '     """"""\n']","['         return uniq\n', ' \n', '     output = _unique1d(consolidated, return_index,\n', '-                       return_inverse, return_counts)\n', '     output = (reshape_uniq(output[0]),) + output[1:]\n', '     return _unpack_tuple(output)\n', ' \n', ' \n', ' def _unique1d(ar, return_index=False, return_inverse=False,\n', '-              return_counts=False):\n', '     """"""\n', '     Find the unique elements of an array, ignoring shape.\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         aux = ar\n', '     mask = np.empty(aux.shape, dtype=np.bool_)\n', '     mask[:1] = True\n', '+    if (equal_nan and aux.shape[0] > 0 and aux.dtype.kind in ""cfmM"" and\n', '+            np.isnan(aux[-1])):\n', '         if aux.dtype.kind == ""c"":  # for complex all NaNs are considered equivalent\n', ""             aux_firstnan = np.searchsorted(np.isnan(aux), True, side='left')\n"", '         else:\n']","['         aux = ar\n', '     mask = np.empty(aux.shape, dtype=np.bool_)\n', '     mask[:1] = True\n', '-    if aux.shape[0] > 0 and aux.dtype.kind in ""cfmM"" and np.isnan(aux[-1]):\n', '         if aux.dtype.kind == ""c"":  # for complex all NaNs are considered equivalent\n', ""             aux_firstnan = np.searchsorted(np.isnan(aux), True, side='left')\n"", '         else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return aux[flag[1:] & flag[:-1]]\n', ' \n', ' \n', '+def _in1d_dispatcher(ar1, ar2, assume_unique=None, invert=None, *,\n', '+                     kind=None):\n', '     return (ar1, ar2)\n', ' \n', ' \n', ' @array_function_dispatch(_in1d_dispatcher)\n', '+def in1d(ar1, ar2, assume_unique=False, invert=False, *, kind=None):\n', '     """"""\n', '     Test whether each element of a 1-D array is also present in a second array.\n', ' \n']","['     return aux[flag[1:] & flag[:-1]]\n', ' \n', ' \n', '-def _in1d_dispatcher(ar1, ar2, assume_unique=None, invert=None):\n', '     return (ar1, ar2)\n', ' \n', ' \n', ' @array_function_dispatch(_in1d_dispatcher)\n', '-def in1d(ar1, ar2, assume_unique=False, invert=False):\n', '     """"""\n', '     Test whether each element of a 1-D array is also present in a second array.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         False where an element of `ar1` is in `ar2` and True otherwise).\n', '         Default is False. ``np.in1d(a, b, invert=True)`` is equivalent\n', '         to (but is faster than) ``np.invert(in1d(a, b))``.\n', ""+    kind : {None, 'sort', 'table'}, optional\n"", '+        The algorithm to use. This will not affect the final result,\n', '+        but will affect the speed and memory use. The default, None,\n', '+        will select automatically based on memory considerations.\n', '+\n', ""+        * If 'sort', will use a mergesort-based approach. This will have\n"", '+          a memory usage of roughly 6 times the sum of the sizes of\n', '+          `ar1` and `ar2`, not accounting for size of dtypes.\n', ""+        * If 'table', will use a lookup table approach similar\n"", '+          to a counting sort. This is only available for boolean and\n', '+          integer arrays. This will have a memory usage of the\n', '+          size of `ar1` plus the max-min value of `ar2`. `assume_unique`\n', ""+          has no effect when the 'table' option is used.\n"", ""+        * If None, will automatically choose 'table' if\n"", '+          the required memory allocation is less than or equal to\n', '+          6 times the sum of the sizes of `ar1` and `ar2`,\n', ""+          otherwise will use 'sort'. This is done to not use\n"", '+          a large amount of memory by default, even though\n', ""+          'table' may be faster in most cases. If 'table' is chosen,\n"", '+          `assume_unique` will have no effect.\n', ' \n', '         .. versionadded:: 1.8.0\n', ' \n']","['         False where an element of `ar1` is in `ar2` and True otherwise).\n', '         Default is False. ``np.in1d(a, b, invert=True)`` is equivalent\n', '         to (but is faster than) ``np.invert(in1d(a, b))``.\n', ' \n', '         .. versionadded:: 1.8.0\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ``asarray(ar2)`` is an object array rather than the expected array of\n', '     contained values.\n', ' \n', ""+    Using ``kind='table'`` tends to be faster than `kind='sort'` if the\n"", '+    following relationship is true:\n', '+    ``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\n', '+    but may use greater memory. The default value for `kind` will\n', '+    be automatically selected based only on memory usage, so one may\n', ""+    manually set ``kind='table'`` if memory constraints can be relaxed.\n"", '+\n', '     .. versionadded:: 1.4.0\n', ' \n', '     Examples\n']","['     ``asarray(ar2)`` is an object array rather than the expected array of\n', '     contained values.\n', ' \n', '     .. versionadded:: 1.4.0\n', ' \n', '     Examples\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if ar2.dtype == object:\n', '         ar2 = ar2.reshape(-1, 1)\n', ' \n', ""+    if kind not in {None, 'sort', 'table'}:\n"", '+        raise ValueError(\n', '+            f""Invalid kind: \'{kind}\'. Please use None, \'sort\' or \'table\'."")\n', '+\n', '+    # Can use the table method if all arrays are integers or boolean:\n', '+    is_int_arrays = all(ar.dtype.kind in (""u"", ""i"", ""b"") for ar in (ar1, ar2))\n', ""+    use_table_method = is_int_arrays and kind in {None, 'table'}\n"", '+\n', '+    if use_table_method:\n', '+        if ar2.size == 0:\n', '+            if invert:\n', '+                return np.ones_like(ar1, dtype=bool)\n', '+            else:\n', '+                return np.zeros_like(ar1, dtype=bool)\n', '+\n', '+        # Convert booleans to uint8 so we can use the fast integer algorithm\n', '+        if ar1.dtype == bool:\n', '+            ar1 = ar1.astype(np.uint8)\n', '+        if ar2.dtype == bool:\n', '+            ar2 = ar2.astype(np.uint8)\n', '+\n', '+        ar2_min = np.min(ar2)\n', '+        ar2_max = np.max(ar2)\n', '+\n', '+        ar2_range = int(ar2_max) - int(ar2_min)\n', '+\n', '+        # Constraints on whether we can actually use the table method:\n', '+        range_safe_from_overflow = ar2_range < np.iinfo(ar2.dtype).max\n', '+        below_memory_constraint = ar2_range <= 6 * (ar1.size + ar2.size)\n', '+\n', '+        # Optimal performance is for approximately\n', '+        # log10(size) > (log10(range) - 2.27) / 0.927.\n', '+        # However, here we set the requirement that by default\n', '+        # the intermediate array can only be 6x\n', '+        # the combined memory allocation of the original\n', '+        # arrays. See discussion on \n', '+        # https://github.com/numpy/numpy/pull/12065.\n', '+\n', '+        if (\n', '+            range_safe_from_overflow and \n', ""+            (below_memory_constraint or kind == 'table')\n"", '+        ):\n', '+\n', '+            if invert:\n', '+                outgoing_array = np.ones_like(ar1, dtype=bool)\n', '+            else:\n', '+                outgoing_array = np.zeros_like(ar1, dtype=bool)\n', '+\n', '+            # Make elements 1 where the integer exists in ar2\n', '+            if invert:\n', '+                isin_helper_ar = np.ones(ar2_range + 1, dtype=bool)\n', '+                isin_helper_ar[ar2 - ar2_min] = 0\n', '+            else:\n', '+                isin_helper_ar = np.zeros(ar2_range + 1, dtype=bool)\n', '+                isin_helper_ar[ar2 - ar2_min] = 1\n', '+\n', ""+            # Mask out elements we know won't work\n"", '+            basic_mask = (ar1 <= ar2_max) & (ar1 >= ar2_min)\n', '+            outgoing_array[basic_mask] = isin_helper_ar[ar1[basic_mask] -\n', '+                                                        ar2_min]\n', '+\n', '+            return outgoing_array\n', ""+        elif kind == 'table':  # not range_safe_from_overflow\n"", '+            raise RuntimeError(\n', '+                ""You have specified kind=\'table\', ""\n', '+                ""but the range of values in `ar2` exceeds the ""\n', '+                ""maximum integer of the datatype. ""\n', '+                ""Please set `kind` to None or \'sort\'.""\n', '+            )\n', ""+    elif kind == 'table':\n"", '+        raise ValueError(\n', '+            ""The \'table\' method is only ""\n', '+            ""supported for boolean or integer arrays. ""\n', '+            ""Please select \'sort\' or None for kind.""\n', '+        )\n', '+\n', '+\n', '     # Check if one of the arrays may contain arbitrary objects\n', '     contains_object = ar1.dtype.hasobject or ar2.dtype.hasobject\n', ' \n']","['     if ar2.dtype == object:\n', '         ar2 = ar2.reshape(-1, 1)\n', ' \n', '     # Check if one of the arrays may contain arbitrary objects\n', '     contains_object = ar1.dtype.hasobject or ar2.dtype.hasobject\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return ret[rev_idx]\n', ' \n', ' \n', '+def _isin_dispatcher(element, test_elements, assume_unique=None, invert=None,\n', '+                     *, kind=None):\n', '     return (element, test_elements)\n', ' \n', ' \n', ' @array_function_dispatch(_isin_dispatcher)\n', '+def isin(element, test_elements, assume_unique=False, invert=False, *,\n', '+         kind=None):\n', '     """"""\n', '     Calculates ``element in test_elements``, broadcasting over `element` only.\n', '     Returns a boolean array of the same shape as `element` that is True\n']","['         return ret[rev_idx]\n', ' \n', ' \n', '-def _isin_dispatcher(element, test_elements, assume_unique=None, invert=None):\n', '     return (element, test_elements)\n', ' \n', ' \n', ' @array_function_dispatch(_isin_dispatcher)\n', '-def isin(element, test_elements, assume_unique=False, invert=False):\n', '     """"""\n', '     Calculates ``element in test_elements``, broadcasting over `element` only.\n', '     Returns a boolean array of the same shape as `element` that is True\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         calculating `element not in test_elements`. Default is False.\n', '         ``np.isin(a, b, invert=True)`` is equivalent to (but faster\n', '         than) ``np.invert(np.isin(a, b))``.\n', ""+    kind : {None, 'sort', 'table'}, optional\n"", '+        The algorithm to use. This will not affect the final result,\n', '+        but will affect the speed and memory use. The default, None,\n', '+        will select automatically based on memory considerations.\n', '+\n', ""+        * If 'sort', will use a mergesort-based approach. This will have\n"", '+          a memory usage of roughly 6 times the sum of the sizes of\n', '+          `ar1` and `ar2`, not accounting for size of dtypes.\n', ""+        * If 'table', will use a lookup table approach similar\n"", '+          to a counting sort. This is only available for boolean and\n', '+          integer arrays. This will have a memory usage of the\n', '+          size of `ar1` plus the max-min value of `ar2`. `assume_unique`\n', ""+          has no effect when the 'table' option is used.\n"", ""+        * If None, will automatically choose 'table' if\n"", '+          the required memory allocation is less than or equal to\n', '+          6 times the sum of the sizes of `ar1` and `ar2`,\n', ""+          otherwise will use 'sort'. This is done to not use\n"", '+          a large amount of memory by default, even though\n', ""+          'table' may be faster in most cases. If 'table' is chosen,\n"", '+          `assume_unique` will have no effect.\n', '+\n', ' \n', '     Returns\n', '     -------\n']","['         calculating `element not in test_elements`. Default is False.\n', '         ``np.isin(a, b, invert=True)`` is equivalent to (but faster\n', '         than) ``np.invert(np.isin(a, b))``.\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     of the `array` constructor's way of handling non-sequence collections.\n"", '     Converting the set to a list usually gives the desired behavior.\n', ' \n', ""+    Using ``kind='table'`` tends to be faster than `kind='sort'` if the\n"", '+    following relationship is true:\n', '+    ``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\n', '+    but may use greater memory. The default value for `kind` will\n', '+    be automatically selected based only on memory usage, so one may\n', ""+    manually set ``kind='table'`` if memory constraints can be relaxed.\n"", '+\n', '     .. versionadded:: 1.13.0\n', ' \n', '     Examples\n']","[""     of the `array` constructor's way of handling non-sequence collections.\n"", '     Converting the set to a list usually gives the desired behavior.\n', ' \n', '     .. versionadded:: 1.13.0\n', ' \n', '     Examples\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     element = np.asarray(element)\n', '     return in1d(element, test_elements, assume_unique=assume_unique,\n', '+                invert=invert, kind=kind).reshape(element.shape)\n', ' \n', ' \n', ' def _union1d_dispatcher(ar1, ar2):\n']","['     """"""\n', '     element = np.asarray(element)\n', '     return in1d(element, test_elements, assume_unique=assume_unique,\n', '-                invert=invert).reshape(element.shape)\n', ' \n', ' \n', ' def _union1d_dispatcher(ar1, ar2):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' MAGIC_LEN = len(MAGIC_PREFIX) + 2\n', ' ARRAY_ALIGN = 64 # plausible values are powers of 2 between 16 and 4096\n', ' BUFFER_SIZE = 2**18  # size of buffer for reading npz files in bytes\n', '+# allow growth within the address space of a 64 bit machine along one axis\n', '+GROWTH_AXIS_MAX_DIGITS = 21  # = len(str(8*2**64-1)) hypothetical int1 dtype\n', ' \n', ' # difference between version 1.0 and 2.0 is a 4 byte (I) header length\n', ' # instead of 2 bytes (H) allowing storage of large structured arrays\n']","[' MAGIC_LEN = len(MAGIC_PREFIX) + 2\n', ' ARRAY_ALIGN = 64 # plausible values are powers of 2 between 16 and 4096\n', ' BUFFER_SIZE = 2**18  # size of buffer for reading npz files in bytes\n', ' \n', ' # difference between version 1.0 and 2.0 is a 4 byte (I) header length\n', ' # instead of 2 bytes (H) allowing storage of large structured arrays\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     (3, 0): ('<I', 'utf8'),\n"", ' }\n', ' \n', ""+# Python's literal_eval is not actually safe for large inputs, since parsing\n"", '+# may become slow or even cause interpreter crashes.\n', '+# This is an arbitrary, low limit which should make it safe in practice.\n', '+_MAX_HEADER_SIZE = 10000\n', ' \n', ' def _check_version(version):\n', '     if version not in [(1, 0), (2, 0), (3, 0), None]:\n']","[""     (3, 0): ('<I', 'utf8'),\n"", ' }\n', ' \n', ' \n', ' def _check_version(version):\n', '     if version not in [(1, 0), (2, 0), (3, 0), None]:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         header.append(""\'%s\': %s, "" % (key, repr(value)))\n', '     header.append(""}"")\n', '     header = """".join(header)\n', '+    \n', '+    # Add some spare space so that the array header can be modified in-place\n', '+    # when changing the array size, e.g. when growing it by appending data at\n', '+    # the end. \n', ""+    shape = d['shape']\n"", '+    header += "" "" * ((GROWTH_AXIS_MAX_DIGITS - len(repr(\n', ""+        shape[-1 if d['fortran_order'] else 0]\n"", '+    ))) if len(shape) > 0 else 0)\n', '+    \n', '     if version is None:\n', '         header = _wrap_header_guess_version(header)\n', '     else:\n']","['         header.append(""\'%s\': %s, "" % (key, repr(value)))\n', '     header.append(""}"")\n', '     header = """".join(header)\n', '     if version is None:\n', '         header = _wrap_header_guess_version(header)\n', '     else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     _write_array_header(fp, d, (2, 0))\n', ' \n', '+def read_array_header_1_0(fp, max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Read an array header from a filelike object using the 1.0 file format\n', '     version.\n']","['     """"""\n', '     _write_array_header(fp, d, (2, 0))\n', ' \n', '-def read_array_header_1_0(fp):\n', '     """"""\n', '     Read an array header from a filelike object using the 1.0 file format\n', '     version.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         contiguous before writing it out.\n', '     dtype : dtype\n', ""         The dtype of the file's data.\n"", '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', ' \n', '     Raises\n', '     ------\n']","['         contiguous before writing it out.\n', '     dtype : dtype\n', ""         The dtype of the file's data.\n"", ' \n', '     Raises\n', '     ------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         If the data is invalid.\n', ' \n', '     """"""\n', '+    return _read_array_header(\n', '+            fp, version=(1, 0), max_header_size=max_header_size)\n', ' \n', '+def read_array_header_2_0(fp, max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Read an array header from a filelike object using the 2.0 file format\n', '     version.\n']","['         If the data is invalid.\n', ' \n', '     """"""\n', '-    return _read_array_header(fp, version=(1, 0))\n', ' \n', '-def read_array_header_2_0(fp):\n', '     """"""\n', '     Read an array header from a filelike object using the 2.0 file format\n', '     version.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     ----------\n', '     fp : filelike object\n', '         A file object or something with a `.read()` method like a file.\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', ' \n', '     Returns\n', '     -------\n']","['     ----------\n', '     fp : filelike object\n', '         A file object or something with a `.read()` method like a file.\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         If the data is invalid.\n', ' \n', '     """"""\n', '+    return _read_array_header(\n', '+            fp, version=(2, 0), max_header_size=max_header_size)\n', ' \n', ' \n', ' def _filter_header(s):\n']","['         If the data is invalid.\n', ' \n', '     """"""\n', '-    return _read_array_header(fp, version=(2, 0))\n', ' \n', ' \n', ' def _filter_header(s):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return tokenize.untokenize(tokens)\n', ' \n', ' \n', '+def _read_array_header(fp, version, max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     see read_array_header_1_0\n', '     """"""\n']","['     return tokenize.untokenize(tokens)\n', ' \n', ' \n', '-def _read_array_header(fp, version):\n', '     """"""\n', '     see read_array_header_1_0\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     header_length = struct.unpack(hlength_type, hlength_str)[0]\n', '     header = _read_bytes(fp, header_length, ""array header"")\n', '     header = header.decode(encoding)\n', '+    if len(header) > max_header_size:\n', '+        raise ValueError(\n', '+            f""Header info length ({len(header)}) is large and may not be safe ""\n', '+            ""to load securely.\\n""\n', '+            ""To allow loading, adjust `max_header_size` or fully trust ""\n', '+            ""the `.npy` file using `allow_pickle=True`.\\n""\n', '+            ""For safety against large resource use or crashes, sandboxing ""\n', '+            ""may be necessary."")\n', ' \n', '     # The header is a pretty-printed string representation of a literal\n', '     # Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\n']","['     header_length = struct.unpack(hlength_type, hlength_str)[0]\n', '     header = _read_bytes(fp, header_length, ""array header"")\n', '     header = header.decode(encoding)\n', ' \n', '     # The header is a pretty-printed string representation of a literal\n', '     # Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                 fp.write(chunk.tobytes('C'))\n"", ' \n', ' \n', '+def read_array(fp, allow_pickle=False, pickle_kwargs=None, *,\n', '+               max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Read an array from an NPY file.\n', ' \n']","[""                 fp.write(chunk.tobytes('C'))\n"", ' \n', ' \n', '-def read_array(fp, allow_pickle=False, pickle_kwargs=None):\n', '     """"""\n', '     Read an array from an NPY file.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         Additional keyword arguments to pass to pickle.load. These are only\n', '         useful when loading object arrays saved on Python 2 when using\n', '         Python 3.\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', '+        This option is ignored when `allow_pickle` is passed.  In that case\n', '+        the file is by definition trusted and the limit is unnecessary.\n', ' \n', '     Returns\n', '     -------\n']","['         Additional keyword arguments to pass to pickle.load. These are only\n', '         useful when loading object arrays saved on Python 2 when using\n', '         Python 3.\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         an object array.\n', ' \n', '     """"""\n', '+    if allow_pickle:\n', '+        # Effectively ignore max_header_size, since `allow_pickle` indicates\n', '+        # that the input is fully trusted.\n', '+        max_header_size = 2**64\n', '+\n', '     version = read_magic(fp)\n', '     _check_version(version)\n', '+    shape, fortran_order, dtype = _read_array_header(\n', '+            fp, version, max_header_size=max_header_size)\n', '     if len(shape) == 0:\n', '         count = 1\n', '     else:\n']","['         an object array.\n', ' \n', '     """"""\n', '     version = read_magic(fp)\n', '     _check_version(version)\n', '-    shape, fortran_order, dtype = _read_array_header(fp, version)\n', '     if len(shape) == 0:\n', '         count = 1\n', '     else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', "" def open_memmap(filename, mode='r+', dtype=None, shape=None,\n"", '+                fortran_order=False, version=None, *,\n', '+                max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Open a .npy file as a memory-mapped array.\n', ' \n']","[' \n', ' \n', "" def open_memmap(filename, mode='r+', dtype=None, shape=None,\n"", '-                fortran_order=False, version=None):\n', '     """"""\n', '     Open a .npy file as a memory-mapped array.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         If the mode is a ""write"" mode, then this is the version of the file\n', '         format used to create the file.  None means use the oldest\n', '         supported version that is able to store the data.  Default: None\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', ' \n', '     Returns\n', '     -------\n']","['         If the mode is a ""write"" mode, then this is the version of the file\n', '         format used to create the file.  None means use the oldest\n', '         supported version that is able to store the data.  Default: None\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             version = read_magic(fp)\n', '             _check_version(version)\n', ' \n', '+            shape, fortran_order, dtype = _read_array_header(\n', '+                    fp, version, max_header_size=max_header_size)\n', '             if dtype.hasobject:\n', '                 msg = ""Array can\'t be memory-mapped: Python objects in dtype.""\n', '                 raise ValueError(msg)\n']","['             version = read_magic(fp)\n', '             _check_version(version)\n', ' \n', '-            shape, fortran_order, dtype = _read_array_header(fp, version)\n', '             if dtype.hasobject:\n', '                 msg = ""Array can\'t be memory-mapped: Python objects in dtype.""\n', '                 raise ValueError(msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     if weights is None:\n', '         avg = a.mean(axis, **keepdims_kw)\n', '+        avg_as_array = np.asanyarray(avg)\n', '+        scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n', '     else:\n', '         wgt = np.asanyarray(weights)\n', ' \n']","[' \n', '     if weights is None:\n', '         avg = a.mean(axis, **keepdims_kw)\n', '-        scl = avg.dtype.type(a.size/avg.size)\n', '     else:\n', '         wgt = np.asanyarray(weights)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n', '             wgt = wgt.swapaxes(-1, axis)\n', ' \n', '+        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n', '         if np.any(scl == 0.0):\n', '             raise ZeroDivisionError(\n', '                 ""Weights sum to zero, can\'t be normalized"")\n', ' \n', '+        avg = avg_as_array = np.multiply(a, wgt,\n', '                           dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n', ' \n', '     if returned:\n', '+        if scl.shape != avg_as_array.shape:\n', '+            scl = np.broadcast_to(scl, avg_as_array.shape).copy()\n', '         return avg, scl\n', '     else:\n', '         return avg\n']","['             wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n', '             wgt = wgt.swapaxes(-1, axis)\n', ' \n', '-        scl = wgt.sum(axis=axis, dtype=result_dtype)\n', '         if np.any(scl == 0.0):\n', '             raise ZeroDivisionError(\n', '                 ""Weights sum to zero, can\'t be normalized"")\n', ' \n', '-        avg = np.multiply(a, wgt,\n', '                           dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n', ' \n', '     if returned:\n', '-        if scl.shape != avg.shape:\n', '-            scl = np.broadcast_to(scl, avg.shape).copy()\n', '         return avg, scl\n', '     else:\n', '         return avg\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     Return a copy of an array sorted along the first axis.\n', ' \n', '+    .. deprecated:: 1.24\n', '+\n', '+       msort is deprecated, use ``np.sort(a, axis=0)`` instead.\n', '+\n', '     Parameters\n', '     ----------\n', '     a : array_like\n']","['     """"""\n', '     Return a copy of an array sorted along the first axis.\n', ' \n', '     Parameters\n', '     ----------\n', '     a : array_like\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -----\n', '     ``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> a = np.array([[1, 4], [3, 1]])\n', '+    >>> np.msort(a)  # sort along the first axis\n', '+    array([[1, 1],\n', '+           [3, 4]])\n', '+\n', '     """"""\n', '+    # 2022-10-20 1.24\n', '+    warnings.warn(\n', '+        ""msort is deprecated, use np.sort(a, axis=0) instead"",\n', '+        DeprecationWarning,\n', '+        stacklevel=3,\n', '+    )\n', '     b = array(a, subok=True, copy=True)\n', '     b.sort(0)\n', '     return b\n']","['     -----\n', '     ``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.\n', ' \n', '     """"""\n', '     b = array(a, subok=True, copy=True)\n', '     b.sort(0)\n', '     return b\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         8. 'median_unbiased'\n"", ""         9. 'normal_unbiased'\n"", ' \n', '+        The first three methods are discontinuous.  NumPy further defines the\n', ""         following discontinuous variations of the default 'linear' (7.) option:\n"", ' \n', ""         * 'lower'\n""]","[""         8. 'median_unbiased'\n"", ""         9. 'normal_unbiased'\n"", ' \n', '-        The first three methods are discontiuous.  NumPy further defines the\n', ""         following discontinuous variations of the default 'linear' (7.) option:\n"", ' \n', ""         * 'lower'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Notes\n', '     -----\n', '+    Given a vector ``V`` of length ``n``, the q-th percentile of ``V`` is\n', '     the value ``q/100`` of the way from the minimum to the maximum in a\n', '     sorted copy of ``V``. The values and distances of the two nearest\n', '     neighbors as well as the `method` parameter will determine the\n']","[' \n', '     Notes\n', '     -----\n', '-    Given a vector ``V`` of length ``N``, the q-th percentile of ``V`` is\n', '     the value ``q/100`` of the way from the minimum to the maximum in a\n', '     sorted copy of ``V``. The values and distances of the two nearest\n', '     neighbors as well as the `method` parameter will determine the\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     same as the minimum if ``q=0`` and the same as the maximum if\n', '     ``q=100``.\n', ' \n', '+    The optional `method` parameter specifies the method to use when the\n', '+    desired percentile lies between two indexes ``i`` and ``j = i + 1``.\n', '+    In that case, we first determine ``i + g``, a virtual index that lies\n', '+    between ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\n', '+    fractional part of the index. The final result is, then, an interpolation\n', '+    of ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n', '+    ``i`` and ``j`` are modified using correction constants ``alpha`` and\n', '+    ``beta`` whose choices depend on the ``method`` used. Finally, note that\n', '+    since Python uses 0-based indexing, the code subtracts another 1 from the\n', '+    index internally.\n', '+\n', '+    The following formula determines the virtual index ``i + g``, the location \n', '+    of the percentile in the sorted sample:\n', ' \n', '     .. math::\n', '+        i + g = (q / 100) * ( n - alpha - beta + 1 ) + alpha\n', ' \n', '     The different methods then work as follows\n', ' \n']","['     same as the minimum if ``q=0`` and the same as the maximum if\n', '     ``q=100``.\n', ' \n', '-    This optional `method` parameter specifies the method to use when the\n', '-    desired quantile lies between two data points ``i < j``.\n', '-    If ``g`` is the fractional part of the index surrounded by ``i`` and\n', '-    alpha and beta are correction constants modifying i and j.\n', '-\n', ""-    Below, 'q' is the quantile value, 'n' is the sample size and\n"", '-    alpha and beta are constants.\n', '-    The following formula gives an interpolation ""i + g"" of where the quantile\n', '-    would be in the sorted sample.\n', ""-    With 'i' being the floor and 'g' the fractional part of the result.\n"", ' \n', '     .. math::\n', '-        i + g = (q - alpha) / ( n - alpha - beta + 1 )\n', ' \n', '     The different methods then work as follows\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Notes\n', '     -----\n', '+    Given a vector ``V`` of length ``n``, the q-th quantile of ``V`` is\n', '+    the value ``q`` of the way from the minimum to the maximum in a\n', '+    sorted copy of ``V``. The values and distances of the two nearest\n', '+    neighbors as well as the `method` parameter will determine the\n', '+    quantile if the normalized ranking does not match the location of\n', '+    ``q`` exactly. This function is the same as the median if ``q=0.5``, the\n', '+    same as the minimum if ``q=0.0`` and the same as the maximum if\n', '+    ``q=1.0``.\n', ' \n', '     The optional `method` parameter specifies the method to use when the\n', '+    desired quantile lies between two indexes ``i`` and ``j = i + 1``.\n', '+    In that case, we first determine ``i + g``, a virtual index that lies\n', '+    between ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\n', '+    fractional part of the index. The final result is, then, an interpolation\n', '+    of ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n', '+    ``i`` and ``j`` are modified using correction constants ``alpha`` and\n', '+    ``beta`` whose choices depend on the ``method`` used. Finally, note that\n', '+    since Python uses 0-based indexing, the code subtracts another 1 from the\n', '+    index internally.\n', '+\n', '+    The following formula determines the virtual index ``i + g``, the location \n', '+    of the quantile in the sorted sample:\n', ' \n', '     .. math::\n', '+        i + g = q * ( n - alpha - beta + 1 ) + alpha\n', ' \n', '     The different methods then work as follows\n', ' \n']","[' \n', '     Notes\n', '     -----\n', '-    Given a vector ``V`` of length ``N``, the q-th quantile of ``V`` is the\n', '-    value ``q`` of the way from the minimum to the maximum in a sorted copy of\n', '-    ``V``. The values and distances of the two nearest neighbors as well as the\n', '-    `method` parameter will determine the quantile if the normalized\n', '-    ranking does not match the location of ``q`` exactly. This function is the\n', '-    same as the median if ``q=0.5``, the same as the minimum if ``q=0.0`` and\n', '-    the same as the maximum if ``q=1.0``.\n', ' \n', '     The optional `method` parameter specifies the method to use when the\n', '-    desired quantile lies between two data points ``i < j``.\n', '-    If ``g`` is the fractional part of the index surrounded by ``i`` and ``j``,\n', '-    and alpha and beta are correction constants modifying i and j:\n', ' \n', '     .. math::\n', '-        i + g = (q - alpha) / ( n - alpha - beta + 1 )\n', ' \n', '     The different methods then work as follows\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     mgrid : Construct a multi-dimensional ""meshgrid"" using indexing notation.\n', '     ogrid : Construct an open multi-dimensional ""meshgrid"" using indexing\n', '             notation.\n', '+    how-to-index\n', ' \n', '     Examples\n', '     --------\n']","['     mgrid : Construct a multi-dimensional ""meshgrid"" using indexing notation.\n', '     ogrid : Construct an open multi-dimensional ""meshgrid"" using indexing\n', '             notation.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> yv\n', '     array([[0.,  0.,  0.],\n', '            [1.,  1.,  1.]])\n', '+\n', '+    The result of `meshgrid` is a coordinate grid:\n', '+\n', '+    >>> import matplotlib.pyplot as plt\n', ""+    >>> plt.plot(xv, yv, marker='o', color='k', linestyle='none')\n"", '+    >>> plt.show()\n', '+\n', '+    You can create sparse output arrays to save memory and computation time.\n', '+\n', '+    >>> xv, yv = np.meshgrid(x, y, sparse=True)\n', '     >>> xv\n', '     array([[0. ,  0.5,  1. ]])\n', '     >>> yv\n', '     array([[0.],\n', '            [1.]])\n', ' \n', '+    `meshgrid` is very useful to evaluate functions on a grid. If the\n', '+    function depends on all coordinates, both dense and sparse outputs can be\n', '+    used.\n', ' \n', '     >>> x = np.linspace(-5, 5, 101)\n', '     >>> y = np.linspace(-5, 5, 101)\n']","['     >>> yv\n', '     array([[0.,  0.,  0.],\n', '            [1.,  1.,  1.]])\n', '-    >>> xv, yv = np.meshgrid(x, y, sparse=True)  # make sparse output arrays\n', '     >>> xv\n', '     array([[0. ,  0.5,  1. ]])\n', '     >>> yv\n', '     array([[0.],\n', '            [1.]])\n', ' \n', '-    `meshgrid` is very useful to evaluate functions on a grid.  If the\n', '-    function depends on all coordinates, you can use the parameter\n', '-    ``sparse=True`` to save memory and computation time.\n', ' \n', '     >>> x = np.linspace(-5, 5, 101)\n', '     >>> y = np.linspace(-5, 5, 101)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> np.array_equal(zz, zs)\n', '     True\n', ' \n', '     >>> h = plt.contourf(x, y, zs)\n', ""     >>> plt.axis('scaled')\n"", '     >>> plt.colorbar()\n']","['     >>> np.array_equal(zz, zs)\n', '     True\n', ' \n', '-    >>> import matplotlib.pyplot as plt\n', '     >>> h = plt.contourf(x, y, zs)\n', ""     >>> plt.axis('scaled')\n"", '     >>> plt.colorbar()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         single_value = False\n', '         _obj = obj\n', '         obj = np.asarray(obj)\n', '+        # `size == 0` to allow empty lists similar to indexing, but (as there)\n', '+        # is really too generic:\n', '         if obj.size == 0 and not isinstance(_obj, np.ndarray):\n', '             obj = obj.astype(intp)\n', '+        elif obj.size == 1 and obj.dtype.kind in ""ui"":\n', '+            # For a size 1 integer array we can use the single-value path\n', '+            # (most dtypes, except boolean, should just fail later).\n', '+            obj = obj.item()\n', '             single_value = True\n', ' \n', '     if single_value:\n']","['         single_value = False\n', '         _obj = obj\n', '         obj = np.asarray(obj)\n', '         if obj.size == 0 and not isinstance(_obj, np.ndarray):\n', '             obj = obj.astype(intp)\n', '-        elif obj.size == 1 and not isinstance(_obj, bool):\n', '-            obj = obj.astype(intp).reshape(())\n', '             single_value = True\n', ' \n', '     if single_value:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def _histogram_dispatcher(\n', '+        a, bins=None, range=None, density=None, weights=None):\n', '     return (a, bins, weights)\n', ' \n', ' \n', ' @array_function_dispatch(_histogram_dispatcher)\n', '+def histogram(a, bins=10, range=None, density=None, weights=None):\n', '     r""""""\n', '     Compute the histogram of a dataset.\n', ' \n']","[' \n', ' \n', ' def _histogram_dispatcher(\n', '-        a, bins=None, range=None, normed=None, weights=None, density=None):\n', '     return (a, bins, weights)\n', ' \n', ' \n', ' @array_function_dispatch(_histogram_dispatcher)\n', '-def histogram(a, bins=10, range=None, normed=None, weights=None,\n', '-              density=None):\n', '     r""""""\n', '     Compute the histogram of a dataset.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         computation as well. While bin width is computed to be optimal\n', '         based on the actual data within `range`, the bin count will fill\n', '         the entire range including portions containing no data.\n', '     weights : array_like, optional\n', '         An array of weights, of the same shape as `a`.  Each value in\n', '         `a` only contributes its associated weight towards the bin count\n']","['         computation as well. While bin width is computed to be optimal\n', '         based on the actual data within `range`, the bin count will fill\n', '         the entire range including portions containing no data.\n', '-    normed : bool, optional\n', '-\n', '-        .. deprecated:: 1.6.0\n', '-\n', '-        This is equivalent to the `density` argument, but produces incorrect\n', '-        results for unequal bin widths. It should not be used.\n', '-\n', '-        .. versionchanged:: 1.15.0\n', '-            DeprecationWarnings are actually emitted.\n', '-\n', '     weights : array_like, optional\n', '         An array of weights, of the same shape as `a`.  Each value in\n', '         `a` only contributes its associated weight towards the bin count\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         histogram values will not be equal to 1 unless bins of unity\n', '         width are chosen; it is not a probability *mass* function.\n', ' \n', '     Returns\n', '     -------\n', '     hist : array\n']","['         histogram values will not be equal to 1 unless bins of unity\n', '         width are chosen; it is not a probability *mass* function.\n', ' \n', '-        Overrides the ``normed`` keyword if given.\n', '-\n', '     Returns\n', '     -------\n', '     hist : array\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         n = np.diff(cum_n)\n', ' \n', '     if density:\n', '         db = np.array(np.diff(bin_edges), float)\n', '         return n/db/n.sum(), bin_edges\n', '+\n', '+    return n, bin_edges\n', ' \n', ' \n', '+def _histogramdd_dispatcher(sample, bins=None, range=None, density=None,\n', '+                            weights=None):\n', ""     if hasattr(sample, 'shape'):  # same condition as used in histogramdd\n"", '         yield sample\n', '     else:\n']","[' \n', '         n = np.diff(cum_n)\n', ' \n', '-    # density overrides the normed keyword\n', '-    if density is not None:\n', '-        if normed is not None:\n', '-            # 2018-06-13, numpy 1.15.0 (this was not noisily deprecated in 1.6)\n', '-            warnings.warn(\n', '-                    ""The normed argument is ignored when density is provided. ""\n', '-                    ""In future passing both will result in an error."",\n', '-                    DeprecationWarning, stacklevel=3)\n', '-        normed = None\n', '-\n', '     if density:\n', '         db = np.array(np.diff(bin_edges), float)\n', '         return n/db/n.sum(), bin_edges\n', '-    elif normed:\n', '-        # 2018-06-13, numpy 1.15.0 (this was not noisily deprecated in 1.6)\n', '-        warnings.warn(\n', '-                ""Passing `normed=True` on non-uniform bins has always been ""\n', '-                ""broken, and computes neither the probability density ""\n', '-                ""function nor the probability mass function. ""\n', '-                ""The result is only correct if the bins are uniform, when ""\n', '-                ""density=True will produce the same result anyway. ""\n', '-                ""The argument will be removed in a future version of ""\n', '-                ""numpy."",\n', '-                np.VisibleDeprecationWarning, stacklevel=3)\n', '-\n', '-        # this normalization is incorrect, but\n', '-        db = np.array(np.diff(bin_edges), float)\n', '-        return n/(n*db).sum(), bin_edges\n', '-    else:\n', '-        if normed is not None:\n', '-            # 2018-06-13, numpy 1.15.0 (this was not noisily deprecated in 1.6)\n', '-            warnings.warn(\n', '-                    ""Passing normed=False is deprecated, and has no effect. ""\n', '-                    ""Consider passing the density argument instead."",\n', '-                    DeprecationWarning, stacklevel=3)\n', '-        return n, bin_edges\n', ' \n', ' \n', '-def _histogramdd_dispatcher(sample, bins=None, range=None, normed=None,\n', '-                            weights=None, density=None):\n', ""     if hasattr(sample, 'shape'):  # same condition as used in histogramdd\n"", '         yield sample\n', '     else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @array_function_dispatch(_histogramdd_dispatcher)\n', '+def histogramdd(sample, bins=10, range=None, density=None, weights=None):\n', '     """"""\n', '     Compute the multidimensional histogram of some data.\n', ' \n', '     Parameters\n', '     ----------\n', '+    sample : (N, D) array, or (N, D) array_like\n', '         The data to be histogrammed.\n', ' \n', '         Note the unusual interpretation of sample when an array_like:\n']","[' \n', ' \n', ' @array_function_dispatch(_histogramdd_dispatcher)\n', '-def histogramdd(sample, bins=10, range=None, normed=None, weights=None,\n', '-                density=None):\n', '     """"""\n', '     Compute the multidimensional histogram of some data.\n', ' \n', '     Parameters\n', '     ----------\n', '-    sample : (N, D) array, or (D, N) array_like\n', '         The data to be histogrammed.\n', ' \n', '         Note the unusual interpretation of sample when an array_like:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         If False, the default, returns the number of samples in each bin.\n', '         If True, returns the probability *density* function at the bin,\n', '         ``bin_count / sample_count / bin_volume``.\n', '     weights : (N,) array_like, optional\n', '         An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.\n', '+        Weights are normalized to 1 if density is True. If density is False,\n', '         the values of the returned histogram are equal to the sum of the\n', '         weights belonging to the samples falling into each bin.\n', ' \n', '     Returns\n', '     -------\n', '     H : ndarray\n', '+        The multidimensional histogram of sample x. See density and weights\n', '         for the different possible semantics.\n', '     edges : list\n', '         A list of D arrays describing the bin edges for each dimension.\n']","['         If False, the default, returns the number of samples in each bin.\n', '         If True, returns the probability *density* function at the bin,\n', '         ``bin_count / sample_count / bin_volume``.\n', '-    normed : bool, optional\n', '-        An alias for the density argument that behaves identically. To avoid\n', '-        confusion with the broken normed argument to `histogram`, `density`\n', '-        should be preferred.\n', '     weights : (N,) array_like, optional\n', '         An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.\n', '-        Weights are normalized to 1 if normed is True. If normed is False,\n', '         the values of the returned histogram are equal to the sum of the\n', '         weights belonging to the samples falling into each bin.\n', ' \n', '     Returns\n', '     -------\n', '     H : ndarray\n', '-        The multidimensional histogram of sample x. See normed and weights\n', '         for the different possible semantics.\n', '     edges : list\n', '         A list of D arrays describing the bin edges for each dimension.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         sample = np.atleast_2d(sample).T\n', '         N, D = sample.shape\n', ' \n', '+    nbin = np.empty(D, np.intp)\n', '     edges = D*[None]\n', '     dedges = D*[None]\n', '     if weights is not None:\n']","['         sample = np.atleast_2d(sample).T\n', '         N, D = sample.shape\n', ' \n', '-    nbin = np.empty(D, int)\n', '     edges = D*[None]\n', '     dedges = D*[None]\n', '     if weights is not None:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     core = D*(slice(1, -1),)\n', '     hist = hist[core]\n', ' \n', '     if density:\n', '         # calculate the probability density function\n', '         s = hist.sum()\n']","['     core = D*(slice(1, -1),)\n', '     hist = hist[core]\n', ' \n', '-    # handle the aliasing normed argument\n', '-    if normed is None:\n', '-        if density is None:\n', '-            density = False\n', '-    elif density is None:\n', '-        # an explicit normed argument was passed, alias it to the new name\n', '-        density = normed\n', '-    else:\n', '-        raise TypeError(""Cannot specify both \'normed\' and \'density\'"")\n', '-\n', '     if density:\n', '         # calculate the probability density function\n', '         s = hist.sum()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def __getitem__(self, key):\n', '         try:\n', '             size = []\n', '+            # Mimic the behavior of `np.arange` and use a data type\n', '+            # which is at least as large as `np.int_`\n', '+            num_list = [0]\n', '+            for k in range(len(key)):\n', '+                step = key[k].step\n', '+                start = key[k].start\n', '+                stop = key[k].stop\n', '                 if start is None:\n', '                     start = 0\n', '                 if step is None:\n', '                     step = 1\n', '                 if isinstance(step, (_nx.complexfloating, complex)):\n', '+                    step = abs(step)\n', '+                    size.append(int(step))\n', '                 else:\n', '                     size.append(\n', '+                        int(math.ceil((stop - start) / (step*1.0))))\n', '+                num_list += [start, stop, step]\n', '+            typ = _nx.result_type(*num_list)\n', '             if self.sparse:\n', '                 nn = [_nx.arange(_x, dtype=_t)\n', '                       for _x, _t in zip(size, (typ,)*len(size))]\n']","['     def __getitem__(self, key):\n', '         try:\n', '             size = []\n', '-            typ = int\n', '-            for kk in key:\n', '-                step = kk.step\n', '-                start = kk.start\n', '                 if start is None:\n', '                     start = 0\n', '                 if step is None:\n', '                     step = 1\n', '                 if isinstance(step, (_nx.complexfloating, complex)):\n', '-                    size.append(int(abs(step)))\n', '-                    typ = float\n', '                 else:\n', '                     size.append(\n', '-                        int(math.ceil((kk.stop - start) / (step * 1.0))))\n', '-                if (isinstance(step, (_nx.floating, float)) or\n', '-                        isinstance(start, (_nx.floating, float)) or\n', '-                        isinstance(kk.stop, (_nx.floating, float))):\n', '-                    typ = float\n', '             if self.sparse:\n', '                 nn = [_nx.arange(_x, dtype=_t)\n', '                       for _x, _t in zip(size, (typ,)*len(size))]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             if start is None:\n', '                 start = 0\n', '             if isinstance(step, (_nx.complexfloating, complex)):\n', '+                # Prevent the (potential) creation of integer arrays\n', '+                step_float = abs(step)\n', '+                step = length = int(step_float)\n', '                 if step != 1:\n', '                     step = (key.stop-start)/float(step-1)\n', '+                typ = _nx.result_type(start, stop, step_float)\n', '+                return _nx.arange(0, length, 1, dtype=typ)*step + start\n', '             else:\n', '                 return _nx.arange(start, stop, step)\n', ' \n']","['             if start is None:\n', '                 start = 0\n', '             if isinstance(step, (_nx.complexfloating, complex)):\n', '-                step = abs(step)\n', '-                length = int(step)\n', '                 if step != 1:\n', '                     step = (key.stop-start)/float(step-1)\n', '-                return _nx.arange(0, length, 1, float)*step + start\n', '             else:\n', '                 return _nx.arange(start, stop, step)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects\n', '     ogrid : like mgrid but returns open (not fleshed out) mesh grids\n', '+    meshgrid: return coordinate matrices from coordinate vectors\n', '     r_ : array concatenator\n', '+    :ref:`how-to-partition`\n', ' \n', '     Examples\n', '     --------\n']","['     --------\n', '     lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects\n', '     ogrid : like mgrid but returns open (not fleshed out) mesh grids\n', '     r_ : array concatenator\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     np.lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects\n', '     mgrid : like `ogrid` but returns dense (or fleshed out) mesh grids\n', '+    meshgrid: return coordinate matrices from coordinate vectors\n', '     r_ : array concatenator\n', '+    :ref:`how-to-partition`\n', ' \n', '     Examples\n', '     --------\n']","['     --------\n', '     np.lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects\n', '     mgrid : like `ogrid` but returns dense (or fleshed out) mesh grids\n', '     r_ : array concatenator\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Parameters\n', '     ----------\n', '     shape : ints, or a single tuple of ints\n', '+        The size of each dimension of the array can be passed as\n', '         individual parameters or as the elements of a tuple.\n', ' \n', '     See Also\n']","['     Parameters\n', '     ----------\n', '     shape : ints, or a single tuple of ints\n', '-        The size of each dimension of the array can be passed as \n', '         individual parameters or as the elements of a tuple.\n', ' \n', '     See Also\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Examples\n', '     --------\n', '     Dimensions as individual arguments\n', '+\n', '     >>> for index in np.ndindex(3, 2, 1):\n', '     ...     print(index)\n', '     (0, 0, 0)\n']","['     Examples\n', '     --------\n', '     Dimensions as individual arguments\n', '-    \n', '     >>> for index in np.ndindex(3, 2, 1):\n', '     ...     print(index)\n', '     (0, 0, 0)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     (2, 1, 0)\n', ' \n', '     Same dimensions - but in a tuple ``(3, 2, 1)``\n', '+\n', '     >>> for index in np.ndindex((3, 2, 1)):\n', '     ...     print(index)\n', '     (0, 0, 0)\n']","['     (2, 1, 0)\n', ' \n', '     Same dimensions - but in a tuple ``(3, 2, 1)``\n', '-    \n', '     >>> for index in np.ndindex((3, 2, 1)):\n', '     ...     print(index)\n', '     (0, 0, 0)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         8. 'median_unbiased'\n"", ""         9. 'normal_unbiased'\n"", ' \n', '+        The first three methods are discontinuous.  NumPy further defines the\n', ""         following discontinuous variations of the default 'linear' (7.) option:\n"", ' \n', ""         * 'lower'\n""]","[""         8. 'median_unbiased'\n"", ""         9. 'normal_unbiased'\n"", ' \n', '-        The first three methods are discontiuous.  NumPy further defines the\n', ""         following discontinuous variations of the default 'linear' (7.) option:\n"", ' \n', ""         * 'lower'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         8. 'median_unbiased'\n"", ""         9. 'normal_unbiased'\n"", ' \n', '+        The first three methods are discontinuous.  NumPy further defines the\n', ""         following discontinuous variations of the default 'linear' (7.) option:\n"", ' \n', ""         * 'lower'\n""]","[""         8. 'median_unbiased'\n"", ""         9. 'normal_unbiased'\n"", ' \n', '-        The first three methods are discontiuous.  NumPy further defines the\n', ""         following discontinuous variations of the default 'linear' (7.) option:\n"", ' \n', ""         * 'lower'\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         Additional keyword arguments to pass on to pickle.load.\n', '         These are only useful when loading object arrays saved on\n', '         Python 2 when using Python 3.\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', '+        This option is ignored when `allow_pickle` is passed.  In that case\n', '+        the file is by definition trusted and the limit is unnecessary.\n', ' \n', '     Parameters\n', '     ----------\n']","['         Additional keyword arguments to pass on to pickle.load.\n', '         These are only useful when loading object arrays saved on\n', '         Python 2 when using Python 3.\n', ' \n', '     Parameters\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     fid = None\n', ' \n', '     def __init__(self, fid, own_fid=False, allow_pickle=False,\n', '+                 pickle_kwargs=None, *,\n', '+                 max_header_size=format._MAX_HEADER_SIZE):\n', '         # Import is postponed to here since zipfile depends on gzip, an\n', '         # optional component of the so-called standard library.\n', '         _zip = zipfile_factory(fid)\n', '         self._files = _zip.namelist()\n', '         self.files = []\n', '         self.allow_pickle = allow_pickle\n', '+        self.max_header_size = max_header_size\n', '         self.pickle_kwargs = pickle_kwargs\n', '         for x in self._files:\n', ""             if x.endswith('.npy'):\n""]","['     fid = None\n', ' \n', '     def __init__(self, fid, own_fid=False, allow_pickle=False,\n', '-                 pickle_kwargs=None):\n', '         # Import is postponed to here since zipfile depends on gzip, an\n', '         # optional component of the so-called standard library.\n', '         _zip = zipfile_factory(fid)\n', '         self._files = _zip.namelist()\n', '         self.files = []\n', '         self.allow_pickle = allow_pickle\n', '         self.pickle_kwargs = pickle_kwargs\n', '         for x in self._files:\n', ""             if x.endswith('.npy'):\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 bytes = self.zip.open(key)\n', '                 return format.read_array(bytes,\n', '                                          allow_pickle=self.allow_pickle,\n', '+                                         pickle_kwargs=self.pickle_kwargs,\n', '+                                         max_header_size=self.max_header_size)\n', '             else:\n', '                 return self.zip.read(key)\n', '         else:\n']","['                 bytes = self.zip.open(key)\n', '                 return format.read_array(bytes,\n', '                                          allow_pickle=self.allow_pickle,\n', '-                                         pickle_kwargs=self.pickle_kwargs)\n', '             else:\n', '                 return self.zip.read(key)\n', '         else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" @set_module('numpy')\n"", ' def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n', ""+         encoding='ASCII', *, max_header_size=format._MAX_HEADER_SIZE):\n"", '     """"""\n', '     Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n', ' \n']","[' \n', "" @set_module('numpy')\n"", ' def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n', ""-         encoding='ASCII'):\n"", '     """"""\n', '     Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         npy/npz files containing object arrays. Values other than 'latin1',\n"", ""         'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n"", ""         data. Default: 'ASCII'\n"", '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', '+        This option is ignored when `allow_pickle` is passed.  In that case\n', '+        the file is by definition trusted and the limit is unnecessary.\n', ' \n', '     Returns\n', '     -------\n']","[""         npy/npz files containing object arrays. Values other than 'latin1',\n"", ""         'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n"", ""         data. Default: 'ASCII'\n"", ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # Potentially transfer file ownership to NpzFile\n', '             stack.pop_all()\n', '             ret = NpzFile(fid, own_fid=own_fid, allow_pickle=allow_pickle,\n', '+                          pickle_kwargs=pickle_kwargs,\n', '+                          max_header_size=max_header_size)\n', '             return ret\n', '         elif magic == format.MAGIC_PREFIX:\n', '             # .npy file\n', '             if mmap_mode:\n', '+                if allow_pickle:\n', '+                    max_header_size = 2**64\n', '+                return format.open_memmap(file, mode=mmap_mode,\n', '+                                          max_header_size=max_header_size)\n', '             else:\n', '                 return format.read_array(fid, allow_pickle=allow_pickle,\n', '+                                         pickle_kwargs=pickle_kwargs,\n', '+                                         max_header_size=max_header_size)\n', '         else:\n', '             # Try a pickle\n', '             if not allow_pickle:\n']","['             # Potentially transfer file ownership to NpzFile\n', '             stack.pop_all()\n', '             ret = NpzFile(fid, own_fid=own_fid, allow_pickle=allow_pickle,\n', '-                          pickle_kwargs=pickle_kwargs)\n', '             return ret\n', '         elif magic == format.MAGIC_PREFIX:\n', '             # .npy file\n', '             if mmap_mode:\n', '-                return format.open_memmap(file, mode=mmap_mode)\n', '             else:\n', '                 return format.read_array(fid, allow_pickle=allow_pickle,\n', '-                                         pickle_kwargs=pickle_kwargs)\n', '         else:\n', '             # Try a pickle\n', '             if not allow_pickle:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     r""""""\n', '     Load data from a text file.\n', ' \n', '     Parameters\n', '     ----------\n', '     fname : file, str, pathlib.Path, list of str, generator\n']","['     r""""""\n', '     Load data from a text file.\n', ' \n', '-    Each row in the text file must have the same number of values.\n', '-\n', '     Parameters\n', '     ----------\n', '     fname : file, str, pathlib.Path, list of str, generator\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         comment. None implies no comments. For backwards compatibility, byte\n', ""         strings will be decoded as 'latin1'. The default is '#'.\n"", '     delimiter : str, optional\n', '+        The character used to separate the values. For backwards compatibility,\n', ""+        byte strings will be decoded as 'latin1'. The default is whitespace.\n"", '+\n', '+        .. versionchanged:: 1.23.0\n', '+           Only single character delimiters are supported. Newline characters\n', '+           cannot be used as the delimiter.\n', '+\n', '     converters : dict or callable, optional\n', '+        Converter functions to customize value parsing. If `converters` is\n', '+        callable, the function is applied to all columns, else it must be a\n', '+        dict that maps column number to a parser function.\n', '+        See examples for further details.\n', '         Default: None.\n', '+\n', '+        .. versionchanged:: 1.23.0\n', '+           The ability to pass a single callable to be applied to all columns\n', '+           was added.\n', '+\n', '     skiprows : int, optional\n', '         Skip the first `skiprows` lines, including comments; default: 0.\n', '     usecols : int or sequence, optional\n']","['         comment. None implies no comments. For backwards compatibility, byte\n', ""         strings will be decoded as 'latin1'. The default is '#'.\n"", '     delimiter : str, optional\n', '-        The string used to separate values. For backwards compatibility, byte\n', ""-        strings will be decoded as 'latin1'. The default is whitespace.\n"", '     converters : dict or callable, optional\n', '-        A function to parse all columns strings into the desired value, or\n', '-        a dictionary mapping column number to a parser function.\n', '-        E.g. if column 0 is a date string: ``converters = {0: datestr2num}``.\n', '-        Converters can also be used to provide a default value for missing\n', '-        data, e.g. ``converters = lambda s: float(s.strip() or 0)`` will\n', '-        convert empty fields to 0.\n', '         Default: None.\n', '     skiprows : int, optional\n', '         Skip the first `skiprows` lines, including comments; default: 0.\n', '     usecols : int or sequence, optional\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         .. versionadded:: 1.14.0\n', '     max_rows : int, optional\n', '+        Read `max_rows` rows of content after `skiprows` lines. The default is\n', '+        to read all the rows. Note that empty rows containing no data such as\n', '+        empty lines and comment lines are not counted towards `max_rows`,\n', '+        while such lines are counted in `skiprows`.\n', ' \n', '         .. versionadded:: 1.16.0\n', '+        \n', '+        .. versionchanged:: 1.23.0\n', '+            Lines containing no data, including comment lines (e.g., lines \n', ""+            starting with '#' or as specified via `comments`) are not counted \n"", '+            towards `max_rows`.\n', '     quotechar : unicode character or None, optional\n', '         The character used to denote the start and end of a quoted item.\n', '         Occurrences of the delimiter or comment characters are ignored within\n']","[' \n', '         .. versionadded:: 1.14.0\n', '     max_rows : int, optional\n', '-        Read `max_rows` lines of content after `skiprows` lines. The default\n', '-        is to read all the lines.\n', ' \n', '         .. versionadded:: 1.16.0\n', '     quotechar : unicode character or None, optional\n', '         The character used to denote the start and end of a quoted item.\n', '         Occurrences of the delimiter or comment characters are ignored within\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     `genfromtxt` function provides more sophisticated handling of, e.g.,\n', '     lines with missing values.\n', ' \n', '+    Each row in the input text file must have the same number of values to be\n', '+    able to read all values. If all rows do not have same number of values, a\n', '+    subset of up to n columns (where n is the least number of values present\n', '+    in all rows) can be read by specifying the columns via `usecols`.\n', '+\n', '     .. versionadded:: 1.10.0\n', ' \n', '     The strings produced by the Python float.hex method can be used as\n']","['     `genfromtxt` function provides more sophisticated handling of, e.g.,\n', '     lines with missing values.\n', ' \n', '     .. versionadded:: 1.10.0\n', ' \n', '     The strings produced by the Python float.hex method can be used as\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> np.loadtxt(s, dtype=""U"", delimiter="","", quotechar=\'""\')\n', '     array(\'Hello, my name is ""Monty""!\', dtype=\'<U26\')\n', ' \n', '+    Read subset of columns when all rows do not contain equal number of values:\n', '+\n', '+    >>> d = StringIO(""1 2\\n2 4\\n3 9 12\\n4 16 20"")\n', '+    >>> np.loadtxt(d, usecols=(0, 1))\n', '+    array([[ 1.,  2.],\n', '+           [ 2.,  4.],\n', '+           [ 3.,  9.],\n', '+           [ 4., 16.]])\n', '+\n', '     """"""\n', ' \n', '     if like is not None:\n']","['     >>> np.loadtxt(s, dtype=""U"", delimiter="","", quotechar=\'""\')\n', '     array(\'Hello, my name is ""Monty""!\', dtype=\'<U26\')\n', ' \n', '     """"""\n', ' \n', '     if like is not None:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.ma.mrecords import MaskedRecords\n', ' from numpy.core.overrides import array_function_dispatch\n', ' from numpy.lib._iotools import _is_string_like\n', ' \n', ' _check_fill_value = np.ma.core._check_fill_value\n', ' \n']","[' from numpy.ma.mrecords import MaskedRecords\n', ' from numpy.core.overrides import array_function_dispatch\n', ' from numpy.lib._iotools import _is_string_like\n', '-from numpy.testing import suppress_warnings\n', ' \n', ' _check_fill_value = np.ma.core._check_fill_value\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                                  'formats': dts,\n"", ""                                  'offsets': offsets,\n"", ""                                  'itemsize': arr.dtype.itemsize})\n"", '+    arr = arr.view(flattened_fields)\n', ' \n', '     # next cast to a packed format with all fields converted to new dtype\n', ""     packed_fields = np.dtype({'names': names,\n""]","[""                                  'formats': dts,\n"", ""                                  'offsets': offsets,\n"", ""                                  'itemsize': arr.dtype.itemsize})\n"", '-    with suppress_warnings() as sup:  # until 1.16 (gh-12447)\n', '-        sup.filter(FutureWarning, ""Numpy has detected"")\n', '-        arr = arr.view(flattened_fields)\n', ' \n', '     # next cast to a packed format with all fields converted to new dtype\n', ""     packed_fields = np.dtype({'names': names,\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', '         if names is not None:\n', '             raise ValueError(""don\'t supply both dtype and names"")\n', '+        # if dtype is the args of np.dtype, construct it\n', '+        dtype = np.dtype(dtype)\n', '         # sanity check of the input dtype\n', '         fields = _get_fields_and_offsets(dtype)\n', '         if len(fields) == 0:\n']","['     else:\n', '         if names is not None:\n', '             raise ValueError(""don\'t supply both dtype and names"")\n', '         # sanity check of the input dtype\n', '         fields = _get_fields_and_offsets(dtype)\n', '         if len(fields) == 0:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestDataSourceOpen:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']","[' \n', ' \n', ' class TestDataSourceOpen:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestDataSourceExists:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']","[' \n', ' \n', ' class TestDataSourceExists:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestDataSourceAbspath:\n', '+    def setup_method(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']","[' \n', ' \n', ' class TestDataSourceAbspath:\n', '-    def setup(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestRepositoryAbspath:\n', '+    def setup_method(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']","[' \n', ' \n', ' class TestRepositoryAbspath:\n', '-    def setup(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestRepositoryExists:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']","[' \n', ' \n', ' class TestRepositoryExists:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestOpenFunc:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', ' \n', '     def test_DataSourceOpen(self):\n']","[' \n', ' \n', ' class TestOpenFunc:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', ' \n', '     def test_DataSourceOpen(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     @pytest.mark.filterwarnings(""ignore:Mean of empty slice:RuntimeWarning"")\n', '     @pytest.mark.filterwarnings(\n', '+        ""ignore:invalid value encountered in( scalar)? divide:RuntimeWarning""\n', '     )\n', '     @pytest.mark.parametrize(""mode"", [""mean"", ""median""])\n', '     def test_zero_stat_length_valid(self, mode):\n']","[' \n', '     @pytest.mark.filterwarnings(""ignore:Mean of empty slice:RuntimeWarning"")\n', '     @pytest.mark.filterwarnings(\n', '-        ""ignore:invalid value encountered in (divide|double_scalars):""\n', '-        ""RuntimeWarning""\n', '     )\n', '     @pytest.mark.parametrize(""mode"", [""mean"", ""median""])\n', '     def test_zero_stat_length_valid(self, mode):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def test_unicode_mode():\n', ""+    a = np.pad([1], 2, mode='constant')\n"", '     b = np.array([0, 0, 1, 0, 0])\n', '     assert_array_equal(a, b)\n', ' \n']","[' \n', ' \n', ' def test_unicode_mode():\n', ""-    a = np.pad([1], 2, mode=u'constant')\n"", '     b = np.array([0, 0, 1, 0, 0])\n', '     assert_array_equal(a, b)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(actual, expected)\n', '         assert actual.dtype == expected.dtype\n', ' \n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_isin(self, kind):\n', ""         # the tests for in1d cover most of isin's behavior\n"", '         # if in1d is removed, would need to change those tests to test\n', '         # isin instead.\n']","['         assert_equal(actual, expected)\n', '         assert actual.dtype == expected.dtype\n', ' \n', '-    def test_isin(self):\n', ""         # the tests for in1d cover most of isin's behavior\n"", '         # if in1d is removed, would need to change those tests to test\n', '         # isin instead.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         isin_slow = np.vectorize(_isin_slow, otypes=[bool], excluded={1})\n', ' \n', '         def assert_isin_equal(a, b):\n', '+            x = isin(a, b, kind=kind)\n', '             y = isin_slow(a, b)\n', '             assert_array_equal(x, y)\n', ' \n']","['         isin_slow = np.vectorize(_isin_slow, otypes=[bool], excluded={1})\n', ' \n', '         def assert_isin_equal(a, b):\n', '-            x = isin(a, b)\n', '             y = isin_slow(a, b)\n', '             assert_array_equal(x, y)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_isin_equal(5, 6)\n', ' \n', '         # empty array-like:\n', '+        if kind != ""table"":\n', '+            # An empty list will become float64,\n', '+            # which is invalid for kind=""table""\n', '+            x = []\n', '+            assert_isin_equal(x, b)\n', '+            assert_isin_equal(a, x)\n', '+            assert_isin_equal(x, x)\n', '+\n', '+        # empty array with various types:\n', '+        for dtype in [bool, np.int64, np.float64]:\n', '+            if kind == ""table"" and dtype == np.float64:\n', '+                continue\n', '+\n', '+            if dtype in {np.int64, np.float64}:\n', '+                ar = np.array([10, 20, 30], dtype=dtype)\n', '+            elif dtype in {bool}:\n', '+                ar = np.array([True, False, False])\n', '+\n', '+            empty_array = np.array([], dtype=dtype)\n', '+\n', '+            assert_isin_equal(empty_array, ar)\n', '+            assert_isin_equal(ar, empty_array)\n', '+            assert_isin_equal(empty_array, empty_array)\n', '+\n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_in1d(self, kind):\n', '         # we use two different sizes for the b array here to test the\n', '         # two different paths in in1d().\n', '         for mult in (1, 10):\n']","['         assert_isin_equal(5, 6)\n', ' \n', '         # empty array-like:\n', '-        x = []\n', '-        assert_isin_equal(x, b)\n', '-        assert_isin_equal(a, x)\n', '-        assert_isin_equal(x, x)\n', '-\n', '-    def test_in1d(self):\n', '         # we use two different sizes for the b array here to test the\n', '         # two different paths in in1d().\n', '         for mult in (1, 10):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             a = [5, 7, 1, 2]\n', '             b = [2, 4, 3, 1, 5] * mult\n', '             ec = np.array([True, False, True, True])\n', '+            c = in1d(a, b, assume_unique=True, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a[0] = 8\n', '             ec = np.array([False, False, True, True])\n', '+            c = in1d(a, b, assume_unique=True, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a[0], a[3] = 4, 8\n', '             ec = np.array([True, False, True, False])\n', '+            c = in1d(a, b, assume_unique=True, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 4, 5, 3, 4, 4, 3, 4, 3, 5, 2, 1, 5, 5])\n', '             b = [2, 3, 4] * mult\n', '             ec = [False, True, False, True, True, True, True, True, True,\n', '                   False, True, False, False, False]\n', '+            c = in1d(a, b, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             b = b + [5, 5, 4] * mult\n', '             ec = [True, True, True, True, True, True, True, True, True, True,\n', '                   True, False, True, True]\n', '+            c = in1d(a, b, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 7, 1, 2])\n', '             b = np.array([2, 4, 3, 1, 5] * mult)\n', '             ec = np.array([True, False, True, True])\n', '+            c = in1d(a, b, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 7, 1, 1, 2])\n', '             b = np.array([2, 4, 3, 3, 1, 5] * mult)\n', '             ec = np.array([True, False, True, True, True])\n', '+            c = in1d(a, b, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 5])\n', '             b = np.array([2, 2] * mult)\n', '             ec = np.array([False, False])\n', '+            c = in1d(a, b, kind=kind)\n', '             assert_array_equal(c, ec)\n', ' \n', '         a = np.array([5])\n', '         b = np.array([2])\n', '         ec = np.array([False])\n', '+        c = in1d(a, b, kind=kind)\n', '         assert_array_equal(c, ec)\n', ' \n', '+        if kind in {None, ""sort""}:\n', '+            assert_array_equal(in1d([], [], kind=kind), [])\n', ' \n', '     def test_in1d_char_array(self):\n', ""         a = np.array(['a', 'b', 'c', 'd', 'e', 'c', 'e', 'b'])\n""]","['             a = [5, 7, 1, 2]\n', '             b = [2, 4, 3, 1, 5] * mult\n', '             ec = np.array([True, False, True, True])\n', '-            c = in1d(a, b, assume_unique=True)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a[0] = 8\n', '             ec = np.array([False, False, True, True])\n', '-            c = in1d(a, b, assume_unique=True)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a[0], a[3] = 4, 8\n', '             ec = np.array([True, False, True, False])\n', '-            c = in1d(a, b, assume_unique=True)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 4, 5, 3, 4, 4, 3, 4, 3, 5, 2, 1, 5, 5])\n', '             b = [2, 3, 4] * mult\n', '             ec = [False, True, False, True, True, True, True, True, True,\n', '                   False, True, False, False, False]\n', '-            c = in1d(a, b)\n', '             assert_array_equal(c, ec)\n', ' \n', '             b = b + [5, 5, 4] * mult\n', '             ec = [True, True, True, True, True, True, True, True, True, True,\n', '                   True, False, True, True]\n', '-            c = in1d(a, b)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 7, 1, 2])\n', '             b = np.array([2, 4, 3, 1, 5] * mult)\n', '             ec = np.array([True, False, True, True])\n', '-            c = in1d(a, b)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 7, 1, 1, 2])\n', '             b = np.array([2, 4, 3, 3, 1, 5] * mult)\n', '             ec = np.array([True, False, True, True, True])\n', '-            c = in1d(a, b)\n', '             assert_array_equal(c, ec)\n', ' \n', '             a = np.array([5, 5])\n', '             b = np.array([2, 2] * mult)\n', '             ec = np.array([False, False])\n', '-            c = in1d(a, b)\n', '             assert_array_equal(c, ec)\n', ' \n', '         a = np.array([5])\n', '         b = np.array([2])\n', '         ec = np.array([False])\n', '-        c = in1d(a, b)\n', '         assert_array_equal(c, ec)\n', ' \n', '-        assert_array_equal(in1d([], []), [])\n', ' \n', '     def test_in1d_char_array(self):\n', ""         a = np.array(['a', 'b', 'c', 'd', 'e', 'c', 'e', 'b'])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         assert_array_equal(c, ec)\n', ' \n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_in1d_invert(self, kind):\n', '         ""Test in1d\'s invert parameter""\n', '         # We use two different sizes for the b array here to test the\n', '         # two different paths in in1d().\n', '         for mult in (1, 10):\n', '             a = np.array([5, 4, 5, 3, 4, 4, 3, 4, 3, 5, 2, 1, 5, 5])\n', '             b = [2, 3, 4] * mult\n', '+            assert_array_equal(np.invert(in1d(a, b, kind=kind)),\n', '+                               in1d(a, b, invert=True, kind=kind))\n', '+\n', '+        # float:\n', '+        if kind in {None, ""sort""}:\n', '+            for mult in (1, 10):\n', '+                a = np.array([5, 4, 5, 3, 4, 4, 3, 4, 3, 5, 2, 1, 5, 5],\n', '+                            dtype=np.float32)\n', '+                b = [2, 3, 4] * mult\n', '+                b = np.array(b, dtype=np.float32)\n', '+                assert_array_equal(np.invert(in1d(a, b, kind=kind)),\n', '+                                   in1d(a, b, invert=True, kind=kind))\n', '+\n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_in1d_ravel(self, kind):\n', '         # Test that in1d ravels its input arrays. This is not documented\n', '         # behavior however. The test is to ensure consistentency.\n', '         a = np.arange(6).reshape(2, 3)\n']","[' \n', '         assert_array_equal(c, ec)\n', ' \n', '-    def test_in1d_invert(self):\n', '         ""Test in1d\'s invert parameter""\n', '         # We use two different sizes for the b array here to test the\n', '         # two different paths in in1d().\n', '         for mult in (1, 10):\n', '             a = np.array([5, 4, 5, 3, 4, 4, 3, 4, 3, 5, 2, 1, 5, 5])\n', '             b = [2, 3, 4] * mult\n', '-            assert_array_equal(np.invert(in1d(a, b)), in1d(a, b, invert=True))\n', '-\n', '-    def test_in1d_ravel(self):\n', '         # Test that in1d ravels its input arrays. This is not documented\n', '         # behavior however. The test is to ensure consistentency.\n', '         a = np.arange(6).reshape(2, 3)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         long_b = np.arange(3, 63).reshape(30, 2)\n', '         ec = np.array([False, False, False, True, True, True])\n', ' \n', '+        assert_array_equal(in1d(a, b, assume_unique=True, kind=kind),\n', '+                           ec)\n', '+        assert_array_equal(in1d(a, b, assume_unique=False,\n', '+                                kind=kind),\n', '+                           ec)\n', '+        assert_array_equal(in1d(a, long_b, assume_unique=True,\n', '+                                kind=kind),\n', '+                           ec)\n', '+        assert_array_equal(in1d(a, long_b, assume_unique=False,\n', '+                                kind=kind),\n', '+                           ec)\n', '+\n', '+    def test_in1d_hit_alternate_algorithm(self):\n', '+        """"""Hit the standard isin code with integers""""""\n', '+        # Need extreme range to hit standard code\n', ""+        # This hits it without the use of kind='table'\n"", '+        a = np.array([5, 4, 5, 3, 4, 4, 1e9], dtype=np.int64)\n', '+        b = np.array([2, 3, 4, 1e9], dtype=np.int64)\n', '+        expected = np.array([0, 1, 0, 1, 1, 1, 1], dtype=bool)\n', '+        assert_array_equal(expected, in1d(a, b))\n', '+        assert_array_equal(np.invert(expected), in1d(a, b, invert=True))\n', '+\n', '+        a = np.array([5, 7, 1, 2], dtype=np.int64)\n', '+        b = np.array([2, 4, 3, 1, 5, 1e9], dtype=np.int64)\n', '+        ec = np.array([True, False, True, True])\n', '+        c = in1d(a, b, assume_unique=True)\n', '+        assert_array_equal(c, ec)\n', '+\n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_in1d_boolean(self, kind):\n', '+        """"""Test that in1d works for boolean input""""""\n', '+        a = np.array([True, False])\n', '+        b = np.array([False, False, False])\n', '+        expected = np.array([False, True])\n', '+        assert_array_equal(expected,\n', '+                           in1d(a, b, kind=kind))\n', '+        assert_array_equal(np.invert(expected),\n', '+                           in1d(a, b, invert=True, kind=kind))\n', '+\n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort""])\n', '+    def test_in1d_timedelta(self, kind):\n', '+        """"""Test that in1d works for timedelta input""""""\n', '+        rstate = np.random.RandomState(0)\n', '+        a = rstate.randint(0, 100, size=10)\n', '+        b = rstate.randint(0, 100, size=10)\n', '+        truth = in1d(a, b)\n', '+        a_timedelta = a.astype(""timedelta64[s]"")\n', '+        b_timedelta = b.astype(""timedelta64[s]"")\n', '+        assert_array_equal(truth, in1d(a_timedelta, b_timedelta, kind=kind))\n', '+\n', '+    def test_in1d_table_timedelta_fails(self):\n', '+        a = np.array([0, 1, 2], dtype=""timedelta64[s]"")\n', '+        b = a\n', '+        # Make sure it raises a value error:\n', '+        with pytest.raises(ValueError):\n', '+            in1d(a, b, kind=""table"")\n', '+\n', '+    @pytest.mark.parametrize(""kind"", [None, ""sort"", ""table""])\n', '+    def test_in1d_mixed_boolean(self, kind):\n', '+        """"""Test that in1d works as expected for bool/int input.""""""\n', '+        for dtype in np.typecodes[""AllInteger""]:\n', '+            a = np.array([True, False, False], dtype=bool)\n', '+            b = np.array([1, 1, 1, 1], dtype=dtype)\n', '+            expected = np.array([True, False, False], dtype=bool)\n', '+            assert_array_equal(in1d(a, b, kind=kind), expected)\n', '+\n', '+            a, b = b, a\n', '+            expected = np.array([True, True, True, True], dtype=bool)\n', '+            assert_array_equal(in1d(a, b, kind=kind), expected)\n', ' \n', '     def test_in1d_first_array_is_object(self):\n', '         ar1 = [None]\n']","['         long_b = np.arange(3, 63).reshape(30, 2)\n', '         ec = np.array([False, False, False, True, True, True])\n', ' \n', '-        assert_array_equal(in1d(a, b, assume_unique=True), ec)\n', '-        assert_array_equal(in1d(a, b, assume_unique=False), ec)\n', '-        assert_array_equal(in1d(a, long_b, assume_unique=True), ec)\n', '-        assert_array_equal(in1d(a, long_b, assume_unique=False), ec)\n', ' \n', '     def test_in1d_first_array_is_object(self):\n', '         ar1 = [None]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         result = np.in1d(ar1, ar2, invert=True)\n', '         assert_array_equal(result, np.invert(expected))\n', ' \n', '+    def test_in1d_errors(self):\n', '+        """"""Test that in1d raises expected errors.""""""\n', '+\n', ""+        # Error 1: `kind` is not one of 'sort' 'table' or None.\n"", '+        ar1 = np.array([1, 2, 3, 4, 5])\n', '+        ar2 = np.array([2, 4, 6, 8, 10])\n', ""+        assert_raises(ValueError, in1d, ar1, ar2, kind='quicksort')\n"", '+\n', '+        # Error 2: `kind=""table""` does not work for non-integral arrays.\n', ""+        obj_ar1 = np.array([1, 'a', 3, 'b', 5], dtype=object)\n"", ""+        obj_ar2 = np.array([1, 'a', 3, 'b', 5], dtype=object)\n"", ""+        assert_raises(ValueError, in1d, obj_ar1, obj_ar2, kind='table')\n"", '+\n', '+        for dtype in [np.int32, np.int64]:\n', '+            ar1 = np.array([-1, 2, 3, 4, 5], dtype=dtype)\n', '+            # The range of this array will overflow:\n', '+            overflow_ar2 = np.array([-1, np.iinfo(dtype).max], dtype=dtype)\n', '+\n', '+            # Error 3: `kind=""table""` will trigger a runtime error\n', '+            #  if there is an integer overflow expected when computing the\n', '+            #  range of ar2\n', '+            assert_raises(\n', '+                RuntimeError,\n', ""+                in1d, ar1, overflow_ar2, kind='table'\n"", '+            )\n', '+\n', '+            # Non-error: `kind=None` will *not* trigger a runtime error\n', '+            #  if there is an integer overflow, it will switch to\n', '+            #  the `sort` algorithm.\n', '+            result = np.in1d(ar1, overflow_ar2, kind=None)\n', '+            assert_array_equal(result, [True] + [False] * 4)\n', ""+            result = np.in1d(ar1, overflow_ar2, kind='sort')\n"", '+            assert_array_equal(result, [True] + [False] * 4)\n', '+\n', '     def test_union1d(self):\n', '         a = np.array([5, 4, 7, 1, 2])\n', '         b = np.array([2, 4, 3, 3, 2, 1, 5])\n']","['         result = np.in1d(ar1, ar2, invert=True)\n', '         assert_array_equal(result, np.invert(expected))\n', ' \n', '     def test_union1d(self):\n', '         a = np.array([5, 4, 7, 1, 2])\n', '         b = np.array([2, 4, 3, 3, 2, 1, 5])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_array_equal(uniq[:, inv], data)\n', '         msg = ""Unique\'s return_counts=True failed with axis=1""\n', '         assert_array_equal(cnt, np.array([2, 1, 1]), msg)\n', '+\n', '+    def test_unique_nanequals(self):\n', '+        # issue 20326\n', '+        a = np.array([1, 1, np.nan, np.nan, np.nan])\n', '+        unq = np.unique(a)\n', '+        not_unq = np.unique(a, equal_nan=False)\n', '+        assert_array_equal(unq, np.array([1, np.nan]))\n', '+        assert_array_equal(not_unq, np.array([1, np.nan, np.nan, np.nan]))\n']","['         assert_array_equal(uniq[:, inv], data)\n', '         msg = ""Unique\'s return_counts=True failed with axis=1""\n', '         assert_array_equal(cnt, np.array([2, 1, 1]), msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy as np\n', ' from numpy.testing import (\n', '     assert_, assert_array_equal, assert_raises, assert_raises_regex,\n', '+    assert_warns, IS_PYPY, IS_WASM\n', '     )\n', ' from numpy.testing._private.utils import requires_memory\n', ' from numpy.lib import format\n']","[' import numpy as np\n', ' from numpy.testing import (\n', '     assert_, assert_array_equal, assert_raises, assert_raises_regex,\n', '-    assert_warns, IS_PYPY,\n', '     )\n', ' from numpy.testing._private.utils import requires_memory\n', ' from numpy.lib import format\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_array_equal(long_str_arr, long_str_arr2)\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""memmap doesn\'t work correctly"")\n', '+@pytest.mark.slow\n', ' def test_memmap_roundtrip(tmpdir):\n', '     for i, arr in enumerate(basic_arrays + record_arrays):\n', '         if arr.dtype.hasobject:\n']","['     assert_array_equal(long_str_arr, long_str_arr2)\n', ' \n', ' \n', ' def test_memmap_roundtrip(tmpdir):\n', '     for i, arr in enumerate(basic_arrays + record_arrays):\n', '         if arr.dtype.hasobject:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_array_equal(arr, arr1)\n', ' \n', ' \n', '+@pytest.mark.xfail(IS_WASM, reason=""Emscripten NODEFS has a buggy dup"")\n', ' def test_python2_python3_interoperability():\n', ""     fname = 'win64python2.npy'\n"", ""     path = os.path.join(os.path.dirname(__file__), 'data', fname)\n""]","['     assert_array_equal(arr, arr1)\n', ' \n', ' \n', ' def test_python2_python3_interoperability():\n', ""     fname = 'win64python2.npy'\n"", ""     path = os.path.join(os.path.dirname(__file__), 'data', fname)\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Python 2 and Python 3 and vice versa\n', ""     data_dir = os.path.join(os.path.dirname(__file__), 'data')\n"", ' \n', ""+    expected = np.array([None, range, '\\u512a\\u826f',\n"", ""                          b'\\xe4\\xb8\\x8d\\xe8\\x89\\xaf'],\n"", '                         dtype=object)\n', ' \n']","['     # Python 2 and Python 3 and vice versa\n', ""     data_dir = os.path.join(os.path.dirname(__file__), 'data')\n"", ' \n', ""-    expected = np.array([None, range, u'\\u512a\\u826f',\n"", ""                          b'\\xe4\\xb8\\x8d\\xe8\\x89\\xaf'],\n"", '                         dtype=object)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_(len(header) % format.ARRAY_ALIGN == 0)\n', ' \n', '     f.seek(0)\n', '+    n = format.read_array(f, max_header_size=200000)\n', '     assert_array_equal(d, n)\n', ' \n', '     # 1.0 requested but data cannot be saved this way\n', '     assert_raises(ValueError, format.write_array, f, d, (1, 0))\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""memmap doesn\'t work correctly"")\n', ' def test_version_2_0_memmap(tmpdir):\n', '     # requires more than 2 byte for header\n', '     dt = [((""%d"" % i) * 100, float) for i in range(500)]\n']","['     assert_(len(header) % format.ARRAY_ALIGN == 0)\n', ' \n', '     f.seek(0)\n', '-    n = format.read_array(f)\n', '     assert_array_equal(d, n)\n', ' \n', '     # 1.0 requested but data cannot be saved this way\n', '     assert_raises(ValueError, format.write_array, f, d, (1, 0))\n', ' \n', ' \n', ' def test_version_2_0_memmap(tmpdir):\n', '     # requires more than 2 byte for header\n', '     dt = [((""%d"" % i) * 100, float) for i in range(500)]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                             shape=d.shape, version=(2, 0))\n', '     ma[...] = d\n', '     ma.flush()\n', ""+    ma = format.open_memmap(tf1, mode='r', max_header_size=200000)\n"", '     assert_array_equal(ma, d)\n', ' \n', '     with warnings.catch_warnings(record=True) as w:\n']","['                             shape=d.shape, version=(2, 0))\n', '     ma[...] = d\n', '     ma.flush()\n', ""-    ma = format.open_memmap(tf1, mode='r')\n"", '     assert_array_equal(ma, d)\n', ' \n', '     with warnings.catch_warnings(record=True) as w:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         ma[...] = d\n', '         ma.flush()\n', ' \n', ""+    ma = format.open_memmap(tf2, mode='r', max_header_size=200000)\n"", '+\n', '     assert_array_equal(ma, d)\n', ' \n', '+@pytest.mark.parametrize(""mmap_mode"", [""r"", None])\n', '+def test_huge_header(tmpdir, mmap_mode):\n', ""+    f = os.path.join(tmpdir, f'large_header.npy')\n"", '+    arr = np.array(1, dtype=""i,""*10000+""i"")\n', '+\n', '+    with pytest.warns(UserWarning, match="".*format 2.0""):\n', '+        np.save(f, arr)\n', '+    \n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f, mmap_mode=mmap_mode)\n', '+\n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f, mmap_mode=mmap_mode, max_header_size=20000)\n', '+\n', '+    res = np.load(f, mmap_mode=mmap_mode, allow_pickle=True)\n', '+    assert_array_equal(res, arr)\n', '+\n', '+    res = np.load(f, mmap_mode=mmap_mode, max_header_size=180000)\n', '+    assert_array_equal(res, arr)\n', '+\n', '+def test_huge_header_npz(tmpdir):\n', ""+    f = os.path.join(tmpdir, f'large_header.npz')\n"", '+    arr = np.array(1, dtype=""i,""*10000+""i"")\n', '+\n', '+    with pytest.warns(UserWarning, match="".*format 2.0""):\n', '+        np.savez(f, arr=arr)\n', '+    \n', '+    # Only getting the array from the file actually reads it\n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f)[""arr""]\n', '+\n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f, max_header_size=20000)[""arr""]\n', '+\n', '+    res = np.load(f, allow_pickle=True)[""arr""]\n', '+    assert_array_equal(res, arr)\n', '+\n', '+    res = np.load(f, max_header_size=180000)[""arr""]\n', '+    assert_array_equal(res, arr)\n', ' \n', ' def test_write_version():\n', '     f = BytesIO()\n']","['         ma[...] = d\n', '         ma.flush()\n', ' \n', ""-    ma = format.open_memmap(tf2, mode='r')\n"", '     assert_array_equal(ma, d)\n', ' \n', ' \n', ' def test_write_version():\n', '     f = BytesIO()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' def test_large_header():\n', '     s = BytesIO()\n', ""+    d = {'shape': tuple(), 'fortran_order': False, 'descr': '<i8'}\n"", '     format.write_array_header_1_0(s, d)\n', ' \n', '     s = BytesIO()\n', ""+    d['descr'] = [('x'*256*256, '<i8')]\n"", '     assert_raises(ValueError, format.write_array_header_1_0, s, d)\n', ' \n', ' \n']","[' \n', ' def test_large_header():\n', '     s = BytesIO()\n', ""-    d = {'a': 1, 'b': 2}\n"", '     format.write_array_header_1_0(s, d)\n', ' \n', '     s = BytesIO()\n', ""-    d = {'a': 1, 'b': 2, 'c': 'x'*256*256}\n"", '     assert_raises(ValueError, format.write_array_header_1_0, s, d)\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_raises(ValueError, format.read_array_header_1_0, s)\n', ' \n', '     # headers without the exact keys required should fail\n', '+    # d = {""shape"": (1, 2),\n', '+    #      ""descr"": ""x""}\n', '+    s = BytesIO(\n', '+        b""\\x93NUMPY\\x01\\x006\\x00{\'descr\': \'x\', \'shape\': (1, 2), }"" +\n', '+        b""                    \\n""\n', '+    )\n', '     assert_raises(ValueError, format.read_array_header_1_0, s)\n', ' \n', '     d = {""shape"": (1, 2),\n']","['     assert_raises(ValueError, format.read_array_header_1_0, s)\n', ' \n', '     # headers without the exact keys required should fail\n', '-    d = {""shape"": (1, 2),\n', '-         ""descr"": ""x""}\n', '-    s = BytesIO()\n', '-    format.write_array_header_1_0(s, d)\n', '     assert_raises(ValueError, format.read_array_header_1_0, s)\n', ' \n', '     d = {""shape"": (1, 2),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_array_equal(r, d)\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_PYPY, reason=""flaky on PyPy"")\n', ' @pytest.mark.skipif(np.dtype(np.intp).itemsize < 8,\n', '                     reason=""test requires 64-bit system"")\n', ' @pytest.mark.slow\n']","['     assert_array_equal(r, d)\n', ' \n', ' \n', ' @pytest.mark.skipif(np.dtype(np.intp).itemsize < 8,\n', '                     reason=""test requires 64-bit system"")\n', ' @pytest.mark.slow\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         (1, 2)\n', '     ], dtype=[\n', ""         ('int', int),\n"", ""+        ('\\N{CJK UNIFIED IDEOGRAPH-6574}\\N{CJK UNIFIED IDEOGRAPH-5F62}', int)\n"", '     ])\n', '     fname = os.path.join(tmpdir, ""unicode.npy"")\n', ""     with open(fname, 'wb') as f:\n""]","['         (1, 2)\n', '     ], dtype=[\n', ""         ('int', int),\n"", ""-        (u'\\N{CJK UNIFIED IDEOGRAPH-6574}\\N{CJK UNIFIED IDEOGRAPH-5F62}', int)\n"", '     ])\n', '     fname = os.path.join(tmpdir, ""unicode.npy"")\n', ""     with open(fname, 'wb') as f:\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with assert_warns(UserWarning):\n', '             format.write_array(f, arr, version=None)\n', ' \n', '+def test_header_growth_axis():\n', '+    for is_fortran_array, dtype_space, expected_header_length in [\n', '+        [False, 22, 128], [False, 23, 192], [True, 23, 128], [True, 24, 192]\n', '+    ]:\n', '+        for size in [10**i for i in range(format.GROWTH_AXIS_MAX_DIGITS)]:\n', '+            fp = BytesIO()\n', '+            format.write_array_header_1_0(fp, {\n', ""+                'shape': (2, size) if is_fortran_array else (size, 2),\n"", ""+                'fortran_order': is_fortran_array,\n"", ""+                'descr': np.dtype([(' '*dtype_space, int)])\n"", '+            })\n', '+\n', '+            assert len(fp.getvalue()) == expected_header_length\n', ' \n', "" @pytest.mark.parametrize('dt, fail', [\n"", ""     (np.dtype({'names': ['a', 'b'], 'formats':  [float, np.dtype('S3',\n""]","['         with assert_warns(UserWarning):\n', '             format.write_array(f, arr, version=None)\n', ' \n', ' \n', "" @pytest.mark.parametrize('dt, fail', [\n"", ""     (np.dtype({'names': ['a', 'b'], 'formats':  [float, np.dtype('S3',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '     assert_, assert_equal, assert_array_equal, assert_almost_equal,\n', '     assert_array_almost_equal, assert_raises, assert_allclose, IS_PYPY,\n', '+    assert_warns, assert_raises_regex, suppress_warnings, HAS_REFCOUNT, IS_WASM\n', '     )\n', ' import numpy.lib.function_base as nfb\n', ' from numpy.random import rand\n']","[' from numpy.testing import (\n', '     assert_, assert_equal, assert_array_equal, assert_almost_equal,\n', '     assert_array_almost_equal, assert_raises, assert_allclose, IS_PYPY,\n', '-    assert_warns, assert_raises_regex, suppress_warnings, HAS_REFCOUNT,\n', '     )\n', ' import numpy.lib.function_base as nfb\n', ' from numpy.random import rand\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         assert_(np.average(y3, weights=w3).dtype == np.result_type(y3, w3))\n', ' \n', '+        # test weights with `keepdims=False` and `keepdims=True`\n', '+        x = np.array([2, 3, 4]).reshape(3, 1)\n', '+        w = np.array([4, 5, 6]).reshape(3, 1)\n', '+\n', '+        actual = np.average(x, weights=w, axis=1, keepdims=False)\n', '+        desired = np.array([2., 3., 4.])\n', '+        assert_array_equal(actual, desired)\n', '+\n', '+        actual = np.average(x, weights=w, axis=1, keepdims=True)\n', '+        desired = np.array([[2.], [3.], [4.]])\n', '+        assert_array_equal(actual, desired)\n', '+\n', '     def test_returned(self):\n', '         y = np.array([[1, 2, 3], [4, 5, 6]])\n', ' \n']","[' \n', '         assert_(np.average(y3, weights=w3).dtype == np.result_type(y3, w3))\n', ' \n', '     def test_returned(self):\n', '         y = np.array([[1, 2, 3], [4, 5, 6]])\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         w /= w.sum()\n', '         assert_almost_equal(a.mean(0), average(a, weights=w))\n', ' \n', '+    def test_average_class_without_dtype(self):\n', '+        # see gh-21988\n', '+        a = np.array([Fraction(1, 5), Fraction(3, 5)])\n', '+        assert_equal(np.average(a), Fraction(2, 5))\n', '+\n', ' class TestSelect:\n', '     choices = [np.array([1, 2, 3]),\n', '                np.array([4, 5, 6]),\n']","['         w /= w.sum()\n', '         assert_almost_equal(a.mean(0), average(a, weights=w))\n', ' \n', ' class TestSelect:\n', '     choices = [np.array([1, 2, 3]),\n', '                np.array([4, 5, 6]),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestDelete:\n', ' \n', '+    def setup_method(self):\n', '         self.a = np.arange(5)\n', '         self.nd_a = np.arange(5).repeat(2).reshape(1, 5, 2)\n', ' \n']","[' \n', ' class TestDelete:\n', ' \n', '-    def setup(self):\n', '         self.a = np.arange(5)\n', '         self.nd_a = np.arange(5).repeat(2).reshape(1, 5, 2)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with pytest.raises(IndexError):\n', '             np.delete([0, 1, 2], np.array([], dtype=float))\n', ' \n', '+    @pytest.mark.parametrize(""indexer"", [np.array([1]), [1]])\n', '+    def test_single_item_array(self, indexer):\n', '+        a_del_int = delete(self.a, 1)\n', '+        a_del = delete(self.a, indexer)\n', '+        assert_equal(a_del_int, a_del)\n', '+\n', '+        nd_a_del_int = delete(self.nd_a, 1, axis=1)\n', '+        nd_a_del = delete(self.nd_a, np.array([1]), axis=1)\n', '+        assert_equal(nd_a_del_int, nd_a_del)\n', '+\n', '+    def test_single_item_array_non_int(self):\n', '+        # Special handling for integer arrays must not affect non-integer ones.\n', '+        # If `False` was cast to `0` it would delete the element:\n', '+        res = delete(np.ones(1), np.array([False]))\n', '+        assert_array_equal(res, np.ones(1))\n', '+\n', '+        # Test the more complicated (with axis) case from gh-21840\n', '+        x = np.ones((3, 1))\n', '+        false_mask = np.array([False], dtype=bool)\n', '+        true_mask = np.array([True], dtype=bool)\n', '+\n', '+        res = delete(x, false_mask, axis=-1)\n', '+        assert_array_equal(res, x)\n', '+        res = delete(x, true_mask, axis=-1)\n', '+        assert_array_equal(res, x[:, :0])\n', '+\n', '+        # Object or e.g. timedeltas should *not* be allowed\n', '+        with pytest.raises(IndexError):\n', '+            delete(np.ones(2), np.array([0], dtype=object))\n', ' \n', '+        with pytest.raises(IndexError):\n', '+            # timedeltas are sometimes ""integral, but clearly not allowed:\n', '+            delete(np.ones(2), np.array([0], dtype=""m8[ns]""))\n', ' \n', ' \n', ' class TestGradient:\n']","['         with pytest.raises(IndexError):\n', '             np.delete([0, 1, 2], np.array([], dtype=float))\n', ' \n', '-    def test_single_item_array(self):\n', '-        a_del = delete(self.a, 1)\n', '-        a_del_arr = delete(self.a, np.array([1]))\n', '-        a_del_lst = delete(self.a, [1])\n', '-        a_del_obj = delete(self.a, np.array([1], dtype=object))\n', '-        assert_equal(a_del, a_del_arr, a_del_lst, a_del_obj)\n', ' \n', '-        nd_a_del = delete(self.nd_a, 1, axis=1)\n', '-        nd_a_del_arr = delete(self.nd_a, np.array([1]), axis=1)\n', '-        nd_a_del_lst = delete(self.nd_a, [1], axis=1)\n', '-        nd_a_del_obj = delete(self.nd_a, np.array([1], dtype=object), axis=1)\n', '-        assert_equal(nd_a_del, nd_a_del_arr, nd_a_del_lst, nd_a_del_obj)\n', ' \n', ' \n', ' class TestGradient:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         A = np.array([[0.44567325, 0.79115165, 0.54900530],\n', '                       [0.36844147, 0.37325583, 0.96098397],\n', '                       [0.64864341, 0.52929049, 0.39172155]])\n', '+        with pytest.warns(DeprecationWarning, match=""msort is deprecated""):\n', '+            assert_almost_equal(\n', '+                msort(A),\n', '+                np.array([[0.36844147, 0.37325583, 0.39172155],\n', '+                          [0.44567325, 0.52929049, 0.54900530],\n', '+                          [0.64864341, 0.79115165, 0.96098397]]))\n', ' \n', ' \n', ' class TestMeshgrid:\n']","['         A = np.array([[0.44567325, 0.79115165, 0.54900530],\n', '                       [0.36844147, 0.37325583, 0.96098397],\n', '                       [0.64864341, 0.52929049, 0.39172155]])\n', '-        assert_almost_equal(\n', '-            msort(A),\n', '-            np.array([[0.36844147, 0.37325583, 0.39172155],\n', '-                      [0.44567325, 0.52929049, 0.54900530],\n', '-                      [0.64864341, 0.79115165, 0.96098397]]))\n', ' \n', ' \n', ' class TestMeshgrid:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     H_F_TYPE_CODES = [(int_type, np.float64)\n', '                       for int_type in np.typecodes[""AllInteger""]\n', '+                      ] + [(np.float16, np.float16),\n', '+                           (np.float32, np.float32),\n', '                            (np.float64, np.float64),\n', '                            (np.longdouble, np.longdouble),\n', '+                           (np.complex64, np.complex64),\n', '                            (np.complex128, np.complex128),\n', '                            (np.clongdouble, np.clongdouble),\n', '                            (np.dtype(""O""), np.float64)]\n']","[' \n', '     H_F_TYPE_CODES = [(int_type, np.float64)\n', '                       for int_type in np.typecodes[""AllInteger""]\n', '-                      ] + [(np.float16, np.float64),\n', '-                           (np.float32, np.float64),\n', '                            (np.float64, np.float64),\n', '                            (np.longdouble, np.longdouble),\n', '-                           (np.complex64, np.complex128),\n', '                            (np.complex128, np.complex128),\n', '                            (np.clongdouble, np.clongdouble),\n', '                            (np.dtype(""O""), np.float64)]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                                   expected,\n', '                                   input_dtype,\n', '                                   expected_dtype):\n', '+        expected_dtype = np.dtype(expected_dtype)\n', '+        if np._get_promotion_state() == ""legacy"":\n', '+            expected_dtype = np.promote_types(expected_dtype, np.float64)\n', '+\n', '         arr = np.asarray([15.0, 20.0, 35.0, 40.0, 50.0], dtype=input_dtype)\n', '         actual = np.percentile(arr, 40.0, method=method)\n', ' \n', '+        np.testing.assert_almost_equal(\n', '+            actual, expected_dtype.type(expected), 14)\n', ' \n', '         if method in [""inverted_cdf"", ""closest_observation""]:\n', '             if input_dtype == ""O"":\n']","['                                   expected,\n', '                                   input_dtype,\n', '                                   expected_dtype):\n', '         arr = np.asarray([15.0, 20.0, 35.0, 40.0, 50.0], dtype=input_dtype)\n', '         actual = np.percentile(arr, 40.0, method=method)\n', ' \n', '-        np.testing.assert_almost_equal(actual, expected, 14)\n', ' \n', '         if method in [""inverted_cdf"", ""closest_observation""]:\n', '             if input_dtype == ""O"":\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # double subtraction is needed to remove the extra precision of t < 0.5\n', '         left = nfb._lerp(a, b, 1 - (1 - t))\n', '         right = nfb._lerp(b, a, 1 - t)\n', '+        assert_allclose(left, right)\n', ' \n', '     def test_linear_interpolation_formula_0d_inputs(self):\n', '         a = np.array(2)\n']","['         # double subtraction is needed to remove the extra precision of t < 0.5\n', '         left = nfb._lerp(a, b, 1 - (1 - t))\n', '         right = nfb._lerp(b, a, 1 - t)\n', '-        assert left == right\n', ' \n', '     def test_linear_interpolation_formula_0d_inputs(self):\n', '         a = np.array(2)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         b[2] = np.nan\n', '         assert_equal(np.median(a, (0, 2)), b)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work correctly"")\n', '     def test_empty(self):\n', '         # mean(empty array) emits two warnings: empty slice and divide by 0\n', '         a = np.array([], dtype=float)\n']","['         b[2] = np.nan\n', '         assert_equal(np.median(a, (0, 2)), b)\n', ' \n', '     def test_empty(self):\n', '         # mean(empty array) emits two warnings: empty slice and divide by 0\n', '         a = np.array([], dtype=float)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_array_almost_equal, assert_raises, assert_allclose,\n', '     assert_array_max_ulp, assert_raises_regex, suppress_warnings,\n', '     )\n', '+from numpy.testing._private.utils import requires_memory\n', ' import pytest\n', ' \n', ' \n', ' class TestHistogram:\n', ' \n', '+    def setup_method(self):\n', '         pass\n', ' \n', '+    def teardown_method(self):\n', '         pass\n', ' \n', '     def test_simple(self):\n']","['     assert_array_almost_equal, assert_raises, assert_allclose,\n', '     assert_array_max_ulp, assert_raises_regex, suppress_warnings,\n', '     )\n', ' import pytest\n', ' \n', ' \n', ' class TestHistogram:\n', ' \n', '-    def setup(self):\n', '         pass\n', ' \n', '-    def teardown(self):\n', '         pass\n', ' \n', '     def test_simple(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(h, np.array([2]))\n', '         assert_allclose(e, np.array([1., 2.]))\n', ' \n', '     def test_density(self):\n', '         # Check that the integral of the density equals 1.\n', '         n = 100\n']","['         assert_equal(h, np.array([2]))\n', '         assert_allclose(e, np.array([1., 2.]))\n', ' \n', '-    def test_normed(self):\n', '-        sup = suppress_warnings()\n', '-        with sup:\n', ""-            rec = sup.record(np.VisibleDeprecationWarning, '.*normed.*')\n"", '-            # Check that the integral of the density equals 1.\n', '-            n = 100\n', '-            v = np.random.rand(n)\n', '-            a, b = histogram(v, normed=True)\n', '-            area = np.sum(a * np.diff(b))\n', '-            assert_almost_equal(area, 1)\n', '-            assert_equal(len(rec), 1)\n', '-\n', '-        sup = suppress_warnings()\n', '-        with sup:\n', ""-            rec = sup.record(np.VisibleDeprecationWarning, '.*normed.*')\n"", '-            # Check with non-constant bin widths (buggy but backwards\n', '-            # compatible)\n', '-            v = np.arange(10)\n', '-            bins = [0, 1, 5, 9, 10]\n', '-            a, b = histogram(v, bins, normed=True)\n', '-            area = np.sum(a * np.diff(b))\n', '-            assert_almost_equal(area, 1)\n', '-            assert_equal(len(rec), 1)\n', '-\n', '     def test_density(self):\n', '         # Check that the integral of the density equals 1.\n', '         n = 100\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         edges = histogram_bin_edges(arr, bins='auto', range=(0, 1))\n"", '         assert_array_equal(edges, e)\n', ' \n', '+    @requires_memory(free_bytes=1e10)\n', '+    @pytest.mark.slow\n', '+    def test_big_arrays(self):\n', '+        sample = np.zeros([100000000, 3])\n', '+        xbins = 400\n', '+        ybins = 400\n', '+        zbins = np.arange(16000)\n', '+        hist = np.histogramdd(sample=sample, bins=(xbins, ybins, zbins))\n', '+        assert_equal(type(hist), type((1, 2)))\n', '+\n', ' \n', ' class TestHistogramOptimBinNums:\n', '     """"""\n']","[""         edges = histogram_bin_edges(arr, bins='auto', range=(0, 1))\n"", '         assert_array_equal(edges, e)\n', ' \n', ' \n', ' class TestHistogramOptimBinNums:\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         hist_dd, edges_dd = histogramdd((v,), (bins,), density=True)\n', '         assert_equal(hist, hist_dd)\n', '         assert_equal(edges, edges_dd[0])\n']","['         hist_dd, edges_dd = histogramdd((v,), (bins,), density=True)\n', '         assert_equal(hist, hist_dd)\n', '         assert_equal(edges, edges_dd[0])\n', '-\n', '-    def test_density_via_normed(self):\n', '-        # normed should simply alias to density argument\n', '-        v = np.arange(10)\n', '-        bins = np.array([0, 1, 3, 6, 10])\n', '-        hist, edges = histogram(v, bins, density=True)\n', '-        hist_dd, edges_dd = histogramdd((v,), (bins,), normed=True)\n', '-        assert_equal(hist, hist_dd)\n', '-        assert_equal(edges, edges_dd[0])\n', '-\n', '-    def test_density_normed_redundancy(self):\n', '-        v = np.arange(10)\n', '-        bins = np.array([0, 1, 3, 6, 10])\n', '-        with assert_raises_regex(TypeError, ""Cannot specify both""):\n', '-            hist_dd, edges_dd = histogramdd((v,), (bins,),\n', '-                                            density=True,\n', '-                                            normed=True)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(grid32.dtype == np.float64)\n', '         assert_array_almost_equal(grid64, grid32)\n', ' \n', '+    def test_accepts_longdouble(self):\n', '+        # regression tests for #16945\n', '+        grid64 = mgrid[0.1:0.33:0.1, ]\n', '+        grid128 = mgrid[\n', '+            np.longdouble(0.1):np.longdouble(0.33):np.longdouble(0.1),\n', '+        ]\n', '+        assert_(grid128.dtype == np.longdouble)\n', '+        assert_array_almost_equal(grid64, grid128)\n', '+\n', '+        grid128c_a = mgrid[0:np.longdouble(1):3.4j]\n', '+        grid128c_b = mgrid[0:np.longdouble(1):3.4j, ]\n', '+        assert_(grid128c_a.dtype == grid128c_b.dtype == np.longdouble)\n', '+        assert_array_equal(grid128c_a, grid128c_b[0])\n', '+\n', '+        # different code path for single slice\n', '+        grid64 = mgrid[0.1:0.33:0.1]\n', '+        grid128 = mgrid[\n', '+            np.longdouble(0.1):np.longdouble(0.33):np.longdouble(0.1)\n', '+        ]\n', '+        assert_(grid128.dtype == np.longdouble)\n', '+        assert_array_almost_equal(grid64, grid128)\n', '+\n', '     def test_accepts_npcomplexfloating(self):\n', '         # Related to #16466\n', '         assert_array_almost_equal(\n']","['         assert_(grid32.dtype == np.float64)\n', '         assert_array_almost_equal(grid64, grid32)\n', ' \n', '     def test_accepts_npcomplexfloating(self):\n', '         # Related to #16466\n', '         assert_array_almost_equal(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             mgrid[0.1:0.3:3j], mgrid[0.1:0.3:np.complex64(3j)]\n', '         )\n', ' \n', '+        # Related to #16945\n', '+        grid64_a = mgrid[0.1:0.3:3.3j]\n', '+        grid64_b = mgrid[0.1:0.3:3.3j, ][0]\n', '+        assert_(grid64_a.dtype == grid64_b.dtype == np.float64)\n', '+        assert_array_equal(grid64_a, grid64_b)\n', '+\n', '+        grid128_a = mgrid[0.1:0.3:np.clongdouble(3.3j)]\n', '+        grid128_b = mgrid[0.1:0.3:np.clongdouble(3.3j), ][0]\n', '+        assert_(grid128_a.dtype == grid128_b.dtype == np.longdouble)\n', '+        assert_array_equal(grid64_a, grid64_b)\n', '+\n', '+\n', ' class TestConcatenator:\n', '     def test_1d(self):\n', '         assert_array_equal(r_[1, 2, 3, 4, 5, 6], np.array([1, 2, 3, 4, 5, 6]))\n']","['             mgrid[0.1:0.3:3j], mgrid[0.1:0.3:np.complex64(3j)]\n', '         )\n', ' \n', ' class TestConcatenator:\n', '     def test_1d(self):\n', '         assert_array_equal(r_[1, 2, 3, 4, 5, 6], np.array([1, 2, 3, 4, 5, 6]))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from io import BytesIO, StringIO\n', ' from datetime import datetime\n', ' import locale\n', '+from multiprocessing import Value, get_context\n', ' from ctypes import c_bool\n', ' \n', ' import numpy as np\n']","[' from io import BytesIO, StringIO\n', ' from datetime import datetime\n', ' import locale\n', '-from multiprocessing import Process, Value\n', ' from ctypes import c_bool\n', ' \n', ' import numpy as np\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert_warns, assert_, assert_raises_regex, assert_raises,\n', '     assert_allclose, assert_array_equal, temppath, tempdir, IS_PYPY,\n', '     HAS_REFCOUNT, suppress_warnings, assert_no_gc_cycles, assert_no_warnings,\n', '+    break_cycles, IS_WASM\n', '     )\n', ' from numpy.testing._private.utils import requires_memory\n', ' \n']","['     assert_warns, assert_, assert_raises_regex, assert_raises,\n', '     assert_allclose, assert_array_equal, temppath, tempdir, IS_PYPY,\n', '     HAS_REFCOUNT, suppress_warnings, assert_no_gc_cycles, assert_no_warnings,\n', '-    break_cycles\n', '     )\n', ' from numpy.testing._private.utils import requires_memory\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(a, l.f.file_a)\n', '         assert_equal(b, l.f.file_b)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""Cannot start thread"")\n', '     def test_savez_filename_clashes(self):\n', '         # Test that issue #852 is fixed\n', '         # and savez functions in multithreaded environment\n']","['         assert_equal(a, l.f.file_a)\n', '         assert_equal(b, l.f.file_b)\n', ' \n', '     def test_savez_filename_clashes(self):\n', '         # Test that issue #852 is fixed\n', '         # and savez functions in multithreaded environment\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         s.seek(0)\n', ""         assert_equal(s.read(), utf8 + '\\n')\n"", ' \n', '+    @pytest.mark.parametrize(""fmt"", [""%f"", b""%f""])\n', '     @pytest.mark.parametrize(""iotype"", [StringIO, BytesIO])\n', '     def test_unicode_and_bytes_fmt(self, fmt, iotype):\n', '         # string type of fmt should not matter, see also gh-4053\n']","['         s.seek(0)\n', ""         assert_equal(s.read(), utf8 + '\\n')\n"", ' \n', '-    @pytest.mark.parametrize(""fmt"", [u""%f"", b""%f""])\n', '     @pytest.mark.parametrize(""iotype"", [StringIO, BytesIO])\n', '     def test_unicode_and_bytes_fmt(self, fmt, iotype):\n', '         # string type of fmt should not matter, see also gh-4053\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         np.savetxt(s, a, fmt=fmt)\n', '         s.seek(0)\n', '         if iotype is StringIO:\n', '+            assert_equal(s.read(), ""%f\\n"" % 1.)\n', '         else:\n', '             assert_equal(s.read(), b""%f\\n"" % 1.)\n', ' \n']","['         np.savetxt(s, a, fmt=fmt)\n', '         s.seek(0)\n', '         if iotype is StringIO:\n', '-            assert_equal(s.read(), u""%f\\n"" % 1.)\n', '         else:\n', '             assert_equal(s.read(), b""%f\\n"" % 1.)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # Use an object in shared memory to re-raise the MemoryError exception\n', '         # in our process if needed, see gh-16889\n', '         memoryerror_raised = Value(c_bool)\n', '+\n', '+        # Since Python 3.8, the default start method for multiprocessing has \n', ""+        # been changed from 'fork' to 'spawn' on macOS, causing inconsistency \n"", '+        # on memory sharing model, lead to failed test for check_large_zip\n', ""+        ctx = get_context('fork')\n"", '+        p = ctx.Process(target=check_large_zip, args=(memoryerror_raised,))\n', '         p.start()\n', '         p.join()\n', '         if memoryerror_raised.value:\n']","['         # Use an object in shared memory to re-raise the MemoryError exception\n', '         # in our process if needed, see gh-16889\n', '         memoryerror_raised = Value(c_bool)\n', '-        p = Process(target=check_large_zip, args=(memoryerror_raised,))\n', '         p.start()\n', '         p.join()\n', '         if memoryerror_raised.value:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestLoadTxt(LoadTxtBase):\n', '     loadfunc = staticmethod(np.loadtxt)\n', ' \n', '+    def setup_method(self):\n', '         # lower chunksize for testing\n', '         self.orig_chunk = np.lib.npyio._loadtxt_chunksize\n', '         np.lib.npyio._loadtxt_chunksize = 1\n', '+\n', '+    def teardown_method(self):\n', '         np.lib.npyio._loadtxt_chunksize = self.orig_chunk\n', ' \n', '     def test_record(self):\n']","[' class TestLoadTxt(LoadTxtBase):\n', '     loadfunc = staticmethod(np.loadtxt)\n', ' \n', '-    def setup(self):\n', '         # lower chunksize for testing\n', '         self.orig_chunk = np.lib.npyio._loadtxt_chunksize\n', '         np.lib.npyio._loadtxt_chunksize = 1\n', '-    def teardown(self):\n', '         np.lib.npyio._loadtxt_chunksize = self.orig_chunk\n', ' \n', '     def test_record(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         c.write('# comment\\n1,2,3,5\\n')\n"", '         c.seek(0)\n', ""         x = np.loadtxt(c, dtype=int, delimiter=',',\n"", ""+                       comments='#')\n"", '         a = np.array([1, 2, 3, 5], int)\n', '         assert_array_equal(x, a)\n', ' \n']","[""         c.write('# comment\\n1,2,3,5\\n')\n"", '         c.seek(0)\n', ""         x = np.loadtxt(c, dtype=int, delimiter=',',\n"", ""-                       comments=u'#')\n"", '         a = np.array([1, 2, 3, 5], int)\n', '         assert_array_equal(x, a)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         with tempdir() as tmpdir:\n', '             fpath = os.path.join(tmpdir, ""test.csv"")\n', '             with open(fpath, ""wb"") as f:\n', ""+                f.write('\\N{GREEK PI SYMBOL}'.encode())\n"", ' \n', ""             # ResourceWarnings are emitted from a destructor, so won't be\n"", '             # detected by regular propagation to errors.\n']","['         with tempdir() as tmpdir:\n', '             fpath = os.path.join(tmpdir, ""test.csv"")\n', '             with open(fpath, ""wb"") as f:\n', ""-                f.write(u'\\N{GREEK PI SYMBOL}'.encode('utf8'))\n"", ' \n', ""             # ResourceWarnings are emitted from a destructor, so won't be\n"", '             # detected by regular propagation to errors.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         test = np.genfromtxt(TextIO(s),\n', ""                              dtype=None, comments=None, delimiter=',',\n"", ""                              encoding='latin1')\n"", '+        assert_equal(test[1, 0], ""test1"")\n', '+        assert_equal(test[1, 1], ""testNonethe"" + latin1.decode(\'latin1\'))\n', '+        assert_equal(test[1, 2], ""test3"")\n', ' \n', '         with warnings.catch_warnings(record=True) as w:\n', ""             warnings.filterwarnings('always', '', np.VisibleDeprecationWarning)\n""]","['         test = np.genfromtxt(TextIO(s),\n', ""                              dtype=None, comments=None, delimiter=',',\n"", ""                              encoding='latin1')\n"", '-        assert_equal(test[1, 0], u""test1"")\n', '-        assert_equal(test[1, 1], u""testNonethe"" + latin1.decode(\'latin1\'))\n', '-        assert_equal(test[1, 2], u""test3"")\n', ' \n', '         with warnings.catch_warnings(record=True) as w:\n', ""             warnings.filterwarnings('always', '', np.VisibleDeprecationWarning)\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_utf8_file_nodtype_unicode(self):\n', '         # bytes encoding with non-latin1 -> unicode upcast\n', ""+        utf8 = '\\u03d6'\n"", ""+        latin1 = '\\xf6\\xfc\\xf6'\n"", ' \n', '         # skip test if cannot encode utf8 test string with preferred\n', '         # encoding. The preferred encoding is assumed to be the default\n']","[' \n', '     def test_utf8_file_nodtype_unicode(self):\n', '         # bytes encoding with non-latin1 -> unicode upcast\n', ""-        utf8 = u'\\u03d6'\n"", ""-        latin1 = u'\\xf6\\xfc\\xf6'\n"", ' \n', '         # skip test if cannot encode utf8 test string with preferred\n', '         # encoding. The preferred encoding is assumed to be the default\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         with temppath() as path:\n', '             with io.open(path, ""wt"") as f:\n', '+                f.write(""norm1,norm2,norm3\\n"")\n', '+                f.write(""norm1,"" + latin1 + "",norm3\\n"")\n', '+                f.write(""test1,testNonethe"" + utf8 + "",test3\\n"")\n', '             with warnings.catch_warnings(record=True) as w:\n', ""                 warnings.filterwarnings('always', '',\n"", '                                         np.VisibleDeprecationWarning)\n']","[' \n', '         with temppath() as path:\n', '             with io.open(path, ""wt"") as f:\n', '-                f.write(u""norm1,norm2,norm3\\n"")\n', '-                f.write(u""norm1,"" + latin1 + u"",norm3\\n"")\n', '-                f.write(u""test1,testNonethe"" + utf8 + u"",test3\\n"")\n', '             with warnings.catch_warnings(record=True) as w:\n', ""                 warnings.filterwarnings('always', '',\n"", '                                         np.VisibleDeprecationWarning)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     @pytest.mark.parametrize(""ndim"", [0, 1, 2])\n', '     def test_ndmin_keyword(self, ndim: int):\n', '+        # lets have the same behaviour of ndmin as loadtxt\n', '         # as they should be the same for non-missing values\n', '         txt = ""42""\n', ' \n']","[' \n', '     @pytest.mark.parametrize(""ndim"", [0, 1, 2])\n', '     def test_ndmin_keyword(self, ndim: int):\n', '-        # lets have the same behaivour of ndmin as loadtxt\n', '         # as they should be the same for non-missing values\n', '         txt = ""42""\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 break_cycles()\n', '                 break_cycles()\n', ' \n', '+    @pytest.mark.xfail(IS_WASM, reason=""memmap doesn\'t work correctly"")\n', '     def test_save_load_memmap_readwrite(self):\n', '         # Test that pathlib.Path instances can be written mem-mapped.\n', ""         with temppath(suffix='.npy') as path:\n""]","['                 break_cycles()\n', '                 break_cycles()\n', ' \n', '     def test_save_load_memmap_readwrite(self):\n', '         # Test that pathlib.Path instances can be written mem-mapped.\n', ""         with temppath(suffix='.npy') as path:\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         with temppath(suffix='.txt') as path:\n"", '             path = Path(path)\n', ""             with path.open('w') as f:\n"", ""+                f.write('A,B\\n0,1\\n2,3')\n"", ' \n', '             kwargs = dict(delimiter="","", missing_values=""N/A"", names=True)\n', '             test = np.recfromtxt(path, **kwargs)\n']","[""         with temppath(suffix='.txt') as path:\n"", '             path = Path(path)\n', ""             with path.open('w') as f:\n"", ""-                f.write(u'A,B\\n0,1\\n2,3')\n"", ' \n', '             kwargs = dict(delimiter="","", missing_values=""N/A"", names=True)\n', '             test = np.recfromtxt(path, **kwargs)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         with temppath(suffix='.txt') as path:\n"", '             path = Path(path)\n', ""             with path.open('w') as f:\n"", ""+                f.write('A,B\\n0,1\\n2,3')\n"", ' \n', '             kwargs = dict(missing_values=""N/A"", names=True, case_sensitive=True)\n', '             test = np.recfromcsv(path, dtype=None, **kwargs)\n']","[""         with temppath(suffix='.txt') as path:\n"", '             path = Path(path)\n', ""             with path.open('w') as f:\n"", ""-                f.write(u'A,B\\n0,1\\n2,3')\n"", ' \n', '             kwargs = dict(missing_values=""N/A"", names=True, case_sensitive=True)\n', '             test = np.recfromcsv(path, dtype=None, **kwargs)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' """"""\n', ' \n', ' import sys\n', '+import os\n', ' import pytest\n', ' from tempfile import NamedTemporaryFile, mkstemp\n', ' from io import StringIO\n']","[' """"""\n', ' \n', ' import sys\n', ' import pytest\n', ' from tempfile import NamedTemporaryFile, mkstemp\n', ' from io import StringIO\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     txt = StringIO(""0,0,XXX\\n0\\n0,XXX,XXX,0,XXX\\n"")\n', '     with pytest.raises(ValueError,\n', '+                match=""invalid column index -2 at row 2 with 1 columns""):\n', '         # There is no -2 column in the second row:\n', '         np.loadtxt(txt, dtype=float, delimiter="","", usecols=[0, -2])\n', ' \n']","[' \n', '     txt = StringIO(""0,0,XXX\\n0\\n0,XXX,XXX,0,XXX\\n"")\n', '     with pytest.raises(ValueError,\n', '-                match=""invalid column index -2 at row 1 with 2 columns""):\n', '         # There is no -2 column in the second row:\n', '         np.loadtxt(txt, dtype=float, delimiter="","", usecols=[0, -2])\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+@pytest.mark.filterwarnings(""error:.*integer via a float.*:DeprecationWarning"")\n', ' def test_integer_signs(dtype):\n', '     dtype = np.dtype(dtype)\n', '     assert np.loadtxt([""+2""], dtype=dtype) == 2\n']","[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', ' def test_integer_signs(dtype):\n', '     dtype = np.dtype(dtype)\n', '     assert np.loadtxt([""+2""], dtype=dtype) == 2\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+@pytest.mark.filterwarnings(""error:.*integer via a float.*:DeprecationWarning"")\n', ' def test_implicit_cast_float_to_int_fails(dtype):\n', '     txt = StringIO(""1.0, 2.1, 3.7\\n4, 5, 6"")\n', '     with pytest.raises(ValueError):\n']","[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', ' def test_implicit_cast_float_to_int_fails(dtype):\n', '     txt = StringIO(""1.0, 2.1, 3.7\\n4, 5, 6"")\n', '     with pytest.raises(ValueError):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '+    os.close(fd)\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=unitless_dtype)\n', '+    os.remove(fname)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']","[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=unitless_dtype)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '+    os.close(fd)\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=""U"", converters=conv, encoding=None)\n', '+    os.remove(fname)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']","[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=""U"", converters=conv, encoding=None)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestRecFunctions:\n', '     # Misc tests\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', ""         z = np.array([('A', 1.), ('B', 2.)],\n""]","[' class TestRecFunctions:\n', '     # Misc tests\n', ' \n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', ""         z = np.array([('A', 1.), ('B', 2.)],\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_raises(NotImplementedError, unstructured_to_structured,\n', '                                            np.zeros((3,0), dtype=np.int32))\n', ' \n', '+    def test_unstructured_to_structured(self):\n', '+        # test if dtype is the args of np.dtype\n', '+        a = np.zeros((20, 2))\n', ""+        test_dtype_args = [('x', float), ('y', float)]\n"", '+        test_dtype = np.dtype(test_dtype_args)\n', '+        field1 = unstructured_to_structured(a, dtype=test_dtype_args)  # now\n', '+        field2 = unstructured_to_structured(a, dtype=test_dtype)  # before\n', '+        assert_equal(field1, field2)\n', '+\n', '     def test_field_assignment_by_name(self):\n', ""         a = np.ones(2, dtype=[('a', 'i4'), ('b', 'f8'), ('c', 'u1')])\n"", ""         newdt = [('b', 'f4'), ('c', 'u1')]\n""]","['         assert_raises(NotImplementedError, unstructured_to_structured,\n', '                                            np.zeros((3,0), dtype=np.int32))\n', ' \n', '     def test_field_assignment_by_name(self):\n', ""         a = np.ones(2, dtype=[('a', 'i4'), ('b', 'f8'), ('c', 'u1')])\n"", ""         newdt = [('b', 'f4'), ('c', 'u1')]\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestMergeArrays:\n', '     # Test merge_arrays\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']","[' class TestMergeArrays:\n', '     # Test merge_arrays\n', ' \n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestAppendFields:\n', '     # Test append_fields\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']","[' class TestAppendFields:\n', '     # Test append_fields\n', ' \n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestStackArrays:\n', '     # Test stack_arrays\n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']","[' \n', ' class TestStackArrays:\n', '     # Test stack_arrays\n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestJoinBy:\n', '+    def setup_method(self):\n', '         self.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                    np.arange(100, 110))),\n', ""                           dtype=[('a', int), ('b', int), ('c', int)])\n""]","[' \n', ' \n', ' class TestJoinBy:\n', '-    def setup(self):\n', '         self.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                    np.arange(100, 110))),\n', ""                           dtype=[('a', int), ('b', int), ('c', int)])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestJoinBy2:\n', '     @classmethod\n', '+    def setup_method(cls):\n', '         cls.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                   np.arange(100, 110))),\n', ""                          dtype=[('a', int), ('b', int), ('c', int)])\n""]","[' \n', ' class TestJoinBy2:\n', '     @classmethod\n', '-    def setup(cls):\n', '         cls.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                   np.arange(100, 110))),\n', ""                          dtype=[('a', int), ('b', int), ('c', int)])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     # https://github.com/numpy/numpy/issues/2346\n', ' \n', '+    def setup_method(self):\n', '         from datetime import date\n', '         self.data = dict(obj=date(2000, 1, 1))\n', ' \n']","['     """"""\n', '     # https://github.com/numpy/numpy/issues/2346\n', ' \n', '-    def setup(self):\n', '         from datetime import date\n', '         self.data = dict(obj=date(2000, 1, 1))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestKron:\n', '+    def test_basic(self):\n', '+        # Using 0-dimensional ndarray\n', '+        a = np.array(1)\n', '+        b = np.array([[1, 2], [3, 4]])\n', '+        k = np.array([[1, 2], [3, 4]])\n', '+        assert_array_equal(np.kron(a, b), k)\n', '+        a = np.array([[1, 2], [3, 4]])\n', '+        b = np.array(1)\n', '+        assert_array_equal(np.kron(a, b), k)\n', '+\n', '+        # Using 1-dimensional ndarray\n', '+        a = np.array([3])\n', '+        b = np.array([[1, 2], [3, 4]])\n', '+        k = np.array([[3, 6], [9, 12]])\n', '+        assert_array_equal(np.kron(a, b), k)\n', '+        a = np.array([[1, 2], [3, 4]])\n', '+        b = np.array([3])\n', '+        assert_array_equal(np.kron(a, b), k)\n', '+\n', '+        # Using 3-dimensional ndarray\n', '+        a = np.array([[[1]], [[2]]])\n', '+        b = np.array([[1, 2], [3, 4]])\n', '+        k = np.array([[[1, 2], [3, 4]], [[2, 4], [6, 8]]])\n', '+        assert_array_equal(np.kron(a, b), k)\n', '+        a = np.array([[1, 2], [3, 4]])\n', '+        b = np.array([[[1]], [[2]]])\n', '+        k = np.array([[[1, 2], [3, 4]], [[2, 4], [6, 8]]])\n', '+        assert_array_equal(np.kron(a, b), k)\n', '+\n', '     def test_return_type(self):\n', '         class myarray(np.ndarray):\n', '             __array_priority__ = 1.0\n']","[' \n', ' \n', ' class TestKron:\n', '     def test_return_type(self):\n', '         class myarray(np.ndarray):\n', '             __array_priority__ = 1.0\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     assert_('\\n        Bizarre' in new_func5.__doc__)\n"", ' \n', ' \n', '+def test_deprecate_module():\n', '+    assert_(old_func.__module__ == __name__)\n', '+\n', '+\n', ' def test_safe_eval_nameconstant():\n', '     # Test if safe_eval supports Python 3.4 _ast.NameConstant\n', ""     utils.safe_eval('None')\n""]","[""     assert_('\\n        Bizarre' in new_func5.__doc__)\n"", ' \n', ' \n', ' def test_safe_eval_nameconstant():\n', '     # Test if safe_eval supports Python 3.4 _ast.NameConstant\n', ""     utils.safe_eval('None')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return v\n', ' \n', ' \n', '+def _histogram2d_dispatcher(x, y, bins=None, range=None, density=None,\n', '+                            weights=None):\n', '     yield x\n', '     yield y\n', ' \n']","['     return v\n', ' \n', ' \n', '-def _histogram2d_dispatcher(x, y, bins=None, range=None, normed=None,\n', '-                            weights=None, density=None):\n', '     yield x\n', '     yield y\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @array_function_dispatch(_histogram2d_dispatcher)\n', '+def histogram2d(x, y, bins=10, range=None, density=None, weights=None):\n', '     """"""\n', '     Compute the bi-dimensional histogram of two data samples.\n', ' \n']","[' \n', ' \n', ' @array_function_dispatch(_histogram2d_dispatcher)\n', '-def histogram2d(x, y, bins=10, range=None, normed=None, weights=None,\n', '-                density=None):\n', '     """"""\n', '     Compute the bi-dimensional histogram of two data samples.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         If False, the default, returns the number of samples in each bin.\n', '         If True, returns the probability *density* function at the bin,\n', '         ``bin_count / sample_count / bin_area``.\n', '     weights : array_like, shape(N,), optional\n', '         An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.\n', '+        Weights are normalized to 1 if `density` is True. If `density` is\n', '         False, the values of the returned histogram are equal to the sum of\n', '         the weights belonging to the samples falling into each bin.\n', ' \n']","['         If False, the default, returns the number of samples in each bin.\n', '         If True, returns the probability *density* function at the bin,\n', '         ``bin_count / sample_count / bin_area``.\n', '-    normed : bool, optional\n', '-        An alias for the density argument that behaves identically. To avoid\n', '-        confusion with the broken normed argument to `histogram`, `density`\n', '-        should be preferred.\n', '     weights : array_like, shape(N,), optional\n', '         An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.\n', '-        Weights are normalized to 1 if `normed` is True. If `normed` is\n', '         False, the values of the returned histogram are equal to the sum of\n', '         the weights belonging to the samples falling into each bin.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Notes\n', '     -----\n', '+    When `density` is True, then the returned histogram is the sample\n', '     density, defined such that the sum over bins of the product\n', '     ``bin_value * bin_area`` is 1.\n', ' \n']","[' \n', '     Notes\n', '     -----\n', '-    When `normed` is True, then the returned histogram is the sample\n', '     density, defined such that the sum over bins of the product\n', '     ``bin_value * bin_area`` is 1.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if N != 1 and N != 2:\n', '         xedges = yedges = asarray(bins)\n', '         bins = [xedges, yedges]\n', '+    hist, edges = histogramdd([x, y], bins, range, density, weights)\n', '     return hist, edges[0], edges[1]\n', ' \n', ' \n']","['     if N != 1 and N != 2:\n', '         xedges = yedges = asarray(bins)\n', '         bins = [xedges, yedges]\n', '-    hist, edges = histogramdd([x, y], bins, range, normed, weights, density)\n', '     return hist, edges[0], edges[1]\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import types\n', ' import re\n', ' import warnings\n', '+import functools\n', ' \n', ' from numpy.core.numerictypes import issubclass_, issubsctype, issubdtype\n', ' from numpy.core.overrides import set_module\n']","[' import types\n', ' import re\n', ' import warnings\n', ' \n', ' from numpy.core.numerictypes import issubclass_, issubsctype, issubdtype\n', ' from numpy.core.overrides import set_module\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' __all__ = [\n', ""     'issubclass_', 'issubsctype', 'issubdtype', 'deprecate',\n"", ""     'deprecate_with_doc', 'get_include', 'info', 'source', 'who',\n"", ""+    'lookfor', 'byte_bounds', 'safe_eval', 'show_runtime'\n"", '     ]\n', ' \n', '+\n', '+def show_runtime():\n', '+    """"""\n', '+    Print information about various resources in the system\n', '+    including available intrinsic support and BLAS/LAPACK library\n', '+    in use\n', '+\n', '+    See Also\n', '+    --------\n', '+    show_config : Show libraries in the system on which NumPy was built.\n', '+\n', '+    Notes\n', '+    -----\n', '+    1. Information is derived with the help of `threadpoolctl <https://pypi.org/project/threadpoolctl/>`_\n', '+       library.\n', '+    2. SIMD related information is derived from ``__cpu_features__``,\n', '+       ``__cpu_baseline__`` and ``__cpu_dispatch__``\n', '+\n', '+    Examples\n', '+    --------\n', '+    >>> import numpy as np\n', '+    >>> np.show_runtime()\n', ""+    [{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],\n"", ""+                          'found': ['SSSE3',\n"", ""+                                    'SSE41',\n"", ""+                                    'POPCNT',\n"", ""+                                    'SSE42',\n"", ""+                                    'AVX',\n"", ""+                                    'F16C',\n"", ""+                                    'FMA3',\n"", ""+                                    'AVX2'],\n"", ""+                          'not_found': ['AVX512F',\n"", ""+                                        'AVX512CD',\n"", ""+                                        'AVX512_KNL',\n"", ""+                                        'AVX512_KNM',\n"", ""+                                        'AVX512_SKX',\n"", ""+                                        'AVX512_CLX',\n"", ""+                                        'AVX512_CNL',\n"", ""+                                        'AVX512_ICL']}},\n"", ""+     {'architecture': 'Zen',\n"", ""+      'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so',\n"", ""+      'internal_api': 'openblas',\n"", ""+      'num_threads': 12,\n"", ""+      'prefix': 'libopenblas',\n"", ""+      'threading_layer': 'pthreads',\n"", ""+      'user_api': 'blas',\n"", ""+      'version': '0.3.20'}]\n"", '+    """"""\n', '+    from numpy.core._multiarray_umath import (\n', '+        __cpu_features__, __cpu_baseline__, __cpu_dispatch__\n', '+    )\n', '+    from pprint import pprint\n', '+    config_found = []\n', '+    features_found, features_not_found = [], []\n', '+    for feature in __cpu_dispatch__:\n', '+        if __cpu_features__[feature]:\n', '+            features_found.append(feature)\n', '+        else:\n', '+            features_not_found.append(feature)\n', '+    config_found.append({\n', '+        ""simd_extensions"": {\n', '+            ""baseline"": __cpu_baseline__,\n', '+            ""found"": features_found,\n', '+            ""not_found"": features_not_found\n', '+        }\n', '+    })\n', '+    try:\n', '+        from threadpoolctl import threadpool_info\n', '+        config_found.extend(threadpool_info())\n', '+    except ImportError:\n', '+        print(""WARNING: `threadpoolctl` not found in system!""\n', '+              "" Install it by `pip install threadpoolctl`.""\n', '+              "" Once installed, try `np.show_runtime` again""\n', '+              "" for more detailed build information"")\n', '+    pprint(config_found)\n', '+\n', '+\n', ' def get_include():\n', '     """"""\n', '     Return the directory that contains the NumPy \\\\*.h header files.\n']","[' __all__ = [\n', ""     'issubclass_', 'issubsctype', 'issubdtype', 'deprecate',\n"", ""     'deprecate_with_doc', 'get_include', 'info', 'source', 'who',\n"", ""-    'lookfor', 'byte_bounds', 'safe_eval'\n"", '     ]\n', ' \n', ' def get_include():\n', '     """"""\n', '     Return the directory that contains the NumPy \\\\*.h header files.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return d\n', ' \n', ' \n', ' class _Deprecate:\n', '     """"""\n', '     Decorator class to deprecate old functions.\n']","['     return d\n', ' \n', ' \n', '-def _set_function_name(func, name):\n', '-    func.__name__ = name\n', '-    return func\n', '-\n', '-\n', ' class _Deprecate:\n', '     """"""\n', '     Decorator class to deprecate old functions.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         message = self.message\n', ' \n', '         if old_name is None:\n', '+            old_name = func.__name__\n', '         if new_name is None:\n', '             depdoc = ""`%s` is deprecated!"" % old_name\n', '         else:\n']","['         message = self.message\n', ' \n', '         if old_name is None:\n', '-            try:\n', '-                old_name = func.__name__\n', '-            except AttributeError:\n', '-                old_name = func.__name__\n', '         if new_name is None:\n', '             depdoc = ""`%s` is deprecated!"" % old_name\n', '         else:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if message is not None:\n', '             depdoc += ""\\n"" + message\n', ' \n', '+        @functools.wraps(func)\n', '+        def newfunc(*args, **kwds):\n', '             warnings.warn(depdoc, DeprecationWarning, stacklevel=2)\n', '             return func(*args, **kwds)\n', ' \n', '+        newfunc.__name__ = old_name\n', '         doc = func.__doc__\n', '         if doc is None:\n', '             doc = depdoc\n']","['         if message is not None:\n', '             depdoc += ""\\n"" + message\n', ' \n', '-        def newfunc(*args,**kwds):\n', '-            """"""`arrayrange` is deprecated, use `arange` instead!""""""\n', '             warnings.warn(depdoc, DeprecationWarning, stacklevel=2)\n', '             return func(*args, **kwds)\n', ' \n', '-        newfunc = _set_function_name(newfunc, old_name)\n', '         doc = func.__doc__\n', '         if doc is None:\n', '             doc = depdoc\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             depdoc = textwrap.indent(depdoc, ' ' * indent)\n"", ""             doc = '\\n\\n'.join([depdoc, doc])\n"", '         newfunc.__doc__ = doc\n', '+\n', '         return newfunc\n', ' \n', ' \n']","[""             depdoc = textwrap.indent(depdoc, ' ' * indent)\n"", ""             doc = '\\n\\n'.join([depdoc, doc])\n"", '         newfunc.__doc__ = doc\n', '-        try:\n', '-            d = func.__dict__\n', '-        except AttributeError:\n', '-            pass\n', '-        else:\n', '-            newfunc.__dict__.update(d)\n', '         return newfunc\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                             finally:\n', '                                 sys.stdout = old_stdout\n', '                                 sys.stderr = old_stderr\n', '+                        except KeyboardInterrupt:\n', '+                            # Assume keyboard interrupt came from a user\n', '+                            raise\n', '+                        except BaseException:\n', '+                            # Ignore also SystemExit and pytests.importorskip\n', '+                            # `Skipped` (these are BaseExceptions; gh-22345)\n', '                             continue\n', ' \n', '             for n, v in _getmembers(item):\n']","['                             finally:\n', '                                 sys.stdout = old_stdout\n', '                                 sys.stderr = old_stderr\n', '-                        # Catch SystemExit, too\n', '-                        except (Exception, SystemExit):\n', '                             continue\n', ' \n', '             for n, v in _getmembers(item):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Evaluate a string containing a Python literal expression without\n', '     allowing the execution of arbitrary non-literal code.\n', ' \n', '+    .. warning::\n', '+\n', '+        This function is identical to :py:meth:`ast.literal_eval` and\n', '+        has the same security implications.  It may not always be safe\n', '+        to evaluate large input strings.\n', '+\n', '     Parameters\n', '     ----------\n', '     source : str\n']","['     Evaluate a string containing a Python literal expression without\n', '     allowing the execution of arbitrary non-literal code.\n', ' \n', '     Parameters\n', '     ----------\n', '     source : str\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.core import (\n', '     array, asarray, zeros, empty, empty_like, intc, single, double,\n', '     csingle, cdouble, inexact, complexfloating, newaxis, all, Inf, dot,\n', '+    add, multiply, sqrt, sum, isfinite,\n', '     finfo, errstate, geterrobj, moveaxis, amin, amax, product, abs,\n', '     atleast_2d, intp, asanyarray, object_, matmul,\n', '     swapaxes, divide, count_nonzero, isnan, sign, argsort, sort,\n']","[' from numpy.core import (\n', '     array, asarray, zeros, empty, empty_like, intc, single, double,\n', '     csingle, cdouble, inexact, complexfloating, newaxis, all, Inf, dot,\n', '-    add, multiply, sqrt, fastCopyAndTranspose, sum, isfinite,\n', '     finfo, errstate, geterrobj, moveaxis, amin, amax, product, abs,\n', '     atleast_2d, intp, asanyarray, object_, matmul,\n', '     swapaxes, divide, count_nonzero, isnan, sign, argsort, sort,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return t, result_type\n', ' \n', ' \n', ' def _to_native_byte_order(*arrays):\n', '     ret = []\n', '     for arr in arrays:\n']","['     return t, result_type\n', ' \n', ' \n', '-# _fastCopyAndTranpose assumes the input is 2D (as all the calls in here are).\n', '-\n', '-_fastCT = fastCopyAndTranspose\n', '-\n', ' def _to_native_byte_order(*arrays):\n', '     ret = []\n', '     for arr in arrays:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', '         return ret\n', ' \n', ' \n', ' def _assert_2d(*arrays):\n', '     for a in arrays:\n']","['     else:\n', '         return ret\n', ' \n', '-def _fastCopyAndTranspose(type, *arrays):\n', '-    cast_arrays = ()\n', '-    for a in arrays:\n', '-        if a.dtype.type is not type:\n', '-            a = a.astype(type)\n', '-        cast_arrays = cast_arrays + (_fastCT(a),)\n', '-    if len(cast_arrays) == 1:\n', '-        return cast_arrays[0]\n', '-    else:\n', '-        return cast_arrays\n', ' \n', ' def _assert_2d(*arrays):\n', '     for a in arrays:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     It is assumed that all indices of `x` are summed over in the product,\n', '     together with the rightmost indices of `a`, as is done in, for example,\n', '+    ``tensordot(a, x, axes=x.ndim)``.\n', ' \n', '     Parameters\n', '     ----------\n']","[' \n', '     It is assumed that all indices of `x` are summed over in the product,\n', '     together with the rightmost indices of `a`, as is done in, for example,\n', '-    ``tensordot(a, x, axes=b.ndim)``.\n', ' \n', '     Parameters\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' def _convertarray(a):\n', '     t, result_t = _commonType(a)\n', '+    a = a.astype(t).T.copy()\n', '     return a, t, result_t\n', ' \n', ' \n']","[' \n', ' def _convertarray(a):\n', '     t, result_t = _commonType(a)\n', '-    a = _fastCT(a.astype(t))\n', '     return a, t, result_t\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             return wrap(u), s, wrap(vt)\n', '         else:\n', '             s = eigvalsh(a)\n', '             s = abs(s)\n', '             return sort(s)[..., ::-1]\n', ' \n']","['             return wrap(u), s, wrap(vt)\n', '         else:\n', '             s = eigvalsh(a)\n', '-            s = s[..., ::-1]\n', '             s = abs(s)\n', '             return sort(s)[..., ::-1]\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_array_equal,\n', '     assert_almost_equal, assert_allclose, suppress_warnings,\n', '+    assert_raises_regex, HAS_LAPACK64, IS_WASM\n', '     )\n', ' \n', ' \n']","[' from numpy.testing import (\n', '     assert_, assert_equal, assert_raises, assert_array_equal,\n', '     assert_almost_equal, assert_allclose, suppress_warnings,\n', '-    assert_raises_regex, HAS_LAPACK64,\n', '     )\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_raises(LinAlgError, matrix_power, np.array([[1], [2]], dt), 1)\n', '         assert_raises(LinAlgError, matrix_power, np.ones((4, 3, 2), dt), 1)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_exceptions_not_invertible(self, dt):\n', '         if dt in self.dtnoinv:\n', '             return\n']","['         assert_raises(LinAlgError, matrix_power, np.array([[1], [2]], dt), 1)\n', '         assert_raises(LinAlgError, matrix_power, np.ones((4, 3, 2), dt), 1)\n', ' \n', '     def test_exceptions_not_invertible(self, dt):\n', '         if dt in self.dtnoinv:\n', '             return\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         c = np.linalg.cholesky(a)\n', ' \n', '         b = np.matmul(c, c.transpose(t).conj())\n', '+        with np._no_nep50_warning():\n', '+            atol = 500 * a.shape[0] * np.finfo(dtype).eps\n', ""+        assert_allclose(b, a, atol=atol, err_msg=f'{shape} {dtype}\\n{a}\\n{c}')\n"", ' \n', '     def test_0_size(self):\n', '         class ArraySubclass(np.ndarray):\n']","['         c = np.linalg.cholesky(a)\n', ' \n', '         b = np.matmul(c, c.transpose(t).conj())\n', '-        assert_allclose(b, a,\n', ""-                        err_msg=f'{shape} {dtype}\\n{a}\\n{c}',\n"", '-                        atol=500 * a.shape[0] * np.finfo(dtype).eps)\n', ' \n', '     def test_0_size(self):\n', '         class ArraySubclass(np.ndarray):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             assert_array_equal(res, routine(sw_arr))\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', ' def test_generalized_raise_multiloop():\n', ""     # It should raise an error even if the error doesn't occur in the\n"", '     # last iteration of the ufunc inner loop\n']","['             assert_array_equal(res, routine(sw_arr))\n', ' \n', ' \n', ' def test_generalized_raise_multiloop():\n', ""     # It should raise an error even if the error doesn't occur in the\n"", '     # last iteration of the ufunc inner loop\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             pytest.skip('Numpy xerbla not linked in.')\n"", ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', ' @pytest.mark.slow\n', ' def test_sdot_bug_8577():\n', '     # Regression test that loading certain other libraries does not\n']","[""             pytest.skip('Numpy xerbla not linked in.')\n"", ' \n', ' \n', ' @pytest.mark.slow\n', ' def test_sdot_bug_8577():\n', '     # Regression test that loading certain other libraries does not\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy as np\n', ' import numpy.core.umath as umath\n', ' import numpy.core.numerictypes as ntypes\n', '+from numpy.core import multiarray as mu\n', ' from numpy import ndarray, amax, amin, iscomplexobj, bool_, _NoValue\n', ' from numpy import array as narray\n', ' from numpy.lib.function_base import angle\n']","[' import numpy as np\n', ' import numpy.core.umath as umath\n', ' import numpy.core.numerictypes as ntypes\n', ' from numpy import ndarray, amax, amin, iscomplexobj, bool_, _NoValue\n', ' from numpy import array as narray\n', ' from numpy.lib.function_base import angle\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""                   'S': b'N/A',\n"", ""                   'u': 999999,\n"", ""                   'V': b'???',\n"", ""+                  'U': 'N/A'\n"", '                   }\n', ' \n', ' # Add datetime64 and timedelta64 types\n']","[""                   'S': b'N/A',\n"", ""                   'u': 999999,\n"", ""                   'V': b'???',\n"", ""-                  'U': u'N/A'\n"", '                   }\n', ' \n', ' # Add datetime64 and timedelta64 types\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Recursively produce a fill value for `dtype`, calling f on scalar dtypes\n', '     """"""\n', '     if dtype.names is not None:\n', '+        # We wrap into `array` here, which ensures we use NumPy cast rules\n', '+        # for integer casts, this allows the use of 99999 as a fill value\n', '+        # for int8.\n', '+        # TODO: This is probably a mess, but should best preserve behavior?\n', '+        vals = tuple(\n', '+                np.array(_recursive_fill_value(dtype[name], f))\n', '+                for name in dtype.names)\n', '         return np.array(vals, dtype=dtype)[()]  # decay to void scalar from 0d\n', '     elif dtype.subdtype:\n', '         subtype, shape = dtype.subdtype\n']","['     Recursively produce a fill value for `dtype`, calling f on scalar dtypes\n', '     """"""\n', '     if dtype.names is not None:\n', '-        vals = tuple(_recursive_fill_value(dtype[name], f) for name in dtype.names)\n', '         return np.array(vals, dtype=dtype)[()]  # decay to void scalar from 0d\n', '     elif dtype.subdtype:\n', '         subtype, shape = dtype.subdtype\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     Mask an array where equal to a given value.\n', ' \n', '+    Return a MaskedArray, masked where the data in array `x` are\n', '+    equal to `value`. The fill_value of the returned MaskedArray\n', '+    is set to `value`.\n', '+\n', '+    For floating point arrays, consider using ``masked_values(x, value)``.\n', ' \n', '     See Also\n', '     --------\n']","['     """"""\n', '     Mask an array where equal to a given value.\n', ' \n', '-    This function is a shortcut to ``masked_where``, with\n', '-    `condition` = (x == value).  For floating point arrays,\n', '-    consider using ``masked_values(x, value)``.\n', ' \n', '     See Also\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Note that `mask` is set to ``nomask`` if possible.\n', ' \n', '+    >>> ma.masked_values(x, 2.1)\n', '     masked_array(data=[1. , 1.1, 2. , 1.1, 3. ],\n', '                  mask=False,\n', '+           fill_value=2.1)\n', ' \n', '+    Unlike `masked_equal`, `masked_values` can perform approximate equalities. \n', ' \n', '+    >>> ma.masked_values(x, 2.1, atol=1e-1)\n', '+    masked_array(data=[1.0, 1.1, --, 1.1, 3.0],\n', '                  mask=[False, False,  True, False, False],\n', '+           fill_value=2.1)\n', ' \n', '     """"""\n', '     xnew = filled(x, value)\n']","[' \n', '     Note that `mask` is set to ``nomask`` if possible.\n', ' \n', '-    >>> ma.masked_values(x, 1.5)\n', '     masked_array(data=[1. , 1.1, 2. , 1.1, 3. ],\n', '                  mask=False,\n', '-           fill_value=1.5)\n', ' \n', '-    For integers, the fill value will be different in general to the\n', '-    result of ``masked_equal``.\n', ' \n', '-    >>> x = np.arange(5)\n', '-    >>> x\n', '-    array([0, 1, 2, 3, 4])\n', '-    >>> ma.masked_values(x, 2)\n', '-    masked_array(data=[0, 1, --, 3, 4],\n', '-                 mask=[False, False,  True, False, False],\n', '-           fill_value=2)\n', '-    >>> ma.masked_equal(x, 2)\n', '-    masked_array(data=[0, 1, --, 3, 4],\n', '                  mask=[False, False,  True, False, False],\n', '-           fill_value=2)\n', ' \n', '     """"""\n', '     xnew = filled(x, value)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['            fill_value=1e+20)\n', ' \n', '     """"""\n', ' \n', '+    return masked_where(~(np.isfinite(getdata(a))), a, copy=copy)\n', ' \n', ' ###############################################################################\n', ' #                            Printing options                                 #\n']","['            fill_value=1e+20)\n', ' \n', '     """"""\n', '-    a = np.array(a, copy=copy, subok=True)\n', ""-    mask = getattr(a, '_mask', None)\n"", '-    if mask is not None:\n', '-        condition = ~(np.isfinite(getdata(a)))\n', '-        if mask is not nomask:\n', '-            condition |= mask\n', '-        cls = type(a)\n', '-    else:\n', '-        condition = ~(np.isfinite(a))\n', '-        cls = MaskedArray\n', '-    result = a.view(cls)\n', '-    result._mask = condition\n', '-    return result\n', ' \n', ' \n', ' ###############################################################################\n', ' #                            Printing options                                 #\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         odata = getdata(other)\n', '         if mask.dtype.names is not None:\n', '+            # only == and != are reasonably defined for structured dtypes,\n', '+            # so give up early for all other comparisons:\n', '+            if compare not in (operator.eq, operator.ne):\n', '+                return NotImplemented\n', '             # For possibly masked structured arrays we need to be careful,\n', '             # since the standard structured array comparison will use all\n', '             # fields, masked or not. To avoid masked fields influencing the\n']","[' \n', '         odata = getdata(other)\n', '         if mask.dtype.names is not None:\n', '             # For possibly masked structured arrays we need to be careful,\n', '             # since the standard structured array comparison will use all\n', '             # fields, masked or not. To avoid masked fields influencing the\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if isinstance(check, (np.bool_, bool)):\n', '             return masked if mask else check\n', ' \n', '+        if mask is not nomask and compare in (operator.eq, operator.ne):\n', '             # Adjust elements that were masked, which should be treated\n', '             # as equal if masked in both, unequal if masked in one.\n', '             # Note that this works automatically for structured arrays too.\n', '+            # Ignore this for operations other than `==` and `!=`\n', '             check = np.where(mask, compare(smask, omask), check)\n', '             if mask.shape != check.shape:\n', '                 # Guarantee consistency of the shape, making a copy since the\n']","['         if isinstance(check, (np.bool_, bool)):\n', '             return masked if mask else check\n', ' \n', '-        if mask is not nomask:\n', '             # Adjust elements that were masked, which should be treated\n', '             # as equal if masked in both, unequal if masked in one.\n', '             # Note that this works automatically for structured arrays too.\n', '             check = np.where(mask, compare(smask, omask), check)\n', '             if mask.shape != check.shape:\n', '                 # Guarantee consistency of the shape, making a copy since the\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         """"""\n', '         return self._comparison(other, operator.ne)\n', ' \n', '+    # All other comparisons:\n', '+    def __le__(self, other):\n', '+        return self._comparison(other, operator.le)\n', '+\n', '+    def __lt__(self, other):\n', '+        return self._comparison(other, operator.lt)\n', '+\n', '+    def __ge__(self, other):\n', '+        return self._comparison(other, operator.ge)\n', '+\n', '+    def __gt__(self, other):\n', '+        return self._comparison(other, operator.gt)\n', '+\n', '     def __add__(self, other):\n', '         """"""\n', '         Add self to other, and return a new masked array.\n']","['         """"""\n', '         return self._comparison(other, operator.ne)\n', ' \n', '     def __add__(self, other):\n', '         """"""\n', '         Add self to other, and return a new masked array.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         else:\n', '             if m is not nomask:\n', '                 self._mask += m\n', '+        other_data = getdata(other)\n', '+        other_data = np.where(self._mask, other_data.dtype.type(0), other_data)\n', '+        self._data.__iadd__(other_data)\n', '         return self\n', ' \n', '     def __isub__(self, other):\n']","['         else:\n', '             if m is not nomask:\n', '                 self._mask += m\n', '-        self._data.__iadd__(np.where(self._mask, self.dtype.type(0),\n', '-                                     getdata(other)))\n', '         return self\n', ' \n', '     def __isub__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 self._mask += m\n', '         elif m is not nomask:\n', '             self._mask += m\n', '+        other_data = getdata(other)\n', '+        other_data = np.where(self._mask, other_data.dtype.type(0), other_data)\n', '+        self._data.__isub__(other_data)\n', '         return self\n', ' \n', '     def __imul__(self, other):\n']","['                 self._mask += m\n', '         elif m is not nomask:\n', '             self._mask += m\n', '-        self._data.__isub__(np.where(self._mask, self.dtype.type(0),\n', '-                                     getdata(other)))\n', '         return self\n', ' \n', '     def __imul__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 self._mask += m\n', '         elif m is not nomask:\n', '             self._mask += m\n', '+        other_data = getdata(other)\n', '+        other_data = np.where(self._mask, other_data.dtype.type(1), other_data)\n', '+        self._data.__imul__(other_data)\n', '         return self\n', ' \n', '     def __idiv__(self, other):\n']","['                 self._mask += m\n', '         elif m is not nomask:\n', '             self._mask += m\n', '-        self._data.__imul__(np.where(self._mask, self.dtype.type(1),\n', '-                                     getdata(other)))\n', '         return self\n', ' \n', '     def __idiv__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         dom_mask = _DomainSafeDivide().__call__(self._data, other_data)\n', '         other_mask = getmask(other)\n', '         new_mask = mask_or(other_mask, dom_mask)\n', '+        # The following 4 lines control the domain filling\n', '         if dom_mask.any():\n', '             (_, fval) = ufunc_fills[np.divide]\n', '+            other_data = np.where(\n', '+                    dom_mask, other_data.dtype.type(fval), other_data)\n', '         self._mask |= new_mask\n', '+        other_data = np.where(self._mask, other_data.dtype.type(1), other_data)\n', '+        self._data.__idiv__(other_data)\n', '         return self\n', ' \n', '     def __ifloordiv__(self, other):\n']","['         dom_mask = _DomainSafeDivide().__call__(self._data, other_data)\n', '         other_mask = getmask(other)\n', '         new_mask = mask_or(other_mask, dom_mask)\n', '-        # The following 3 lines control the domain filling\n', '         if dom_mask.any():\n', '             (_, fval) = ufunc_fills[np.divide]\n', '-            other_data = np.where(dom_mask, fval, other_data)\n', '         self._mask |= new_mask\n', '-        self._data.__idiv__(np.where(self._mask, self.dtype.type(1),\n', '-                                     other_data))\n', '         return self\n', ' \n', '     def __ifloordiv__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # The following 3 lines control the domain filling\n', '         if dom_mask.any():\n', '             (_, fval) = ufunc_fills[np.floor_divide]\n', '+            other_data = np.where(\n', '+                    dom_mask, other_data.dtype.type(fval), other_data)\n', '         self._mask |= new_mask\n', '+        other_data = np.where(self._mask, other_data.dtype.type(1), other_data)\n', '+        self._data.__ifloordiv__(other_data)\n', '         return self\n', ' \n', '     def __itruediv__(self, other):\n']","['         # The following 3 lines control the domain filling\n', '         if dom_mask.any():\n', '             (_, fval) = ufunc_fills[np.floor_divide]\n', '-            other_data = np.where(dom_mask, fval, other_data)\n', '         self._mask |= new_mask\n', '-        self._data.__ifloordiv__(np.where(self._mask, self.dtype.type(1),\n', '-                                          other_data))\n', '         return self\n', ' \n', '     def __itruediv__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # The following 3 lines control the domain filling\n', '         if dom_mask.any():\n', '             (_, fval) = ufunc_fills[np.true_divide]\n', '+            other_data = np.where(\n', '+                    dom_mask, other_data.dtype.type(fval), other_data)\n', '         self._mask |= new_mask\n', '+        other_data = np.where(self._mask, other_data.dtype.type(1), other_data)\n', '+        self._data.__itruediv__(other_data)\n', '         return self\n', ' \n', '     def __ipow__(self, other):\n']","['         # The following 3 lines control the domain filling\n', '         if dom_mask.any():\n', '             (_, fval) = ufunc_fills[np.true_divide]\n', '-            other_data = np.where(dom_mask, fval, other_data)\n', '         self._mask |= new_mask\n', '-        self._data.__itruediv__(np.where(self._mask, self.dtype.type(1),\n', '-                                         other_data))\n', '         return self\n', ' \n', '     def __ipow__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         """"""\n', '         other_data = getdata(other)\n', '+        other_data = np.where(self._mask, other_data.dtype.type(1), other_data)\n', '         other_mask = getmask(other)\n', ""         with np.errstate(divide='ignore', invalid='ignore'):\n"", '+            self._data.__ipow__(other_data)\n', '         invalid = np.logical_not(np.isfinite(self._data))\n', '         if invalid.any():\n', '             if self._mask is not nomask:\n']","[' \n', '         """"""\n', '         other_data = getdata(other)\n', '         other_mask = getmask(other)\n', ""         with np.errstate(divide='ignore', invalid='ignore'):\n"", '-            self._data.__ipow__(np.where(self._mask, self.dtype.type(1),\n', '-                                         other_data))\n', '         invalid = np.logical_not(np.isfinite(self._data))\n', '         if invalid.any():\n', '             if self._mask is not nomask:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         """"""\n', ""         kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}\n"", '         if self._mask is nomask:\n', '             result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n', '         else:\n', '+            is_float16_result = False\n', '+            if dtype is None:\n', '+                if issubclass(self.dtype.type, (ntypes.integer, ntypes.bool_)):\n', ""+                    dtype = mu.dtype('f8')\n"", '+                elif issubclass(self.dtype.type, ntypes.float16):\n', ""+                    dtype = mu.dtype('f4')\n"", '+                    is_float16_result = True\n', '             dsum = self.sum(axis=axis, dtype=dtype, **kwargs)\n', '             cnt = self.count(axis=axis, **kwargs)\n', '             if cnt.shape == () and (cnt == 0):\n', '                 result = masked\n', '+            elif is_float16_result:\n', '+                result = self.dtype.type(dsum * 1. / cnt)\n', '             else:\n', '                 result = dsum * 1. / cnt\n', '         if out is not None:\n']","[' \n', '         """"""\n', ""         kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}\n"", '-\n', '         if self._mask is nomask:\n', '             result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n', '         else:\n', '             dsum = self.sum(axis=axis, dtype=dtype, **kwargs)\n', '             cnt = self.count(axis=axis, **kwargs)\n', '             if cnt.shape == () and (cnt == 0):\n', '                 result = masked\n', '             else:\n', '                 result = dsum * 1. / cnt\n', '         if out is not None:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         ma.minimum_fill_value\n', '             Returns the minimum filling value for a given datatype.\n', ' \n', '+        Examples\n', '+        --------\n', '+        >>> import numpy.ma as ma\n', '+        >>> x = [[1., -2., 3.], [0.2, -0.7, 0.1]]\n', '+        >>> mask = [[1, 1, 0], [0, 0, 1]]\n', '+        >>> masked_x = ma.masked_array(x, mask)\n', '+        >>> masked_x\n', '+        masked_array(\n', '+          data=[[--, --, 3.0],\n', '+                [0.2, -0.7, --]],\n', '+          mask=[[ True,  True, False],\n', '+                [False, False,  True]],\n', '+          fill_value=1e+20)\n', '+        >>> ma.min(masked_x)\n', '+        -0.7\n', '+        >>> ma.min(masked_x, axis=-1)\n', '+        masked_array(data=[3.0, -0.7],\n', '+                     mask=[False, False],\n', '+                fill_value=1e+20)\n', '+        >>> ma.min(masked_x, axis=0, keepdims=True)\n', '+        masked_array(data=[[0.2, -0.7, 3.0]],\n', '+                     mask=[[False, False, False]],\n', '+                fill_value=1e+20)\n', '+        >>> mask = [[1, 1, 1,], [1, 1, 1]]\n', '+        >>> masked_x = ma.masked_array(x, mask)\n', '+        >>> ma.min(masked_x, axis=0)\n', '+        masked_array(data=[--, --, --],\n', '+                     mask=[ True,  True,  True],\n', '+                fill_value=1e+20,\n', '+                    dtype=float64)\n', '         """"""\n', ""         kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}\n"", ' \n']","['         ma.minimum_fill_value\n', '             Returns the minimum filling value for a given datatype.\n', ' \n', '         """"""\n', ""         kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             np.copyto(out, np.nan, where=newmask)\n', '         return out\n', ' \n', '     def max(self, axis=None, out=None, fill_value=None, keepdims=np._NoValue):\n', '         """"""\n', '         Return the maximum along a given axis.\n']","['             np.copyto(out, np.nan, where=newmask)\n', '         return out\n', ' \n', '-    # unique to masked arrays\n', '-    def mini(self, axis=None):\n', '-        """"""\n', '-        Return the array minimum along the specified axis.\n', '-\n', '-        .. deprecated:: 1.13.0\n', '-           This function is identical to both:\n', '-\n', '-            * ``self.min(keepdims=True, axis=axis).squeeze(axis=axis)``\n', '-            * ``np.ma.minimum.reduce(self, axis=axis)``\n', '-\n', '-           Typically though, ``self.min(axis=axis)`` is sufficient.\n', '-\n', '-        Parameters\n', '-        ----------\n', '-        axis : int, optional\n', '-            The axis along which to find the minima. Default is None, in which case\n', '-            the minimum value in the whole array is returned.\n', '-\n', '-        Returns\n', '-        -------\n', '-        min : scalar or MaskedArray\n', '-            If `axis` is None, the result is a scalar. Otherwise, if `axis` is\n', '-            given and the array is at least 2-D, the result is a masked array with\n', '-            dimension one smaller than the array on which `mini` is called.\n', '-\n', '-        Examples\n', '-        --------\n', '-        >>> x = np.ma.array(np.arange(6), mask=[0 ,1, 0, 0, 0 ,1]).reshape(3, 2)\n', '-        >>> x\n', '-        masked_array(\n', '-          data=[[0, --],\n', '-                [2, 3],\n', '-                [4, --]],\n', '-          mask=[[False,  True],\n', '-                [False, False],\n', '-                [False,  True]],\n', '-          fill_value=999999)\n', '-        >>> x.mini()\n', '-        masked_array(data=0,\n', '-                     mask=False,\n', '-               fill_value=999999)\n', '-        >>> x.mini(axis=0)\n', '-        masked_array(data=[0, 3],\n', '-                     mask=[False, False],\n', '-               fill_value=999999)\n', '-        >>> x.mini(axis=1)\n', '-        masked_array(data=[0, 2, 4],\n', '-                     mask=[False, False, False],\n', '-               fill_value=999999)\n', '-\n', '-        There is a small difference between `mini` and `min`:\n', '-\n', '-        >>> x[:,1].mini(axis=0)\n', '-        masked_array(data=3,\n', '-                     mask=False,\n', '-               fill_value=999999)\n', '-        >>> x[:,1].min(axis=0)\n', '-        3\n', '-        """"""\n', '-\n', '-        # 2016-04-13, 1.13.0, gh-8764\n', '-        warnings.warn(\n', '-            ""`mini` is deprecated; use the `min` method or ""\n', '-            ""`np.ma.minimum.reduce instead."",\n', '-            DeprecationWarning, stacklevel=2)\n', '-        return minimum.reduce(self, axis)\n', '-\n', '     def max(self, axis=None, out=None, fill_value=None, keepdims=np._NoValue):\n', '         """"""\n', '         Return the maximum along a given axis.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         ma.maximum_fill_value\n', '             Returns the maximum filling value for a given datatype.\n', ' \n', '+        Examples\n', '+        --------\n', '+        >>> import numpy.ma as ma\n', '+        >>> x = [[-1., 2.5], [4., -2.], [3., 0.]]\n', '+        >>> mask = [[0, 0], [1, 0], [1, 0]]\n', '+        >>> masked_x = ma.masked_array(x, mask)\n', '+        >>> masked_x\n', '+        masked_array(\n', '+          data=[[-1.0, 2.5],\n', '+                [--, -2.0],\n', '+                [--, 0.0]],\n', '+          mask=[[False, False],\n', '+                [ True, False],\n', '+                [ True, False]],\n', '+          fill_value=1e+20)\n', '+        >>> ma.max(masked_x)\n', '+        2.5\n', '+        >>> ma.max(masked_x, axis=0)\n', '+        masked_array(data=[-1.0, 2.5],\n', '+                     mask=[False, False],\n', '+               fill_value=1e+20)\n', '+        >>> ma.max(masked_x, axis=1, keepdims=True)\n', '+        masked_array(\n', '+          data=[[2.5],\n', '+                [-2.0],\n', '+                [0.0]],\n', '+          mask=[[False],\n', '+                [False],\n', '+                [False]],\n', '+          fill_value=1e+20)\n', '+        >>> mask = [[1, 1], [1, 1], [1, 1]]\n', '+        >>> masked_x = ma.masked_array(x, mask)\n', '+        >>> ma.max(masked_x, axis=1)\n', '+        masked_array(data=[--, --, --],\n', '+                     mask=[ True,  True,  True],\n', '+               fill_value=1e+20,\n', '+                    dtype=float64)\n', '         """"""\n', ""         kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}\n"", ' \n']","['         ma.maximum_fill_value\n', '             Returns the maximum filling value for a given datatype.\n', ' \n', '         """"""\n', ""         kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.compare = compare\n', '         self.fill_value_func = fill_value\n', ' \n', '+    def __call__(self, a, b):\n', '         ""Executes the call behavior.""\n', '+\n', '         return where(self.compare(a, b), a, b)\n', ' \n', '     def reduce(self, target, axis=np._NoValue):\n']","['         self.compare = compare\n', '         self.fill_value_func = fill_value\n', ' \n', '-    def __call__(self, a, b=None):\n', '         ""Executes the call behavior.""\n', '-        if b is None:\n', '-            # 2016-04-13, 1.13.0\n', '-            warnings.warn(\n', '-                f""Single-argument form of np.ma.{self.__name__} is deprecated. Use ""\n', '-                f""np.ma.{self.__name__}.reduce instead."",\n', '-                DeprecationWarning, stacklevel=2)\n', '-            return self.reduce(a)\n', '         return where(self.compare(a, b), a, b)\n', ' \n', '     def reduce(self, target, axis=np._NoValue):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     The *out* argument to `numpy.power` is not supported, `third` has to be\n', '     None.\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> import numpy.ma as ma\n', '+    >>> x = [11.2, -3.973, 0.801, -1.41]\n', '+    >>> mask = [0, 0, 0, 1]\n', '+    >>> masked_x = ma.masked_array(x, mask)\n', '+    >>> masked_x\n', '+    masked_array(data=[11.2, -3.973, 0.801, --],\n', '+             mask=[False, False, False,  True],\n', '+       fill_value=1e+20)\n', '+    >>> ma.power(masked_x, 2)\n', '+    masked_array(data=[125.43999999999998, 15.784728999999999,\n', '+                   0.6416010000000001, --],\n', '+             mask=[False, False, False,  True],\n', '+       fill_value=1e+20)\n', '+    >>> y = [-0.5, 2, 0, 17]\n', '+    >>> masked_y = ma.masked_array(y, mask)\n', '+    >>> masked_y\n', '+    masked_array(data=[-0.5, 2.0, 0.0, --],\n', '+             mask=[False, False, False,  True],\n', '+       fill_value=1e+20)\n', '+    >>> ma.power(masked_x, masked_y)\n', '+    masked_array(data=[0.29880715233359845, 15.784728999999999, 1.0, --],\n', '+             mask=[False, False, False,  True],\n', '+       fill_value=1e+20)\n', '+\n', '     """"""\n', '     if third is not None:\n', '         raise MaskError(""3-argument power not supported."")\n']","['     The *out* argument to `numpy.power` is not supported, `third` has to be\n', '     None.\n', ' \n', '     """"""\n', '     if third is not None:\n', '         raise MaskError(""3-argument power not supported."")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     If out is given and does not have a mask attribute, the mask of a\n', '     is lost!\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> import numpy.ma as ma\n', '+    >>> x = [11.2, -3.973, 0.801, -1.41]\n', '+    >>> mask = [0, 0, 0, 1]\n', '+    >>> masked_x = ma.masked_array(x, mask)\n', '+    >>> masked_x\n', '+    masked_array(data=[11.2, -3.973, 0.801, --],\n', '+                 mask=[False, False, False, True],\n', '+        fill_value=1e+20)\n', '+    >>> ma.round_(masked_x)\n', '+    masked_array(data=[11.0, -4.0, 1.0, --],\n', '+                 mask=[False, False, False, True],\n', '+        fill_value=1e+20)\n', '+    >>> ma.round(masked_x, decimals=1)\n', '+    masked_array(data=[11.2, -4.0, 0.8, --],\n', '+                 mask=[False, False, False, True],\n', '+        fill_value=1e+20)\n', '+    >>> ma.round_(masked_x, decimals=-1)\n', '+    masked_array(data=[10.0, -0.0, 0.0, --],\n', '+                 mask=[False, False, False, True],\n', '+        fill_value=1e+20)\n', '     """"""\n', '     if out is None:\n', '         return np.round_(a, decimals, out)\n']","['     If out is given and does not have a mask attribute, the mask of a\n', '     is lost!\n', ' \n', '     """"""\n', '     if out is None:\n', '         return np.round_(a, decimals, out)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' #                               Pickling                                     #\n', ' ##############################################################################\n', ' \n', ' \n', "" def fromfile(file, dtype=float, count=-1, sep=''):\n"", '     raise NotImplementedError(\n']","[' #                               Pickling                                     #\n', ' ##############################################################################\n', ' \n', '-def _pickle_warn(method):\n', '-    # NumPy 1.15.0, 2017-12-10\n', '-    warnings.warn(\n', '-        f""np.ma.{method} is deprecated, use pickle.{method} instead"",\n', '-        DeprecationWarning, stacklevel=3)\n', '-\n', ' \n', "" def fromfile(file, dtype=float, count=-1, sep=''):\n"", '     raise NotImplementedError(\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             wgt = wgt*(~a.mask)\n', '             wgt.mask |= a.mask\n', ' \n', '+        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n', '         avg = np.multiply(a, wgt,\n', '                           dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n', ' \n']","['             wgt = wgt*(~a.mask)\n', '             wgt.mask |= a.mask\n', ' \n', '-        scl = wgt.sum(axis=axis, dtype=result_dtype)\n', '         avg = np.multiply(a, wgt,\n', '                           dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     numpy.unique : Equivalent function for ndarrays.\n', ' \n', '+    Examples\n', '+    --------\n', '+    >>> import numpy.ma as ma\n', '+    >>> a = [1, 2, 1000, 2, 3]\n', '+    >>> mask = [0, 0, 1, 0, 0]\n', '+    >>> masked_a = ma.masked_array(a, mask)\n', '+    >>> masked_a\n', '+    masked_array(data=[1, 2, --, 2, 3],\n', '+                mask=[False, False,  True, False, False],\n', '+        fill_value=999999)\n', '+    >>> ma.unique(masked_a)\n', '+    masked_array(data=[1, 2, 3, --],\n', '+                mask=[False, False, False,  True],\n', '+        fill_value=999999)\n', '+    >>> ma.unique(masked_a, return_index=True)\n', '+    (masked_array(data=[1, 2, 3, --],\n', '+                mask=[False, False, False,  True],\n', '+        fill_value=999999), array([0, 1, 4, 2]))\n', '+    >>> ma.unique(masked_a, return_inverse=True)\n', '+    (masked_array(data=[1, 2, 3, --],\n', '+                mask=[False, False, False,  True],\n', '+        fill_value=999999), array([0, 1, 3, 1, 2]))\n', '+    >>> ma.unique(masked_a, return_index=True, return_inverse=True)\n', '+    (masked_array(data=[1, 2, 3, --],\n', '+                mask=[False, False, False,  True],\n', '+        fill_value=999999), array([0, 1, 4, 2]), array([0, 1, 3, 1, 2]))\n', '     """"""\n', '     output = np.unique(ar1,\n', '                        return_index=return_index,\n']","['     --------\n', '     numpy.unique : Equivalent function for ndarrays.\n', ' \n', '     """"""\n', '     output = np.unique(ar1,\n', '                        return_index=return_index,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     a = asarray(a)\n', '     nd = a.ndim\n', '     if nd > 2:\n', '+        raise NotImplementedError(""Currently limited to at most 2D array."")\n', '     if axis is None or nd == 1:\n', '         return flatnotmasked_contiguous(a)\n', '     #\n']","['     a = asarray(a)\n', '     nd = a.ndim\n', '     if nd > 2:\n', '-        raise NotImplementedError(""Currently limited to atmost 2D array."")\n', '     if axis is None or nd == 1:\n', '         return flatnotmasked_contiguous(a)\n', '     #\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy.core.fromnumeric as fromnumeric\n', ' import numpy.core.umath as umath\n', ' from numpy.testing import (\n', '+    assert_raises, assert_warns, suppress_warnings, IS_WASM\n', '     )\n', ' from numpy import ndarray\n', ' from numpy.compat import asbytes\n']","[' import numpy.core.fromnumeric as fromnumeric\n', ' import numpy.core.umath as umath\n', ' from numpy.testing import (\n', '-    assert_raises, assert_warns, suppress_warnings\n', '     )\n', ' from numpy import ndarray\n', ' from numpy.compat import asbytes\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestMaskedArray:\n', '     # Base test class for MaskedArrays.\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']","[' class TestMaskedArray:\n', '     # Base test class for MaskedArrays.\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             np.set_printoptions(**oldopts)\n', ' \n', '     def test_0d_unicode(self):\n', ""+        u = 'caf\\xe9'\n"", '         utype = type(u)\n', ' \n', '         arr_nomask = np.ma.array(u)\n', '         arr_masked = np.ma.array(u, mask=True)\n', ' \n', '         assert_equal(utype(arr_nomask), u)\n', ""+        assert_equal(utype(arr_masked), '--')\n"", ' \n', '     def test_pickling(self):\n', '         # Tests pickling\n']","['             np.set_printoptions(**oldopts)\n', ' \n', '     def test_0d_unicode(self):\n', ""-        u = u'caf\\xe9'\n"", '         utype = type(u)\n', ' \n', '         arr_nomask = np.ma.array(u)\n', '         arr_masked = np.ma.array(u, mask=True)\n', ' \n', '         assert_equal(utype(arr_nomask), u)\n', ""-        assert_equal(utype(arr_masked), u'--')\n"", ' \n', '     def test_pickling(self):\n', '         # Tests pickling\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestMaskedArrayArithmetic:\n', '     # Base test class for MaskedArrays.\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']","[' class TestMaskedArrayArithmetic:\n', '     # Base test class for MaskedArrays.\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_basic_arithmetic(self):\n']","['         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_basic_arithmetic(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(test.mask, [True, False])\n', '         assert_(test.fill_value == True)\n', ' \n', ""+    @pytest.mark.parametrize('dt1', num_dts, ids=num_ids)\n"", ""+    @pytest.mark.parametrize('dt2', num_dts, ids=num_ids)\n"", ""+    @pytest.mark.parametrize('fill', [None, 1])\n"", ""+    @pytest.mark.parametrize('op',\n"", '+            [operator.le, operator.lt, operator.ge, operator.gt])\n', '+    def test_comparisons_for_numeric(self, op, dt1, dt2, fill):\n', '+        # Test the equality of structured arrays\n', '+        a = array([0, 1], dtype=dt1, mask=[0, 1], fill_value=fill)\n', '+\n', '+        test = op(a, a)\n', '+        assert_equal(test.data, op(a._data, a._data))\n', '+        assert_equal(test.mask, [False, True])\n', '+        assert_(test.fill_value == True)\n', '+\n', '+        test = op(a, a[0])\n', '+        assert_equal(test.data, op(a._data, a._data[0]))\n', '+        assert_equal(test.mask, [False, True])\n', '+        assert_(test.fill_value == True)\n', '+\n', '+        b = array([0, 1], dtype=dt2, mask=[1, 0], fill_value=fill)\n', '+        test = op(a, b)\n', '+        assert_equal(test.data, op(a._data, b._data))\n', '+        assert_equal(test.mask, [True, True])\n', '+        assert_(test.fill_value == True)\n', '+\n', '+        test = op(a[0], b)\n', '+        assert_equal(test.data, op(a._data[0], b._data))\n', '+        assert_equal(test.mask, [True, False])\n', '+        assert_(test.fill_value == True)\n', '+\n', '+        test = op(b, a[0])\n', '+        assert_equal(test.data, op(b._data, a._data[0]))\n', '+        assert_equal(test.mask, [True, False])\n', '+        assert_(test.fill_value == True)\n', '+\n', ""+    @pytest.mark.parametrize('op',\n"", '+            [operator.le, operator.lt, operator.ge, operator.gt])\n', '+    @pytest.mark.parametrize(\'fill\', [None, ""N/A""])\n', '+    def test_comparisons_strings(self, op, fill):\n', '+        # See gh-21770, mask propagation is broken for strings (and some other\n', '+        # cases) so we explicitly test strings here.\n', '+        # In principle only == and != may need special handling...\n', '+        ma1 = masked_array([""a"", ""b"", ""cde""], mask=[0, 1, 0], fill_value=fill)\n', '+        ma2 = masked_array([""cde"", ""b"", ""a""], mask=[0, 1, 0], fill_value=fill)\n', '+        assert_equal(op(ma1, ma2)._data, op(ma1._data, ma2._data))\n', '+\n', '     def test_eq_with_None(self):\n', '         # Really, comparisons with None should not be done, but check them\n', '         # anyway. Note that pep8 will flag these tests.\n']","['         assert_equal(test.mask, [True, False])\n', '         assert_(test.fill_value == True)\n', ' \n', '     def test_eq_with_None(self):\n', '         # Really, comparisons with None should not be done, but check them\n', '         # anyway. Note that pep8 will flag these tests.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestUfuncs:\n', '     # Test class for the application of ufuncs on MaskedArrays.\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', '         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_testUfuncRegression(self):\n']","[' class TestUfuncs:\n', '     # Test class for the application of ufuncs on MaskedArrays.\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', '         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_testUfuncRegression(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestMaskedArrayInPlaceArithmetic:\n', '     # Test MaskedArray Arithmetic\n', ' \n', '+    def setup_method(self):\n', '         x = arange(10)\n', '         y = arange(10)\n', '         xm = arange(10)\n']","[' class TestMaskedArrayInPlaceArithmetic:\n', '     # Test MaskedArray Arithmetic\n', ' \n', '-    def setup(self):\n', '         x = arange(10)\n', '         y = arange(10)\n', '         xm = arange(10)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_inplace_addition_scalar_type(self):\n', '         # Test of inplace additions\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 xm[2] = masked\n', '                 x += t(1)\n']","['     def test_inplace_addition_scalar_type(self):\n', '         # Test of inplace additions\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 xm[2] = masked\n', '                 x += t(1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 xm += t(1)\n', '                 assert_equal(xm, y + t(1))\n', ' \n', '     def test_inplace_addition_array_type(self):\n', '         # Test of inplace additions\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']","['                 xm += t(1)\n', '                 assert_equal(xm, y + t(1))\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', '     def test_inplace_addition_array_type(self):\n', '         # Test of inplace additions\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 assert_equal(xm, y + a)\n', '                 assert_equal(xm.mask, mask_or(m, a.mask))\n', ' \n', '     def test_inplace_subtraction_scalar_type(self):\n', '         # Test of inplace subtractions\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 x -= t(1)\n', '                 assert_equal(x, y - t(1))\n', '                 xm -= t(1)\n', '                 assert_equal(xm, y - t(1))\n', ' \n', '     def test_inplace_subtraction_array_type(self):\n', '         # Test of inplace subtractions\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']","['                 assert_equal(xm, y + a)\n', '                 assert_equal(xm.mask, mask_or(m, a.mask))\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', '     def test_inplace_subtraction_scalar_type(self):\n', '         # Test of inplace subtractions\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 x -= t(1)\n', '                 assert_equal(x, y - t(1))\n', '                 xm -= t(1)\n', '                 assert_equal(xm, y - t(1))\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', '     def test_inplace_subtraction_array_type(self):\n', '         # Test of inplace subtractions\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 assert_equal(xm, y - a)\n', '                 assert_equal(xm.mask, mask_or(m, a.mask))\n', ' \n', '     def test_inplace_multiplication_scalar_type(self):\n', '         # Test of inplace multiplication\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 x *= t(2)\n', '                 assert_equal(x, y * t(2))\n', '                 xm *= t(2)\n', '                 assert_equal(xm, y * t(2))\n', ' \n', '     def test_inplace_multiplication_array_type(self):\n', '         # Test of inplace multiplication\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']","['                 assert_equal(xm, y - a)\n', '                 assert_equal(xm.mask, mask_or(m, a.mask))\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', '     def test_inplace_multiplication_scalar_type(self):\n', '         # Test of inplace multiplication\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 x *= t(2)\n', '                 assert_equal(x, y * t(2))\n', '                 xm *= t(2)\n', '                 assert_equal(xm, y * t(2))\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', '     def test_inplace_multiplication_array_type(self):\n', '         # Test of inplace multiplication\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 assert_equal(xm, y * a)\n', '                 assert_equal(xm.mask, mask_or(m, a.mask))\n', ' \n', '     def test_inplace_floor_division_scalar_type(self):\n', '         # Test of inplace division\n', '         # Check for TypeError in case of unsupported types\n', '         unsupported = {np.dtype(t).type for t in np.typecodes[""Complex""]}\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 x = arange(10, dtype=t) * t(2)\n', '                 xm = arange(10, dtype=t) * t(2)\n']","['                 assert_equal(xm, y * a)\n', '                 assert_equal(xm.mask, mask_or(m, a.mask))\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', '     def test_inplace_floor_division_scalar_type(self):\n', '         # Test of inplace division\n', '         # Check for TypeError in case of unsupported types\n', '         unsupported = {np.dtype(t).type for t in np.typecodes[""Complex""]}\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 x = arange(10, dtype=t) * t(2)\n', '                 xm = arange(10, dtype=t) * t(2)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     xm //= t(2)\n', '                     assert_equal(x, y)\n', '                     assert_equal(xm, y)\n', '                 except TypeError:\n', '                     msg = f""Supported type {t} throwing TypeError""\n', '                     assert t in unsupported, msg\n']","['                     xm //= t(2)\n', '                     assert_equal(x, y)\n', '                     assert_equal(xm, y)\n', '-\n', '-                    assert_equal(len(w), 0, ""Failed on type=%s."" % t)\n', '                 except TypeError:\n', '                     msg = f""Supported type {t} throwing TypeError""\n', '                     assert t in unsupported, msg\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # Check for TypeError in case of unsupported types\n', '         unsupported = {np.dtype(t).type for t in np.typecodes[""Complex""]}\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']","['         # Check for TypeError in case of unsupported types\n', '         unsupported = {np.dtype(t).type for t in np.typecodes[""Complex""]}\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 (x, y, xm) = (_.astype(t) for _ in self.uint8data)\n', '                 m = xm.mask\n', '                 a = arange(10, dtype=t)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                         xm.mask,\n', '                         mask_or(mask_or(m, a.mask), (a == t(0)))\n', '                     )\n', '                 except TypeError:\n', '                     msg = f""Supported type {t} throwing TypeError""\n', '                     assert t in unsupported, msg\n']","['                         xm.mask,\n', '                         mask_or(mask_or(m, a.mask), (a == t(0)))\n', '                     )\n', '-\n', ""-                    assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '                 except TypeError:\n', '                     msg = f""Supported type {t} throwing TypeError""\n', '                     assert t in unsupported, msg\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_inplace_pow_type(self):\n', '         # Test keeping data w/ (inplace) power\n', '         for t in self.othertypes:\n', '+            with warnings.catch_warnings():\n', '+                warnings.filterwarnings(""error"")\n', '                 # Test pow on scalar\n', '                 x = array([1, 2, 3], mask=[0, 0, 1], dtype=t)\n', '                 xx = x ** t(2)\n']","['     def test_inplace_pow_type(self):\n', '         # Test keeping data w/ (inplace) power\n', '         for t in self.othertypes:\n', '-            with warnings.catch_warnings(record=True) as w:\n', '-                warnings.filterwarnings(""always"")\n', '                 # Test pow on scalar\n', '                 x = array([1, 2, 3], mask=[0, 0, 1], dtype=t)\n', '                 xx = x ** t(2)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 assert_equal(x.data, xx_r.data)\n', '                 assert_equal(x.mask, xx_r.mask)\n', ' \n', ' \n', ' class TestMaskedArrayMethods:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']","['                 assert_equal(x.data, xx_r.data)\n', '                 assert_equal(x.mask, xx_r.mask)\n', ' \n', ""-                assert_equal(len(w), 0, f'Failed on type={t}.')\n"", '-\n', ' \n', ' class TestMaskedArrayMethods:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestMaskedArrayMathMethods:\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']","[' \n', ' class TestMaskedArrayMathMethods:\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(a.max(-1), [3, 6])\n', '         assert_equal(a.max(1), [3, 6])\n', ' \n', '+    def test_mean_overflow(self):\n', '+        # Test overflow in masked arrays\n', '+        # gh-20272\n', '+        a = masked_array(np.full((10000, 10000), 65535, dtype=np.uint16),\n', '+                         mask=np.zeros((10000, 10000)))\n', '+        assert_equal(a.mean(), 65535.0)\n', ' \n', ' class TestMaskedArrayMathMethodsComplex:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([8.375j, 7.545j, 8.828j, 8.5j, 1.757j, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']","['         assert_equal(a.max(-1), [3, 6])\n', '         assert_equal(a.max(1), [3, 6])\n', ' \n', ' \n', ' class TestMaskedArrayMathMethodsComplex:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([8.375j, 7.545j, 8.828j, 8.5j, 1.757j, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestMaskedArrayFunctions:\n', '     # Test class for miscellaneous functions.\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         m1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n']","[' class TestMaskedArrayFunctions:\n', '     # Test class for miscellaneous functions.\n', ' \n', '-    def setup(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         m1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # test that masked_where on a structured array sets a structured\n', '         # mask (see issue #2972)\n', '         a = np.zeros(10, dtype=[(""A"", ""<f2""), (""B"", ""<f4"")])\n', '+        with np.errstate(over=""ignore""):\n', '+            # NOTE: The float16 ""uses"" 1e20 as mask, which overflows to inf\n', '+            #       and warns.  Unrelated to this test, but probably undesired.\n', '+            #       But NumPy previously did not warn for this overflow.\n', '+            am = np.ma.masked_where(a[""A""] < 5, a)\n', '         assert_equal(am.mask.dtype.names, am.dtype.names)\n', '         assert_equal(am[""A""],\n', '                     np.ma.masked_array(np.zeros(10), np.ones(10)))\n']","['         # test that masked_where on a structured array sets a structured\n', '         # mask (see issue #2972)\n', '         a = np.zeros(10, dtype=[(""A"", ""<f2""), (""B"", ""<f4"")])\n', '-        am = np.ma.masked_where(a[""A""] < 5, a)\n', '         assert_equal(am.mask.dtype.names, am.dtype.names)\n', '         assert_equal(am[""A""],\n', '                     np.ma.masked_array(np.zeros(10), np.ones(10)))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(test, ctrl)\n', '         assert_equal(test.mask, ctrl.mask)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     def test_where(self):\n', '         # Test the where function\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n']","['         assert_equal(test, ctrl)\n', '         assert_equal(test.mask, ctrl.mask)\n', ' \n', '     def test_where(self):\n', '         # Test the where function\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         tmp[(xm <= 2).filled(True)] = True\n', '         assert_equal(d._mask, tmp)\n', ' \n', '+        with np.errstate(invalid=""warn""):\n', '+            # The fill value is 1e20, it cannot be converted to `int`:\n', '+            with pytest.warns(RuntimeWarning, match=""invalid value""):\n', '+                ixm = xm.astype(int)\n', '         d = where(ixm > 2, ixm, masked)\n', '         assert_equal(d, [-9, -9, -9, -9, -9, 4, -9, -9, 10, -9, -9, 3])\n', '         assert_equal(d.dtype, ixm.dtype)\n']","['         tmp[(xm <= 2).filled(True)] = True\n', '         assert_equal(d._mask, tmp)\n', ' \n', '-        ixm = xm.astype(int)\n', '         d = where(ixm > 2, ixm, masked)\n', '         assert_equal(d, [-9, -9, -9, -9, -9, 4, -9, -9, 10, -9, -9, 3])\n', '         assert_equal(d.dtype, ixm.dtype)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_equal(ma, expected)\n', '         assert_equal(ma.mask, expected.mask)\n', ' \n', '+    def test_masked_invalid_error(self):\n', '+        a = np.arange(5, dtype=object)\n', '+        a[3] = np.PINF\n', '+        a[2] = np.NaN\n', '+        with pytest.raises(TypeError,\n', '+                           match=""not supported for the input types""):\n', '+            np.ma.masked_invalid(a)\n', '+\n', '     def test_choose(self):\n', '         # Test choose\n', '         choices = [[0, 1, 2, 3], [10, 11, 12, 13],\n']","['         assert_equal(ma, expected)\n', '         assert_equal(ma.mask, expected.mask)\n', ' \n', '     def test_choose(self):\n', '         # Test choose\n', '         choices = [[0, 1, 2, 3], [10, 11, 12, 13],\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestMaskedFields:\n', ' \n', '+    def setup_method(self):\n', '         ilist = [1, 2, 3, 4, 5]\n', '         flist = [1.1, 2.2, 3.3, 4.4, 5.5]\n', ""         slist = ['one', 'two', 'three', 'four', 'five']\n""]","[' \n', ' class TestMaskedFields:\n', ' \n', '-    def setup(self):\n', '         ilist = [1, 2, 3, 4, 5]\n', '         flist = [1.1, 2.2, 3.3, 4.4, 5.5]\n', ""         slist = ['one', 'two', 'three', 'four', 'five']\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestMaskedView:\n', ' \n', '+    def setup_method(self):\n', '         iterator = list(zip(np.arange(10), np.random.rand(10)))\n', '         data = np.array(iterator)\n', ""         a = array(iterator, dtype=[('a', float), ('b', float)])\n""]","[' \n', ' class TestMaskedView:\n', ' \n', '-    def setup(self):\n', '         iterator = list(zip(np.arange(10), np.random.rand(10)))\n', '         data = np.array(iterator)\n', ""         a = array(iterator, dtype=[('a', float), ('b', float)])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_coercion_unicode(self):\n', ""         a_u = np.zeros((), 'U10')\n"", '         a_u[()] = np.ma.masked\n', ""+        assert_equal(a_u[()], '--')\n"", ' \n', '     @pytest.mark.xfail(reason=""See gh-9750"")\n', '     def test_coercion_bytes(self):\n']","['     def test_coercion_unicode(self):\n', ""         a_u = np.zeros((), 'U10')\n"", '         a_u[()] = np.ma.masked\n', ""-        assert_equal(a_u[()], u'--')\n"", ' \n', '     @pytest.mark.xfail(reason=""See gh-9750"")\n', '     def test_coercion_bytes(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     a = np.ma.array([1, 2, 3, 4], mask=[1, 0, 0, 0])\n', '     _ = np.ma.masked_where(a == 3, a, copy=False)\n', '     assert_array_equal(a.mask, [True, False, True, False])\n', '+    # check masked array with masked_invalid is updated in place\n', '+    a = np.ma.array([np.inf, 1, 2, 3, 4])\n', '+    _ = np.ma.masked_invalid(a, copy=False)\n', '+    assert_array_equal(a.mask, [True, False, False, False, False])\n', ' \n', ' def test_append_masked_array():\n', '     a = np.ma.masked_equal([1,2,3], value=2)\n']","['     a = np.ma.array([1, 2, 3, 4], mask=[1, 0, 0, 0])\n', '     _ = np.ma.masked_where(a == 3, a, copy=False)\n', '     assert_array_equal(a.mask, [True, False, True, False])\n', ' \n', ' def test_append_masked_array():\n', '     a = np.ma.masked_equal([1,2,3], value=2)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def test_astype_mask_ordering():\n', ""+    descr = np.dtype([('v', int, 3), ('x', [('y', float)])])\n"", '     x = array([\n', '         [([1, 2, 3], (1.0,)),  ([1, 2, 3], (2.0,))],\n', '         [([1, 2, 3], (3.0,)),  ([1, 2, 3], (4.0,))]], dtype=descr)\n']","[' \n', ' \n', ' def test_astype_mask_ordering():\n', ""-    descr = [('v', int, 3), ('x', [('y', float)])]\n"", '     x = array([\n', '         [([1, 2, 3], (1.0,)),  ([1, 2, 3], (2.0,))],\n', '         [([1, 2, 3], (3.0,)),  ([1, 2, 3], (4.0,))]], dtype=descr)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestMinimumMaximum:\n', ' \n', '     def test_axis_default(self):\n', '         # NumPy 1.13, 2017-05-06\n']","[' \n', ' \n', ' class TestMinimumMaximum:\n', '-    def test_minimum(self):\n', '-        assert_warns(DeprecationWarning, np.ma.minimum, np.ma.array([1, 2]))\n', '-\n', '-    def test_maximum(self):\n', '-        assert_warns(DeprecationWarning, np.ma.maximum, np.ma.array([1, 2]))\n', ' \n', '     def test_axis_default(self):\n', '         # NumPy 1.13, 2017-05-06\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a2dma = average(a2dm, axis=1)\n', '         assert_equal(a2dma, [1.5, 4.0])\n', ' \n', '+    def test_testAverage4(self):\n', '+        # Test that `keepdims` works with average\n', '+        x = np.array([2, 3, 4]).reshape(3, 1)\n', '+        b = np.ma.array(x, mask=[[False], [False], [True]])\n', '+        w = np.array([4, 5, 6]).reshape(3, 1)\n', '+        actual = average(b, weights=w, axis=1, keepdims=True)\n', '+        desired = masked_array([[2.], [3.], [4.]], [[False], [False], [True]])\n', '+        assert_equal(actual, desired)\n', '+\n', '     def test_onintegers_with_mask(self):\n', '         # Test average on integers with mask\n', '         a = average(array([1, 2]))\n']","['         a2dma = average(a2dm, axis=1)\n', '         assert_equal(a2dma, [1.5, 4.0])\n', ' \n', '     def test_onintegers_with_mask(self):\n', '         # Test average on integers with mask\n', '         a = average(array([1, 2]))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestCov:\n', ' \n', '+    def setup_method(self):\n', '         self.data = array(np.random.rand(12))\n', ' \n', '     def test_1d_without_missing(self):\n']","[' \n', ' class TestCov:\n', ' \n', '-    def setup(self):\n', '         self.data = array(np.random.rand(12))\n', ' \n', '     def test_1d_without_missing(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestCorrcoef:\n', ' \n', '+    def setup_method(self):\n', '         self.data = array(np.random.rand(12))\n', '         self.data2 = array(np.random.rand(12))\n', ' \n']","[' \n', ' class TestCorrcoef:\n', ' \n', '-    def setup(self):\n', '         self.data = array(np.random.rand(12))\n', '         self.data2 = array(np.random.rand(12))\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestView:\n', ' \n', '+    def setup_method(self):\n', '         (a, b) = (np.arange(10), np.random.rand(10))\n', ""         ndtype = [('a', float), ('b', float)]\n"", '         arr = np.array(list(zip(a, b)), dtype=ndtype)\n']","[' \n', ' class TestView:\n', ' \n', '-    def setup(self):\n', '         (a, b) = (np.arange(10), np.random.rand(10))\n', ""         ndtype = [('a', float), ('b', float)]\n"", '         arr = np.array(list(zip(a, b)), dtype=ndtype)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from functools import reduce\n', ' \n', '+import pytest\n', '+\n', ' import numpy as np\n', ' import numpy.core.umath as umath\n', ' import numpy.core.fromnumeric as fromnumeric\n']","[' from functools import reduce\n', ' \n', ' import numpy as np\n', ' import numpy.core.umath as umath\n', ' import numpy.core.fromnumeric as fromnumeric\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestMa:\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         a10 = 10.\n']","[' \n', ' class TestMa:\n', ' \n', '-    def setup(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         a10 = 10.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_(eq(filled(xm, 1.e20), xf))\n', '         assert_(eq(x, xm))\n', ' \n', '+    @pytest.mark.parametrize(""s"", [(4, 3), (6, 2)])\n', '+    def test_testBasic2d(self, s):\n', '         # Test of basic array creation and properties in 2 dimensions.\n', '+        (x, y, a10, m1, m2, xm, ym, z, zm, xf, s) = self.d\n', '+        x.shape = s\n', '+        y.shape = s\n', '+        xm.shape = s\n', '+        ym.shape = s\n', '+        xf.shape = s\n', '+\n', '+        assert_(not isMaskedArray(x))\n', '+        assert_(isMaskedArray(xm))\n', '+        assert_equal(shape(xm), s)\n', '+        assert_equal(xm.shape, s)\n', '+        assert_equal(xm.size, reduce(lambda x, y: x * y, s))\n', '+        assert_equal(count(xm), len(m1) - reduce(lambda x, y: x + y, m1))\n', '+        assert_(eq(xm, xf))\n', '+        assert_(eq(filled(xm, 1.e20), xf))\n', '+        assert_(eq(x, xm))\n', ' \n', '     def test_testArithmetic(self):\n', '         # Test of basic arithmetic.\n']","['         assert_(eq(filled(xm, 1.e20), xf))\n', '         assert_(eq(x, xm))\n', ' \n', '-    def test_testBasic2d(self):\n', '         # Test of basic array creation and properties in 2 dimensions.\n', '-        for s in [(4, 3), (6, 2)]:\n', '-            (x, y, a10, m1, m2, xm, ym, z, zm, xf, s) = self.d\n', '-            x.shape = s\n', '-            y.shape = s\n', '-            xm.shape = s\n', '-            ym.shape = s\n', '-            xf.shape = s\n', '-\n', '-            assert_(not isMaskedArray(x))\n', '-            assert_(isMaskedArray(xm))\n', '-            assert_equal(shape(xm), s)\n', '-            assert_equal(xm.shape, s)\n', '-            assert_equal(xm.size, reduce(lambda x, y:x * y, s))\n', '-            assert_equal(count(xm),\n', '-                             len(m1) - reduce(lambda x, y:x + y, m1))\n', '-            assert_(eq(xm, xf))\n', '-            assert_(eq(filled(xm, 1.e20), xf))\n', '-            assert_(eq(x, xm))\n', '-            self.setup()\n', ' \n', '     def test_testArithmetic(self):\n', '         # Test of basic arithmetic.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestUfuncs:\n', '+    def setup_method(self):\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', ' \n']","[' \n', ' \n', ' class TestUfuncs:\n', '-    def setup(self):\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestArrayMethods:\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n', '                       3.012, 6.022, 5.095, 3.116, 5.238, 3.957,\n']","[' \n', ' class TestArrayMethods:\n', ' \n', '-    def setup(self):\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n', '                       3.012, 6.022, 5.095, 3.116, 5.238, 3.957,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_masked_array_repr_unicode(self):\n', '         # Ticket #1256\n', '+        repr(np.ma.array(""Unicode""))\n', ' \n', '     def test_atleast_2d(self):\n', '         # Ticket #1559\n']","[' \n', '     def test_masked_array_repr_unicode(self):\n', '         # Ticket #1256\n', '-        repr(np.ma.array(u""Unicode""))\n', ' \n', '     def test_atleast_2d(self):\n', '         # Ticket #1559\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' """"""\n', ' import numpy as np\n', '+from numpy.lib.mixins import NDArrayOperatorsMixin\n', ' from numpy.testing import assert_, assert_raises\n', ' from numpy.ma.testutils import assert_equal\n', ' from numpy.ma.core import (\n']","[' \n', ' """"""\n', ' import numpy as np\n', ' from numpy.testing import assert_, assert_raises\n', ' from numpy.ma.testutils import assert_equal\n', ' from numpy.ma.core import (\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return obj\n', ' \n', ' \n', '+class WrappedArray(NDArrayOperatorsMixin):\n', '+    """"""\n', '+    Wrapping a MaskedArray rather than subclassing to test that\n', '+    ufunc deferrals are commutative.\n', '+    See: https://github.com/numpy/numpy/issues/15200)\n', '+    """"""\n', '+    __array_priority__ = 20\n', '+\n', '+    def __init__(self, array, **attrs):\n', '+        self._array = array\n', '+        self.attrs = attrs\n', '+\n', '+    def __repr__(self):\n', '+        return f""{self.__class__.__name__}(\\n{self._array}\\n{self.attrs}\\n)""\n', '+\n', '+    def __array__(self):\n', '+        return np.asarray(self._array)\n', '+\n', '+    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n', ""+        if method == '__call__':\n"", '+            inputs = [arg._array if isinstance(arg, self.__class__) else arg\n', '+                      for arg in inputs]\n', '+            return self.__class__(ufunc(*inputs, **kwargs), **self.attrs)\n', '+        else:\n', '+            return NotImplemented\n', '+\n', '+\n', ' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '+    def setup_method(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = msubarray(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']","['         return obj\n', ' \n', ' \n', ' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '-    def setup(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = msubarray(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Test that the mask is False and not shared when keep_mask=False\n', '     assert_(not new_array.mask)\n', '     assert_(not new_array.sharedmask)\n', '+\n', '+\n', '+class TestClassWrapping:\n', '+    # Test suite for classes that wrap MaskedArrays\n', '+\n', '+    def setup_method(self):\n', '+        m = np.ma.masked_array([1, 3, 5], mask=[False, True, False])\n', '+        wm = WrappedArray(m)\n', '+        self.data = (m, wm)\n', '+\n', '+    def test_masked_unary_operations(self):\n', '+        # Tests masked_unary_operation\n', '+        (m, wm) = self.data\n', ""+        with np.errstate(divide='ignore'):\n"", '+            assert_(isinstance(np.log(wm), WrappedArray))\n', '+\n', '+    def test_masked_binary_operations(self):\n', '+        # Tests masked_binary_operation\n', '+        (m, wm) = self.data\n', '+        # Result should be a WrappedArray\n', '+        assert_(isinstance(np.add(wm, wm), WrappedArray))\n', '+        assert_(isinstance(np.add(m, wm), WrappedArray))\n', '+        assert_(isinstance(np.add(wm, m), WrappedArray))\n', ""+        # add and '+' should call the same ufunc\n"", '+        assert_equal(np.add(m, wm), m + wm)\n', '+        assert_(isinstance(np.hypot(m, wm), WrappedArray))\n', '+        assert_(isinstance(np.hypot(wm, m), WrappedArray))\n', '+        # Test domained binary operations\n', '+        assert_(isinstance(np.divide(wm, m), WrappedArray))\n', '+        assert_(isinstance(np.divide(m, wm), WrappedArray))\n', '+        assert_equal(np.divide(wm, m) * m, np.divide(m, m) * wm)\n', '+        # Test broadcasting\n', '+        m2 = np.stack([m, m])\n', '+        assert_(isinstance(np.divide(wm, m2), WrappedArray))\n', '+        assert_(isinstance(np.divide(m2, wm), WrappedArray))\n', '+        assert_equal(np.divide(m2, wm), np.divide(wm, m2))\n']","['     # Test that the mask is False and not shared when keep_mask=False\n', '     assert_(not new_array.mask)\n', '     assert_(not new_array.sharedmask)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Notes\n', '     -----\n', '+    For random samples from the normal distribution with mean ``mu`` and\n', '+    standard deviation ``sigma``, use::\n', ' \n', '+        sigma * np.matlib.randn(...) + mu\n', ' \n', '     Examples\n', '     --------\n']","[' \n', '     Notes\n', '     -----\n', '-    For random samples from :math:`N(\\\\mu, \\\\sigma^2)`, use:\n', ' \n', '-    ``sigma * np.matlib.randn(...) + mu``\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     matrix([[ 0.99734545,  0.2829785 , -1.50629471],\n', '             [-0.57860025,  1.65143654, -2.42667924]])\n', ' \n', '+    Two-by-four matrix of samples from the normal distribution with\n', '+    mean 3 and standard deviation 2.5:\n', ' \n', '     >>> 2.5 * np.matlib.randn((2, 4)) + 3\n', '     matrix([[1.92771843, 6.16484065, 0.83314899, 1.30278462],\n']","['     matrix([[ 0.99734545,  0.2829785 , -1.50629471],\n', '             [-0.57860025,  1.65143654, -2.42667924]])\n', ' \n', '-    Two-by-four matrix of samples from :math:`N(3, 6.25)`:\n', ' \n', '     >>> 2.5 * np.matlib.randn((2, 4)) + 3\n', '     matrix([[1.92771843, 6.16484065, 0.83314899, 1.30278462],\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '+    def setup_method(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = MMatrix(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']","[' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '-    def setup(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = MMatrix(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     window : (2,) array_like, optional\n', '         Window, see domain for its use. The default value is the\n', '         derived class window.\n', '+    symbol : str, optional\n', '+        Symbol used to represent the independent variable in string \n', '+        representations of the polynomial expression, e.g. for printing.\n', ""+        The symbol must be a valid Python identifier. Default value is 'x'.\n"", '+\n', '+        .. versionadded:: 1.24\n', ' \n', '     Attributes\n', '     ----------\n']","['     window : (2,) array_like, optional\n', '         Window, see domain for its use. The default value is the\n', '         derived class window.\n', ' \n', '     Attributes\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         Domain that is mapped to window.\n', '     window : (2,) ndarray\n', '         Window that domain is mapped to.\n', '+    symbol : str\n', '+        Symbol representing the independent variable.\n', ' \n', '     Class Attributes\n', '     ----------------\n']","['         Domain that is mapped to window.\n', '     window : (2,) ndarray\n', '         Window that domain is mapped to.\n', ' \n', '     Class Attributes\n', '     ----------------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # printing on windows.\n', ""     _use_unicode = not os.name == 'nt'\n"", ' \n', '+    @property\n', '+    def symbol(self):\n', '+        return self._symbol\n', '+\n', '     @property\n', '     @abc.abstractmethod\n', '     def domain(self):\n']","['     # printing on windows.\n', ""     _use_unicode = not os.name == 'nt'\n"", ' \n', '     @property\n', '     @abc.abstractmethod\n', '     def domain(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 raise TypeError(""Domains differ"")\n', '             elif not np.all(self.window == other.window):\n', '                 raise TypeError(""Windows differ"")\n', '+            elif self.symbol != other.symbol:\n', '+                raise ValueError(""Polynomial symbols differ"")\n', '             return other.coef\n', '         return other\n', ' \n', ""+    def __init__(self, coef, domain=None, window=None, symbol='x'):\n"", '         [coef] = pu.as_series([coef], trim=False)\n', '         self.coef = coef\n', ' \n']","['                 raise TypeError(""Domains differ"")\n', '             elif not np.all(self.window == other.window):\n', '                 raise TypeError(""Windows differ"")\n', '             return other.coef\n', '         return other\n', ' \n', '-    def __init__(self, coef, domain=None, window=None):\n', '         [coef] = pu.as_series([coef], trim=False)\n', '         self.coef = coef\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 raise ValueError(""Window has wrong number of elements."")\n', '             self.window = window\n', ' \n', '+        # Validation for symbol\n', '+        try:\n', '+            if not symbol.isidentifier():\n', '+                raise ValueError(\n', '+                    ""Symbol string must be a valid Python identifier""\n', '+                )\n', '+        # If a user passes in something other than a string, the above\n', '+        # results in an AttributeError. Catch this and raise a more\n', '+        # informative exception\n', '+        except AttributeError:\n', '+            raise TypeError(""Symbol must be a non-empty string"")\n', '+\n', '+        self._symbol = symbol\n', '+\n', '     def __repr__(self):\n', '         coef = repr(self.coef)[6:-1]\n', '         domain = repr(self.domain)[6:-1]\n', '         window = repr(self.window)[6:-1]\n', '         name = self.__class__.__name__\n', '+        return (f""{name}({coef}, domain={domain}, window={window}, ""\n', '+                f""symbol=\'{self.symbol}\')"")\n', ' \n', '     def __format__(self, fmt_str):\n', ""         if fmt_str == '':\n""]","['                 raise ValueError(""Window has wrong number of elements."")\n', '             self.window = window\n', ' \n', '     def __repr__(self):\n', '         coef = repr(self.coef)[6:-1]\n', '         domain = repr(self.domain)[6:-1]\n', '         window = repr(self.window)[6:-1]\n', '         name = self.__class__.__name__\n', '-        return f""{name}({coef}, domain={domain}, window={window})""\n', ' \n', '     def __format__(self, fmt_str):\n', ""         if fmt_str == '':\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         linewidth = np.get_printoptions().get('linewidth', 75)\n"", '         if linewidth < 1:\n', '             linewidth = 1\n', '+        out = pu.format_float(self.coef[0])\n', '         for i, coef in enumerate(self.coef[1:]):\n', '             out += "" ""\n', '             power = str(i + 1)\n']","[""         linewidth = np.get_printoptions().get('linewidth', 75)\n"", '         if linewidth < 1:\n', '             linewidth = 1\n', '-        out = f""{self.coef[0]}""\n', '         for i, coef in enumerate(self.coef[1:]):\n', '             out += "" ""\n', '             power = str(i + 1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # complex). In this case, represent the coefficient as-is.\n', '             try:\n', '                 if coef >= 0:\n', '+                    next_term = f""+ "" + pu.format_float(coef, parens=True)\n', '                 else:\n', '+                    next_term = f""- "" + pu.format_float(-coef, parens=True)\n', '             except TypeError:\n', '                 next_term = f""+ {coef}""\n', '             # Polynomial term\n', '+            next_term += term_method(power, self.symbol)\n', '             # Length of the current line with next term added\n', ""             line_len = len(out.split('\\n')[-1]) + len(next_term)\n"", '             # If not the last term in the polynomial, it will be two\n']","['             # complex). In this case, represent the coefficient as-is.\n', '             try:\n', '                 if coef >= 0:\n', '-                    next_term = f""+ {coef}""\n', '                 else:\n', '-                    next_term = f""- {-coef}""\n', '             except TypeError:\n', '                 next_term = f""+ {coef}""\n', '             # Polynomial term\n', '-            next_term += term_method(power, ""x"")\n', '             # Length of the current line with next term added\n', ""             line_len = len(out.split('\\n')[-1]) + len(next_term)\n"", '             # If not the last term in the polynomial, it will be two\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         return f""{{{cls.basis_name}}}_{{{i}}}({arg_str})""\n', ' \n', '     @staticmethod\n', '+    def _repr_latex_scalar(x, parens=False):\n', ""         # TODO: we're stuck with disabling math formatting until we handle\n"", '         # exponents in this function\n', ""+        return r'\\text{{{}}}'.format(pu.format_float(x, parens=parens))\n"", ' \n', '     def _repr_latex_(self):\n', '         # get the scaled argument string to the basis functions\n', '         off, scale = self.mapparms()\n', '         if off == 0 and scale == 1:\n', '+            term = self.symbol\n', '             needs_parens = False\n', '         elif scale == 1:\n', '+            term = f""{self._repr_latex_scalar(off)} + {self.symbol}""\n', '             needs_parens = True\n', '         elif off == 0:\n', '+            term = f""{self._repr_latex_scalar(scale)}{self.symbol}""\n', '             needs_parens = True\n', '         else:\n', '             term = (\n', '                 f""{self._repr_latex_scalar(off)} + ""\n', '+                f""{self._repr_latex_scalar(scale)}{self.symbol}""\n', '             )\n', '             needs_parens = True\n', ' \n']","['         return f""{{{cls.basis_name}}}_{{{i}}}({arg_str})""\n', ' \n', '     @staticmethod\n', '-    def _repr_latex_scalar(x):\n', ""         # TODO: we're stuck with disabling math formatting until we handle\n"", '         # exponents in this function\n', ""-        return r'\\text{{{}}}'.format(x)\n"", ' \n', '     def _repr_latex_(self):\n', '         # get the scaled argument string to the basis functions\n', '         off, scale = self.mapparms()\n', '         if off == 0 and scale == 1:\n', ""-            term = 'x'\n"", '             needs_parens = False\n', '         elif scale == 1:\n', '-            term = f""{self._repr_latex_scalar(off)} + x""\n', '             needs_parens = True\n', '         elif off == 0:\n', '-            term = f""{self._repr_latex_scalar(scale)}x""\n', '             needs_parens = True\n', '         else:\n', '             term = (\n', '                 f""{self._repr_latex_scalar(off)} + ""\n', '-                f""{self._repr_latex_scalar(scale)}x""\n', '             )\n', '             needs_parens = True\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             elif not isinstance(c, numbers.Real):\n', '                 coef_str = f"" + ({self._repr_latex_scalar(c)})""\n', '             elif not np.signbit(c):\n', '+                coef_str = f"" + {self._repr_latex_scalar(c, parens=True)}""\n', '             else:\n', '+                coef_str = f"" - {self._repr_latex_scalar(-c, parens=True)}""\n', ' \n', '             # produce the string for the term\n', '             term_str = self._repr_latex_term(i, term, needs_parens)\n']","['             elif not isinstance(c, numbers.Real):\n', '                 coef_str = f"" + ({self._repr_latex_scalar(c)})""\n', '             elif not np.signbit(c):\n', '-                coef_str = f"" + {self._repr_latex_scalar(c)}""\n', '             else:\n', '-                coef_str = f"" - {self._repr_latex_scalar(-c)}""\n', ' \n', '             # produce the string for the term\n', '             term_str = self._repr_latex_term(i, term, needs_parens)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # in case somehow there are no coefficients at all\n', ""             body = '0'\n"", ' \n', '+        return rf""${self.symbol} \\mapsto {body}$""\n', ' \n', ' \n', ' \n']","['             # in case somehow there are no coefficients at all\n', ""             body = '0'\n"", ' \n', '-        return rf""$x \\mapsto {body}$""\n', ' \n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         ret['coef'] = self.coef.copy()\n"", ""         ret['domain'] = self.domain.copy()\n"", ""         ret['window'] = self.window.copy()\n"", ""+        ret['symbol'] = self.symbol.copy()\n"", '         return ret\n', ' \n', '     def __setstate__(self, dict):\n']","[""         ret['coef'] = self.coef.copy()\n"", ""         ret['domain'] = self.domain.copy()\n"", ""         ret['window'] = self.window.copy()\n"", '         return ret\n', ' \n', '     def __setstate__(self, dict):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Numeric properties.\n', ' \n', '     def __neg__(self):\n', '+        return self.__class__(\n', '+            -self.coef, self.domain, self.window, self.symbol\n', '+        )\n', ' \n', '     def __pos__(self):\n', '         return self\n']","['     # Numeric properties.\n', ' \n', '     def __neg__(self):\n', '-        return self.__class__(-self.coef, self.domain, self.window)\n', ' \n', '     def __pos__(self):\n', '         return self\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             coef = self._add(self.coef, othercoef)\n', '         except Exception:\n', '             return NotImplemented\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def __sub__(self, other):\n', '         othercoef = self._get_coefficients(other)\n']","['             coef = self._add(self.coef, othercoef)\n', '         except Exception:\n', '             return NotImplemented\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def __sub__(self, other):\n', '         othercoef = self._get_coefficients(other)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             coef = self._sub(self.coef, othercoef)\n', '         except Exception:\n', '             return NotImplemented\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def __mul__(self, other):\n', '         othercoef = self._get_coefficients(other)\n']","['             coef = self._sub(self.coef, othercoef)\n', '         except Exception:\n', '             return NotImplemented\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def __mul__(self, other):\n', '         othercoef = self._get_coefficients(other)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             coef = self._mul(self.coef, othercoef)\n', '         except Exception:\n', '             return NotImplemented\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def __truediv__(self, other):\n', '         # there is no true divide if the rhs is not a Number, although it\n']","['             coef = self._mul(self.coef, othercoef)\n', '         except Exception:\n', '             return NotImplemented\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def __truediv__(self, other):\n', '         # there is no true divide if the rhs is not a Number, although it\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             raise\n', '         except Exception:\n', '             return NotImplemented\n', '+        quo = self.__class__(quo, self.domain, self.window, self.symbol)\n', '+        rem = self.__class__(rem, self.domain, self.window, self.symbol)\n', '         return quo, rem\n', ' \n', '     def __pow__(self, other):\n', '         coef = self._pow(self.coef, other, maxpower=self.maxpower)\n', '+        res = self.__class__(coef, self.domain, self.window, self.symbol)\n', '         return res\n', ' \n', '     def __radd__(self, other):\n']","['             raise\n', '         except Exception:\n', '             return NotImplemented\n', '-        quo = self.__class__(quo, self.domain, self.window)\n', '-        rem = self.__class__(rem, self.domain, self.window)\n', '         return quo, rem\n', ' \n', '     def __pow__(self, other):\n', '         coef = self._pow(self.coef, other, maxpower=self.maxpower)\n', '-        res = self.__class__(coef, self.domain, self.window)\n', '         return res\n', ' \n', '     def __radd__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             coef = self._add(other, self.coef)\n', '         except Exception:\n', '             return NotImplemented\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def __rsub__(self, other):\n', '         try:\n', '             coef = self._sub(other, self.coef)\n', '         except Exception:\n', '             return NotImplemented\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def __rmul__(self, other):\n', '         try:\n', '             coef = self._mul(other, self.coef)\n', '         except Exception:\n', '             return NotImplemented\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def __rdiv__(self, other):\n', '         # set to __floordiv__ /.\n']","['             coef = self._add(other, self.coef)\n', '         except Exception:\n', '             return NotImplemented\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def __rsub__(self, other):\n', '         try:\n', '             coef = self._sub(other, self.coef)\n', '         except Exception:\n', '             return NotImplemented\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def __rmul__(self, other):\n', '         try:\n', '             coef = self._mul(other, self.coef)\n', '         except Exception:\n', '             return NotImplemented\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def __rdiv__(self, other):\n', '         # set to __floordiv__ /.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             raise\n', '         except Exception:\n', '             return NotImplemented\n', '+        quo = self.__class__(quo, self.domain, self.window, self.symbol)\n', '+        rem = self.__class__(rem, self.domain, self.window, self.symbol)\n', '         return quo, rem\n', ' \n', '     def __eq__(self, other):\n']","['             raise\n', '         except Exception:\n', '             return NotImplemented\n', '-        quo = self.__class__(quo, self.domain, self.window)\n', '-        rem = self.__class__(rem, self.domain, self.window)\n', '         return quo, rem\n', ' \n', '     def __eq__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                np.all(self.domain == other.domain) and\n', '                np.all(self.window == other.window) and\n', '                (self.coef.shape == other.coef.shape) and\n', '+               np.all(self.coef == other.coef) and\n', '+               (self.symbol == other.symbol))\n', '         return res\n', ' \n', '     def __ne__(self, other):\n']","['                np.all(self.domain == other.domain) and\n', '                np.all(self.window == other.window) and\n', '                (self.coef.shape == other.coef.shape) and\n', '-               np.all(self.coef == other.coef))\n', '         return res\n', ' \n', '     def __ne__(self, other):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             Copy of self.\n', ' \n', '         """"""\n', '+        return self.__class__(self.coef, self.domain, self.window, self.symbol)\n', ' \n', '     def degree(self):\n', '         """"""The degree of the series.\n']","['             Copy of self.\n', ' \n', '         """"""\n', '-        return self.__class__(self.coef, self.domain, self.window)\n', ' \n', '     def degree(self):\n', '         """"""The degree of the series.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         """"""\n', '         coef = pu.trimcoef(self.coef, tol)\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def truncate(self, size):\n', '         """"""Truncate series to length `size`.\n']","[' \n', '         """"""\n', '         coef = pu.trimcoef(self.coef, tol)\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def truncate(self, size):\n', '         """"""Truncate series to length `size`.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             coef = self.coef\n', '         else:\n', '             coef = self.coef[:isize]\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def convert(self, domain=None, kind=None, window=None):\n', '         """"""Convert series to a different kind and/or domain and/or window.\n']","['             coef = self.coef\n', '         else:\n', '             coef = self.coef[:isize]\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def convert(self, domain=None, kind=None, window=None):\n', '         """"""Convert series to a different kind and/or domain and/or window.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             domain = kind.domain\n', '         if window is None:\n', '             window = kind.window\n', '+        return self(kind.identity(domain, window=window, symbol=self.symbol))\n', ' \n', '     def mapparms(self):\n', '         """"""Return the mapping parameters.\n']","['             domain = kind.domain\n', '         if window is None:\n', '             window = kind.window\n', '-        return self(kind.identity(domain, window=window))\n', ' \n', '     def mapparms(self):\n', '         """"""Return the mapping parameters.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         else:\n', '             lbnd = off + scl*lbnd\n', '         coef = self._int(self.coef, m, k, lbnd, 1./scl)\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def deriv(self, m=1):\n', '         """"""Differentiate.\n']","['         else:\n', '             lbnd = off + scl*lbnd\n', '         coef = self._int(self.coef, m, k, lbnd, 1./scl)\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def deriv(self, m=1):\n', '         """"""Differentiate.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         """"""\n', '         off, scl = self.mapparms()\n', '         coef = self._der(self.coef, m, scl)\n', '+        return self.__class__(coef, self.domain, self.window, self.symbol)\n', ' \n', '     def roots(self):\n', '         """"""Return the roots of the series polynomial.\n']","['         """"""\n', '         off, scl = self.mapparms()\n', '         coef = self._der(self.coef, m, scl)\n', '-        return self.__class__(coef, self.domain, self.window)\n', ' \n', '     def roots(self):\n', '         """"""Return the roots of the series polynomial.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     @classmethod\n', '     def fit(cls, x, y, deg, domain=None, rcond=None, full=False, w=None,\n', ""+        window=None, symbol='x'):\n"", '         """"""Least squares fit to data.\n', ' \n', '         Return a series instance that is the least squares fit to the data\n']","[' \n', '     @classmethod\n', '     def fit(cls, x, y, deg, domain=None, rcond=None, full=False, w=None,\n', '-        window=None):\n', '         """"""Least squares fit to data.\n', ' \n', '         Return a series instance that is the least squares fit to the data\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             value is the default class domain\n', ' \n', '             .. versionadded:: 1.6.0\n', '+        symbol : str, optional\n', ""+            Symbol representing the independent variable. Default is 'x'.\n"", ' \n', '         Returns\n', '         -------\n']","['             value is the default class domain\n', ' \n', '             .. versionadded:: 1.6.0\n', ' \n', '         Returns\n', '         -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         res = cls._fit(xnew, y, deg, w=w, rcond=rcond, full=full)\n', '         if full:\n', '             [coef, status] = res\n', '+            return (\n', '+                cls(coef, domain=domain, window=window, symbol=symbol), status\n', '+            )\n', '         else:\n', '             coef = res\n', '+            return cls(coef, domain=domain, window=window, symbol=symbol)\n', ' \n', '     @classmethod\n', ""+    def fromroots(cls, roots, domain=[], window=None, symbol='x'):\n"", '         """"""Return series instance that has the specified roots.\n', ' \n', '         Returns a series representing the product\n']","['         res = cls._fit(xnew, y, deg, w=w, rcond=rcond, full=full)\n', '         if full:\n', '             [coef, status] = res\n', '-            return cls(coef, domain=domain, window=window), status\n', '         else:\n', '             coef = res\n', '-            return cls(coef, domain=domain, window=window)\n', ' \n', '     @classmethod\n', '-    def fromroots(cls, roots, domain=[], window=None):\n', '         """"""Return series instance that has the specified roots.\n', ' \n', '         Returns a series representing the product\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         window : {None, array_like}, optional\n', '             Window for the returned series. If None the class window is\n', '             used. The default is None.\n', '+        symbol : str, optional\n', ""+            Symbol representing the independent variable. Default is 'x'.\n"", ' \n', '         Returns\n', '         -------\n']","['         window : {None, array_like}, optional\n', '             Window for the returned series. If None the class window is\n', '             used. The default is None.\n', ' \n', '         Returns\n', '         -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         off, scl = pu.mapparms(domain, window)\n', '         rnew = off + scl*roots\n', '         coef = cls._fromroots(rnew) / scl**deg\n', '+        return cls(coef, domain=domain, window=window, symbol=symbol)\n', ' \n', '     @classmethod\n', ""+    def identity(cls, domain=None, window=None, symbol='x'):\n"", '         """"""Identity function.\n', ' \n', '         If ``p`` is the returned series, then ``p(x) == x`` for all\n']","['         off, scl = pu.mapparms(domain, window)\n', '         rnew = off + scl*roots\n', '         coef = cls._fromroots(rnew) / scl**deg\n', '-        return cls(coef, domain=domain, window=window)\n', ' \n', '     @classmethod\n', '-    def identity(cls, domain=None, window=None):\n', '         """"""Identity function.\n', ' \n', '         If ``p`` is the returned series, then ``p(x) == x`` for all\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             ``[beg, end]``, where ``beg`` and ``end`` are the endpoints of\n', '             the window. If None is given then the class window is used. The\n', '             default is None.\n', '+        symbol : str, optional\n', ""+            Symbol representing the independent variable. Default is 'x'.\n"", ' \n', '         Returns\n', '         -------\n']","['             ``[beg, end]``, where ``beg`` and ``end`` are the endpoints of\n', '             the window. If None is given then the class window is used. The\n', '             default is None.\n', ' \n', '         Returns\n', '         -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             window = cls.window\n', '         off, scl = pu.mapparms(window, domain)\n', '         coef = cls._line(off, scl)\n', '+        return cls(coef, domain, window, symbol)\n', ' \n', '     @classmethod\n', ""+    def basis(cls, deg, domain=None, window=None, symbol='x'):\n"", '         """"""Series basis polynomial of degree `deg`.\n', ' \n', '         Returns the series representing the basis polynomial of degree `deg`.\n']","['             window = cls.window\n', '         off, scl = pu.mapparms(window, domain)\n', '         coef = cls._line(off, scl)\n', '-        return cls(coef, domain, window)\n', ' \n', '     @classmethod\n', '-    def basis(cls, deg, domain=None, window=None):\n', '         """"""Series basis polynomial of degree `deg`.\n', ' \n', '         Returns the series representing the basis polynomial of degree `deg`.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             ``[beg, end]``, where ``beg`` and ``end`` are the endpoints of\n', '             the window. If None is given then the class window is used. The\n', '             default is None.\n', '+        symbol : str, optional\n', ""+            Symbol representing the independent variable. Default is 'x'.\n"", ' \n', '         Returns\n', '         -------\n']","['             ``[beg, end]``, where ``beg`` and ``end`` are the endpoints of\n', '             the window. If None is given then the class window is used. The\n', '             default is None.\n', ' \n', '         Returns\n', '         -------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '         if ideg != deg or ideg < 0:\n', '             raise ValueError(""deg must be non-negative integer"")\n', '+        return cls([0]*ideg + [1], domain, window, symbol)\n', ' \n', '     @classmethod\n', '     def cast(cls, series, domain=None, window=None):\n']","[' \n', '         if ideg != deg or ideg < 0:\n', '             raise ValueError(""deg must be non-negative integer"")\n', '-        return cls([0]*ideg + [1], domain, window)\n', ' \n', '     @classmethod\n', '     def cast(cls, series, domain=None, window=None):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Chebyshev points of the second kind.\n', ' \n', '     The Chebyshev points of the second kind are the points ``cos(x)``,\n', '+    where ``x = [pi*k/(npts - 1) for k in range(npts)]`` sorted in ascending\n', '+    order.\n', ' \n', '     Parameters\n', '     ----------\n']","['     Chebyshev points of the second kind.\n', ' \n', '     The Chebyshev points of the second kind are the points ``cos(x)``,\n', '-    where ``x = [pi*k/(npts - 1) for k in range(npts)]``.\n', ' \n', '     Parameters\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     .. math::  p(x) = c_0 + c_1 * L_1(x) + ... + c_n * L_n(x),\n', ' \n', '+    where ``n`` is `deg`.\n', ' \n', '     Parameters\n', '     ----------\n']","[' \n', '     .. math::  p(x) = c_0 + c_1 * L_1(x) + ... + c_n * L_n(x),\n', ' \n', '-    where `n` is `deg`.\n', ' \n', '     Parameters\n', '     ----------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -------\n', '     coef : ndarray, shape (M,) or (M, K)\n', '         Laguerre coefficients ordered from low to high. If `y` was 2-D,\n', '+        the coefficients for the data in column *k*  of `y` are in column\n', '+        *k*.\n', ' \n', '     [residuals, rank, singular_values, rcond] : list\n', '         These values are only returned if ``full == True``\n']","['     -------\n', '     coef : ndarray, shape (M,) or (M, K)\n', '         Laguerre coefficients ordered from low to high. If `y` was 2-D,\n', '-        the coefficients for the data in column k  of `y` are in column\n', '-        `k`.\n', ' \n', '     [residuals, rank, singular_values, rcond] : list\n', '         These values are only returned if ``full == True``\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     Notes\n', '     -----\n', '+    The solution is the coefficients of the Laguerre series ``p`` that\n', '     minimizes the sum of the weighted squared errors\n', ' \n', '     .. math:: E = \\\\sum_j w_j^2 * |y_j - p(x_j)|^2,\n']","[' \n', '     Notes\n', '     -----\n', '-    The solution is the coefficients of the Laguerre series `p` that\n', '     minimizes the sum of the weighted squared errors\n', ' \n', '     .. math:: E = \\\\sum_j w_j^2 * |y_j - p(x_j)|^2,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     .. math:: V(x) * c = w * y,\n', ' \n', '+    where ``V`` is the weighted pseudo Vandermonde matrix of `x`, ``c`` are the\n', '     coefficients to be solved for, `w` are the weights, and `y` are the\n', '     observed values.  This equation is then solved using the singular value\n', '+    decomposition of ``V``.\n', ' \n', '     If some of the singular values of `V` are so small that they are\n', '     neglected, then a `RankWarning` will be issued. This means that the\n']","[' \n', '     .. math:: V(x) * c = w * y,\n', ' \n', '-    where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the\n', '     coefficients to be solved for, `w` are the weights, and `y` are the\n', '     observed values.  This equation is then solved using the singular value\n', '-    decomposition of `V`.\n', ' \n', '     If some of the singular values of `V` are so small that they are\n', '     neglected, then a `RankWarning` will be issued. This means that the\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     spurious and have large contributions from roundoff error.\n', ' \n', '     Fits using Laguerre series are probably most useful when the data can\n', '+    be approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)`` is the Laguerre\n', '     weight. In that case the weight ``sqrt(w(x[i]))`` should be used\n', '     together with data values ``y[i]/sqrt(w(x[i]))``. The weight function is\n', '     available as `lagweight`.\n']","['     spurious and have large contributions from roundoff error.\n', ' \n', '     Fits using Laguerre series are probably most useful when the data can\n', '-    be approximated by ``sqrt(w(x)) * p(x)``, where `w(x)` is the Laguerre\n', '     weight. In that case the weight ``sqrt(w(x[i]))`` should be used\n', '     together with data values ``y[i]/sqrt(w(x[i]))``. The weight function is\n', '     available as `lagweight`.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> np.random.seed(123)\n', '     >>> from numpy.polynomial import polynomial as P\n', '     >>> x = np.linspace(-1,1,51) # x ""data"": [-1, -0.96, ..., 0.96, 1]\n', '+    >>> y = x**3 - x + np.random.randn(len(x))  # x^3 - x + Gaussian noise\n', '     >>> c, stats = P.polyfit(x,y,3,full=True)\n', '     >>> np.random.seed(123)\n', '     >>> c # c[0], c[2] should be approx. 0, c[1] approx. -1, c[3] approx. 1\n']","['     >>> np.random.seed(123)\n', '     >>> from numpy.polynomial import polynomial as P\n', '     >>> x = np.linspace(-1,1,51) # x ""data"": [-1, -0.96, ..., 0.96, 1]\n', '-    >>> y = x**3 - x + np.random.randn(len(x)) # x^3 - x + N(0,1) ""noise""\n', '     >>> c, stats = P.polyfit(x,y,3,full=True)\n', '     >>> np.random.seed(123)\n', '     >>> c # c[0], c[2] should be approx. 0, c[1] approx. -1, c[3] approx. 1\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     @classmethod\n', '     def _str_term_unicode(cls, i, arg_str):\n', ""+        if i == '1':\n"", '+            return f""·{arg_str}""\n', '+        else:\n', '+            return f""·{arg_str}{i.translate(cls._superscript_mapping)}""\n', ' \n', '     @staticmethod\n', '     def _str_term_ascii(i, arg_str):\n', ""+        if i == '1':\n"", '+            return f"" {arg_str}""\n', '+        else:\n', '+            return f"" {arg_str}**{i}""\n', ' \n', '     @staticmethod\n', '     def _repr_latex_term(i, arg_str, needs_parens):\n']","[' \n', '     @classmethod\n', '     def _str_term_unicode(cls, i, arg_str):\n', '-        return f""·{arg_str}{i.translate(cls._superscript_mapping)}""\n', ' \n', '     @staticmethod\n', '     def _str_term_ascii(i, arg_str):\n', '-        return f"" {arg_str}**{i}""\n', ' \n', '     @staticmethod\n', '     def _repr_latex_term(i, arg_str, needs_parens):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' import numpy as np\n', ' \n', '+from numpy.core.multiarray import dragon4_positional, dragon4_scientific\n', '+from numpy.core.umath import absolute\n', '+\n', ' __all__ = [\n', ""     'RankWarning', 'as_series', 'trimseq',\n"", ""+    'trimcoef', 'getdomain', 'mapdomain', 'mapparms',\n"", ""+    'format_float']\n"", ' \n', ' #\n', ' # Warnings and Exceptions\n']","[' \n', ' import numpy as np\n', ' \n', ' __all__ = [\n', ""     'RankWarning', 'as_series', 'trimseq',\n"", ""-    'trimcoef', 'getdomain', 'mapdomain', 'mapparms']\n"", ' \n', ' #\n', ' # Warnings and Exceptions\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 return ix\n', ' \n', '         raise TypeError(f""{desc} must be an integer"") from e\n', '+\n', '+\n', '+def format_float(x, parens=False):\n', '+    if not np.issubdtype(type(x), np.floating):\n', '+        return str(x)\n', '+\n', '+    opts = np.get_printoptions()\n', '+\n', '+    if np.isnan(x):\n', ""+        return opts['nanstr']\n"", '+    elif np.isinf(x):\n', ""+        return opts['infstr']\n"", '+\n', '+    exp_format = False\n', '+    if x != 0:\n', '+        a = absolute(x)\n', ""+        if a >= 1.e8 or a < 10**min(0, -(opts['precision']-1)//2):\n"", '+            exp_format = True\n', '+\n', ""+    trim, unique = '0', True\n"", ""+    if opts['floatmode'] == 'fixed':\n"", ""+        trim, unique = 'k', False\n"", '+\n', '+    if exp_format:\n', ""+        s = dragon4_scientific(x, precision=opts['precision'],\n"", '+                               unique=unique, trim=trim, \n', ""+                               sign=opts['sign'] == '+')\n"", '+        if parens:\n', ""+            s = '(' + s + ')'\n"", '+    else:\n', ""+        s = dragon4_positional(x, precision=opts['precision'],\n"", '+                               fractional=True,\n', '+                               unique=unique, trim=trim,\n', ""+                               sign=opts['sign'] == '+')\n"", '+    return s\n']","['                 return ix\n', ' \n', '         raise TypeError(f""{desc} must be an integer"") from e\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+from math import nan, inf\n', ' import pytest\n', ' from numpy.core import array, arange, printoptions\n', ' import numpy.polynomial as poly\n']","[' import pytest\n', ' from numpy.core import array, arange, printoptions\n', ' import numpy.polynomial as poly\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         poly.set_default_printstyle('unicode')\n"", ' \n', ""     @pytest.mark.parametrize(('inp', 'tgt'), (\n"", '+        ([1, 2, 3], ""1.0 + 2.0·x + 3.0·x²""),\n', '+        ([-1, 0, 3, -1], ""-1.0 + 0.0·x + 3.0·x² - 1.0·x³""),\n', '+        (arange(12), (""0.0 + 1.0·x + 2.0·x² + 3.0·x³ + 4.0·x⁴ + 5.0·x⁵ + ""\n', '                       ""6.0·x⁶ + 7.0·x⁷ +\\n8.0·x⁸ + 9.0·x⁹ + 10.0·x¹⁰ + ""\n', '                       ""11.0·x¹¹"")),\n', '     ))\n']","[""         poly.set_default_printstyle('unicode')\n"", ' \n', ""     @pytest.mark.parametrize(('inp', 'tgt'), (\n"", '-        ([1, 2, 3], ""1.0 + 2.0·x¹ + 3.0·x²""),\n', '-        ([-1, 0, 3, -1], ""-1.0 + 0.0·x¹ + 3.0·x² - 1.0·x³""),\n', '-        (arange(12), (""0.0 + 1.0·x¹ + 2.0·x² + 3.0·x³ + 4.0·x⁴ + 5.0·x⁵ + ""\n', '                       ""6.0·x⁶ + 7.0·x⁷ +\\n8.0·x⁸ + 9.0·x⁹ + 10.0·x¹⁰ + ""\n', '                       ""11.0·x¹¹"")),\n', '     ))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         poly.set_default_printstyle('ascii')\n"", ' \n', ""     @pytest.mark.parametrize(('inp', 'tgt'), (\n"", '+        ([1, 2, 3], ""1.0 + 2.0 x + 3.0 x**2""),\n', '+        ([-1, 0, 3, -1], ""-1.0 + 0.0 x + 3.0 x**2 - 1.0 x**3""),\n', '+        (arange(12), (""0.0 + 1.0 x + 2.0 x**2 + 3.0 x**3 + 4.0 x**4 + ""\n', '                       ""5.0 x**5 + 6.0 x**6 +\\n7.0 x**7 + 8.0 x**8 + ""\n', '                       ""9.0 x**9 + 10.0 x**10 + 11.0 x**11"")),\n', '     ))\n']","[""         poly.set_default_printstyle('ascii')\n"", ' \n', ""     @pytest.mark.parametrize(('inp', 'tgt'), (\n"", '-        ([1, 2, 3], ""1.0 + 2.0 x**1 + 3.0 x**2""),\n', '-        ([-1, 0, 3, -1], ""-1.0 + 0.0 x**1 + 3.0 x**2 - 1.0 x**3""),\n', '-        (arange(12), (""0.0 + 1.0 x**1 + 2.0 x**2 + 3.0 x**3 + 4.0 x**4 + ""\n', '                       ""5.0 x**5 + 6.0 x**6 +\\n7.0 x**7 + 8.0 x**8 + ""\n', '                       ""9.0 x**9 + 10.0 x**10 + 11.0 x**11"")),\n', '     ))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     def test_single_line_one_less(self):\n', ""         # With 'ascii' style, len(str(p)) is default linewidth - 1 (i.e. 74)\n"", '+        p = poly.Polynomial([12345678, 12345678, 12345678, 12345678, 123])\n', '         assert_equal(len(str(p)), 74)\n', '         assert_equal(str(p), (\n', ""+            '12345678.0 + 12345678.0 x + 12345678.0 x**2 + '\n"", ""+            '12345678.0 x**3 + 123.0 x**4'\n"", '         ))\n', ' \n', '     def test_num_chars_is_linewidth(self):\n', '         # len(str(p)) == default linewidth == 75\n', '+        p = poly.Polynomial([12345678, 12345678, 12345678, 12345678, 1234])\n', '         assert_equal(len(str(p)), 75)\n', '         assert_equal(str(p), (\n', ""+            '12345678.0 + 12345678.0 x + 12345678.0 x**2 + '\n"", ""+            '12345678.0 x**3 +\\n1234.0 x**4'\n"", '         ))\n', ' \n', '     def test_first_linebreak_multiline_one_less_than_linewidth(self):\n', '         # Multiline str where len(first_line) + len(next_term) == lw - 1 == 74\n', '         p = poly.Polynomial(\n', '+                [12345678, 12345678, 12345678, 12345678, 1, 12345678]\n', '             )\n', ""         assert_equal(len(str(p).split('\\n')[0]), 74)\n"", '         assert_equal(str(p), (\n', ""+            '12345678.0 + 12345678.0 x + 12345678.0 x**2 + '\n"", ""+            '12345678.0 x**3 + 1.0 x**4 +\\n12345678.0 x**5'\n"", '         ))\n', ' \n', '     def test_first_linebreak_multiline_on_linewidth(self):\n', '         # First line is one character longer than previous test\n', '         p = poly.Polynomial(\n', '+                [12345678, 12345678, 12345678, 12345678.12, 1, 12345678]\n', '             )\n', '         assert_equal(str(p), (\n', ""+            '12345678.0 + 12345678.0 x + 12345678.0 x**2 + '\n"", ""+            '12345678.12 x**3 +\\n1.0 x**4 + 12345678.0 x**5'\n"", '         ))\n', ' \n', ""     @pytest.mark.parametrize(('lw', 'tgt'), (\n"", ""+        (75, ('0.0 + 10.0 x + 200.0 x**2 + 3000.0 x**3 + 40000.0 x**4 + '\n"", ""+              '500000.0 x**5 +\\n600000.0 x**6 + 70000.0 x**7 + 8000.0 x**8 + '\n"", ""               '900.0 x**9')),\n"", ""+        (45, ('0.0 + 10.0 x + 200.0 x**2 + 3000.0 x**3 +\\n40000.0 x**4 + '\n"", ""               '500000.0 x**5 +\\n600000.0 x**6 + 70000.0 x**7 + 8000.0 x**8 +\\n'\n"", ""               '900.0 x**9')),\n"", ""+        (132, ('0.0 + 10.0 x + 200.0 x**2 + 3000.0 x**3 + 40000.0 x**4 + '\n"", ""                '500000.0 x**5 + 600000.0 x**6 + 70000.0 x**7 + 8000.0 x**8 + '\n"", ""                '900.0 x**9')),\n"", '     ))\n']","[' \n', '     def test_single_line_one_less(self):\n', ""         # With 'ascii' style, len(str(p)) is default linewidth - 1 (i.e. 74)\n"", '-        p = poly.Polynomial([123456789, 123456789, 123456789, 1234, 1])\n', '         assert_equal(len(str(p)), 74)\n', '         assert_equal(str(p), (\n', ""-            '123456789.0 + 123456789.0 x**1 + 123456789.0 x**2 + '\n"", ""-            '1234.0 x**3 + 1.0 x**4'\n"", '         ))\n', ' \n', '     def test_num_chars_is_linewidth(self):\n', '         # len(str(p)) == default linewidth == 75\n', '-        p = poly.Polynomial([123456789, 123456789, 123456789, 1234, 10])\n', '         assert_equal(len(str(p)), 75)\n', '         assert_equal(str(p), (\n', ""-            '123456789.0 + 123456789.0 x**1 + 123456789.0 x**2 + '\n"", ""-            '1234.0 x**3 +\\n10.0 x**4'\n"", '         ))\n', ' \n', '     def test_first_linebreak_multiline_one_less_than_linewidth(self):\n', '         # Multiline str where len(first_line) + len(next_term) == lw - 1 == 74\n', '         p = poly.Polynomial(\n', '-                [123456789, 123456789, 123456789, 12, 1, 123456789]\n', '             )\n', ""         assert_equal(len(str(p).split('\\n')[0]), 74)\n"", '         assert_equal(str(p), (\n', ""-            '123456789.0 + 123456789.0 x**1 + 123456789.0 x**2 + '\n"", ""-            '12.0 x**3 + 1.0 x**4 +\\n123456789.0 x**5'\n"", '         ))\n', ' \n', '     def test_first_linebreak_multiline_on_linewidth(self):\n', '         # First line is one character longer than previous test\n', '         p = poly.Polynomial(\n', '-                [123456789, 123456789, 123456789, 123, 1, 123456789]\n', '             )\n', '         assert_equal(str(p), (\n', ""-            '123456789.0 + 123456789.0 x**1 + 123456789.0 x**2 + '\n"", ""-            '123.0 x**3 +\\n1.0 x**4 + 123456789.0 x**5'\n"", '         ))\n', ' \n', ""     @pytest.mark.parametrize(('lw', 'tgt'), (\n"", ""-        (75, ('0.0 + 10.0 x**1 + 200.0 x**2 + 3000.0 x**3 + 40000.0 x**4 +\\n'\n"", ""-              '500000.0 x**5 + 600000.0 x**6 + 70000.0 x**7 + 8000.0 x**8 + '\n"", ""               '900.0 x**9')),\n"", ""-        (45, ('0.0 + 10.0 x**1 + 200.0 x**2 + 3000.0 x**3 +\\n40000.0 x**4 + '\n"", ""               '500000.0 x**5 +\\n600000.0 x**6 + 70000.0 x**7 + 8000.0 x**8 +\\n'\n"", ""               '900.0 x**9')),\n"", ""-        (132, ('0.0 + 10.0 x**1 + 200.0 x**2 + 3000.0 x**3 + 40000.0 x**4 + '\n"", ""                '500000.0 x**5 + 600000.0 x**6 + 70000.0 x**7 + 8000.0 x**8 + '\n"", ""                '900.0 x**9')),\n"", '     ))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     p = poly.Polynomial([1, 2, 3])\n', '     c = poly.Chebyshev([1, 2, 3])\n', ""     poly.set_default_printstyle('ascii')\n"", '+    assert_equal(str(p), ""1.0 + 2.0 x + 3.0 x**2"")\n', '     assert_equal(str(c), ""1.0 + 2.0 T_1(x) + 3.0 T_2(x)"")\n', ""     poly.set_default_printstyle('unicode')\n"", '+    assert_equal(str(p), ""1.0 + 2.0·x + 3.0·x²"")\n', '     assert_equal(str(c), ""1.0 + 2.0·T₁(x) + 3.0·T₂(x)"")\n', '     with pytest.raises(ValueError):\n', ""         poly.set_default_printstyle('invalid_input')\n""]","['     p = poly.Polynomial([1, 2, 3])\n', '     c = poly.Chebyshev([1, 2, 3])\n', ""     poly.set_default_printstyle('ascii')\n"", '-    assert_equal(str(p), ""1.0 + 2.0 x**1 + 3.0 x**2"")\n', '     assert_equal(str(c), ""1.0 + 2.0 T_1(x) + 3.0 T_2(x)"")\n', ""     poly.set_default_printstyle('unicode')\n"", '-    assert_equal(str(p), ""1.0 + 2.0·x¹ + 3.0·x²"")\n', '     assert_equal(str(c), ""1.0 + 2.0·T₁(x) + 3.0·T₂(x)"")\n', '     with pytest.raises(ValueError):\n', ""         poly.set_default_printstyle('invalid_input')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Python complex\n', '     p2 = poly.Polynomial(array(coefs, dtype=object))\n', ""     poly.set_default_printstyle('unicode')\n"", '+    assert_equal(str(p1), ""1j + (1+1j)·x - (2-2j)·x² + (3+0j)·x³"")\n', '+    assert_equal(str(p2), ""1j + (1+1j)·x + (-2+2j)·x² + (3+0j)·x³"")\n', ""     poly.set_default_printstyle('ascii')\n"", '+    assert_equal(str(p1), ""1j + (1+1j) x - (2-2j) x**2 + (3+0j) x**3"")\n', '+    assert_equal(str(p2), ""1j + (1+1j) x + (-2+2j) x**2 + (3+0j) x**3"")\n', ' \n', ' \n', "" @pytest.mark.parametrize(('coefs', 'tgt'), (\n"", '     (array([Fraction(1, 2), Fraction(3, 4)], dtype=object), (\n', '+        ""1/2 + 3/4·x""\n', '     )),\n', '     (array([1, 2, Fraction(5, 7)], dtype=object), (\n', '+        ""1 + 2·x + 5/7·x²""\n', '     )),\n', ""     (array([Decimal('1.00'), Decimal('2.2'), 3], dtype=object), (\n"", '+        ""1.00 + 2.2·x + 3·x²""\n', '     )),\n', ' ))\n', ' def test_numeric_object_coefficients(coefs, tgt):\n']","['     # Python complex\n', '     p2 = poly.Polynomial(array(coefs, dtype=object))\n', ""     poly.set_default_printstyle('unicode')\n"", '-    assert_equal(str(p1), ""1j + (1+1j)·x¹ - (2-2j)·x² + (3+0j)·x³"")\n', '-    assert_equal(str(p2), ""1j + (1+1j)·x¹ + (-2+2j)·x² + (3+0j)·x³"")\n', ""     poly.set_default_printstyle('ascii')\n"", '-    assert_equal(str(p1), ""1j + (1+1j) x**1 - (2-2j) x**2 + (3+0j) x**3"")\n', '-    assert_equal(str(p2), ""1j + (1+1j) x**1 + (-2+2j) x**2 + (3+0j) x**3"")\n', ' \n', ' \n', "" @pytest.mark.parametrize(('coefs', 'tgt'), (\n"", '     (array([Fraction(1, 2), Fraction(3, 4)], dtype=object), (\n', '-        ""1/2 + 3/4·x¹""\n', '     )),\n', '     (array([1, 2, Fraction(5, 7)], dtype=object), (\n', '-        ""1 + 2·x¹ + 5/7·x²""\n', '     )),\n', ""     (array([Decimal('1.00'), Decimal('2.2'), 3], dtype=object), (\n"", '-        ""1.00 + 2.2·x¹ + 3·x²""\n', '     )),\n', ' ))\n', ' def test_numeric_object_coefficients(coefs, tgt):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', "" @pytest.mark.parametrize(('coefs', 'tgt'), (\n"", ""+    (array([1, 2, 'f'], dtype=object), '1 + 2·x + f·x²'),\n"", ""+    (array([1, 2, [3, 4]], dtype=object), '1 + 2·x + [3, 4]·x²'),\n"", ' ))\n', ' def test_nonnumeric_object_coefficients(coefs, tgt):\n', '     """"""\n']","[' \n', ' \n', "" @pytest.mark.parametrize(('coefs', 'tgt'), (\n"", ""-    (array([1, 2, 'f'], dtype=object), '1 + 2·x¹ + f·x²'),\n"", ""-    (array([1, 2, [3, 4]], dtype=object), '1 + 2·x¹ + [3, 4]·x²'),\n"", ' ))\n', ' def test_nonnumeric_object_coefficients(coefs, tgt):\n', '     """"""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     def test_format_unicode(self):\n', ""         poly.set_default_printstyle('ascii')\n"", '         p = poly.Polynomial([1, 2, 0, -1])\n', '+        assert_equal(format(p, \'unicode\'), ""1.0 + 2.0·x + 0.0·x² - 1.0·x³"")\n', ' \n', '     def test_format_ascii(self):\n', ""         poly.set_default_printstyle('unicode')\n"", '         p = poly.Polynomial([1, 2, 0, -1])\n', '         assert_equal(\n', '+            format(p, \'ascii\'), ""1.0 + 2.0 x + 0.0 x**2 - 1.0 x**3""\n', '         )\n', ' \n', '     def test_empty_formatstr(self):\n', ""         poly.set_default_printstyle('ascii')\n"", '         p = poly.Polynomial([1, 2, 3])\n', '+        assert_equal(format(p), ""1.0 + 2.0 x + 3.0 x**2"")\n', '+        assert_equal(f""{p}"", ""1.0 + 2.0 x + 3.0 x**2"")\n', ' \n', '     def test_bad_formatstr(self):\n', '         p = poly.Polynomial([1, 2, 0, -1])\n']","['     def test_format_unicode(self):\n', ""         poly.set_default_printstyle('ascii')\n"", '         p = poly.Polynomial([1, 2, 0, -1])\n', '-        assert_equal(format(p, \'unicode\'), ""1.0 + 2.0·x¹ + 0.0·x² - 1.0·x³"")\n', ' \n', '     def test_format_ascii(self):\n', ""         poly.set_default_printstyle('unicode')\n"", '         p = poly.Polynomial([1, 2, 0, -1])\n', '         assert_equal(\n', '-            format(p, \'ascii\'), ""1.0 + 2.0 x**1 + 0.0 x**2 - 1.0 x**3""\n', '         )\n', ' \n', '     def test_empty_formatstr(self):\n', ""         poly.set_default_printstyle('ascii')\n"", '         p = poly.Polynomial([1, 2, 3])\n', '-        assert_equal(format(p), ""1.0 + 2.0 x**1 + 3.0 x**2"")\n', '-        assert_equal(f""{p}"", ""1.0 + 2.0 x**1 + 3.0 x**2"")\n', ' \n', '     def test_bad_formatstr(self):\n', '         p = poly.Polynomial([1, 2, 0, -1])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""             format(p, '.2f')\n"", ' \n', ' \n', ""+@pytest.mark.parametrize(('poly', 'tgt'), (\n"", ""+    (poly.Polynomial, '1.0 + 2.0·z + 3.0·z²'),\n"", ""+    (poly.Chebyshev, '1.0 + 2.0·T₁(z) + 3.0·T₂(z)'),\n"", ""+    (poly.Hermite, '1.0 + 2.0·H₁(z) + 3.0·H₂(z)'),\n"", ""+    (poly.HermiteE, '1.0 + 2.0·He₁(z) + 3.0·He₂(z)'),\n"", ""+    (poly.Laguerre, '1.0 + 2.0·L₁(z) + 3.0·L₂(z)'),\n"", ""+    (poly.Legendre, '1.0 + 2.0·P₁(z) + 3.0·P₂(z)'),\n"", '+))\n', '+def test_symbol(poly, tgt):\n', ""+    p = poly([1, 2, 3], symbol='z')\n"", '+    assert_equal(f""{p:unicode}"", tgt)\n', '+\n', '+\n', ' class TestRepr:\n', '     def test_polynomial_str(self):\n', '         res = repr(poly.Polynomial([0, 1]))\n', '+        tgt = (\n', '+            ""Polynomial([0., 1.], domain=[-1,  1], window=[-1,  1], ""\n', '+            ""symbol=\'x\')""\n', '+        )\n', '         assert_equal(res, tgt)\n', ' \n', '     def test_chebyshev_str(self):\n', '         res = repr(poly.Chebyshev([0, 1]))\n', '+        tgt = (\n', '+            ""Chebyshev([0., 1.], domain=[-1,  1], window=[-1,  1], ""\n', '+            ""symbol=\'x\')""\n', '+        )\n', '         assert_equal(res, tgt)\n', ' \n', '     def test_legendre_repr(self):\n', '         res = repr(poly.Legendre([0, 1]))\n', '+        tgt = (\n', '+            ""Legendre([0., 1.], domain=[-1,  1], window=[-1,  1], ""\n', '+            ""symbol=\'x\')""\n', '+        )\n', '         assert_equal(res, tgt)\n', ' \n', '     def test_hermite_repr(self):\n', '         res = repr(poly.Hermite([0, 1]))\n', '+        tgt = (\n', '+            ""Hermite([0., 1.], domain=[-1,  1], window=[-1,  1], ""\n', '+            ""symbol=\'x\')""\n', '+        )\n', '         assert_equal(res, tgt)\n', ' \n', '     def test_hermiteE_repr(self):\n', '         res = repr(poly.HermiteE([0, 1]))\n', '+        tgt = (\n', '+            ""HermiteE([0., 1.], domain=[-1,  1], window=[-1,  1], ""\n', '+            ""symbol=\'x\')""\n', '+        )\n', '         assert_equal(res, tgt)\n', ' \n', '     def test_laguerre_repr(self):\n', '         res = repr(poly.Laguerre([0, 1]))\n', '+        tgt = (\n', '+            ""Laguerre([0., 1.], domain=[0, 1], window=[0, 1], ""\n', '+            ""symbol=\'x\')""\n', '+        )\n', '         assert_equal(res, tgt)\n', ' \n', ' \n']","[""             format(p, '.2f')\n"", ' \n', ' \n', ' class TestRepr:\n', '     def test_polynomial_str(self):\n', '         res = repr(poly.Polynomial([0, 1]))\n', ""-        tgt = 'Polynomial([0., 1.], domain=[-1,  1], window=[-1,  1])'\n"", '         assert_equal(res, tgt)\n', ' \n', '     def test_chebyshev_str(self):\n', '         res = repr(poly.Chebyshev([0, 1]))\n', ""-        tgt = 'Chebyshev([0., 1.], domain=[-1,  1], window=[-1,  1])'\n"", '         assert_equal(res, tgt)\n', ' \n', '     def test_legendre_repr(self):\n', '         res = repr(poly.Legendre([0, 1]))\n', ""-        tgt = 'Legendre([0., 1.], domain=[-1,  1], window=[-1,  1])'\n"", '         assert_equal(res, tgt)\n', ' \n', '     def test_hermite_repr(self):\n', '         res = repr(poly.Hermite([0, 1]))\n', ""-        tgt = 'Hermite([0., 1.], domain=[-1,  1], window=[-1,  1])'\n"", '         assert_equal(res, tgt)\n', ' \n', '     def test_hermiteE_repr(self):\n', '         res = repr(poly.HermiteE([0, 1]))\n', ""-        tgt = 'HermiteE([0., 1.], domain=[-1,  1], window=[-1,  1])'\n"", '         assert_equal(res, tgt)\n', ' \n', '     def test_laguerre_repr(self):\n', '         res = repr(poly.Laguerre([0, 1]))\n', ""-        tgt = 'Laguerre([0., 1.], domain=[0, 1], window=[0, 1])'\n"", '         assert_equal(res, tgt)\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # right now we ignore the formatting of scalars in our tests, since\n', '         # it makes them too verbose. Ideally, the formatting of scalars will\n', '         # be fixed such that tests below continue to pass\n', '+        obj._repr_latex_scalar = lambda x, parens=False: str(x)\n', '         try:\n', '             return obj._repr_latex_()\n', '         finally:\n']","['         # right now we ignore the formatting of scalars in our tests, since\n', '         # it makes them too verbose. Ideally, the formatting of scalars will\n', '         # be fixed such that tests below continue to pass\n', '-        obj._repr_latex_scalar = lambda x: str(x)\n', '         try:\n', '             return obj._repr_latex_()\n', '         finally:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         p = poly.HermiteE([1, 2, 3])\n', '         assert_equal(self.as_latex(p),\n', ""             r'$x \\mapsto 1.0\\,{He}_{0}(x) + 2.0\\,{He}_{1}(x) + 3.0\\,{He}_{2}(x)$')\n"", '+\n', '+    def test_symbol_basic(self):\n', '+        # default input\n', ""+        p = poly.Polynomial([1, 2, 3], symbol='z')\n"", '+        assert_equal(self.as_latex(p),\n', ""+            r'$z \\mapsto 1.0 + 2.0\\,z + 3.0\\,z^{2}$')\n"", '+\n', '+        # translated input\n', ""+        p = poly.Polynomial([1, 2, 3], domain=[-2, 0], symbol='z')\n"", '+        assert_equal(\n', '+            self.as_latex(p),\n', '+            (\n', ""+                r'$z \\mapsto 1.0 + 2.0\\,\\left(1.0 + z\\right) + 3.0\\,'\n"", ""+                r'\\left(1.0 + z\\right)^{2}$'\n"", '+            ),\n', '+        )\n', '+\n', '+        # scaled input\n', ""+        p = poly.Polynomial([1, 2, 3], domain=[-0.5, 0.5], symbol='z')\n"", '+        assert_equal(\n', '+            self.as_latex(p),\n', '+            (\n', ""+                r'$z \\mapsto 1.0 + 2.0\\,\\left(2.0z\\right) + 3.0\\,'\n"", ""+                r'\\left(2.0z\\right)^{2}$'\n"", '+            ),\n', '+        )\n', '+\n', '+        # affine input\n', ""+        p = poly.Polynomial([1, 2, 3], domain=[-1, 0], symbol='z')\n"", '+        assert_equal(\n', '+            self.as_latex(p),\n', '+            (\n', ""+                r'$z \\mapsto 1.0 + 2.0\\,\\left(1.0 + 2.0z\\right) + 3.0\\,'\n"", ""+                r'\\left(1.0 + 2.0z\\right)^{2}$'\n"", '+            ),\n', '+        )\n', '+\n', '+\n', '+SWITCH_TO_EXP = (\n', ""+    '1.0 + (1.0e-01) x + (1.0e-02) x**2',\n"", ""+    '1.2 + (1.2e-01) x + (1.2e-02) x**2',\n"", ""+    '1.23 + 0.12 x + (1.23e-02) x**2 + (1.23e-03) x**3',\n"", ""+    '1.235 + 0.123 x + (1.235e-02) x**2 + (1.235e-03) x**3',\n"", ""+    '1.2346 + 0.1235 x + 0.0123 x**2 + (1.2346e-03) x**3 + (1.2346e-04) x**4',\n"", ""+    '1.23457 + 0.12346 x + 0.01235 x**2 + (1.23457e-03) x**3 + '\n"", ""+    '(1.23457e-04) x**4',\n"", ""+    '1.234568 + 0.123457 x + 0.012346 x**2 + 0.001235 x**3 + '\n"", ""+    '(1.234568e-04) x**4 + (1.234568e-05) x**5',\n"", ""+    '1.2345679 + 0.1234568 x + 0.0123457 x**2 + 0.0012346 x**3 + '\n"", ""+    '(1.2345679e-04) x**4 + (1.2345679e-05) x**5')\n"", '+\n', '+class TestPrintOptions:\n', '+    """"""\n', '+    Test the output is properly configured via printoptions.\n', '+    The exponential notation is enabled automatically when the values \n', '+    are too small or too large.\n', '+    """"""\n', '+\n', '+    def test_str(self):\n', '+        p = poly.Polynomial([1/2, 1/7, 1/7*10**8, 1/7*10**9])\n', ""+        assert_equal(str(p), '0.5 + 0.14285714 x + 14285714.28571429 x**2 '\n"", ""+                             '+ (1.42857143e+08) x**3')\n"", '+\n', '+        with printoptions(precision=3):\n', ""+            assert_equal(str(p), '0.5 + 0.143 x + 14285714.286 x**2 '\n"", ""+                                 '+ (1.429e+08) x**3')\n"", '+\n', '+    def test_latex(self):\n', '+        p = poly.Polynomial([1/2, 1/7, 1/7*10**8, 1/7*10**9])\n', '+        assert_equal(p._repr_latex_(),\n', ""+            r'$x \\mapsto \\text{0.5} + \\text{0.14285714}\\,x + '\n"", ""+            r'\\text{14285714.28571429}\\,x^{2} + '\n"", ""+            r'\\text{(1.42857143e+08)}\\,x^{3}$')\n"", '+        \n', '+        with printoptions(precision=3):\n', '+            assert_equal(p._repr_latex_(),\n', ""+                r'$x \\mapsto \\text{0.5} + \\text{0.143}\\,x + '\n"", ""+                r'\\text{14285714.286}\\,x^{2} + \\text{(1.429e+08)}\\,x^{3}$')\n"", '+\n', '+    def test_fixed(self):\n', '+        p = poly.Polynomial([1/2])\n', ""+        assert_equal(str(p), '0.5')\n"", '+        \n', ""+        with printoptions(floatmode='fixed'):\n"", ""+            assert_equal(str(p), '0.50000000')\n"", '+        \n', ""+        with printoptions(floatmode='fixed', precision=4):\n"", ""+            assert_equal(str(p), '0.5000')\n"", '+\n', '+    def test_switch_to_exp(self):\n', '+        for i, s in enumerate(SWITCH_TO_EXP):\n', '+            with printoptions(precision=i):\n', '+                p = poly.Polynomial([1.23456789*10**-i \n', '+                                     for i in range(i//2+3)])\n', ""+                assert str(p).replace('\\n', ' ') == s \n"", '+    \n', '+    def test_non_finite(self):\n', '+        p = poly.Polynomial([nan, inf])\n', ""+        assert str(p) == 'nan + inf x'\n"", ""+        assert p._repr_latex_() == r'$x \\mapsto \\text{nan} + \\text{inf}\\,x$'\n"", ""+        with printoptions(nanstr='NAN', infstr='INF'):\n"", ""+            assert str(p) == 'NAN + INF x'\n"", '+            assert p._repr_latex_() == \\\n', ""+                r'$x \\mapsto \\text{NAN} + \\text{INF}\\,x$'\n""]","['         p = poly.HermiteE([1, 2, 3])\n', '         assert_equal(self.as_latex(p),\n', ""             r'$x \\mapsto 1.0\\,{He}_{0}(x) + 2.0\\,{He}_{1}(x) + 3.0\\,{He}_{2}(x)$')\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+""""""\n', '+Tests related to the ``symbol`` attribute of the ABCPolyBase class.\n', '+""""""\n', '+\n', '+import pytest\n', '+import numpy.polynomial as poly\n', '+from numpy.core import array\n', '+from numpy.testing import assert_equal, assert_raises, assert_\n', '+\n', '+\n', '+class TestInit:\n', '+    """"""\n', '+    Test polynomial creation with symbol kwarg.\n', '+    """"""\n', '+    c = [1, 2, 3]\n', '+\n', '+    def test_default_symbol(self):\n', '+        p = poly.Polynomial(self.c)\n', ""+        assert_equal(p.symbol, 'x')\n"", '+\n', ""+    @pytest.mark.parametrize(('bad_input', 'exception'), (\n"", ""+        ('', ValueError),\n"", ""+        ('3', ValueError),\n"", '+        (None, TypeError),\n', '+        (1, TypeError),\n', '+    ))\n', '+    def test_symbol_bad_input(self, bad_input, exception):\n', '+        with pytest.raises(exception):\n', '+            p = poly.Polynomial(self.c, symbol=bad_input)\n', '+\n', ""+    @pytest.mark.parametrize('symbol', (\n"", ""+        'x',\n"", ""+        'x_1',\n"", ""+        'A',\n"", ""+        'xyz',\n"", ""+        'β',\n"", '+    ))\n', '+    def test_valid_symbols(self, symbol):\n', '+        """"""\n', '+        Values for symbol that should pass input validation.\n', '+        """"""\n', '+        p = poly.Polynomial(self.c, symbol=symbol)\n', '+        assert_equal(p.symbol, symbol)\n', '+\n', '+    def test_property(self):\n', '+        """"""\n', ""+        'symbol' attribute is read only.\n"", '+        """"""\n', ""+        p = poly.Polynomial(self.c, symbol='x')\n"", '+        with pytest.raises(AttributeError):\n', ""+            p.symbol = 'z'\n"", '+\n', '+    def test_change_symbol(self):\n', ""+        p = poly.Polynomial(self.c, symbol='y')\n"", '+        # Create new polynomial from p with different symbol\n', ""+        pt = poly.Polynomial(p.coef, symbol='t')\n"", ""+        assert_equal(pt.symbol, 't')\n"", '+\n', '+\n', '+class TestUnaryOperators:\n', ""+    p = poly.Polynomial([1, 2, 3], symbol='z')\n"", '+\n', '+    def test_neg(self):\n', '+        n = -self.p\n', ""+        assert_equal(n.symbol, 'z')\n"", '+\n', '+    def test_scalarmul(self):\n', '+        out = self.p * 10\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_rscalarmul(self):\n', '+        out = 10 * self.p\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_pow(self):\n', '+        out = self.p ** 3\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+\n', '+@pytest.mark.parametrize(\n', ""+    'rhs',\n"", '+    (\n', ""+        poly.Polynomial([4, 5, 6], symbol='z'),\n"", '+        array([4, 5, 6]),\n', '+    ),\n', '+)\n', '+class TestBinaryOperatorsSameSymbol:\n', '+    """"""\n', '+    Ensure symbol is preserved for numeric operations on polynomials with\n', '+    the same symbol\n', '+    """"""\n', ""+    p = poly.Polynomial([1, 2, 3], symbol='z')\n"", '+\n', '+    def test_add(self, rhs):\n', '+        out = self.p + rhs\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_sub(self, rhs):\n', '+        out = self.p - rhs\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_polymul(self, rhs):\n', '+        out = self.p * rhs\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_divmod(self, rhs):\n', '+        for out in divmod(self.p, rhs):\n', ""+            assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_radd(self, rhs):\n', '+        out = rhs + self.p\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_rsub(self, rhs):\n', '+        out = rhs - self.p\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_rmul(self, rhs):\n', '+        out = rhs * self.p\n', ""+        assert_equal(out.symbol, 'z')\n"", '+\n', '+    def test_rdivmod(self, rhs):\n', '+        for out in divmod(rhs, self.p):\n', ""+            assert_equal(out.symbol, 'z')\n"", '+\n', '+\n', '+class TestBinaryOperatorsDifferentSymbol:\n', ""+    p = poly.Polynomial([1, 2, 3], symbol='x')\n"", ""+    other = poly.Polynomial([4, 5, 6], symbol='y')\n"", '+    ops = (p.__add__, p.__sub__, p.__mul__, p.__floordiv__, p.__mod__)\n', '+\n', ""+    @pytest.mark.parametrize('f', ops)\n"", '+    def test_binops_fails(self, f):\n', '+        assert_raises(ValueError, f, self.other)\n', '+\n', '+\n', '+class TestEquality:\n', ""+    p = poly.Polynomial([1, 2, 3], symbol='x')\n"", '+\n', '+    def test_eq(self):\n', ""+        other = poly.Polynomial([1, 2, 3], symbol='x')\n"", '+        assert_(self.p == other)\n', '+\n', '+    def test_neq(self):\n', ""+        other = poly.Polynomial([1, 2, 3], symbol='y')\n"", '+        assert_(not self.p == other)\n', '+\n', '+\n', '+class TestExtraMethods:\n', '+    """"""\n', '+    Test other methods for manipulating/creating polynomial objects.\n', '+    """"""\n', ""+    p = poly.Polynomial([1, 2, 3, 0], symbol='z')\n"", '+\n', '+    def test_copy(self):\n', '+        other = self.p.copy()\n', ""+        assert_equal(other.symbol, 'z')\n"", '+\n', '+    def test_trim(self):\n', '+        other = self.p.trim()\n', ""+        assert_equal(other.symbol, 'z')\n"", '+\n', '+    def test_truncate(self):\n', '+        other = self.p.truncate(2)\n', ""+        assert_equal(other.symbol, 'z')\n"", '+\n', ""+    @pytest.mark.parametrize('kwarg', (\n"", ""+        {'domain': [-10, 10]},\n"", ""+        {'window': [-10, 10]},\n"", ""+        {'kind': poly.Chebyshev},\n"", '+    ))\n', '+    def test_convert(self, kwarg):\n', '+        other = self.p.convert(**kwarg)\n', ""+        assert_equal(other.symbol, 'z')\n"", '+\n', '+    def test_integ(self):\n', '+        other = self.p.integ()\n', ""+        assert_equal(other.symbol, 'z')\n"", '+\n', '+    def test_deriv(self):\n', '+        other = self.p.deriv()\n', ""+        assert_equal(other.symbol, 'z')\n"", '+\n', '+\n', '+def test_composition():\n', '+    p = poly.Polynomial([3, 2, 1], symbol=""t"")\n', '+    q = poly.Polynomial([5, 1, 0, -1], symbol=""λ_1"")\n', '+    r = p(q)\n', '+    assert r.symbol == ""λ_1""\n', '+\n', '+\n', '+#\n', '+# Class methods that result in new polynomial class instances\n', '+#\n', '+\n', '+\n', '+def test_fit():\n', '+    x, y = (range(10),)*2\n', ""+    p = poly.Polynomial.fit(x, y, deg=1, symbol='z')\n"", ""+    assert_equal(p.symbol, 'z')\n"", '+\n', '+\n', '+def test_froomroots():\n', '+    roots = [-2, 2]\n', ""+    p = poly.Polynomial.fromroots(roots, symbol='z')\n"", ""+    assert_equal(p.symbol, 'z')\n"", '+\n', '+\n', '+def test_identity():\n', ""+    p = poly.Polynomial.identity(domain=[-1, 1], window=[5, 20], symbol='z')\n"", ""+    assert_equal(p.symbol, 'z')\n"", '+\n', '+\n', '+def test_basis():\n', ""+    p = poly.Polynomial.basis(3, symbol='z')\n"", ""+    assert_equal(p.symbol, 'z')\n""]",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"['                  }\n', ' \n', ' \n', ""+def __bit_generator_ctor(bit_generator_name='MT19937'):\n"", '     """"""\n', '+    Pickling helper function that returns a bit generator object\n', ' \n', '     Parameters\n', '     ----------\n', '     bit_generator_name : str\n', '+        String containing the name of the BitGenerator\n', ' \n', '     Returns\n', '     -------\n', '+    bit_generator : BitGenerator\n', '+        BitGenerator instance\n', '     """"""\n', '     if bit_generator_name in BitGenerators:\n', '         bit_generator = BitGenerators[bit_generator_name]\n']","['                  }\n', ' \n', ' \n', ""-def __generator_ctor(bit_generator_name='MT19937'):\n"", '     """"""\n', '-    Pickling helper function that returns a Generator object\n', ' \n', '     Parameters\n', '     ----------\n', '     bit_generator_name : str\n', '-        String containing the core BitGenerator\n', ' \n', '     Returns\n', '     -------\n', '-    rg : Generator\n', '-        Generator using the named core BitGenerator\n', '     """"""\n', '     if bit_generator_name in BitGenerators:\n', '         bit_generator = BitGenerators[bit_generator_name]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         raise ValueError(str(bit_generator_name) + ' is not a known '\n"", ""                                                    'BitGenerator module.')\n"", ' \n', '+    return bit_generator()\n', ' \n', ' \n', '+def __generator_ctor(bit_generator_name=""MT19937"",\n', '+                     bit_generator_ctor=__bit_generator_ctor):\n', '     """"""\n', '+    Pickling helper function that returns a Generator object\n', ' \n', '     Parameters\n', '     ----------\n', '     bit_generator_name : str\n', ""+        String containing the core BitGenerator's name\n"", '+    bit_generator_ctor : callable, optional\n', '+        Callable function that takes bit_generator_name as its only argument\n', '+        and returns an instantized bit generator.\n', ' \n', '     Returns\n', '     -------\n', '+    rg : Generator\n', '+        Generator using the named core BitGenerator\n', '     """"""\n', '+    return Generator(bit_generator_ctor(bit_generator_name))\n', ' \n', ' \n', '+def __randomstate_ctor(bit_generator_name=""MT19937"",\n', '+                       bit_generator_ctor=__bit_generator_ctor):\n', '     """"""\n', '     Pickling helper function that returns a legacy RandomState-like object\n', ' \n', '     Parameters\n', '     ----------\n', '     bit_generator_name : str\n', ""+        String containing the core BitGenerator's name\n"", '+    bit_generator_ctor : callable, optional\n', '+        Callable function that takes bit_generator_name as its only argument\n', '+        and returns an instantized bit generator.\n', ' \n', '     Returns\n', '     -------\n', '     rs : RandomState\n', '         Legacy RandomState using the named core BitGenerator\n', '     """"""\n', ' \n', '+    return RandomState(bit_generator_ctor(bit_generator_name))\n']","[""         raise ValueError(str(bit_generator_name) + ' is not a known '\n"", ""                                                    'BitGenerator module.')\n"", ' \n', '-    return Generator(bit_generator())\n', ' \n', ' \n', ""-def __bit_generator_ctor(bit_generator_name='MT19937'):\n"", '     """"""\n', '-    Pickling helper function that returns a bit generator object\n', ' \n', '     Parameters\n', '     ----------\n', '     bit_generator_name : str\n', '-        String containing the name of the BitGenerator\n', ' \n', '     Returns\n', '     -------\n', '-    bit_generator : BitGenerator\n', '-        BitGenerator instance\n', '     """"""\n', '-    if bit_generator_name in BitGenerators:\n', '-        bit_generator = BitGenerators[bit_generator_name]\n', '-    else:\n', ""-        raise ValueError(str(bit_generator_name) + ' is not a known '\n"", ""-                                                   'BitGenerator module.')\n"", '-\n', '-    return bit_generator()\n', ' \n', ' \n', ""-def __randomstate_ctor(bit_generator_name='MT19937'):\n"", '     """"""\n', '     Pickling helper function that returns a legacy RandomState-like object\n', ' \n', '     Parameters\n', '     ----------\n', '     bit_generator_name : str\n', '-        String containing the core BitGenerator\n', ' \n', '     Returns\n', '     -------\n', '     rs : RandomState\n', '         Legacy RandomState using the named core BitGenerator\n', '     """"""\n', '-    if bit_generator_name in BitGenerators:\n', '-        bit_generator = BitGenerators[bit_generator_name]\n', '-    else:\n', ""-        raise ValueError(str(bit_generator_name) + ' is not a known '\n"", ""-                                                   'BitGenerator module.')\n"", ' \n', '-    return RandomState(bit_generator())\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import warnings\n', ' import numpy as np\n', ' from numpy.distutils.misc_util import exec_mod_from_location\n', '+from numpy.testing import IS_WASM\n', ' \n', ' try:\n', '     import cffi\n']","[' import warnings\n', ' import numpy as np\n', ' from numpy.distutils.misc_util import exec_mod_from_location\n', ' \n', ' try:\n', '     import cffi\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # too old or wrong cython, skip the test\n', '         cython = None\n', ' \n', '+\n', '+@pytest.mark.skipif(IS_WASM, reason=""Can\'t start subprocess"")\n', ' @pytest.mark.skipif(cython is None, reason=""requires cython"")\n', ' @pytest.mark.slow\n', ' def test_cython(tmp_path):\n']","['         # too old or wrong cython, skip the test\n', '         cython = None\n', ' \n', ' @pytest.mark.skipif(cython is None, reason=""requires cython"")\n', ' @pytest.mark.slow\n', ' def test_cython(tmp_path):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '     assert_, assert_raises, assert_equal, assert_allclose,\n', '     assert_warns, assert_no_warnings, assert_array_equal,\n', '+    assert_array_almost_equal, suppress_warnings, IS_WASM)\n', ' \n', ' from numpy.random import Generator, MT19937, SeedSequence, RandomState\n', ' \n']","[' from numpy.testing import (\n', '     assert_, assert_raises, assert_equal, assert_allclose,\n', '     assert_warns, assert_no_warnings, assert_array_equal,\n', '-    assert_array_almost_equal, suppress_warnings)\n', ' \n', ' from numpy.random import Generator, MT19937, SeedSequence, RandomState\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestMultivariateHypergeometric:\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 8675309\n', ' \n', '     def test_argument_validation(self):\n']","[' \n', ' class TestMultivariateHypergeometric:\n', ' \n', '-    def setup(self):\n', '         self.seed = 8675309\n', ' \n', '     def test_argument_validation(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestSetState:\n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', '         self.rg = Generator(MT19937(self.seed))\n', '         self.bit_generator = self.rg.bit_generator\n']","[' \n', ' \n', ' class TestSetState:\n', '-    def setup(self):\n', '         self.seed = 1234567890\n', '         self.rg = Generator(MT19937(self.seed))\n', '         self.bit_generator = self.rg.bit_generator\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_integers(self):\n']","['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '-    def setup(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_integers(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                             [5, 1]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '+    def test_logseries_zero(self):\n', '+        random = Generator(MT19937(self.seed))\n', '+        assert random.logseries(0) == 1\n', '+\n', '+    @pytest.mark.parametrize(""value"", [np.nextafter(0., -1), 1., np.nan, 5.])\n', '+    def test_logseries_exceptions(self, value):\n', '+        random = Generator(MT19937(self.seed))\n', '+        with np.errstate(invalid=""ignore""):\n', '+            with pytest.raises(ValueError):\n', '+                random.logseries(value)\n', '+            with pytest.raises(ValueError):\n', '+                # contiguous path:\n', '+                random.logseries(np.array([value] * 10))\n', '+            with pytest.raises(ValueError):\n', '+                # non-contiguous path:\n', '+                random.logseries(np.array([value] * 10)[::2])\n', ' \n', '     def test_multinomial(self):\n', '         random = Generator(MT19937(self.seed))\n']","['                             [5, 1]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '-    def test_logseries_exceptions(self):\n', ""-        with np.errstate(invalid='ignore'):\n"", '-            assert_raises(ValueError, random.logseries, np.nan)\n', '-            assert_raises(ValueError, random.logseries, [np.nan] * 10)\n', ' \n', '     def test_multinomial(self):\n', '         random = Generator(MT19937(self.seed))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                              [5, 5, 3, 1, 2, 4]]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '+    @pytest.mark.skipif(IS_WASM, reason=""fp errors don\'t work in wasm"")\n', '     @pytest.mark.parametrize(""method"", [""svd"", ""eigh"", ""cholesky""])\n', '     def test_multivariate_normal(self, method):\n', '         random = Generator(MT19937(self.seed))\n']","['                              [5, 5, 3, 1, 2, 4]]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '     @pytest.mark.parametrize(""method"", [""svd"", ""eigh"", ""cholesky""])\n', '     def test_multivariate_normal(self, method):\n', '         random = Generator(MT19937(self.seed))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                       mu, np.empty((3, 2)))\n', '         assert_raises(ValueError, random.multivariate_normal,\n', '                       mu, np.eye(3))\n', '+        \n', ""+    @pytest.mark.parametrize('mean, cov', [([0], [[1+1j]]), ([0j], [[1]])])\n"", '+    def test_multivariate_normal_disallow_complex(self, mean, cov):\n', '+        random = Generator(MT19937(self.seed))\n', '+        with pytest.raises(TypeError, match=""must not be complex""):\n', '+            random.multivariate_normal(mean, cov)\n', ' \n', '     @pytest.mark.parametrize(""method"", [""svd"", ""eigh"", ""cholesky""])\n', '     def test_multivariate_normal_basic_stats(self, method):\n']","['                       mu, np.empty((3, 2)))\n', '         assert_raises(ValueError, random.multivariate_normal,\n', '                       mu, np.eye(3))\n', ' \n', '     @pytest.mark.parametrize(""method"", [""svd"", ""eigh"", ""cholesky""])\n', '     def test_multivariate_normal_basic_stats(self, method):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '+    def setup_method(self):\n', '         self.seed = 123456789\n', ' \n', ' \n']","[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '-    def setup(self):\n', '         self.seed = 123456789\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert actual.shape == (3, 0, 7, 4)\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""can\'t start thread"")\n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '+    def setup_method(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']","['         assert actual.shape == (3, 0, 7, 4)\n', ' \n', ' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '-    def setup(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '+    def setup_method(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']","[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '-    def setup(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert variates is out\n', '     variates = dist(out=out, dtype=dtype, size=out.shape)\n', '     assert variates is out\n', '+\n', '+\n', '+def test_generator_ctor_old_style_pickle():\n', '+    rg = np.random.Generator(np.random.PCG64DXSM(0))\n', '+    rg.standard_normal(1)\n', '+    # Directly call reduce which is used in pickling\n', '+    ctor, args, state_a = rg.__reduce__()\n', '+    # Simulate unpickling an old pickle that only has the name\n', '+    assert args[:1] == (""PCG64DXSM"",)\n', '+    b = ctor(*args[:1])\n', '+    b.bit_generator.state = state_a\n', '+    state_b = b.bit_generator.state\n', '+    assert state_a == state_b\n']","['     assert variates is out\n', '     variates = dist(out=out, dtype=dtype, size=out.shape)\n', '     assert variates is out\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '         assert_, assert_raises, assert_equal, assert_warns,\n', '         assert_no_warnings, assert_array_equal, assert_array_almost_equal,\n', '+        suppress_warnings, IS_WASM\n', '         )\n', ' from numpy import random\n', ' import sys\n']","[' from numpy.testing import (\n', '         assert_, assert_raises, assert_equal, assert_warns,\n', '         assert_no_warnings, assert_array_equal, assert_array_almost_equal,\n', '-        suppress_warnings\n', '         )\n', ' from numpy import random\n', ' import sys\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestSetState:\n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', '         self.prng = random.RandomState(self.seed)\n', '         self.state = self.prng.get_state()\n']","[' \n', ' \n', ' class TestSetState:\n', '-    def setup(self):\n', '         self.seed = 1234567890\n', '         self.prng = random.RandomState(self.seed)\n', '         self.state = self.prng.get_state()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']","['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '-    def setup(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '+    def setup_method(self):\n', '         self.seed = 123456789\n', ' \n', '     def setSeed(self):\n']","[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '-    def setup(self):\n', '         self.seed = 123456789\n', ' \n', '     def setSeed(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_raises(ValueError, logseries, bad_p_two * 3)\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""can\'t start thread"")\n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '+    def setup_method(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']","['         assert_raises(ValueError, logseries, bad_p_two * 3)\n', ' \n', ' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '-    def setup(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '+    def setup_method(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']","[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '-    def setup(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             out = func(self.argOne, argTwo[0])\n', '             assert_equal(out.shape, self.tgtShape)\n', ' \n', '+    def test_randint(self):\n', '+        itype = [bool, np.int8, np.uint8, np.int16, np.uint16,\n', '+                 np.int32, np.uint32, np.int64, np.uint64]\n', '+        func = np.random.randint\n', '+        high = np.array([1])\n', '+        low = np.array([0])\n', '+\n', '+        for dt in itype:\n', '+            out = func(low, high, dtype=dt)\n', '+            assert_equal(out.shape, self.tgtShape)\n', '+\n', '+            out = func(low[0], high, dtype=dt)\n', '+            assert_equal(out.shape, self.tgtShape)\n', '+\n', '+            out = func(low, high[0], dtype=dt)\n', '+            assert_equal(out.shape, self.tgtShape)\n', ' \n', '     def test_three_arg_funcs(self):\n', '         funcs = [np.random.noncentral_f, np.random.triangular,\n']","['             out = func(self.argOne, argTwo[0])\n', '             assert_equal(out.shape, self.tgtShape)\n', ' \n', '-# TODO: Uncomment once randint can broadcast arguments\n', '-#    def test_randint(self):\n', '-#        itype = [bool, np.int8, np.uint8, np.int16, np.uint16,\n', '-#                 np.int32, np.uint32, np.int64, np.uint64]\n', '-#        func = np.random.randint\n', '-#        high = np.array([1])\n', '-#        low = np.array([0])\n', '-#\n', '-#        for dt in itype:\n', '-#            out = func(low, high, dtype=dt)\n', '-#            self.assert_equal(out.shape, self.tgtShape)\n', '-#\n', '-#            out = func(low[0], high, dtype=dt)\n', '-#            self.assert_equal(out.shape, self.tgtShape)\n', '-#\n', '-#            out = func(low, high[0], dtype=dt)\n', '-#            self.assert_equal(out.shape, self.tgtShape)\n', ' \n', '     def test_three_arg_funcs(self):\n', '         funcs = [np.random.noncentral_f, np.random.triangular,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from numpy.testing import (\n', '         assert_, assert_raises, assert_equal, assert_warns,\n', '         assert_no_warnings, assert_array_equal, assert_array_almost_equal,\n', '+        suppress_warnings, IS_WASM\n', '         )\n', ' \n', ' from numpy.random import MT19937, PCG64\n']","[' from numpy.testing import (\n', '         assert_, assert_raises, assert_equal, assert_warns,\n', '         assert_no_warnings, assert_array_equal, assert_array_almost_equal,\n', '-        suppress_warnings\n', '         )\n', ' \n', ' from numpy.random import MT19937, PCG64\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             INT_FUNC_HASHES[request.param])\n', ' \n', ' \n', '+@pytest.fixture\n', '+def restore_singleton_bitgen():\n', '+    """"""Ensures that the singleton bitgen is restored after a test""""""\n', '+    orig_bitgen = np.random.get_bit_generator()\n', '+    yield\n', '+    np.random.set_bit_generator(orig_bitgen)\n', '+\n', '+\n', ' def assert_mt19937_state_equal(a, b):\n', ""     assert_equal(a['bit_generator'], b['bit_generator'])\n"", ""     assert_array_equal(a['state']['key'], b['state']['key'])\n""]","['             INT_FUNC_HASHES[request.param])\n', ' \n', ' \n', ' def assert_mt19937_state_equal(a, b):\n', ""     assert_equal(a['bit_generator'], b['bit_generator'])\n"", ""     assert_array_equal(a['state']['key'], b['state']['key'])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' class TestSetState:\n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', '         self.random_state = random.RandomState(self.seed)\n', '         self.state = self.random_state.get_state()\n']","[' \n', ' \n', ' class TestSetState:\n', '-    def setup(self):\n', '         self.seed = 1234567890\n', '         self.random_state = random.RandomState(self.seed)\n', '         self.state = self.random_state.get_state()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']","['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '-    def setup(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                             [3, 6]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '+    def test_logseries_zero(self):\n', '+        assert random.logseries(0) == 1\n', '+\n', '+    @pytest.mark.parametrize(""value"", [np.nextafter(0., -1), 1., np.nan, 5.])\n', '+    def test_logseries_exceptions(self, value):\n', '+        with np.errstate(invalid=""ignore""):\n', '+            with pytest.raises(ValueError):\n', '+                random.logseries(value)\n', '+            with pytest.raises(ValueError):\n', '+                # contiguous path:\n', '+                random.logseries(np.array([value] * 10))\n', '+            with pytest.raises(ValueError):\n', '+                # non-contiguous path:\n', '+                random.logseries(np.array([value] * 10)[::2])\n', ' \n', '     def test_multinomial(self):\n', '         random.seed(self.seed)\n']","['                             [3, 6]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '-    def test_logseries_exceptions(self):\n', '-        with suppress_warnings() as sup:\n', '-            sup.record(RuntimeWarning)\n', '-            assert_raises(ValueError, random.logseries, np.nan)\n', '-            assert_raises(ValueError, random.logseries, [np.nan] * 10)\n', ' \n', '     def test_multinomial(self):\n', '         random.seed(self.seed)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '+    def setup_method(self):\n', '         self.seed = 123456789\n', ' \n', '     def set_seed(self):\n']","[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '-    def setup(self):\n', '         self.seed = 123456789\n', ' \n', '     def set_seed(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         assert_raises(ValueError, logseries, bad_p_two * 3)\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""can\'t start thread"")\n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '+    def setup_method(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']","['         assert_raises(ValueError, logseries, bad_p_two * 3)\n', ' \n', ' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '-    def setup(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '+    def setup_method(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']","[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '-    def setup(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         random.binomial([1, 2], 0.3, size=(2, 1))\n', '     with pytest.raises(ValueError):\n', '         random.binomial([1, 2], [0.3, 0.7], size=(2, 1))\n', '+\n', '+\n', '+def test_randomstate_ctor_old_style_pickle():\n', '+    rs = np.random.RandomState(MT19937(0))\n', '+    rs.standard_normal(1)\n', '+    # Directly call reduce which is used in pickling\n', '+    ctor, args, state_a = rs.__reduce__()\n', '+    # Simulate unpickling an old pickle that only has the name\n', '+    assert args[:1] == (""MT19937"",)\n', '+    b = ctor(*args[:1])\n', '+    b.set_state(state_a)\n', '+    state_b = b.get_state(legacy=False)\n', '+\n', ""+    assert_equal(state_a['bit_generator'], state_b['bit_generator'])\n"", ""+    assert_array_equal(state_a['state']['key'], state_b['state']['key'])\n"", ""+    assert_array_equal(state_a['state']['pos'], state_b['state']['pos'])\n"", ""+    assert_equal(state_a['has_gauss'], state_b['has_gauss'])\n"", ""+    assert_equal(state_a['gauss'], state_b['gauss'])\n"", '+\n', '+def test_hot_swap(restore_singleton_bitgen):\n', '+    # GH 21808\n', '+    def_bg = np.random.default_rng(0)\n', '+    bg = def_bg.bit_generator\n', '+    np.random.set_bit_generator(bg)\n', '+    assert isinstance(np.random.mtrand._rand._bit_generator, type(bg))\n', '+\n', '+    second_bg = np.random.get_bit_generator()\n', '+    assert bg is second_bg\n', '+\n', '+\n', '+def test_seed_alt_bit_gen(restore_singleton_bitgen):\n', '+    # GH 21808\n', '+    bg = PCG64(0)\n', '+    np.random.set_bit_generator(bg)\n', '+    state = np.random.get_state(legacy=False)\n', '+    np.random.seed(1)\n', '+    new_state = np.random.get_state(legacy=False)\n', '+    print(state)\n', '+    print(new_state)\n', '+    assert state[""bit_generator""] == ""PCG64""\n', '+    assert state[""state""][""state""] != new_state[""state""][""state""]\n', '+    assert state[""state""][""inc""] != new_state[""state""][""inc""]\n', '+\n', '+\n', '+def test_state_error_alt_bit_gen(restore_singleton_bitgen):\n', '+    # GH 21808\n', '+    state = np.random.get_state()\n', '+    bg = PCG64(0)\n', '+    np.random.set_bit_generator(bg)\n', '+    with pytest.raises(ValueError, match=""state must be for a PCG64""):\n', '+        np.random.set_state(state)\n', '+\n', '+\n', '+def test_swap_worked(restore_singleton_bitgen):\n', '+    # GH 21808\n', '+    np.random.seed(98765)\n', '+    vals = np.random.randint(0, 2 ** 30, 10)\n', '+    bg = PCG64(0)\n', '+    state = bg.state\n', '+    np.random.set_bit_generator(bg)\n', '+    state_direct = np.random.get_state(legacy=False)\n', '+    for field in state:\n', '+        assert state[field] == state_direct[field]\n', '+    np.random.seed(98765)\n', '+    pcg_vals = np.random.randint(0, 2 ** 30, 10)\n', '+    assert not np.all(vals == pcg_vals)\n', '+    new_state = bg.state\n', '+    assert new_state[""state""][""state""] != state[""state""][""state""]\n', '+    assert new_state[""state""][""inc""] == new_state[""state""][""inc""]\n', '+\n', '+\n', '+def test_swapped_singleton_against_direct(restore_singleton_bitgen):\n', '+    np.random.set_bit_generator(PCG64(98765))\n', '+    singleton_vals = np.random.randint(0, 2 ** 30, 10)\n', '+    rg = np.random.RandomState(PCG64(98765))\n', '+    non_singleton_vals = rg.randint(0, 2 ** 30, 10)\n', '+    assert_equal(non_singleton_vals, singleton_vals)\n']","['         random.binomial([1, 2], 0.3, size=(2, 1))\n', '     with pytest.raises(ValueError):\n', '         random.binomial([1, 2], [0.3, 0.7], size=(2, 1))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     dirname = builddir / name\n', '     dirname.mkdir(exist_ok=True)\n', '     cfile = _convert_str_to_file(source_string, dirname)\n', ""+    include_dirs = include_dirs + [sysconfig.get_config_var('INCLUDEPY')]\n"", ' \n', '     return _c_compile(\n', '         cfile, outputfilename=dirname / modname,\n']","['     dirname = builddir / name\n', '     dirname.mkdir(exist_ok=True)\n', '     cfile = _convert_str_to_file(source_string, dirname)\n', ""-    include_dirs = [sysconfig.get_config_var('INCLUDEPY')] + include_dirs\n"", ' \n', '     return _c_compile(\n', '         cfile, outputfilename=dirname / modname,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         'assert_array_max_ulp', 'assert_warns', 'assert_no_warnings',\n"", ""         'assert_allclose', 'IgnoreException', 'clear_and_catch_warnings',\n"", ""         'SkipTest', 'KnownFailureException', 'temppath', 'tempdir', 'IS_PYPY',\n"", '+        \'HAS_REFCOUNT\', ""IS_WASM"", \'suppress_warnings\', \'assert_array_compare\',\n', ""         'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',\n"", ""+        '_OLD_PROMOTION'\n"", '         ]\n', ' \n', ' \n']","[""         'assert_array_max_ulp', 'assert_warns', 'assert_no_warnings',\n"", ""         'assert_allclose', 'IgnoreException', 'clear_and_catch_warnings',\n"", ""         'SkipTest', 'KnownFailureException', 'temppath', 'tempdir', 'IS_PYPY',\n"", ""-        'HAS_REFCOUNT', 'suppress_warnings', 'assert_array_compare',\n"", ""         'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',\n"", '         ]\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' KnownFailureTest = KnownFailureException  # backwards compat\n', ' verbose = 0\n', ' \n', '+IS_WASM = platform.machine() in [""wasm32"", ""wasm64""]\n', ""+IS_PYPY = sys.implementation.name == 'pypy'\n"", ' IS_PYSTON = hasattr(sys, ""pyston_version_info"")\n', "" HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON\n"", ' HAS_LAPACK64 = numpy.linalg.lapack_lite._ilp64\n', ' \n', ""+_OLD_PROMOTION = lambda: np._get_promotion_state() == 'legacy'\n"", '+\n', ' \n', ' def import_nose():\n', '     """""" Import nose only when needed.\n']","[' KnownFailureTest = KnownFailureException  # backwards compat\n', ' verbose = 0\n', ' \n', ""-IS_PYPY = platform.python_implementation() == 'PyPy'\n"", ' IS_PYSTON = hasattr(sys, ""pyston_version_info"")\n', "" HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON\n"", ' HAS_LAPACK64 = numpy.linalg.lapack_lite._ilp64\n', ' \n', ' \n', ' def import_nose():\n', '     """""" Import nose only when needed.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         raise AssertionError(msg.getvalue())\n', ' \n', ' \n', '+@np._no_nep50_warning()\n', "" def assert_almost_equal(actual,desired,decimal=7,err_msg='',verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two items are not equal up to desired\n']","['         raise AssertionError(msg.getvalue())\n', ' \n', ' \n', "" def assert_almost_equal(actual,desired,decimal=7,err_msg='',verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two items are not equal up to desired\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     The test verifies that the elements of `actual` and `desired` satisfy.\n', ' \n', '+        ``abs(desired-actual) < float64(1.5 * 10**(-decimal))``\n', ' \n', '     That is a looser test than originally documented, but agrees with what the\n', '     actual implementation in `assert_array_almost_equal` did up to rounding\n']","[' \n', '     The test verifies that the elements of `actual` and `desired` satisfy.\n', ' \n', '-        ``abs(desired-actual) < 1.5 * 10**(-decimal)``\n', ' \n', '     That is a looser test than originally documented, but agrees with what the\n', '     actual implementation in `assert_array_almost_equal` did up to rounding\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             return\n', '     except (NotImplementedError, TypeError):\n', '         pass\n', '+    if abs(desired - actual) >= np.float64(1.5 * 10.0**(-decimal)):\n', '         raise AssertionError(_build_err_msg())\n', ' \n', ' \n', '+@np._no_nep50_warning()\n', "" def assert_approx_equal(actual,desired,significant=7,err_msg='',verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two items are not equal up to significant\n']","['             return\n', '     except (NotImplementedError, TypeError):\n', '         pass\n', '-    if abs(desired - actual) >= 1.5 * 10.0**(-decimal):\n', '         raise AssertionError(_build_err_msg())\n', ' \n', ' \n', "" def assert_approx_equal(actual,desired,significant=7,err_msg='',verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two items are not equal up to significant\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         raise AssertionError(msg)\n', ' \n', ' \n', '+@np._no_nep50_warning()\n', "" def assert_array_compare(comparison, x, y, err_msg='', verbose=True, header='',\n"", '+                         precision=6, equal_nan=True, equal_inf=True,\n', '+                         *, strict=False):\n', '     __tracebackhide__ = True  # Hide traceback for py.test\n', '     from numpy.core import array, array2string, isnan, inf, bool_, errstate, all, max, object_\n', ' \n']","['         raise AssertionError(msg)\n', ' \n', ' \n', "" def assert_array_compare(comparison, x, y, err_msg='', verbose=True, header='',\n"", '-                         precision=6, equal_nan=True, equal_inf=True):\n', '     __tracebackhide__ = True  # Hide traceback for py.test\n', '     from numpy.core import array, array2string, isnan, inf, bool_, errstate, all, max, object_\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             return y_id\n', ' \n', '     try:\n', '+        if strict:\n', '+            cond = x.shape == y.shape and x.dtype == y.dtype\n', '+        else:\n', '+            cond = (x.shape == () or y.shape == ()) or x.shape == y.shape\n', '         if not cond:\n', '+            if x.shape != y.shape:\n', ""+                reason = f'\\n(shapes {x.shape}, {y.shape} mismatch)'\n"", '+            else:\n', ""+                reason = f'\\n(dtypes {x.dtype}, {y.dtype} mismatch)'\n"", '             msg = build_err_msg([x, y],\n', '                                 err_msg\n', '+                                + reason,\n', '                                 verbose=verbose, header=header,\n', ""                                 names=('x', 'y'), precision=precision)\n"", '             raise AssertionError(msg)\n']","['             return y_id\n', ' \n', '     try:\n', '-        cond = (x.shape == () or y.shape == ()) or x.shape == y.shape\n', '         if not cond:\n', '             msg = build_err_msg([x, y],\n', '                                 err_msg\n', ""-                                + f'\\n(shapes {x.shape}, {y.shape} mismatch)',\n"", '                                 verbose=verbose, header=header,\n', ""                                 names=('x', 'y'), precision=precision)\n"", '             raise AssertionError(msg)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 # ignore errors for non-numeric types\n', '                 with contextlib.suppress(TypeError):\n', '                     error = abs(x - y)\n', '+                    if np.issubdtype(x.dtype, np.unsignedinteger):\n', '+                        error2 = abs(y - x)\n', '+                        np.minimum(error, error2, out=error)\n', '                     max_abs_error = max(error)\n', ""                     if getattr(error, 'dtype', object_) == object_:\n"", ""                         remarks.append('Max absolute difference: '\n""]","['                 # ignore errors for non-numeric types\n', '                 with contextlib.suppress(TypeError):\n', '                     error = abs(x - y)\n', '                     max_abs_error = max(error)\n', ""                     if getattr(error, 'dtype', object_) == object_:\n"", ""                         remarks.append('Max absolute difference: '\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         raise ValueError(msg)\n', ' \n', ' \n', ""+def assert_array_equal(x, y, err_msg='', verbose=True, *, strict=False):\n"", '     """"""\n', '     Raises an AssertionError if two array_like objects are not equal.\n', ' \n']","['         raise ValueError(msg)\n', ' \n', ' \n', ""-def assert_array_equal(x, y, err_msg='', verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two array_like objects are not equal.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         The error message to be printed in case of failure.\n', '     verbose : bool, optional\n', '         If True, the conflicting values are appended to the error message.\n', '+    strict : bool, optional\n', '+        If True, raise an AssertionError when either the shape or the data\n', '+        type of the array_like objects does not match. The special\n', '+        handling for scalars mentioned in the Notes section is disabled.\n', ' \n', '     Raises\n', '     ------\n']","['         The error message to be printed in case of failure.\n', '     verbose : bool, optional\n', '         If True, the conflicting values are appended to the error message.\n', ' \n', '     Raises\n', '     ------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -----\n', '     When one of `x` and `y` is a scalar and the other is array_like, the\n', '     function checks that each element of the array_like object is equal to\n', '+    the scalar. This behaviour can be disabled with the `strict` parameter.\n', ' \n', '     Examples\n', '     --------\n']","['     -----\n', '     When one of `x` and `y` is a scalar and the other is array_like, the\n', '     function checks that each element of the array_like object is equal to\n', '-    the scalar.\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     >>> x = np.full((2, 5), fill_value=3)\n', '     >>> np.testing.assert_array_equal(x, 3)\n', ' \n', '+    Use `strict` to raise an AssertionError when comparing a scalar with an\n', '+    array:\n', '+\n', '+    >>> np.testing.assert_array_equal(x, 3, strict=True)\n', '+    Traceback (most recent call last):\n', '+        ...\n', '+    AssertionError:\n', '+    Arrays are not equal\n', '+    <BLANKLINE>\n', '+    (shapes (2, 5), () mismatch)\n', '+     x: array([[3, 3, 3, 3, 3],\n', '+           [3, 3, 3, 3, 3]])\n', '+     y: array(3)\n', '+\n', '+    The `strict` parameter also ensures that the array data types match:\n', '+\n', '+    >>> x = np.array([2, 2, 2])\n', '+    >>> y = np.array([2., 2., 2.], dtype=np.float32)\n', '+    >>> np.testing.assert_array_equal(x, y, strict=True)\n', '+    Traceback (most recent call last):\n', '+        ...\n', '+    AssertionError:\n', '+    Arrays are not equal\n', '+    <BLANKLINE>\n', '+    (dtypes int64, float32 mismatch)\n', '+     x: array([2, 2, 2])\n', '+     y: array([2., 2., 2.], dtype=float32)\n', '     """"""\n', '     __tracebackhide__ = True  # Hide traceback for py.test\n', '     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n', ""+                         verbose=verbose, header='Arrays are not equal',\n"", '+                         strict=strict)\n', ' \n', ' \n', '+@np._no_nep50_warning()\n', "" def assert_array_almost_equal(x, y, decimal=6, err_msg='', verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two objects are not equal up to desired\n']","['     >>> x = np.full((2, 5), fill_value=3)\n', '     >>> np.testing.assert_array_equal(x, 3)\n', ' \n', '     """"""\n', '     __tracebackhide__ = True  # Hide traceback for py.test\n', '     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n', ""-                         verbose=verbose, header='Arrays are not equal')\n"", ' \n', ' \n', "" def assert_array_almost_equal(x, y, decimal=6, err_msg='', verbose=True):\n"", '     """"""\n', '     Raises an AssertionError if two objects are not equal up to desired\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     Raises an AssertionError if two objects are not equal up to desired\n', '     tolerance.\n', ' \n', '+    Given two array_like objects, check that their shapes and all elements\n', '+    are equal (but see the Notes for the special handling of a scalar). An\n', '+    exception is raised if the shapes mismatch or any values conflict. In \n', '+    contrast to the standard usage in numpy, NaNs are compared like numbers,\n', '+    no assertion is raised if both objects have NaNs in the same positions.\n', '+\n', '     The test is equivalent to ``allclose(actual, desired, rtol, atol)`` (note\n', '     that ``allclose`` has different default values). It compares the difference\n', '     between `actual` and `desired` to ``atol + rtol * abs(desired)``.\n']","['     Raises an AssertionError if two objects are not equal up to desired\n', '     tolerance.\n', ' \n', '     The test is equivalent to ``allclose(actual, desired, rtol, atol)`` (note\n', '     that ``allclose`` has different default values). It compares the difference\n', '     between `actual` and `desired` to ``atol + rtol * abs(desired)``.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     --------\n', '     assert_array_almost_equal_nulp, assert_array_max_ulp\n', ' \n', '+    Notes\n', '+    -----\n', '+    When one of `actual` and `desired` is a scalar and the other is\n', '+    array_like, the function checks that each element of the array_like\n', '+    object is equal to the scalar.\n', '+\n', '     Examples\n', '     --------\n', '     >>> x = [1e-5, 1e-3, 1e-1]\n']","['     --------\n', '     assert_array_almost_equal_nulp, assert_array_max_ulp\n', ' \n', '     Examples\n', '     --------\n', '     >>> x = [1e-5, 1e-3, 1e-1]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     -----\n', '     An assertion is raised if the following condition is not met::\n', ' \n', '+        abs(x - y) <= nulp * spacing(maximum(abs(x), abs(y)))\n', ' \n', '     Examples\n', '     --------\n']","['     -----\n', '     An assertion is raised if the following condition is not met::\n', ' \n', '-        abs(x - y) <= nulps * spacing(maximum(abs(x), abs(y)))\n', ' \n', '     Examples\n', '     --------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestArrayEqual(_GenericTest):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_array_equal\n', ' \n', '     def test_generic_rank1(self):\n']","[' \n', ' class TestArrayEqual(_GenericTest):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_array_equal\n', ' \n', '     def test_generic_rank1(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     np.array([1, 2, 3], np.float32),\n', '                     np.array([1, 1e-40, 3], np.float32))\n', ' \n', '+    def test_array_vs_scalar_is_equal(self):\n', '+        """"""Test comparing an array with a scalar when all values are equal.""""""\n', '+        a = np.array([1., 1., 1.])\n', '+        b = 1.\n', '+\n', '+        self._test_equal(a, b)\n', '+\n', '+    def test_array_vs_scalar_not_equal(self):\n', '+        """"""Test comparing an array with a scalar when not all values equal.""""""\n', '+        a = np.array([1., 2., 3.])\n', '+        b = 1.\n', '+\n', '+        self._test_not_equal(a, b)\n', '+\n', '+    def test_array_vs_scalar_strict(self):\n', '+        """"""Test comparing an array with a scalar with strict option.""""""\n', '+        a = np.array([1., 1., 1.])\n', '+        b = 1.\n', '+\n', '+        with pytest.raises(AssertionError):\n', '+            assert_array_equal(a, b, strict=True)\n', '+\n', '+    def test_array_vs_array_strict(self):\n', '+        """"""Test comparing two arrays with strict option.""""""\n', '+        a = np.array([1., 1., 1.])\n', '+        b = np.array([1., 1., 1.])\n', '+\n', '+        assert_array_equal(a, b, strict=True)\n', '+\n', '+    def test_array_vs_float_array_strict(self):\n', '+        """"""Test comparing two arrays with strict option.""""""\n', '+        a = np.array([1, 1, 1])\n', '+        b = np.array([1., 1., 1.])\n', '+\n', '+        with pytest.raises(AssertionError):\n', '+            assert_array_equal(a, b, strict=True)\n', '+\n', ' \n', ' class TestBuildErrorMessage:\n', ' \n']","['                     np.array([1, 2, 3], np.float32),\n', '                     np.array([1, 1e-40, 3], np.float32))\n', ' \n', ' \n', ' class TestBuildErrorMessage:\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestEqual(TestArrayEqual):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_equal\n', ' \n', '     def test_nan_items(self):\n']","[' \n', ' class TestEqual(TestArrayEqual):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_equal\n', ' \n', '     def test_nan_items(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestArrayAlmostEqual(_GenericTest):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_array_almost_equal\n', ' \n', '     def test_closeness(self):\n']","[' \n', ' class TestArrayAlmostEqual(_GenericTest):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_array_almost_equal\n', ' \n', '     def test_closeness(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestAlmostEqual(_GenericTest):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_almost_equal\n', ' \n', '     def test_closeness(self):\n']","[' \n', ' class TestAlmostEqual(_GenericTest):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_almost_equal\n', ' \n', '     def test_closeness(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestApproxEqual:\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_approx_equal\n', ' \n', '     def test_simple_0d_arrays(self):\n']","[' \n', ' class TestApproxEqual:\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_approx_equal\n', ' \n', '     def test_simple_0d_arrays(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' class TestArrayAssertLess:\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_array_less\n', ' \n', '     def test_simple_arrays(self):\n']","[' \n', ' class TestArrayAssertLess:\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_array_less\n', ' \n', '     def test_simple_arrays(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @pytest.mark.skip(reason=""The raises decorator depends on Nose"")\n', ' class TestRaises:\n', ' \n', '+    def setup_method(self):\n', '         class MyException(Exception):\n', '             pass\n', ' \n']","[' @pytest.mark.skip(reason=""The raises decorator depends on Nose"")\n', ' class TestRaises:\n', ' \n', '-    def setup(self):\n', '         class MyException(Exception):\n', '             pass\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         a = np.array([[1, 2, 3, ""NaT""]], dtype=""m8[ns]"")\n', '         assert_allclose(a, a)\n', ' \n', '+    def test_error_message_unsigned(self):\n', '+        """"""Check the the message is formatted correctly when overflow can occur\n', '+           (gh21768)""""""\n', '+        # Ensure to test for potential overflow in the case of:\n', '+        #        x - y\n', '+        # and\n', '+        #        y - x\n', ""+        x = np.asarray([0, 1, 8], dtype='uint8')\n"", ""+        y = np.asarray([4, 4, 4], dtype='uint8')\n"", '+        with pytest.raises(AssertionError) as exc_info:\n', '+            assert_allclose(x, y, atol=3)\n', ""+        msgs = str(exc_info.value).split('\\n')\n"", ""+        assert_equal(msgs[4], 'Max absolute difference: 4')\n"", '+\n', ' \n', ' class TestArrayAlmostEqualNulp:\n', ' \n']","['         a = np.array([[1, 2, 3, ""NaT""]], dtype=""m8[ns]"")\n', '         assert_allclose(a, a)\n', ' \n', ' \n', ' class TestArrayAlmostEqualNulp:\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+import sys\n', '+import importlib\n', '+from importlib.util import LazyLoader, find_spec, module_from_spec\n', '+import pytest\n', '+\n', '+\n', '+# Warning raised by _reload_guard() in numpy/__init__.py\n', '+@pytest.mark.filterwarnings(""ignore:The NumPy module was reloaded"")\n', '+def test_lazy_load():\n', ""+    # gh-22045. lazyload doesn't import submodule names into the namespace\n"", '+    # muck with sys.modules to test the importing system\n', '+    old_numpy = sys.modules.pop(""numpy"")\n', '+\n', '+    numpy_modules = {}\n', '+    for mod_name, mod in list(sys.modules.items()):\n', '+        if mod_name[:6] == ""numpy."":\n', '+            numpy_modules[mod_name] = mod\n', '+            sys.modules.pop(mod_name)\n', '+\n', '+    try:\n', '+        # create lazy load of numpy as np\n', '+        spec = find_spec(""numpy"")\n', '+        module = module_from_spec(spec)\n', '+        sys.modules[""numpy""] = module\n', '+        loader = LazyLoader(spec.loader)\n', '+        loader.exec_module(module)\n', '+        np = module\n', '+\n', '+        # test a subpackage import\n', '+        from numpy.lib import recfunctions\n', '+\n', '+        # test triggering the import of the package\n', '+        np.ndarray\n', '+\n', '+    finally:\n', '+        if old_numpy:\n', '+            sys.modules[""numpy""] = old_numpy\n', '+            sys.modules.update(numpy_modules)\n']",[]
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import numpy as np\n', ' import numpy\n', ' import pytest\n', '+from numpy.testing import IS_WASM\n', ' \n', ' try:\n', '     import ctypes\n']","[' import numpy as np\n', ' import numpy\n', ' import pytest\n', ' \n', ' try:\n', '     import ctypes\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         'deprecate': 'numpy.lib.utils.deprecate',\n"", ""         'deprecate_with_doc': 'numpy.lib.utils.deprecate_with_doc',\n"", ""         'disp': 'numpy.lib.function_base.disp',\n"", ""+        'fastCopyAndTranspose': 'numpy.core._multiarray_umath.fastCopyAndTranspose',\n"", ""         'get_array_wrap': 'numpy.lib.shape_base.get_array_wrap',\n"", ""         'get_include': 'numpy.lib.utils.get_include',\n"", ""         'recfromcsv': 'numpy.lib.npyio.recfromcsv',\n""]","[""         'deprecate': 'numpy.lib.utils.deprecate',\n"", ""         'deprecate_with_doc': 'numpy.lib.utils.deprecate_with_doc',\n"", ""         'disp': 'numpy.lib.function_base.disp',\n"", ""-        'fastCopyAndTranspose': 'numpy.core._multiarray_umath._fastCopyAndTranspose',\n"", ""         'get_array_wrap': 'numpy.lib.shape_base.get_array_wrap',\n"", ""         'get_include': 'numpy.lib.utils.get_include',\n"", ""         'recfromcsv': 'numpy.lib.npyio.recfromcsv',\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         'safe_eval': 'numpy.lib.utils.safe_eval',\n"", ""         'set_string_function': 'numpy.core.arrayprint.set_string_function',\n"", ""         'show_config': 'numpy.__config__.show',\n"", ""+        'show_runtime': 'numpy.lib.utils.show_runtime',\n"", ""         'who': 'numpy.lib.utils.who',\n"", '     }\n', '     # We override dir to not show these members\n']","[""         'safe_eval': 'numpy.lib.utils.safe_eval',\n"", ""         'set_string_function': 'numpy.core.arrayprint.set_string_function',\n"", ""         'show_config': 'numpy.__config__.show',\n"", ""         'who': 'numpy.lib.utils.who',\n"", '     }\n', '     # We override dir to not show these members\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     assert bad_results == allowlist\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""can\'t start subprocess"")\n', "" @pytest.mark.parametrize('name', ['testing', 'Tester'])\n"", ' def test_import_lazy_import(name):\n', '     """"""Make sure we can actually use the modules we lazy load.\n']","['     assert bad_results == allowlist\n', ' \n', ' \n', "" @pytest.mark.parametrize('name', ['testing', 'Tester'])\n"", ' def test_import_lazy_import(name):\n', '     """"""Make sure we can actually use the modules we lazy load.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['+from numpy.testing import (\n', '+    assert_raises,\n', '+    assert_warns,\n', '+    assert_,\n', '+    assert_equal,\n', '+    IS_WASM,\n', '+)\n', ' from numpy.compat import pickle\n', ' \n', '+import pytest\n', ' import sys\n', ' import subprocess\n', ' import textwrap\n']","['-from numpy.testing import assert_raises, assert_warns, assert_, assert_equal\n', ' from numpy.compat import pickle\n', ' \n', ' import sys\n', ' import subprocess\n', ' import textwrap\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                                           protocol=proto)) is np._NoValue)\n', ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""can\'t start subprocess"")\n', ' def test_full_reimport():\n', '     """"""At the time of writing this, it is *not* truly supported, but\n', '     apparently enough users rely on it, for it to be an annoying change\n']","['                                           protocol=proto)) is np._NoValue)\n', ' \n', ' \n', ' def test_full_reimport():\n', '     """"""At the time of writing this, it is *not* truly supported, but\n', '     apparently enough users rely on it, for it to be an annoying change\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import subprocess\n', ' \n', ' import numpy as np\n', '+from numpy.testing import assert_equal, IS_WASM\n', ' \n', "" is_inplace = isfile(pathjoin(dirname(np.__file__),  '..', 'setup.py'))\n"", ' \n']","[' import subprocess\n', ' \n', ' import numpy as np\n', '-from numpy.testing import assert_equal\n', ' \n', "" is_inplace = isfile(pathjoin(dirname(np.__file__),  '..', 'setup.py'))\n"", ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     assert_equal(stdout.strip(), np.__version__.encode('ascii'))\n"", ' \n', ' \n', '+@pytest.mark.skipif(IS_WASM, reason=""Cannot start subprocess"")\n', ' def test_pep338():\n', ""     stdout = subprocess.check_output([sys.executable, '-mnumpy.f2py', '-v'])\n"", ""     assert_equal(stdout.strip(), np.__version__.encode('ascii'))\n""]","[""     assert_equal(stdout.strip(), np.__version__.encode('ascii'))\n"", ' \n', ' \n', ' def test_pep338():\n', ""     stdout = subprocess.check_output([sys.executable, '-mnumpy.f2py', '-v'])\n"", ""     assert_equal(stdout.strip(), np.__version__.encode('ascii'))\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' from typing import Any\n', ' import numpy as np\n', '+import pytest\n', ' \n', ' c16 = np.complex128(1)\n', ' f8 = np.float64(1)\n']","[' \n', ' from typing import Any\n', ' import numpy as np\n', ' \n', ' c16 = np.complex128(1)\n', ' f8 = np.float64(1)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' AR_LIKE_c - AR_O\n', ' AR_LIKE_O - AR_O\n', ' \n', '+AR_u += AR_b\n', '+AR_u += AR_u\n', '+AR_u += 1  # Allowed during runtime as long as the object is 0D and >=0\n', '+\n', ' # Array floor division\n', ' \n', ' AR_b // AR_LIKE_b\n']","[' AR_LIKE_c - AR_O\n', ' AR_LIKE_O - AR_O\n', ' \n', ' # Array floor division\n', ' \n', ' AR_b // AR_LIKE_b\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' -f4\n', ' -i8\n', ' -i4\n', '+with pytest.warns(RuntimeWarning):\n', '+    -u8\n', '+    -u4\n', ' -td\n', ' -AR_f\n', ' \n']","[' -f4\n', ' -i8\n', ' -i4\n', '--u8\n', '--u4\n', ' -td\n', ' -AR_f\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' B1 = np.empty((1,), dtype=np.int32).view(SubClass)\n', ' B2 = np.empty((1, 1), dtype=np.int32).view(SubClass)\n', ' C: np.ndarray[Any, np.dtype[np.int32]] = np.array([0, 1, 2], dtype=np.int32)\n', '+D = np.ones(3).view(SubClass)\n', ' \n', ' i4.all()\n', ' A.all()\n']","[' B1 = np.empty((1,), dtype=np.int32).view(SubClass)\n', ' B2 = np.empty((1, 1), dtype=np.int32).view(SubClass)\n', ' C: np.ndarray[Any, np.dtype[np.int32]] = np.array([0, 1, 2], dtype=np.int32)\n', '-D = np.empty(3).view(SubClass)\n', ' \n', ' i4.all()\n', ' A.all()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' random_st.tomaxint()\n', ' random_st.tomaxint(1)\n', ' random_st.tomaxint((1,))\n', '+\n', '+np.random.set_bit_generator(SEED_PCG64)\n', '+np.random.get_bit_generator()\n']","[' random_st.tomaxint()\n', ' random_st.tomaxint(1)\n', ' random_st.tomaxint((1,))\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' np.void(np.bool_(True))\n', ' np.void(b""test"")\n', ' np.void(np.bytes_(""test""))\n', '+np.void(object(), [(""a"", ""O""), (""b"", ""O"")])\n', '+np.void(object(), dtype=[(""a"", ""O""), (""b"", ""O"")])\n', ' \n', ' # Protocols\n', ' i8 = np.int64()\n']","[' np.void(np.bool_(True))\n', ' np.void(b""test"")\n', ' np.void(np.bytes_(""test""))\n', ' \n', ' # Protocols\n', ' i8 = np.int64()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' c16.transpose()\n', ' \n', ' # Aliases\n', ' np.string_()\n', ' \n', ' np.byte()\n', ' np.short()\n', ' np.intc()\n', ' np.intp()\n', ' np.int_()\n', ' np.longlong()\n', ' \n']","[' c16.transpose()\n', ' \n', ' # Aliases\n', '-np.str0()\n', '-np.bool8()\n', '-np.bytes0()\n', ' np.string_()\n', '-np.object0()\n', '-np.void0(0)\n', ' \n', ' np.byte()\n', ' np.short()\n', ' np.intc()\n', ' np.intp()\n', '-np.int0()\n', ' np.int_()\n', ' np.longlong()\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' np.ushort()\n', ' np.uintc()\n', ' np.uintp()\n', ' np.uint()\n', ' np.ulonglong()\n', ' \n']","[' np.ushort()\n', ' np.uintc()\n', ' np.uintp()\n', '-np.uint0()\n', ' np.uint()\n', ' np.ulonglong()\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import pytest\n', ' import numpy as np\n', ' from numpy._typing._generic_alias import _GenericAlias\n', '+from typing_extensions import Unpack\n', ' \n', ' ScalarType = TypeVar(""ScalarType"", bound=np.generic, covariant=True)\n', ' T1 = TypeVar(""T1"")\n']","[' import pytest\n', ' import numpy as np\n', ' from numpy._typing._generic_alias import _GenericAlias\n', ' \n', ' ScalarType = TypeVar(""ScalarType"", bound=np.generic, covariant=True)\n', ' T1 = TypeVar(""T1"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         (""__origin__"", lambda n: n.__origin__),\n', '         (""__args__"", lambda n: n.__args__),\n', '         (""__parameters__"", lambda n: n.__parameters__),\n', '         (""__mro_entries__"", lambda n: n.__mro_entries__([object])),\n', '         (""__hash__"", lambda n: hash(n)),\n', '         (""__repr__"", lambda n: repr(n)),\n']","['         (""__origin__"", lambda n: n.__origin__),\n', '         (""__args__"", lambda n: n.__args__),\n', '         (""__parameters__"", lambda n: n.__parameters__),\n', '-        (""__reduce__"", lambda n: n.__reduce__()[1:]),\n', '-        (""__reduce_ex__"", lambda n: n.__reduce_ex__(1)[1:]),\n', '         (""__mro_entries__"", lambda n: n.__mro_entries__([object])),\n', '         (""__hash__"", lambda n: hash(n)),\n', '         (""__repr__"", lambda n: repr(n)),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         (""__getitem__"", lambda n: n[Union[T1, T2]][np.float32, np.float64]),\n', '         (""__eq__"", lambda n: n == n),\n', '         (""__ne__"", lambda n: n != np.ndarray),\n', '         (""__call__"", lambda n: n((1,), np.int64, BUFFER)),\n', '         (""__call__"", lambda n: n(shape=(1,), dtype=np.int64, buffer=BUFFER)),\n', '         (""subclassing"", lambda n: _get_subclass_mro(n)),\n']","['         (""__getitem__"", lambda n: n[Union[T1, T2]][np.float32, np.float64]),\n', '         (""__eq__"", lambda n: n == n),\n', '         (""__ne__"", lambda n: n != np.ndarray),\n', '-        (""__dir__"", lambda n: dir(n)),\n', '         (""__call__"", lambda n: n((1,), np.int64, BUFFER)),\n', '         (""__call__"", lambda n: n(shape=(1,), dtype=np.int64, buffer=BUFFER)),\n', '         (""subclassing"", lambda n: _get_subclass_mro(n)),\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             value_ref = func(NDArray_ref)\n', '             assert value == value_ref\n', ' \n', '+    def test_dir(self) -> None:\n', '+        value = dir(NDArray)\n', '+        if sys.version_info < (3, 9):\n', '+            return\n', '+\n', '+        # A number attributes only exist in `types.GenericAlias` in >= 3.11\n', '+        if sys.version_info < (3, 11, 0, ""beta"", 3):\n', '+            value.remove(""__typing_unpacked_tuple_args__"")\n', '+        if sys.version_info < (3, 11, 0, ""beta"", 1):\n', '+            value.remove(""__unpacked__"")\n', '+        assert value == dir(NDArray_ref)\n', '+\n', '+    @pytest.mark.parametrize(""name,func,dev_version"", [\n', '+        (""__iter__"", lambda n: len(list(n)), (""beta"", 1)),\n', '+        (""__iter__"", lambda n: next(iter(n)), (""beta"", 1)),\n', '+        (""__unpacked__"", lambda n: n.__unpacked__, (""beta"", 1)),\n', '+        (""Unpack"", lambda n: Unpack[n], (""beta"", 1)),\n', '+\n', '+        # The right operand should now have `__unpacked__ = True`,\n', '+        # and they are thus now longer equivalent\n', '+        (""__ne__"", lambda n: n != next(iter(n)), (""beta"", 1)),\n', '+\n', '+        # >= beta3\n', '+        (""__typing_unpacked_tuple_args__"",\n', '+         lambda n: n.__typing_unpacked_tuple_args__, (""beta"", 3)),\n', '+\n', '+        # >= beta4\n', '+        (""__class__"", lambda n: n.__class__ == type(n), (""beta"", 4)),\n', '+    ])\n', '+    def test_py311_features(\n', '+        self,\n', '+        name: str,\n', '+        func: FuncType,\n', '+        dev_version: tuple[str, int],\n', '+    ) -> None:\n', '+        """"""Test Python 3.11 features.""""""\n', '+        value = func(NDArray)\n', '+\n', '+        if sys.version_info >= (3, 11, 0, *dev_version):\n', '+            value_ref = func(NDArray_ref)\n', '+            assert value == value_ref\n', '+\n', '     def test_weakref(self) -> None:\n', '         """"""Test ``__weakref__``.""""""\n', '         value = weakref.ref(NDArray)()\n']","['             value_ref = func(NDArray_ref)\n', '             assert value == value_ref\n', ' \n', '     def test_weakref(self) -> None:\n', '         """"""Test ``__weakref__``.""""""\n', '         value = weakref.ref(NDArray)()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from __future__ import annotations\n', ' \n', ' import sys\n', '+from typing import (\n', '+    get_type_hints,\n', '+    Union,\n', '+    NamedTuple,\n', '+    get_args,\n', '+    get_origin,\n', '+    Any,\n', '+)\n', ' \n', ' import pytest\n', ' import numpy as np\n', ' import numpy.typing as npt\n', '+import numpy._typing as _npt\n', ' \n', ' \n', ' class TypeTup(NamedTuple):\n']","[' from __future__ import annotations\n', ' \n', ' import sys\n', '-from typing import get_type_hints, Union, NamedTuple, get_args, get_origin\n', ' \n', ' import pytest\n', ' import numpy as np\n', ' import numpy.typing as npt\n', ' \n', ' \n', ' class TypeTup(NamedTuple):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     keys = TYPES.keys()\n', '     ref = set(npt.__all__)\n', '     assert keys == ref\n', '+\n', '+\n', '+PROTOCOLS: dict[str, tuple[type[Any], object]] = {\n', '+    ""_SupportsDType"": (_npt._SupportsDType, np.int64(1)),\n', '+    ""_SupportsArray"": (_npt._SupportsArray, np.arange(10)),\n', '+    ""_SupportsArrayFunc"": (_npt._SupportsArrayFunc, np.arange(10)),\n', '+    ""_NestedSequence"": (_npt._NestedSequence, [1]),\n', '+}\n', '+\n', '+\n', '+@pytest.mark.parametrize(""cls,obj"", PROTOCOLS.values(), ids=PROTOCOLS.keys())\n', '+class TestRuntimeProtocol:\n', '+    def test_isinstance(self, cls: type[Any], obj: object) -> None:\n', '+        assert isinstance(obj, cls)\n', '+        assert not isinstance(None, cls)\n', '+\n', '+    def test_issubclass(self, cls: type[Any], obj: object) -> None:\n', '+        if cls is _npt._SupportsDType:\n', '+            pytest.xfail(\n', '+                ""Protocols with non-method members don\'t support issubclass()""\n', '+            )\n', '+        assert issubclass(type(obj), cls)\n', '+        assert not issubclass(type(None), cls)\n']","['     keys = TYPES.keys()\n', '     ref = set(npt.__all__)\n', '     assert keys == ref\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.24.0-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.23.0-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" run(['git', 'init'])\n"", ' # ensure the working branch is called ""main""\n', '+# (`--initial-branch=main` appeared to have failed on older git versions):\n', "" run(['git', 'checkout', '-b', 'main'])\n"", "" run(['git', 'remote', 'add', 'origin',  args.remote])\n"", "" run(['git', 'config', '--local', 'user.name', args.committer])\n""]","[' \n', "" run(['git', 'init'])\n"", ' # ensure the working branch is called ""main""\n', '-# (`--initial-branch=main` appared to have failed on older git versions):\n', "" run(['git', 'checkout', '-b', 'main'])\n"", "" run(['git', 'remote', 'add', 'origin',  args.remote])\n"", "" run(['git', 'config', '--local', 'user.name', args.committer])\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' files; while waiting for a proper build system. Uses file hashes to\n', ' figure out if rebuild is needed.\n', ' \n', ' Originally written by Dag Sverre Seljebotn, and copied here from:\n', ' \n', ' https://raw.github.com/dagss/private-scipy-refactor/cythonize/cythonize.py\n']","[' files; while waiting for a proper build system. Uses file hashes to\n', ' figure out if rebuild is needed.\n', ' \n', '-For now, this script should be run by developers when changing Cython files\n', '-only, and the resulting C files checked in, so that end-users (and Python-only\n', '-developers) do not get the Cython/Tempita dependencies.\n', '-\n', ' Originally written by Dag Sverre Seljebotn, and copied here from:\n', ' \n', ' https://raw.github.com/dagss/private-scipy-refactor/cythonize/cythonize.py\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import urllib3\n', ' from bs4 import BeautifulSoup\n', ' \n', '+__version__ = ""0.1""\n', ' \n', ' # Edit these for other projects.\n', '+STAGING_URL = ""https://anaconda.org/multibuild-wheels-staging/numpy""\n', '+PREFIX = ""numpy""\n', '+\n', '+# Name endings of the files to download.\n', '+WHL = r""-.*\\.whl$""\n', '+ZIP = r""\\.zip$""\n', '+GZIP = r""\\.tar\\.gz$""\n', '+SUFFIX = rf""({WHL}|{GZIP}|{ZIP})""\n', ' \n', ' \n', ' def get_wheel_names(version):\n']","[' import urllib3\n', ' from bs4 import BeautifulSoup\n', ' \n', ""-__version__ = '0.1'\n"", ' \n', ' # Edit these for other projects.\n', ""-STAGING_URL = 'https://anaconda.org/multibuild-wheels-staging/numpy'\n"", ""-PREFIX = 'numpy'\n"", ' \n', ' \n', ' def get_wheel_names(version):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         The release version. For instance, ""1.18.3"".\n', ' \n', '     """"""\n', '+    http = urllib3.PoolManager(cert_reqs=""CERT_REQUIRED"")\n', '+    tmpl = re.compile(rf""^.*{PREFIX}-{version}{SUFFIX}"")\n', '     index_url = f""{STAGING_URL}/files""\n', '+    index_html = http.request(""GET"", index_url)\n', '+    soup = BeautifulSoup(index_html.data, ""html.parser"")\n', '     return soup.findAll(text=tmpl)\n', ' \n', ' \n']","['         The release version. For instance, ""1.18.3"".\n', ' \n', '     """"""\n', ""-    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED')\n"", '-    tmpl = re.compile(rf""^.*{PREFIX}-{version}-.*\\.whl$"")\n', '     index_url = f""{STAGING_URL}/files""\n', ""-    index_html = http.request('GET', index_url)\n"", ""-    soup = BeautifulSoup(index_html.data, 'html.parser')\n"", '     return soup.findAll(text=tmpl)\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         Directory in which to download the wheels.\n', ' \n', '     """"""\n', '+    http = urllib3.PoolManager(cert_reqs=""CERT_REQUIRED"")\n', '     wheel_names = get_wheel_names(version)\n', ' \n', '     for i, wheel_name in enumerate(wheel_names):\n', '         wheel_url = f""{STAGING_URL}/{version}/download/{wheel_name}""\n', '         wheel_path = os.path.join(wheelhouse, wheel_name)\n', '+        with open(wheel_path, ""wb"") as f:\n', '+            with http.request(""GET"", wheel_url, preload_content=False,) as r:\n', '                 print(f""{i + 1:<4}{wheel_name}"")\n', '                 shutil.copyfileobj(r, f)\n', '     print(f""\\nTotal files downloaded: {len(wheel_names)}"")\n', ' \n', ' \n', '+if __name__ == ""__main__"":\n', '     parser = argparse.ArgumentParser()\n', '     parser.add_argument(\n', '         ""version"",\n']","['         Directory in which to download the wheels.\n', ' \n', '     """"""\n', ""-    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED')\n"", '     wheel_names = get_wheel_names(version)\n', ' \n', '     for i, wheel_name in enumerate(wheel_names):\n', '         wheel_url = f""{STAGING_URL}/{version}/download/{wheel_name}""\n', '         wheel_path = os.path.join(wheelhouse, wheel_name)\n', ""-        with open(wheel_path, 'wb') as f:\n"", ""-            with http.request('GET', wheel_url, preload_content=False,) as r:\n"", '                 print(f""{i + 1:<4}{wheel_name}"")\n', '                 shutil.copyfileobj(r, f)\n', '     print(f""\\nTotal files downloaded: {len(wheel_names)}"")\n', ' \n', ' \n', ""-if __name__ == '__main__':\n"", '     parser = argparse.ArgumentParser()\n', '     parser.add_argument(\n', '         ""version"",\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from urllib.request import urlopen, Request\n', ' from urllib.error import HTTPError\n', ' \n', ""+OPENBLAS_V = '0.3.21'\n"", ""+OPENBLAS_LONG = 'v0.3.21'\n"", "" BASE_LOC = 'https://anaconda.org/multibuild-wheels-staging/openblas-libs'\n"", "" BASEURL = f'{BASE_LOC}/{OPENBLAS_LONG}/download'\n"", ' SUPPORTED_PLATFORMS = [\n']","[' from urllib.request import urlopen, Request\n', ' from urllib.error import HTTPError\n', ' \n', ""-OPENBLAS_V = '0.3.20'\n"", ""-OPENBLAS_LONG = 'v0.3.20'\n"", "" BASE_LOC = 'https://anaconda.org/multibuild-wheels-staging/openblas-libs'\n"", "" BASEURL = f'{BASE_LOC}/{OPENBLAS_LONG}/download'\n"", ' SUPPORTED_PLATFORMS = [\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def get_manylinux(arch):\n', ""+    default = '2014'\n"", '     ret = os.environ.get(""MB_ML_VER"", default)\n', '     # XXX For PEP 600 this can be a glibc version\n', ""+    assert ret in ('2010', '2014', '_2_24'), f'invalid MB_ML_VER {ret}'\n"", '     return ret\n', ' \n', ' \n']","[' \n', ' \n', ' def get_manylinux(arch):\n', ""-    if arch in ('x86_64', 'i686'):\n"", ""-        default = '2010'\n"", '-    else:\n', ""-        default = '2014'\n"", '     ret = os.environ.get(""MB_ML_VER"", default)\n', '     # XXX For PEP 600 this can be a glibc version\n', ""-    assert ret in ('1', '2010', '2014', '_2_24'), f'invalid MB_ML_VER {ret}'\n"", '     return ret\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         suffix = f'manylinux{ml_ver}_{arch}.tar.gz'\n"", ""         typ = 'tar.gz'\n"", ""     elif plat == 'macosx-x86_64':\n"", ""+        suffix = 'macosx_10_9_x86_64-gf_c469a42.tar.gz'\n"", ""         typ = 'tar.gz'\n"", ""     elif plat == 'macosx-arm64':\n"", ""+        suffix = 'macosx_11_0_arm64-gf_5272328.tar.gz'\n"", ""         typ = 'tar.gz'\n"", ""     elif osname == 'win':\n"", '         if plat == ""win-32"":\n', ""+            suffix = 'win32-gcc_8_3_0.zip'\n"", '         else:\n', ""+            suffix = 'win_amd64-gcc_10_3_0.zip'\n"", ""         typ = 'zip'\n"", ' \n', '     if not suffix:\n']","[""         suffix = f'manylinux{ml_ver}_{arch}.tar.gz'\n"", ""         typ = 'tar.gz'\n"", ""     elif plat == 'macosx-x86_64':\n"", ""-        suffix = 'macosx_10_9_x86_64-gf_1becaaa.tar.gz'\n"", ""         typ = 'tar.gz'\n"", ""     elif plat == 'macosx-arm64':\n"", ""-        suffix = 'macosx_11_0_arm64-gf_f26990f.tar.gz'\n"", ""         typ = 'tar.gz'\n"", ""     elif osname == 'win':\n"", '         if plat == ""win-32"":\n', ""-            suffix = 'win32-gcc_8_1_0.zip'\n"", '         else:\n', ""-            suffix = 'win_amd64-gcc_8_1_0.zip'\n"", ""         typ = 'zip'\n"", ' \n', '     if not suffix:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if response.status != 200:\n', '         print(f\'Could not download ""{filename}""\', file=sys.stderr)\n', '         return None\n', '+    # print(f""Downloading {length} from {filename}"", file=sys.stderr)\n', '     data = response.read()\n', '     # Verify hash\n', '     key = os.path.basename(filename)\n', '+    # print(""Saving to file"", file=sys.stderr)\n', ""     with open(target, 'wb') as fid:\n"", '         fid.write(data)\n', '     return typ\n']","['     if response.status != 200:\n', '         print(f\'Could not download ""{filename}""\', file=sys.stderr)\n', '         return None\n', '-    print(f""Downloading {length} from {filename}"", file=sys.stderr)\n', '     data = response.read()\n', '     # Verify hash\n', '     key = os.path.basename(filename)\n', '-    print(""Saving to file"", file=sys.stderr)\n', ""     with open(target, 'wb') as fid:\n"", '         fid.write(data)\n', '     return typ\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     if osname == 'win':\n"", ""         if not typ == 'zip':\n"", ""             return f'expecting to download zipfile on windows, not {typ}'\n"", '+        return unpack_windows_zip(tmp, plat)\n', '     else:\n', ""         if not typ == 'tar.gz':\n"", ""             return 'expecting to download tar.gz, not %s' % str(typ)\n"", '         return unpack_targz(tmp)\n', ' \n', ' \n', '+def unpack_windows_zip(fname, plat):\n', ""+    unzip_base = os.path.join(gettempdir(), 'openblas')\n"", '+    if not os.path.exists(unzip_base):\n', '+        os.mkdir(unzip_base)\n', ""     with zipfile.ZipFile(fname, 'r') as zf:\n"", '+        zf.extractall(unzip_base)\n', '+    if plat == ""win-32"":\n', '+        target = os.path.join(unzip_base, ""32"")\n', '+    else:\n', '+        target = os.path.join(unzip_base, ""64"")\n', '+    # Copy the lib to openblas.lib. Once we can properly use pkg-config\n', '+    # this will not be needed\n', ""+    lib = glob.glob(os.path.join(target, 'lib', '*.lib'))\n"", '+    assert len(lib) == 1\n', '+    for f in lib:\n', ""+        shutil.copy(f, os.path.join(target, 'lib', 'openblas.lib'))\n"", ""+        shutil.copy(f, os.path.join(target, 'lib', 'openblas64_.lib'))\n"", '+    # Copy the dll from bin to lib so system_info can pick it up\n', ""+    dll = glob.glob(os.path.join(target, 'bin', '*.dll'))\n"", '+    for f in dll:\n', ""+        shutil.copy(f, os.path.join(target, 'lib'))\n"", '     return target\n', ' \n', ' \n']","[""     if osname == 'win':\n"", ""         if not typ == 'zip':\n"", ""             return f'expecting to download zipfile on windows, not {typ}'\n"", '-        return unpack_windows_zip(tmp)\n', '     else:\n', ""         if not typ == 'tar.gz':\n"", ""             return 'expecting to download tar.gz, not %s' % str(typ)\n"", '         return unpack_targz(tmp)\n', ' \n', ' \n', '-def unpack_windows_zip(fname):\n', ""     with zipfile.ZipFile(fname, 'r') as zf:\n"", '-        # Get the openblas.a file, but not openblas.dll.a nor openblas.dev.a\n', '-        lib = [x for x in zf.namelist() if OPENBLAS_LONG in x and\n', ""-               x.endswith('a') and not x.endswith('dll.a') and\n"", ""-               not x.endswith('dev.a')]\n"", '-        if not lib:\n', ""-            return 'could not find libopenblas_%s*.a ' \\\n"", ""-                    'in downloaded zipfile' % OPENBLAS_LONG\n"", '-        if get_ilp64() is None:\n', ""-            target = os.path.join(gettempdir(), 'openblas.a')\n"", '-        else:\n', ""-            target = os.path.join(gettempdir(), 'openblas64_.a')\n"", ""-        with open(target, 'wb') as fid:\n"", '-            fid.write(zf.read(lib[0]))\n', '     return target\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' def test_setup(plats):\n', ""     '''\n"", '+    Make sure all the downloadable files needed for wheel building\n', '+    exist and can be opened\n', ""     '''\n"", '     def items():\n', '         """""" yields all combinations of arch, ilp64\n']","[' \n', ' def test_setup(plats):\n', ""     '''\n"", '-    Make sure all the downloadable files exist and can be opened\n', ""     '''\n"", '     def items():\n', '         """""" yields all combinations of arch, ilp64\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         for plat in plats:\n', '             yield plat, None\n', '             osname, arch = plat.split(""-"")\n', ""+            if arch not in ('i686', '32'):\n"", ""                 yield plat, '64_'\n"", ' \n', '     errs = []\n', '     for plat, ilp64 in items():\n']","['         for plat in plats:\n', '             yield plat, None\n', '             osname, arch = plat.split(""-"")\n', ""-            if arch not in ('i686', 'arm64', '32'):\n"", ""                 yield plat, '64_'\n"", '-            if osname == ""linux"" and arch in (\'i686\', \'x86_64\'):\n', ""-                oldval = os.environ.get('MB_ML_VER', None)\n"", ""-                os.environ['MB_ML_VER'] = '1'\n"", '-                yield plat, None\n', '-                # Once we create x86_64 and i686 manylinux2014 wheels...\n', ""-                # os.environ['MB_ML_VER'] = '2014'\n"", '-                # yield arch, None, False\n', '-                if oldval:\n', ""-                    os.environ['MB_ML_VER'] = oldval\n"", '-                else:\n', ""-                    os.environ.pop('MB_ML_VER')\n"", ' \n', '     errs = []\n', '     for plat, ilp64 in items():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 continue\n', '             if not target:\n', ""                 raise RuntimeError(f'Could not setup {plat}')\n"", ""+            print('success with', plat, ilp64)\n"", ""             if osname == 'win':\n"", ""                 if not target.endswith('.a'):\n"", '                     raise RuntimeError(""Not .a extracted!"")\n']","['                 continue\n', '             if not target:\n', ""                 raise RuntimeError(f'Could not setup {plat}')\n"", '-            print(target)\n', ""             if osname == 'win':\n"", ""                 if not target.endswith('.a'):\n"", '                     raise RuntimeError(""Not .a extracted!"")\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         raise errs[0]\n', ' \n', ' \n', '+def test_version(expected_version=None):\n', '     """"""\n', '     Assert that expected OpenBLAS version is\n', '+    actually available via NumPy. Requires threadpoolctl\n', '     """"""\n', '     import numpy\n', '+    import threadpoolctl\n', ' \n', '+    data = threadpoolctl.threadpool_info()\n', '+    if len(data) != 1:\n', '+        raise ValueError(f""expected single threadpool_info result, got {data}"")\n', '     if not expected_version:\n', '         expected_version = OPENBLAS_V\n', ""+    if data[0]['version'] != expected_version:\n"", '+        raise ValueError(\n', '+            f""expected OpenBLAS version {expected_version}, got {data}""\n', '+        )\n', '+    print(""OK"")\n', ' \n', "" if __name__ == '__main__':\n"", '     import argparse\n']","['         raise errs[0]\n', ' \n', ' \n', '-def test_version(expected_version, ilp64=get_ilp64()):\n', '     """"""\n', '     Assert that expected OpenBLAS version is\n', '-    actually available via NumPy\n', '     """"""\n', '     import numpy\n', '-    import ctypes\n', ' \n', '-    dll = ctypes.CDLL(numpy.core._multiarray_umath.__file__)\n', '-    if ilp64 == ""64_"":\n', '-        get_config = dll.openblas_get_config64_\n', '-    else:\n', '-        get_config = dll.openblas_get_config\n', '-    get_config.restype = ctypes.c_char_p\n', '-    res = get_config()\n', ""-    print('OpenBLAS get_config returned', str(res))\n"", '     if not expected_version:\n', '         expected_version = OPENBLAS_V\n', ""-    check_str = b'OpenBLAS %s' % expected_version.encode()\n"", '-    print(check_str)\n', ""-    assert check_str in res, f'{expected_version} not found in {res}'\n"", '-    if ilp64:\n', '-        assert b""USE64BITINT"" in res\n', '-    else:\n', '-        assert b""USE64BITINT"" not in res\n', '-\n', ' \n', "" if __name__ == '__main__':\n"", '     import argparse\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' from doctest import NORMALIZE_WHITESPACE, ELLIPSIS, IGNORE_EXCEPTION_DETAIL\n', ' \n', ' from docutils.parsers.rst import directives\n', ' \n', ' import sphinx\n', ' import numpy as np\n']","[' from doctest import NORMALIZE_WHITESPACE, ELLIPSIS, IGNORE_EXCEPTION_DETAIL\n', ' \n', ' from docutils.parsers.rst import directives\n', '-from pkg_resources import parse_version\n', ' \n', ' import sphinx\n', ' import numpy as np\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', "" SKIPBLOCK = doctest.register_optionflag('SKIPBLOCK')\n"", ' \n', '+# Enable specific Sphinx directives\n', '+from sphinx.directives.other import SeeAlso, Only\n', ""+directives.register_directive('seealso', SeeAlso)\n"", ""+directives.register_directive('only', Only)\n"", ' \n', ' \n', ' BASE_MODULE = ""numpy""\n']","[' \n', "" SKIPBLOCK = doctest.register_optionflag('SKIPBLOCK')\n"", ' \n', ""-if parse_version(sphinx.__version__) >= parse_version('1.5'):\n"", '-    # Enable specific Sphinx directives\n', '-    from sphinx.directives.other import SeeAlso, Only\n', ""-    directives.register_directive('seealso', SeeAlso)\n"", ""-    directives.register_directive('only', Only)\n"", '-else:\n', ""-    # Remove sphinx directives that don't run without Sphinx environment.\n"", '-    # Sphinx < 1.5 installs all directives on import...\n', ""-    directives._directives.pop('versionadded', None)\n"", ""-    directives._directives.pop('versionchanged', None)\n"", ""-    directives._directives.pop('moduleauthor', None)\n"", ""-    directives._directives.pop('sectionauthor', None)\n"", ""-    directives._directives.pop('codeauthor', None)\n"", ""-    directives._directives.pop('toctree', None)\n"", ' \n', ' \n', ' BASE_MODULE = ""numpy""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""     'f2py.getting-started.rst',\n"", ""     'f2py-examples.rst',\n"", ""     'arrays.nditer.cython.rst',\n"", ""+    'how-to-verify-bug.rst',\n"", '     # See PR 17222, these should be fixed\n', ""     'basics.dispatch.rst',\n"", ""     'basics.subclassing.rst',\n"", ""     'basics.interoperability.rst',\n"", ""     'misc.rst',\n"", ""+    'TESTS.rst'\n"", ' ]\n', ' \n', ' # these names are not required to be present in ALL despite being in\n']","[""     'f2py.getting-started.rst',\n"", ""     'f2py-examples.rst',\n"", ""     'arrays.nditer.cython.rst',\n"", '     # See PR 17222, these should be fixed\n', ""     'basics.dispatch.rst',\n"", ""     'basics.subclassing.rst',\n"", ""     'basics.interoperability.rst',\n"", ""     'misc.rst',\n"", ' ]\n', ' \n', ' # these names are not required to be present in ALL despite being in\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         init_matplotlib()\n', ' \n', '     for submodule_name in module_names:\n', ""+        prefix = BASE_MODULE + '.'\n"", '+        if not submodule_name.startswith(prefix):\n', '+            module_name = prefix + submodule_name\n', '+        else:\n', '+            module_name = submodule_name\n', '+\n', '         __import__(module_name)\n', '         module = sys.modules[module_name]\n', ' \n']","['         init_matplotlib()\n', ' \n', '     for submodule_name in module_names:\n', ""-        module_name = BASE_MODULE + '.' + submodule_name\n"", '         __import__(module_name)\n', '         module = sys.modules[module_name]\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '+# Version: 0.26\n', ' \n', ' """"""The Versioneer - like a rocketeer, but for versions.\n', ' \n']","[' \n', '-# Version: 0.19\n', ' \n', ' """"""The Versioneer - like a rocketeer, but for versions.\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' * like a rocketeer, but for versions!\n', ' * https://github.com/python-versioneer/python-versioneer\n', ' * Brian Warner\n', '+* License: Public Domain (Unlicense)\n', '+* Compatible with: Python 3.7, 3.8, 3.9, 3.10 and pypy3\n', ' * [![Latest Version][pypi-image]][pypi-url]\n', ' * [![Build Status][travis-image]][travis-url]\n', ' \n', '+This is a tool for managing a recorded version number in setuptools-based\n', ' python projects. The goal is to remove the tedious and error-prone ""update\n', ' the embedded version string"" step from your release process. Making a new\n', ' release should be as easy as recording a new tag in your version-control\n']","[' * like a rocketeer, but for versions!\n', ' * https://github.com/python-versioneer/python-versioneer\n', ' * Brian Warner\n', '-* License: Public Domain\n', '-* Compatible with: Python 3.6, 3.7, 3.8, 3.9 and pypy3\n', ' * [![Latest Version][pypi-image]][pypi-url]\n', ' * [![Build Status][travis-image]][travis-url]\n', ' \n', '-This is a tool for managing a recorded version number in distutils-based\n', ' python projects. The goal is to remove the tedious and error-prone ""update\n', ' the embedded version string"" step from your release process. Making a new\n', ' release should be as easy as recording a new tag in your version-control\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' ## Quick Install\n', ' \n', '+Versioneer provides two installation modes. The ""classic"" vendored mode installs\n', '+a copy of versioneer into your repository. The experimental build-time dependency mode\n', '+is intended to allow you to skip this step and simplify the process of upgrading.\n', '+\n', '+### Vendored mode\n', '+\n', '+* `pip install versioneer` to somewhere in your $PATH\n', '+* add a `[tool.versioneer]` section to your `pyproject.toml or a\n', '+  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))\n', '+* run `versioneer install --vendor` in your source tree, commit the results\n', '+* verify version information with `python setup.py version`\n', '+\n', '+### Build-time dependency mode\n', '+\n', ' * `pip install versioneer` to somewhere in your $PATH\n', '+* add a `[tool.versioneer]` section to your `pyproject.toml or a\n', '+  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))\n', '+* add `versioneer` to the `requires` key of the `build-system` table in\n', '+  `pyproject.toml`:\n', '+  ```toml\n', '+  [build-system]\n', '+  requires = [""setuptools"", ""versioneer""]\n', '+  build-backend = ""setuptools.build_meta""\n', '+  ```\n', '+* run `versioneer install --no-vendor` in your source tree, commit the results\n', '+* verify version information with `python setup.py version`\n', ' \n', ' ## Version Identifiers\n', ' \n']","[' \n', ' ## Quick Install\n', ' \n', ' * `pip install versioneer` to somewhere in your $PATH\n', '-* add a `[versioneer]` section to your setup.cfg (see [Install](INSTALL.md))\n', '-* run `versioneer install` in your source tree, commit the results\n', '-* Verify version information with `python setup.py version`\n', ' \n', ' ## Version Identifiers\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' To upgrade your project to a new release of Versioneer, do the following:\n', ' \n', ' * install the new Versioneer (`pip install -U versioneer` or equivalent)\n', '+* edit `setup.cfg` and `pyproject.toml`, if necessary,\n', '+  to include any new configuration settings indicated by the release notes.\n', '+  See [UPGRADING](./UPGRADING.md) for details.\n', '+* re-run `versioneer install --[no-]vendor` in your source tree, to replace\n', '   `SRC/_version.py`\n', ' * commit any changed files\n', ' \n']","[' To upgrade your project to a new release of Versioneer, do the following:\n', ' \n', ' * install the new Versioneer (`pip install -U versioneer` or equivalent)\n', '-* edit `setup.cfg`, if necessary, to include any new configuration settings\n', '-  indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.\n', '-* re-run `versioneer install` in your source tree, to replace\n', '   `SRC/_version.py`\n', ' * commit any changed files\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['   dependency\n', ' * [minver](https://github.com/jbweston/miniver) - a lightweight reimplementation of\n', '   versioneer\n', '+* [versioningit](https://github.com/jwodder/versioningit) - a PEP 518-based setuptools\n', '+  plugin\n', ' \n', ' ## License\n', ' \n']","['   dependency\n', ' * [minver](https://github.com/jbweston/miniver) - a lightweight reimplementation of\n', '   versioneer\n', ' \n', ' ## License\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' [travis-url]: https://travis-ci.com/github/python-versioneer/python-versioneer\n', ' \n', ' """"""\n', '+# pylint:disable=invalid-name,import-outside-toplevel,missing-function-docstring\n', '+# pylint:disable=missing-class-docstring,too-many-branches,too-many-statements\n', '+# pylint:disable=raise-missing-from,too-many-lines,too-many-locals,import-error\n', '+# pylint:disable=too-few-public-methods,redefined-outer-name,consider-using-with\n', '+# pylint:disable=attribute-defined-outside-init,too-many-arguments\n', ' \n', ' import configparser\n', ' import errno\n']","[' [travis-url]: https://travis-ci.com/github/python-versioneer/python-versioneer\n', ' \n', ' """"""\n', ' \n', ' import configparser\n', ' import errno\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import re\n', ' import subprocess\n', ' import sys\n', '+from pathlib import Path\n', '+from typing import Callable, Dict\n', '+import functools\n', '+try:\n', '+    import tomli\n', '+    have_tomli = True\n', '+except ImportError:\n', '+    have_tomli = False\n', ' \n', ' \n', ' class VersioneerConfig:\n']","[' import re\n', ' import subprocess\n', ' import sys\n', ' \n', ' \n', ' class VersioneerConfig:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[""         # module-import table will cache the first one. So we can't use\n"", '         # os.path.dirname(__file__), as that will find whichever\n', '         # versioneer.py was first imported, even in later projects.\n', '+        my_path = os.path.realpath(os.path.abspath(__file__))\n', '+        me_dir = os.path.normcase(os.path.splitext(my_path)[0])\n', '         vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n', '+        if me_dir != vsr_dir and ""VERSIONEER_PEP518"" not in globals():\n', '             print(""Warning: build in %s is using versioneer.py from %s""\n', '+                  % (os.path.dirname(my_path), versioneer_py))\n', '     except NameError:\n', '         pass\n', '     return root\n']","[""         # module-import table will cache the first one. So we can't use\n"", '         # os.path.dirname(__file__), as that will find whichever\n', '         # versioneer.py was first imported, even in later projects.\n', '-        me = os.path.realpath(os.path.abspath(__file__))\n', '-        me_dir = os.path.normcase(os.path.splitext(me)[0])\n', '         vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n', '-        if me_dir != vsr_dir:\n', '             print(""Warning: build in %s is using versioneer.py from %s""\n', '-                  % (os.path.dirname(me), versioneer_py))\n', '     except NameError:\n', '         pass\n', '     return root\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' def get_config_from_root(root):\n', '     """"""Read the project setup.cfg file to determine Versioneer config.""""""\n', '+    # This might raise OSError (if setup.cfg is missing), or\n', '     # configparser.NoSectionError (if it lacks a [versioneer] section), or\n', '     # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n', '     # the top of versioneer.py for instructions on writing your setup.cfg .\n', '+    root = Path(root)\n', '+    pyproject_toml = root / ""pyproject.toml""\n', '+    setup_cfg = root / ""setup.cfg""\n', '+    section = None\n', '+    if pyproject_toml.exists() and have_tomli:\n', '+        try:\n', ""+            with open(pyproject_toml, 'rb') as fobj:\n"", '+                pp = tomli.load(fobj)\n', ""+            section = pp['tool']['versioneer']\n"", '+        except (tomli.TOMLDecodeError, KeyError):\n', '+            pass\n', '+    if not section:\n', '+        parser = configparser.ConfigParser()\n', '+        with open(setup_cfg) as cfg_file:\n', '+            parser.read_file(cfg_file)\n', '+        parser.get(""versioneer"", ""VCS"")  # raise error if missing\n', '+\n', '+        section = parser[""versioneer""]\n', '+\n', '     cfg = VersioneerConfig()\n', ""+    cfg.VCS = section['VCS']\n"", '+    cfg.style = section.get(""style"", """")\n', '+    cfg.versionfile_source = section.get(""versionfile_source"")\n', '+    cfg.versionfile_build = section.get(""versionfile_build"")\n', '+    cfg.tag_prefix = section.get(""tag_prefix"")\n', '+    if cfg.tag_prefix in (""\'\'"", \'""""\', None):\n', '         cfg.tag_prefix = """"\n', '+    cfg.parentdir_prefix = section.get(""parentdir_prefix"")\n', '+    cfg.verbose = section.get(""verbose"")\n', '     return cfg\n', ' \n', ' \n']","[' \n', ' def get_config_from_root(root):\n', '     """"""Read the project setup.cfg file to determine Versioneer config.""""""\n', '-    # This might raise EnvironmentError (if setup.cfg is missing), or\n', '     # configparser.NoSectionError (if it lacks a [versioneer] section), or\n', '     # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n', '     # the top of versioneer.py for instructions on writing your setup.cfg .\n', '-    setup_cfg = os.path.join(root, ""setup.cfg"")\n', '-    parser = configparser.ConfigParser()\n', '-    with open(setup_cfg, ""r"") as f:\n', '-        parser.read_file(f)\n', '-    VCS = parser.get(""versioneer"", ""VCS"")  # mandatory\n', '-\n', '-    def get(parser, name):\n', '-        if parser.has_option(""versioneer"", name):\n', '-            return parser.get(""versioneer"", name)\n', '-        return None\n', '     cfg = VersioneerConfig()\n', '-    cfg.VCS = VCS\n', '-    cfg.style = get(parser, ""style"") or """"\n', '-    cfg.versionfile_source = get(parser, ""versionfile_source"")\n', '-    cfg.versionfile_build = get(parser, ""versionfile_build"")\n', '-    cfg.tag_prefix = get(parser, ""tag_prefix"")\n', '-    if cfg.tag_prefix in (""\'\'"", \'""""\'):\n', '         cfg.tag_prefix = """"\n', '-    cfg.parentdir_prefix = get(parser, ""parentdir_prefix"")\n', '-    cfg.verbose = get(parser, ""verbose"")\n', '     return cfg\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' # these dictionaries contain VCS-specific tools\n', '+LONG_VERSION_PY: Dict[str, str] = {}\n', '+HANDLERS: Dict[str, Dict[str, Callable]] = {}\n', ' \n', ' \n', ' def register_vcs_handler(vcs, method):  # decorator\n', '     """"""Create decorator to mark a method as the handler of a VCS.""""""\n', '     def decorate(f):\n', '         """"""Store f in HANDLERS[vcs][method].""""""\n', '+        HANDLERS.setdefault(vcs, {})[method] = f\n', '         return f\n', '     return decorate\n', ' \n']","[' \n', ' \n', ' # these dictionaries contain VCS-specific tools\n', '-LONG_VERSION_PY = {}\n', '-HANDLERS = {}\n', ' \n', ' \n', ' def register_vcs_handler(vcs, method):  # decorator\n', '     """"""Create decorator to mark a method as the handler of a VCS.""""""\n', '     def decorate(f):\n', '         """"""Store f in HANDLERS[vcs][method].""""""\n', '-        if vcs not in HANDLERS:\n', '-            HANDLERS[vcs] = {}\n', '-        HANDLERS[vcs][method] = f\n', '         return f\n', '     return decorate\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 env=None):\n', '     """"""Call the given command(s).""""""\n', '     assert isinstance(commands, list)\n', '+    process = None\n', '+\n', '+    popen_kwargs = {}\n', '+    if sys.platform == ""win32"":\n', '+        # This hides the console window if pythonw.exe is used\n', '+        startupinfo = subprocess.STARTUPINFO()\n', '+        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n', '+        popen_kwargs[""startupinfo""] = startupinfo\n', '+\n', '+    for command in commands:\n', '         try:\n', '+            dispcmd = str([command] + args)\n', '             # remember shell=False, so use git.cmd on windows, not just git\n', '+            process = subprocess.Popen([command] + args, cwd=cwd, env=env,\n', '+                                       stdout=subprocess.PIPE,\n', '+                                       stderr=(subprocess.PIPE if hide_stderr\n', '+                                               else None), **popen_kwargs)\n', '             break\n', '+        except OSError:\n', '             e = sys.exc_info()[1]\n', '             if e.errno == errno.ENOENT:\n', '                 continue\n']","['                 env=None):\n', '     """"""Call the given command(s).""""""\n', '     assert isinstance(commands, list)\n', '-    p = None\n', '-    for c in commands:\n', '         try:\n', '-            dispcmd = str([c] + args)\n', '             # remember shell=False, so use git.cmd on windows, not just git\n', '-            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n', '-                                 stdout=subprocess.PIPE,\n', '-                                 stderr=(subprocess.PIPE if hide_stderr\n', '-                                         else None))\n', '             break\n', '-        except EnvironmentError:\n', '             e = sys.exc_info()[1]\n', '             if e.errno == errno.ENOENT:\n', '                 continue\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if verbose:\n', '             print(""unable to find command, tried %s"" % (commands,))\n', '         return None, None\n', '+    stdout = process.communicate()[0].strip().decode()\n', '+    if process.returncode != 0:\n', '         if verbose:\n', '             print(""unable to run %s (error)"" % dispcmd)\n', '             print(""stdout was %s"" % stdout)\n', '+        return None, process.returncode\n', '+    return stdout, process.returncode\n', ' \n', ' \n', "" LONG_VERSION_PY['git'] = r'''\n""]","['         if verbose:\n', '             print(""unable to find command, tried %s"" % (commands,))\n', '         return None, None\n', '-    stdout = p.communicate()[0].strip().decode()\n', '-    if p.returncode != 0:\n', '         if verbose:\n', '             print(""unable to run %s (error)"" % dispcmd)\n', '             print(""stdout was %s"" % stdout)\n', '-        return None, p.returncode\n', '-    return stdout, p.returncode\n', ' \n', ' \n', "" LONG_VERSION_PY['git'] = r'''\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' # directories (produced by setup.py build) will contain a much shorter file\n', ' # that just contains the computed version number.\n', ' \n', '+# This file is released into the public domain.\n', '+# Generated by versioneer-0.26\n', '+# https://github.com/python-versioneer/python-versioneer\n', ' \n', ' """"""Git implementation of _version.py.""""""\n', ' \n']","[' # directories (produced by setup.py build) will contain a much shorter file\n', ' # that just contains the computed version number.\n', ' \n', '-# This file is released into the public domain. Generated by\n', '-# versioneer-0.19 (https://github.com/python-versioneer/python-versioneer)\n', ' \n', ' """"""Git implementation of _version.py.""""""\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' import re\n', ' import subprocess\n', ' import sys\n', '+from typing import Callable, Dict\n', '+import functools\n', ' \n', ' \n', ' def get_keywords():\n']","[' import re\n', ' import subprocess\n', ' import sys\n', ' \n', ' \n', ' def get_keywords():\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""Exception raised if a method is not valid for the current scenario.""""""\n', ' \n', ' \n', '+LONG_VERSION_PY: Dict[str, str] = {}\n', '+HANDLERS: Dict[str, Dict[str, Callable]] = {}\n', ' \n', ' \n', ' def register_vcs_handler(vcs, method):  # decorator\n']","['     """"""Exception raised if a method is not valid for the current scenario.""""""\n', ' \n', ' \n', '-LONG_VERSION_PY = {}\n', '-HANDLERS = {}\n', ' \n', ' \n', ' def register_vcs_handler(vcs, method):  # decorator\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 env=None):\n', '     """"""Call the given command(s).""""""\n', '     assert isinstance(commands, list)\n', '+    process = None\n', '+\n', '+    popen_kwargs = {}\n', '+    if sys.platform == ""win32"":\n', '+        # This hides the console window if pythonw.exe is used\n', '+        startupinfo = subprocess.STARTUPINFO()\n', '+        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n', '+        popen_kwargs[""startupinfo""] = startupinfo\n', '+\n', '+    for command in commands:\n', '         try:\n', '+            dispcmd = str([command] + args)\n', '             # remember shell=False, so use git.cmd on windows, not just git\n', '+            process = subprocess.Popen([command] + args, cwd=cwd, env=env,\n', '+                                       stdout=subprocess.PIPE,\n', '+                                       stderr=(subprocess.PIPE if hide_stderr\n', '+                                               else None), **popen_kwargs)\n', '             break\n', '+        except OSError:\n', '             e = sys.exc_info()[1]\n', '             if e.errno == errno.ENOENT:\n', '                 continue\n']","['                 env=None):\n', '     """"""Call the given command(s).""""""\n', '     assert isinstance(commands, list)\n', '-    p = None\n', '-    for c in commands:\n', '         try:\n', '-            dispcmd = str([c] + args)\n', '             # remember shell=False, so use git.cmd on windows, not just git\n', '-            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n', '-                                 stdout=subprocess.PIPE,\n', '-                                 stderr=(subprocess.PIPE if hide_stderr\n', '-                                         else None))\n', '             break\n', '-        except EnvironmentError:\n', '             e = sys.exc_info()[1]\n', '             if e.errno == errno.ENOENT:\n', '                 continue\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if verbose:\n', '             print(""unable to find command, tried %%s"" %% (commands,))\n', '         return None, None\n', '+    stdout = process.communicate()[0].strip().decode()\n', '+    if process.returncode != 0:\n', '         if verbose:\n', '             print(""unable to run %%s (error)"" %% dispcmd)\n', '             print(""stdout was %%s"" %% stdout)\n', '+        return None, process.returncode\n', '+    return stdout, process.returncode\n', ' \n', ' \n', ' def versions_from_parentdir(parentdir_prefix, root, verbose):\n']","['         if verbose:\n', '             print(""unable to find command, tried %%s"" %% (commands,))\n', '         return None, None\n', '-    stdout = p.communicate()[0].strip().decode()\n', '-    if p.returncode != 0:\n', '         if verbose:\n', '             print(""unable to run %%s (error)"" %% dispcmd)\n', '             print(""stdout was %%s"" %% stdout)\n', '-        return None, p.returncode\n', '-    return stdout, p.returncode\n', ' \n', ' \n', ' def versions_from_parentdir(parentdir_prefix, root, verbose):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     rootdirs = []\n', ' \n', '+    for _ in range(3):\n', '         dirname = os.path.basename(root)\n', '         if dirname.startswith(parentdir_prefix):\n', '             return {""version"": dirname[len(parentdir_prefix):],\n', '                     ""full-revisionid"": None,\n', '                     ""dirty"": False, ""error"": None, ""date"": None}\n', '+        rootdirs.append(root)\n', '+        root = os.path.dirname(root)  # up a level\n', ' \n', '     if verbose:\n', '         print(""Tried directories %%s but none started with prefix %%s"" %%\n']","['     """"""\n', '     rootdirs = []\n', ' \n', '-    for i in range(3):\n', '         dirname = os.path.basename(root)\n', '         if dirname.startswith(parentdir_prefix):\n', '             return {""version"": dirname[len(parentdir_prefix):],\n', '                     ""full-revisionid"": None,\n', '                     ""dirty"": False, ""error"": None, ""date"": None}\n', '-        else:\n', '-            rootdirs.append(root)\n', '-            root = os.path.dirname(root)  # up a level\n', ' \n', '     if verbose:\n', '         print(""Tried directories %%s but none started with prefix %%s"" %%\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # _version.py.\n', '     keywords = {}\n', '     try:\n', '+        with open(versionfile_abs, ""r"") as fobj:\n', '+            for line in fobj:\n', '+                if line.strip().startswith(""git_refnames =""):\n', '+                    mo = re.search(r\'=\\s*""(.*)""\', line)\n', '+                    if mo:\n', '+                        keywords[""refnames""] = mo.group(1)\n', '+                if line.strip().startswith(""git_full =""):\n', '+                    mo = re.search(r\'=\\s*""(.*)""\', line)\n', '+                    if mo:\n', '+                        keywords[""full""] = mo.group(1)\n', '+                if line.strip().startswith(""git_date =""):\n', '+                    mo = re.search(r\'=\\s*""(.*)""\', line)\n', '+                    if mo:\n', '+                        keywords[""date""] = mo.group(1)\n', '+    except OSError:\n', '         pass\n', '     return keywords\n', ' \n']","['     # _version.py.\n', '     keywords = {}\n', '     try:\n', '-        f = open(versionfile_abs, ""r"")\n', '-        for line in f.readlines():\n', '-            if line.strip().startswith(""git_refnames =""):\n', '-                mo = re.search(r\'=\\s*""(.*)""\', line)\n', '-                if mo:\n', '-                    keywords[""refnames""] = mo.group(1)\n', '-            if line.strip().startswith(""git_full =""):\n', '-                mo = re.search(r\'=\\s*""(.*)""\', line)\n', '-                if mo:\n', '-                    keywords[""full""] = mo.group(1)\n', '-            if line.strip().startswith(""git_date =""):\n', '-                mo = re.search(r\'=\\s*""(.*)""\', line)\n', '-                if mo:\n', '-                    keywords[""date""] = mo.group(1)\n', '-        f.close()\n', '-    except EnvironmentError:\n', '         pass\n', '     return keywords\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @register_vcs_handler(""git"", ""keywords"")\n', ' def git_versions_from_keywords(keywords, tag_prefix, verbose):\n', '     """"""Get version information from git keywords.""""""\n', '+    if ""refnames"" not in keywords:\n', '+        raise NotThisMethod(""Short version file found"")\n', '     date = keywords.get(""date"")\n', '     if date is not None:\n', '         # Use only the last line.  Previous lines may contain GPG signature\n']","[' @register_vcs_handler(""git"", ""keywords"")\n', ' def git_versions_from_keywords(keywords, tag_prefix, verbose):\n', '     """"""Get version information from git keywords.""""""\n', '-    if not keywords:\n', '-        raise NotThisMethod(""no keywords at all, weird"")\n', '     date = keywords.get(""date"")\n', '     if date is not None:\n', '         # Use only the last line.  Previous lines may contain GPG signature\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if verbose:\n', '             print(""keywords are unexpanded, not using"")\n', '         raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n', '+    refs = {r.strip() for r in refnames.strip(""()"").split("","")}\n', '     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n', '     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n', '     TAG = ""tag: ""\n', '+    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n', '     if not tags:\n', ""         # Either we're using git < 1.8.3, or there really are no tags. We use\n"", '         # a heuristic: assume all version tags have a digit. The old git %%d\n']","['         if verbose:\n', '             print(""keywords are unexpanded, not using"")\n', '         raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n', '-    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n', '     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n', '     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n', '     TAG = ""tag: ""\n', '-    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n', '     if not tags:\n', ""         # Either we're using git < 1.8.3, or there really are no tags. We use\n"", '         # a heuristic: assume all version tags have a digit. The old git %%d\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # between branches and tags. By ignoring refnames without digits, we\n', '         # filter out many common branch names like ""release"" and\n', '         # ""stabilization"", as well as ""HEAD"" and ""master"".\n', ""+        tags = {r for r in refs if re.search(r'\\d', r)}\n"", '         if verbose:\n', '             print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n', '     if verbose:\n']","['         # between branches and tags. By ignoring refnames without digits, we\n', '         # filter out many common branch names like ""release"" and\n', '         # ""stabilization"", as well as ""HEAD"" and ""master"".\n', ""-        tags = set([r for r in refs if re.search(r'\\d', r)])\n"", '         if verbose:\n', '             print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n', '     if verbose:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n', '         if ref.startswith(tag_prefix):\n', '             r = ref[len(tag_prefix):]\n', ""+            # Filter out refs that exactly match prefix or that don't start\n"", '+            # with a number once the prefix is stripped (mostly a concern\n', ""+            # when prefix is '')\n"", ""+            if not re.match(r'\\d', r):\n"", '+                continue\n', '             if verbose:\n', '                 print(""picking %%s"" %% r)\n', '             return {""version"": r,\n']","['         # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n', '         if ref.startswith(tag_prefix):\n', '             r = ref[len(tag_prefix):]\n', '             if verbose:\n', '                 print(""picking %%s"" %% r)\n', '             return {""version"": r,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @register_vcs_handler(""git"", ""pieces_from_vcs"")\n', '+def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):\n', '     """"""Get version from \'git describe\' in the root of the source tree.\n', ' \n', ""     This only gets called if the git-archive 'subst' keywords were *not*\n""]","[' \n', ' \n', ' @register_vcs_handler(""git"", ""pieces_from_vcs"")\n', '-def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n', '     """"""Get version from \'git describe\' in the root of the source tree.\n', ' \n', ""     This only gets called if the git-archive 'subst' keywords were *not*\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', ' \n', '+    # GIT_DIR can interfere with correct operation of Versioneer.\n', '+    # It may be intended to be passed to the Versioneer-versioned project,\n', '+    # but that should not change where we get our version from.\n', '+    env = os.environ.copy()\n', '+    env.pop(""GIT_DIR"", None)\n', '+    runner = functools.partial(runner, env=env)\n', '+\n', '+    _, rc = runner(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n', '+                   hide_stderr=not verbose)\n', '     if rc != 0:\n', '         if verbose:\n', '             print(""Directory %%s not under git control"" %% root)\n']","['     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', ' \n', '-    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n', '-                          hide_stderr=True)\n', '     if rc != 0:\n', '         if verbose:\n', '             print(""Directory %%s not under git control"" %% root)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n', ""     # if there isn't one, this yields HEX[-dirty] (no NUM)\n"", '+    describe_out, rc = runner(GITS, [\n', '+        ""describe"", ""--tags"", ""--dirty="", ""--always"", ""--long"",\n', '+        ""--match"", f""{tag_prefix}[[:digit:]]*""\n', '+    ], cwd=root)\n', '     # --long was added in git-1.5.5\n', '     if describe_out is None:\n', '         raise NotThisMethod(""\'git describe\' failed"")\n', '     describe_out = describe_out.strip()\n', '+    full_out, rc = runner(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n', '     if full_out is None:\n', '         raise NotThisMethod(""\'git rev-parse\' failed"")\n', '     full_out = full_out.strip()\n']","[' \n', '     # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n', ""     # if there isn't one, this yields HEX[-dirty] (no NUM)\n"", '-    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty="",\n', '-                                          ""--always"", ""--long"",\n', '-                                          ""--match"", ""%%s*"" %% tag_prefix],\n', '-                                   cwd=root)\n', '     # --long was added in git-1.5.5\n', '     if describe_out is None:\n', '         raise NotThisMethod(""\'git describe\' failed"")\n', '     describe_out = describe_out.strip()\n', '-    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n', '     if full_out is None:\n', '         raise NotThisMethod(""\'git rev-parse\' failed"")\n', '     full_out = full_out.strip()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     pieces[""short""] = full_out[:7]  # maybe improved later\n', '     pieces[""error""] = None\n', ' \n', '+    branch_name, rc = runner(GITS, [""rev-parse"", ""--abbrev-ref"", ""HEAD""],\n', '+                             cwd=root)\n', '+    # --abbrev-ref was added in git-1.6.3\n', '+    if rc != 0 or branch_name is None:\n', '+        raise NotThisMethod(""\'git rev-parse --abbrev-ref\' returned error"")\n', '+    branch_name = branch_name.strip()\n', '+\n', '+    if branch_name == ""HEAD"":\n', ""+        # If we aren't exactly on a branch, pick a branch which represents\n"", '+        # the current commit. If all else fails, we are on a branchless\n', '+        # commit.\n', '+        branches, rc = runner(GITS, [""branch"", ""--contains""], cwd=root)\n', '+        # --contains was added in git-1.5.4\n', '+        if rc != 0 or branches is None:\n', '+            raise NotThisMethod(""\'git branch --contains\' returned error"")\n', '+        branches = branches.split(""\\n"")\n', '+\n', ""+        # Remove the first line if we're running detached\n"", '+        if ""("" in branches[0]:\n', '+            branches.pop(0)\n', '+\n', '+        # Strip off the leading ""* "" from the list of branches.\n', '+        branches = [branch[2:] for branch in branches]\n', '+        if ""master"" in branches:\n', '+            branch_name = ""master""\n', '+        elif not branches:\n', '+            branch_name = None\n', '+        else:\n', '+            # Pick the first branch that is returned. Good or bad.\n', '+            branch_name = branches[0]\n', '+\n', '+    pieces[""branch""] = branch_name\n', '+\n', '     # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n', '     # TAG might have hyphens.\n', '     git_describe = describe_out\n']","['     pieces[""short""] = full_out[:7]  # maybe improved later\n', '     pieces[""error""] = None\n', ' \n', '     # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n', '     # TAG might have hyphens.\n', '     git_describe = describe_out\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # TAG-NUM-gHEX\n', ""         mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n"", '         if not mo:\n', '+            # unparsable. Maybe git-describe is misbehaving?\n', '             pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n', '                                %% describe_out)\n', '             return pieces\n']","['         # TAG-NUM-gHEX\n', ""         mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n"", '         if not mo:\n', '-            # unparseable. Maybe git-describe is misbehaving?\n', '             pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n', '                                %% describe_out)\n', '             return pieces\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', '         # HEX: no tags\n', '         pieces[""closest-tag""] = None\n', '+        out, rc = runner(GITS, [""rev-list"", ""HEAD"", ""--left-right""], cwd=root)\n', '+        pieces[""distance""] = len(out.split())  # total number of commits\n', ' \n', '     # commit date: see ISO-8601 comment in git_versions_from_keywords()\n', '+    date = runner(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""], cwd=root)[0].strip()\n', '     # Use only the last line.  Previous lines may contain GPG signature\n', '     # information.\n', '     date = date.splitlines()[-1]\n']","['     else:\n', '         # HEX: no tags\n', '         pieces[""closest-tag""] = None\n', '-        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n', '-                                    cwd=root)\n', '-        pieces[""distance""] = int(count_out)  # total number of commits\n', ' \n', '     # commit date: see ISO-8601 comment in git_versions_from_keywords()\n', '-    date = run_command(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""],\n', '-                       cwd=root)[0].strip()\n', '     # Use only the last line.  Previous lines may contain GPG signature\n', '     # information.\n', '     date = date.splitlines()[-1]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return rendered\n', ' \n', ' \n', '+def render_pep440_branch(pieces):\n', '+    """"""TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n', '+\n', '+    The "".dev0"" means not master branch. Note that .dev0 sorts backwards\n', '+    (a feature branch will appear ""older"" than the master branch).\n', '+\n', '+    Exceptions:\n', '+    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n', '+    """"""\n', '+    if pieces[""closest-tag""]:\n', '+        rendered = pieces[""closest-tag""]\n', '+        if pieces[""distance""] or pieces[""dirty""]:\n', '+            if pieces[""branch""] != ""master"":\n', '+                rendered += "".dev0""\n', '+            rendered += plus_or_dot(pieces)\n', '+            rendered += ""%%d.g%%s"" %% (pieces[""distance""], pieces[""short""])\n', '+            if pieces[""dirty""]:\n', '+                rendered += "".dirty""\n', '+    else:\n', '+        # exception #1\n', '+        rendered = ""0""\n', '+        if pieces[""branch""] != ""master"":\n', '+            rendered += "".dev0""\n', '+        rendered += ""+untagged.%%d.g%%s"" %% (pieces[""distance""],\n', '+                                          pieces[""short""])\n', '+        if pieces[""dirty""]:\n', '+            rendered += "".dirty""\n', '+    return rendered\n', '+\n', '+\n', '+def pep440_split_post(ver):\n', '+    """"""Split pep440 version string at the post-release segment.\n', '+\n', '+    Returns the release segments before the post-release and the\n', '+    post-release version number (or -1 if no post-release segment is present).\n', '+    """"""\n', '+    vc = str.split(ver, "".post"")\n', '+    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n', '+\n', '+\n', ' def render_pep440_pre(pieces):\n', '+    """"""TAG[.postN.devDISTANCE] -- No -dirty.\n', ' \n', '     Exceptions:\n', '     1: no tags. 0.post0.devDISTANCE\n', '     """"""\n', '     if pieces[""closest-tag""]:\n', '         if pieces[""distance""]:\n', '+            # update the post release segment\n', '+            tag_version, post_version = pep440_split_post(pieces[""closest-tag""])\n', '+            rendered = tag_version\n', '+            if post_version is not None:\n', '+                rendered += "".post%%d.dev%%d"" %% (post_version + 1, pieces[""distance""])\n', '+            else:\n', '+                rendered += "".post0.dev%%d"" %% (pieces[""distance""])\n', '+        else:\n', '+            # no commits, use the tag as the version\n', '+            rendered = pieces[""closest-tag""]\n', '     else:\n', '         # exception #1\n', '         rendered = ""0.post0.dev%%d"" %% pieces[""distance""]\n']","['     return rendered\n', ' \n', ' \n', ' def render_pep440_pre(pieces):\n', '-    """"""TAG[.post0.devDISTANCE] -- No -dirty.\n', ' \n', '     Exceptions:\n', '     1: no tags. 0.post0.devDISTANCE\n', '     """"""\n', '     if pieces[""closest-tag""]:\n', '-        rendered = pieces[""closest-tag""]\n', '         if pieces[""distance""]:\n', '-            rendered += "".post0.dev%%d"" %% pieces[""distance""]\n', '     else:\n', '         # exception #1\n', '         rendered = ""0.post0.dev%%d"" %% pieces[""distance""]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return rendered\n', ' \n', ' \n', '+def render_pep440_post_branch(pieces):\n', '+    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n', '+\n', '+    The "".dev0"" means not master branch.\n', '+\n', '+    Exceptions:\n', '+    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n', '+    """"""\n', '+    if pieces[""closest-tag""]:\n', '+        rendered = pieces[""closest-tag""]\n', '+        if pieces[""distance""] or pieces[""dirty""]:\n', '+            rendered += "".post%%d"" %% pieces[""distance""]\n', '+            if pieces[""branch""] != ""master"":\n', '+                rendered += "".dev0""\n', '+            rendered += plus_or_dot(pieces)\n', '+            rendered += ""g%%s"" %% pieces[""short""]\n', '+            if pieces[""dirty""]:\n', '+                rendered += "".dirty""\n', '+    else:\n', '+        # exception #1\n', '+        rendered = ""0.post%%d"" %% pieces[""distance""]\n', '+        if pieces[""branch""] != ""master"":\n', '+            rendered += "".dev0""\n', '+        rendered += ""+g%%s"" %% pieces[""short""]\n', '+        if pieces[""dirty""]:\n', '+            rendered += "".dirty""\n', '+    return rendered\n', '+\n', '+\n', ' def render_pep440_old(pieces):\n', '     """"""TAG[.postDISTANCE[.dev0]] .\n', ' \n']","['     return rendered\n', ' \n', ' \n', ' def render_pep440_old(pieces):\n', '     """"""TAG[.postDISTANCE[.dev0]] .\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     if style == ""pep440"":\n', '         rendered = render_pep440(pieces)\n', '+    elif style == ""pep440-branch"":\n', '+        rendered = render_pep440_branch(pieces)\n', '     elif style == ""pep440-pre"":\n', '         rendered = render_pep440_pre(pieces)\n', '     elif style == ""pep440-post"":\n', '         rendered = render_pep440_post(pieces)\n', '+    elif style == ""pep440-post-branch"":\n', '+        rendered = render_pep440_post_branch(pieces)\n', '     elif style == ""pep440-old"":\n', '         rendered = render_pep440_old(pieces)\n', '     elif style == ""git-describe"":\n']","[' \n', '     if style == ""pep440"":\n', '         rendered = render_pep440(pieces)\n', '     elif style == ""pep440-pre"":\n', '         rendered = render_pep440_pre(pieces)\n', '     elif style == ""pep440-post"":\n', '         rendered = render_pep440_post(pieces)\n', '     elif style == ""pep440-old"":\n', '         rendered = render_pep440_old(pieces)\n', '     elif style == ""git-describe"":\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # versionfile_source is the relative path from the top of the source\n', '         # tree (where the .git directory might live) to this file. Invert\n', '         # this to find the root from __file__.\n', ""+        for _ in cfg.versionfile_source.split('/'):\n"", '             root = os.path.dirname(root)\n', '     except NameError:\n', '         return {""version"": ""0+unknown"", ""full-revisionid"": None,\n']","['         # versionfile_source is the relative path from the top of the source\n', '         # tree (where the .git directory might live) to this file. Invert\n', '         # this to find the root from __file__.\n', ""-        for i in cfg.versionfile_source.split('/'):\n"", '             root = os.path.dirname(root)\n', '     except NameError:\n', '         return {""version"": ""0+unknown"", ""full-revisionid"": None,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     # _version.py.\n', '     keywords = {}\n', '     try:\n', '+        with open(versionfile_abs, ""r"") as fobj:\n', '+            for line in fobj:\n', '                 if line.strip().startswith(""git_refnames =""):\n', '                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n']","['     # _version.py.\n', '     keywords = {}\n', '     try:\n', '-        with open(versionfile_abs, ""r"") as f:\n', '-            for line in f.readlines():\n', '                 if line.strip().startswith(""git_refnames =""):\n', '                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n', '                         keywords[""date""] = mo.group(1)\n', '+    except OSError:\n', '         pass\n', '     return keywords\n', ' \n']","['                     mo = re.search(r\'=\\s*""(.*)""\', line)\n', '                     if mo:\n', '                         keywords[""date""] = mo.group(1)\n', '-    except EnvironmentError:\n', '         pass\n', '     return keywords\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' @register_vcs_handler(""git"", ""keywords"")\n', ' def git_versions_from_keywords(keywords, tag_prefix, verbose):\n', '     """"""Get version information from git keywords.""""""\n', '+    if ""refnames"" not in keywords:\n', '+        raise NotThisMethod(""Short version file found"")\n', '     date = keywords.get(""date"")\n', '     if date is not None:\n', '         # Use only the last line.  Previous lines may contain GPG signature\n']","[' @register_vcs_handler(""git"", ""keywords"")\n', ' def git_versions_from_keywords(keywords, tag_prefix, verbose):\n', '     """"""Get version information from git keywords.""""""\n', '-    if not keywords:\n', '-        raise NotThisMethod(""no keywords at all, weird"")\n', '     date = keywords.get(""date"")\n', '     if date is not None:\n', '         # Use only the last line.  Previous lines may contain GPG signature\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         if verbose:\n', '             print(""keywords are unexpanded, not using"")\n', '         raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n', '+    refs = {r.strip() for r in refnames.strip(""()"").split("","")}\n', '     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n', '     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n', '     TAG = ""tag: ""\n', '+    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n', '     if not tags:\n', ""         # Either we're using git < 1.8.3, or there really are no tags. We use\n"", '         # a heuristic: assume all version tags have a digit. The old git %d\n']","['         if verbose:\n', '             print(""keywords are unexpanded, not using"")\n', '         raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n', '-    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n', '     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n', '     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n', '     TAG = ""tag: ""\n', '-    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n', '     if not tags:\n', ""         # Either we're using git < 1.8.3, or there really are no tags. We use\n"", '         # a heuristic: assume all version tags have a digit. The old git %d\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # between branches and tags. By ignoring refnames without digits, we\n', '         # filter out many common branch names like ""release"" and\n', '         # ""stabilization"", as well as ""HEAD"" and ""master"".\n', ""+        tags = {r for r in refs if re.search(r'\\d', r)}\n"", '         if verbose:\n', '             print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n', '     if verbose:\n']","['         # between branches and tags. By ignoring refnames without digits, we\n', '         # filter out many common branch names like ""release"" and\n', '         # ""stabilization"", as well as ""HEAD"" and ""master"".\n', ""-        tags = set([r for r in refs if re.search(r'\\d', r)])\n"", '         if verbose:\n', '             print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n', '     if verbose:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n', '         if ref.startswith(tag_prefix):\n', '             r = ref[len(tag_prefix):]\n', ""+            # Filter out refs that exactly match prefix or that don't start\n"", '+            # with a number once the prefix is stripped (mostly a concern\n', ""+            # when prefix is '')\n"", ""+            if not re.match(r'\\d', r):\n"", '+                continue\n', '             if verbose:\n', '                 print(""picking %s"" % r)\n', '             return {""version"": r,\n']","['         # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n', '         if ref.startswith(tag_prefix):\n', '             r = ref[len(tag_prefix):]\n', '             if verbose:\n', '                 print(""picking %s"" % r)\n', '             return {""version"": r,\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' @register_vcs_handler(""git"", ""pieces_from_vcs"")\n', '+def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):\n', '     """"""Get version from \'git describe\' in the root of the source tree.\n', ' \n', ""     This only gets called if the git-archive 'subst' keywords were *not*\n""]","[' \n', ' \n', ' @register_vcs_handler(""git"", ""pieces_from_vcs"")\n', '-def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n', '     """"""Get version from \'git describe\' in the root of the source tree.\n', ' \n', ""     This only gets called if the git-archive 'subst' keywords were *not*\n""]"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', ' \n', '+    # GIT_DIR can interfere with correct operation of Versioneer.\n', '+    # It may be intended to be passed to the Versioneer-versioned project,\n', '+    # but that should not change where we get our version from.\n', '+    env = os.environ.copy()\n', '+    env.pop(""GIT_DIR"", None)\n', '+    runner = functools.partial(runner, env=env)\n', '+\n', '+    _, rc = runner(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n', '+                   hide_stderr=not verbose)\n', '     if rc != 0:\n', '         if verbose:\n', '             print(""Directory %s not under git control"" % root)\n']","['     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', ' \n', '-    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n', '-                          hide_stderr=True)\n', '     if rc != 0:\n', '         if verbose:\n', '             print(""Directory %s not under git control"" % root)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n', ""     # if there isn't one, this yields HEX[-dirty] (no NUM)\n"", '+    describe_out, rc = runner(GITS, [\n', '+        ""describe"", ""--tags"", ""--dirty="", ""--always"", ""--long"",\n', '+        ""--match"", f""{tag_prefix}[[:digit:]]*""\n', '+    ], cwd=root)\n', '     # --long was added in git-1.5.5\n', '     if describe_out is None:\n', '         raise NotThisMethod(""\'git describe\' failed"")\n', '     describe_out = describe_out.strip()\n', '+    full_out, rc = runner(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n', '     if full_out is None:\n', '         raise NotThisMethod(""\'git rev-parse\' failed"")\n', '     full_out = full_out.strip()\n']","[' \n', '     # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n', ""     # if there isn't one, this yields HEX[-dirty] (no NUM)\n"", '-    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty="",\n', '-                                          ""--always"", ""--long"",\n', '-                                          ""--match"", ""%s*"" % tag_prefix],\n', '-                                   cwd=root)\n', '     # --long was added in git-1.5.5\n', '     if describe_out is None:\n', '         raise NotThisMethod(""\'git describe\' failed"")\n', '     describe_out = describe_out.strip()\n', '-    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n', '     if full_out is None:\n', '         raise NotThisMethod(""\'git rev-parse\' failed"")\n', '     full_out = full_out.strip()\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     pieces[""short""] = full_out[:7]  # maybe improved later\n', '     pieces[""error""] = None\n', ' \n', '+    branch_name, rc = runner(GITS, [""rev-parse"", ""--abbrev-ref"", ""HEAD""],\n', '+                             cwd=root)\n', '+    # --abbrev-ref was added in git-1.6.3\n', '+    if rc != 0 or branch_name is None:\n', '+        raise NotThisMethod(""\'git rev-parse --abbrev-ref\' returned error"")\n', '+    branch_name = branch_name.strip()\n', '+\n', '+    if branch_name == ""HEAD"":\n', ""+        # If we aren't exactly on a branch, pick a branch which represents\n"", '+        # the current commit. If all else fails, we are on a branchless\n', '+        # commit.\n', '+        branches, rc = runner(GITS, [""branch"", ""--contains""], cwd=root)\n', '+        # --contains was added in git-1.5.4\n', '+        if rc != 0 or branches is None:\n', '+            raise NotThisMethod(""\'git branch --contains\' returned error"")\n', '+        branches = branches.split(""\\n"")\n', '+\n', ""+        # Remove the first line if we're running detached\n"", '+        if ""("" in branches[0]:\n', '+            branches.pop(0)\n', '+\n', '+        # Strip off the leading ""* "" from the list of branches.\n', '+        branches = [branch[2:] for branch in branches]\n', '+        if ""master"" in branches:\n', '+            branch_name = ""master""\n', '+        elif not branches:\n', '+            branch_name = None\n', '+        else:\n', '+            # Pick the first branch that is returned. Good or bad.\n', '+            branch_name = branches[0]\n', '+\n', '+    pieces[""branch""] = branch_name\n', '+\n', '     # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n', '     # TAG might have hyphens.\n', '     git_describe = describe_out\n']","['     pieces[""short""] = full_out[:7]  # maybe improved later\n', '     pieces[""error""] = None\n', ' \n', '     # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n', '     # TAG might have hyphens.\n', '     git_describe = describe_out\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         # TAG-NUM-gHEX\n', ""         mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n"", '         if not mo:\n', '+            # unparsable. Maybe git-describe is misbehaving?\n', '             pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n', '                                % describe_out)\n', '             return pieces\n']","['         # TAG-NUM-gHEX\n', ""         mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n"", '         if not mo:\n', '-            # unparseable. Maybe git-describe is misbehaving?\n', '             pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n', '                                % describe_out)\n', '             return pieces\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     else:\n', '         # HEX: no tags\n', '         pieces[""closest-tag""] = None\n', '+        out, rc = runner(GITS, [""rev-list"", ""HEAD"", ""--left-right""], cwd=root)\n', '+        pieces[""distance""] = len(out.split())  # total number of commits\n', ' \n', '     # commit date: see ISO-8601 comment in git_versions_from_keywords()\n', '+    date = runner(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[0].strip()\n', '     # Use only the last line.  Previous lines may contain GPG signature\n', '     # information.\n', '     date = date.splitlines()[-1]\n']","['     else:\n', '         # HEX: no tags\n', '         pieces[""closest-tag""] = None\n', '-        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n', '-                                    cwd=root)\n', '-        pieces[""distance""] = int(count_out)  # total number of commits\n', ' \n', '     # commit date: see ISO-8601 comment in git_versions_from_keywords()\n', '-    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n', '-                       cwd=root)[0].strip()\n', '     # Use only the last line.  Previous lines may contain GPG signature\n', '     # information.\n', '     date = date.splitlines()[-1]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return pieces\n', ' \n', ' \n', '+def do_vcs_install(versionfile_source, ipy):\n', '     """"""Git-specific installation logic for Versioneer.\n', ' \n', '     For Git, this means creating/changing .gitattributes to mark _version.py\n']","['     return pieces\n', ' \n', ' \n', '-def do_vcs_install(manifest_in, versionfile_source, ipy):\n', '     """"""Git-specific installation logic for Versioneer.\n', ' \n', '     For Git, this means creating/changing .gitattributes to mark _version.py\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     GITS = [""git""]\n', '     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', '+    files = [versionfile_source]\n', '     if ipy:\n', '         files.append(ipy)\n', '+    if ""VERSIONEER_PEP518"" not in globals():\n', '+        try:\n', '+            my_path = __file__\n', '+            if my_path.endswith("".pyc"") or my_path.endswith("".pyo""):\n', '+                my_path = os.path.splitext(my_path)[0] + "".py""\n', '+            versioneer_file = os.path.relpath(my_path)\n', '+        except NameError:\n', '+            versioneer_file = ""versioneer.py""\n', '+        files.append(versioneer_file)\n', '     present = False\n', '     try:\n', '+        with open("".gitattributes"", ""r"") as fobj:\n', '+            for line in fobj:\n', '                 if line.strip().startswith(versionfile_source):\n', '                     if ""export-subst"" in line.strip().split()[1:]:\n', '                         present = True\n', '+                        break\n', '+    except OSError:\n', '         pass\n', '     if not present:\n', '+        with open("".gitattributes"", ""a+"") as fobj:\n', '+            fobj.write(f""{versionfile_source} export-subst\\n"")\n', '         files.append("".gitattributes"")\n', '     run_command(GITS, [""add"", ""--""] + files)\n', ' \n']","['     GITS = [""git""]\n', '     if sys.platform == ""win32"":\n', '         GITS = [""git.cmd"", ""git.exe""]\n', '-    files = [manifest_in, versionfile_source]\n', '     if ipy:\n', '         files.append(ipy)\n', '-    try:\n', '-        me = __file__\n', '-        if me.endswith("".pyc"") or me.endswith("".pyo""):\n', '-            me = os.path.splitext(me)[0] + "".py""\n', '-        versioneer_file = os.path.relpath(me)\n', '-    except NameError:\n', '-        versioneer_file = ""versioneer.py""\n', '-    files.append(versioneer_file)\n', '     present = False\n', '     try:\n', '-        with open("".gitattributes"", ""r"") as f:\n', '-            for line in f.readlines():\n', '                 if line.strip().startswith(versionfile_source):\n', '                     if ""export-subst"" in line.strip().split()[1:]:\n', '                         present = True\n', '-    except EnvironmentError:\n', '         pass\n', '     if not present:\n', '-        with open("".gitattributes"", ""a+"") as f:\n', '-            f.write(""%s export-subst\\n"" % versionfile_source)\n', '         files.append("".gitattributes"")\n', '     run_command(GITS, [""add"", ""--""] + files)\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     """"""\n', '     rootdirs = []\n', ' \n', '+    for _ in range(3):\n', '         dirname = os.path.basename(root)\n', '         if dirname.startswith(parentdir_prefix):\n', '             return {""version"": dirname[len(parentdir_prefix):],\n', '                     ""full-revisionid"": None,\n', '                     ""dirty"": False, ""error"": None, ""date"": None}\n', '+        rootdirs.append(root)\n', '+        root = os.path.dirname(root)  # up a level\n', ' \n', '     if verbose:\n', '         print(""Tried directories %s but none started with prefix %s"" %\n']","['     """"""\n', '     rootdirs = []\n', ' \n', '-    for i in range(3):\n', '         dirname = os.path.basename(root)\n', '         if dirname.startswith(parentdir_prefix):\n', '             return {""version"": dirname[len(parentdir_prefix):],\n', '                     ""full-revisionid"": None,\n', '                     ""dirty"": False, ""error"": None, ""date"": None}\n', '-        else:\n', '-            rootdirs.append(root)\n', '-            root = os.path.dirname(root)  # up a level\n', ' \n', '     if verbose:\n', '         print(""Tried directories %s but none started with prefix %s"" %\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' SHORT_VERSION_PY = """"""\n', ""+# This file was generated by 'versioneer.py' (0.26) from\n"", ' # revision-control system data, or from the parent directory name of an\n', ' # unpacked source archive. Distribution tarballs contain a pre-generated copy\n', ' # of this file.\n']","[' \n', ' \n', ' SHORT_VERSION_PY = """"""\n', ""-# This file was generated by 'versioneer.py' (0.19) from\n"", ' # revision-control system data, or from the parent directory name of an\n', ' # unpacked source archive. Distribution tarballs contain a pre-generated copy\n', ' # of this file.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     try:\n', '         with open(filename) as f:\n', '             contents = f.read()\n', '+    except OSError:\n', '         raise NotThisMethod(""unable to read _version.py"")\n', '     mo = re.search(r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"",\n', '                    contents, re.M | re.S)\n']","['     try:\n', '         with open(filename) as f:\n', '             contents = f.read()\n', '-    except EnvironmentError:\n', '         raise NotThisMethod(""unable to read _version.py"")\n', '     mo = re.search(r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"",\n', '                    contents, re.M | re.S)\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return rendered\n', ' \n', ' \n', '+def render_pep440_branch(pieces):\n', '+    """"""TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n', '+\n', '+    The "".dev0"" means not master branch. Note that .dev0 sorts backwards\n', '+    (a feature branch will appear ""older"" than the master branch).\n', '+\n', '+    Exceptions:\n', '+    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n', '+    """"""\n', '+    if pieces[""closest-tag""]:\n', '+        rendered = pieces[""closest-tag""]\n', '+        if pieces[""distance""] or pieces[""dirty""]:\n', '+            if pieces[""branch""] != ""master"":\n', '+                rendered += "".dev0""\n', '+            rendered += plus_or_dot(pieces)\n', '+            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n', '+            if pieces[""dirty""]:\n', '+                rendered += "".dirty""\n', '+    else:\n', '+        # exception #1\n', '+        rendered = ""0""\n', '+        if pieces[""branch""] != ""master"":\n', '+            rendered += "".dev0""\n', '+        rendered += ""+untagged.%d.g%s"" % (pieces[""distance""],\n', '+                                          pieces[""short""])\n', '+        if pieces[""dirty""]:\n', '+            rendered += "".dirty""\n', '+    return rendered\n', '+\n', '+\n', '+def pep440_split_post(ver):\n', '+    """"""Split pep440 version string at the post-release segment.\n', '+\n', '+    Returns the release segments before the post-release and the\n', '+    post-release version number (or -1 if no post-release segment is present).\n', '+    """"""\n', '+    vc = str.split(ver, "".post"")\n', '+    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n', '+\n', '+\n', ' def render_pep440_pre(pieces):\n', '+    """"""TAG[.postN.devDISTANCE] -- No -dirty.\n', ' \n', '     Exceptions:\n', '     1: no tags. 0.post0.devDISTANCE\n', '     """"""\n', '     if pieces[""closest-tag""]:\n', '         if pieces[""distance""]:\n', '+            # update the post release segment\n', '+            tag_version, post_version = pep440_split_post(pieces[""closest-tag""])\n', '+            rendered = tag_version\n', '+            if post_version is not None:\n', '+                rendered += "".post%d.dev%d"" % (post_version + 1, pieces[""distance""])\n', '+            else:\n', '+                rendered += "".post0.dev%d"" % (pieces[""distance""])\n', '+        else:\n', '+            # no commits, use the tag as the version\n', '+            rendered = pieces[""closest-tag""]\n', '     else:\n', '         # exception #1\n', '         rendered = ""0.post0.dev%d"" % pieces[""distance""]\n']","['     return rendered\n', ' \n', ' \n', ' def render_pep440_pre(pieces):\n', '-    """"""TAG[.post0.devDISTANCE] -- No -dirty.\n', ' \n', '     Exceptions:\n', '     1: no tags. 0.post0.devDISTANCE\n', '     """"""\n', '     if pieces[""closest-tag""]:\n', '-        rendered = pieces[""closest-tag""]\n', '         if pieces[""distance""]:\n', '-            rendered += "".post0.dev%d"" % pieces[""distance""]\n', '     else:\n', '         # exception #1\n', '         rendered = ""0.post0.dev%d"" % pieces[""distance""]\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return rendered\n', ' \n', ' \n', '+def render_pep440_post_branch(pieces):\n', '+    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n', '+\n', '+    The "".dev0"" means not master branch.\n', '+\n', '+    Exceptions:\n', '+    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n', '+    """"""\n', '+    if pieces[""closest-tag""]:\n', '+        rendered = pieces[""closest-tag""]\n', '+        if pieces[""distance""] or pieces[""dirty""]:\n', '+            rendered += "".post%d"" % pieces[""distance""]\n', '+            if pieces[""branch""] != ""master"":\n', '+                rendered += "".dev0""\n', '+            rendered += plus_or_dot(pieces)\n', '+            rendered += ""g%s"" % pieces[""short""]\n', '+            if pieces[""dirty""]:\n', '+                rendered += "".dirty""\n', '+    else:\n', '+        # exception #1\n', '+        rendered = ""0.post%d"" % pieces[""distance""]\n', '+        if pieces[""branch""] != ""master"":\n', '+            rendered += "".dev0""\n', '+        rendered += ""+g%s"" % pieces[""short""]\n', '+        if pieces[""dirty""]:\n', '+            rendered += "".dirty""\n', '+    return rendered\n', '+\n', '+\n', ' def render_pep440_old(pieces):\n', '     """"""TAG[.postDISTANCE[.dev0]] .\n', ' \n']","['     return rendered\n', ' \n', ' \n', ' def render_pep440_old(pieces):\n', '     """"""TAG[.postDISTANCE[.dev0]] .\n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     if style == ""pep440"":\n', '         rendered = render_pep440(pieces)\n', '+    elif style == ""pep440-branch"":\n', '+        rendered = render_pep440_branch(pieces)\n', '     elif style == ""pep440-pre"":\n', '         rendered = render_pep440_pre(pieces)\n', '     elif style == ""pep440-post"":\n', '         rendered = render_pep440_post(pieces)\n', '+    elif style == ""pep440-post-branch"":\n', '+        rendered = render_pep440_post_branch(pieces)\n', '     elif style == ""pep440-old"":\n', '         rendered = render_pep440_old(pieces)\n', '     elif style == ""git-describe"":\n']","[' \n', '     if style == ""pep440"":\n', '         rendered = render_pep440(pieces)\n', '     elif style == ""pep440-pre"":\n', '         rendered = render_pep440_pre(pieces)\n', '     elif style == ""pep440-post"":\n', '         rendered = render_pep440_post(pieces)\n', '     elif style == ""pep440-old"":\n', '         rendered = render_pep440_old(pieces)\n', '     elif style == ""git-describe"":\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' \n', ' def get_cmdclass(cmdclass=None):\n', '+    """"""Get the custom setuptools subclasses used by Versioneer.\n', ' \n', '     If the package uses a different cmdclass (e.g. one from numpy), it\n', '     should be provide as an argument.\n']","[' \n', ' \n', ' def get_cmdclass(cmdclass=None):\n', '-    """"""Get the custom setuptools/distutils subclasses used by Versioneer.\n', ' \n', '     If the package uses a different cmdclass (e.g. one from numpy), it\n', '     should be provide as an argument.\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', '     cmds = {} if cmdclass is None else cmdclass.copy()\n', ' \n', '+    # we add ""version"" to setuptools\n', '+    from setuptools import Command\n', ' \n', '     class cmd_version(Command):\n', '         description = ""report generated version string""\n']","[' \n', '     cmds = {} if cmdclass is None else cmdclass.copy()\n', ' \n', '-    # we add ""version"" to both distutils and setuptools\n', '-    from distutils.core import Command\n', ' \n', '     class cmd_version(Command):\n', '         description = ""report generated version string""\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 print("" error: %s"" % vers[""error""])\n', '     cmds[""version""] = cmd_version\n', ' \n', '+    # we override ""build_py"" in setuptools\n', '     #\n', '     # most invocation pathways end up running build_py:\n', '     #  distutils/build -> build_py\n']","['                 print("" error: %s"" % vers[""error""])\n', '     cmds[""version""] = cmd_version\n', ' \n', '-    # we override ""build_py"" in both distutils and setuptools\n', '     #\n', '     # most invocation pathways end up running build_py:\n', '     #  distutils/build -> build_py\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     #   then does setup.py bdist_wheel, or sometimes setup.py install\n', '     #  setup.py egg_info -> ?\n', ' \n', '+    # pip install -e . and setuptool/editable_wheel will invoke build_py\n', '+    # but the build_py command is not expected to copy any files.\n', '+\n', '     # we override different ""build_py"" commands for both environments\n', ""     if 'build_py' in cmds:\n"", ""         _build_py = cmds['build_py']\n"", '     else:\n', '+        from setuptools.command.build_py import build_py as _build_py\n', ' \n', '     class cmd_build_py(_build_py):\n', '         def run(self):\n']","['     #   then does setup.py bdist_wheel, or sometimes setup.py install\n', '     #  setup.py egg_info -> ?\n', ' \n', '     # we override different ""build_py"" commands for both environments\n', ""     if 'build_py' in cmds:\n"", ""         _build_py = cmds['build_py']\n"", '-    elif ""setuptools"" in sys.modules:\n', '-        from setuptools.command.build_py import build_py as _build_py\n', '     else:\n', '-        from distutils.command.build_py import build_py as _build_py\n', ' \n', '     class cmd_build_py(_build_py):\n', '         def run(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             cfg = get_config_from_root(root)\n', '             versions = get_versions()\n', '             _build_py.run(self)\n', '+            if getattr(self, ""editable_mode"", False):\n', '+                # During editable installs `.py` and data files are\n', '+                # not copied to build_lib\n', '+                return\n', '             # now locate _version.py in the new build/ directory and replace\n', '             # it with an updated value\n', '             if cfg.versionfile_build:\n']","['             cfg = get_config_from_root(root)\n', '             versions = get_versions()\n', '             _build_py.run(self)\n', '             # now locate _version.py in the new build/ directory and replace\n', '             # it with an updated value\n', '             if cfg.versionfile_build:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                 write_to_version_file(target_versionfile, versions)\n', '     cmds[""build_py""] = cmd_build_py\n', ' \n', ""+    if 'build_ext' in cmds:\n"", ""+        _build_ext = cmds['build_ext']\n"", '     else:\n', '+        from setuptools.command.build_ext import build_ext as _build_ext\n', ' \n', '     class cmd_build_ext(_build_ext):\n', '         def run(self):\n']","['                 write_to_version_file(target_versionfile, versions)\n', '     cmds[""build_py""] = cmd_build_py\n', ' \n', '-    if ""setuptools"" in sys.modules:\n', '-        from setuptools.command.build_ext import build_ext as _build_ext\n', '     else:\n', '-        from distutils.command.build_ext import build_ext as _build_ext\n', ' \n', '     class cmd_build_ext(_build_ext):\n', '         def run(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['             # now locate _version.py in the new build/ directory and replace\n', '             # it with an updated value\n', '             target_versionfile = os.path.join(self.build_lib,\n', '+                                              cfg.versionfile_build)\n', '+            if not os.path.exists(target_versionfile):\n', '+                print(f""Warning: {target_versionfile} does not exist, skipping ""\n', '+                      ""version update. This can happen if you are running build_ext ""\n', '+                      ""without first running build_py."")\n', '+                return\n', '             print(""UPDATING %s"" % target_versionfile)\n', '             write_to_version_file(target_versionfile, versions)\n', '     cmds[""build_ext""] = cmd_build_ext\n']","['             # now locate _version.py in the new build/ directory and replace\n', '             # it with an updated value\n', '             target_versionfile = os.path.join(self.build_lib,\n', '-                                              cfg.versionfile_source)\n', '             print(""UPDATING %s"" % target_versionfile)\n', '             write_to_version_file(target_versionfile, versions)\n', '     cmds[""build_ext""] = cmd_build_ext\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         del cmds[""build_py""]\n', ' \n', ""     if 'py2exe' in sys.modules:  # py2exe enabled?\n"", '+        try:\n', '+            from py2exe.setuptools_buildexe import py2exe as _py2exe\n', '+        except ImportError:\n', '+            from py2exe.distutils_buildexe import py2exe as _py2exe\n', ' \n', '         class cmd_py2exe(_py2exe):\n', '             def run(self):\n']","['         del cmds[""build_py""]\n', ' \n', ""     if 'py2exe' in sys.modules:  # py2exe enabled?\n"", '-        from py2exe.distutils_buildexe import py2exe as _py2exe\n', ' \n', '         class cmd_py2exe(_py2exe):\n', '             def run(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['                              })\n', '         cmds[""py2exe""] = cmd_py2exe\n', ' \n', '+    # sdist farms its file list building out to egg_info\n', ""+    if 'egg_info' in cmds:\n"", ""+        _egg_info = cmds['egg_info']\n"", '+    else:\n', '+        from setuptools.command.egg_info import egg_info as _egg_info\n', '+\n', '+    class cmd_egg_info(_egg_info):\n', '+        def find_sources(self):\n', '+            # egg_info.find_sources builds the manifest list and writes it\n', '+            # in one shot\n', '+            super().find_sources()\n', '+\n', '+            # Modify the filelist and normalize it\n', '+            root = get_root()\n', '+            cfg = get_config_from_root(root)\n', ""+            self.filelist.append('versioneer.py')\n"", '+            if cfg.versionfile_source:\n', '+                # There are rare cases where versionfile_source might not be\n', '+                # included by default, so we must be explicit\n', '+                self.filelist.append(cfg.versionfile_source)\n', '+            self.filelist.sort()\n', '+            self.filelist.remove_duplicates()\n', '+\n', '+            # The write method is hidden in the manifest_maker instance that\n', '+            # generated the filelist and was thrown away\n', '+            # We will instead replicate their final normalization (to unicode,\n', '+            # and POSIX-style paths)\n', '+            from setuptools import unicode_utils\n', ""+            normalized = [unicode_utils.filesys_decode(f).replace(os.sep, '/')\n"", '+                          for f in self.filelist.files]\n', '+\n', ""+            manifest_filename = os.path.join(self.egg_info, 'SOURCES.txt')\n"", ""+            with open(manifest_filename, 'w') as fobj:\n"", ""+                fobj.write('\\n'.join(normalized))\n"", '+\n', ""+    cmds['egg_info'] = cmd_egg_info\n"", '+\n', '     # we override different ""sdist"" commands for both environments\n', ""     if 'sdist' in cmds:\n"", ""         _sdist = cmds['sdist']\n"", '     else:\n', '+        from setuptools.command.sdist import sdist as _sdist\n', ' \n', '     class cmd_sdist(_sdist):\n', '         def run(self):\n']","['                              })\n', '         cmds[""py2exe""] = cmd_py2exe\n', ' \n', '     # we override different ""sdist"" commands for both environments\n', ""     if 'sdist' in cmds:\n"", ""         _sdist = cmds['sdist']\n"", '-    elif ""setuptools"" in sys.modules:\n', '-        from setuptools.command.sdist import sdist as _sdist\n', '     else:\n', '-        from distutils.command.sdist import sdist as _sdist\n', ' \n', '     class cmd_sdist(_sdist):\n', '         def run(self):\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"[' \n', ' """"""\n', ' \n', '+OLD_SNIPPET = """"""\n', ' from ._version import get_versions\n', "" __version__ = get_versions()['version']\n"", ' del get_versions\n', ' """"""\n', ' \n', '+INIT_PY_SNIPPET = """"""\n', '+from . import {0}\n', ""+__version__ = {0}.get_versions()['version']\n"", '+""""""\n', '+\n', ' \n', ' def do_setup():\n', '     """"""Do main VCS-independent setup function for installing Versioneer.""""""\n', '     root = get_root()\n', '     try:\n', '         cfg = get_config_from_root(root)\n', '+    except (OSError, configparser.NoSectionError,\n', '             configparser.NoOptionError) as e:\n', '+        if isinstance(e, (OSError, configparser.NoSectionError)):\n', '             print(""Adding sample versioneer config to setup.cfg"",\n', '                   file=sys.stderr)\n', '             with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n']","[' \n', ' """"""\n', ' \n', '-INIT_PY_SNIPPET = """"""\n', ' from ._version import get_versions\n', "" __version__ = get_versions()['version']\n"", ' del get_versions\n', ' """"""\n', ' \n', ' \n', ' def do_setup():\n', '     """"""Do main VCS-independent setup function for installing Versioneer.""""""\n', '     root = get_root()\n', '     try:\n', '         cfg = get_config_from_root(root)\n', '-    except (EnvironmentError, configparser.NoSectionError,\n', '             configparser.NoOptionError) as e:\n', '-        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n', '             print(""Adding sample versioneer config to setup.cfg"",\n', '                   file=sys.stderr)\n', '             with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['         try:\n', '             with open(ipy, ""r"") as f:\n', '                 old = f.read()\n', '+        except OSError:\n', '             old = """"\n', '+        module = os.path.splitext(os.path.basename(cfg.versionfile_source))[0]\n', '+        snippet = INIT_PY_SNIPPET.format(module)\n', '+        if OLD_SNIPPET in old:\n', '+            print("" replacing boilerplate in %s"" % ipy)\n', '+            with open(ipy, ""w"") as f:\n', '+                f.write(old.replace(OLD_SNIPPET, snippet))\n', '+        elif snippet not in old:\n', '             print("" appending to %s"" % ipy)\n', '             with open(ipy, ""a"") as f:\n', '+                f.write(snippet)\n', '         else:\n', '             print("" %s unmodified"" % ipy)\n', '     else:\n', '         print("" %s doesn\'t exist, ok"" % ipy)\n', '         ipy = None\n', ' \n', '     # Make VCS-specific changes. For git, this means creating/changing\n', '     # .gitattributes to mark _version.py for export-subst keyword\n', '     # substitution.\n', '+    do_vcs_install(cfg.versionfile_source, ipy)\n', '     return 0\n', ' \n', ' \n']","['         try:\n', '             with open(ipy, ""r"") as f:\n', '                 old = f.read()\n', '-        except EnvironmentError:\n', '             old = """"\n', '-        if INIT_PY_SNIPPET not in old:\n', '             print("" appending to %s"" % ipy)\n', '             with open(ipy, ""a"") as f:\n', '-                f.write(INIT_PY_SNIPPET)\n', '         else:\n', '             print("" %s unmodified"" % ipy)\n', '     else:\n', '         print("" %s doesn\'t exist, ok"" % ipy)\n', '         ipy = None\n', ' \n', '-    # Make sure both the top-level ""versioneer.py"" and versionfile_source\n', '-    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n', ""-    # they'll be copied into source distributions. Pip won't be able to\n"", '-    # install the package without this.\n', '-    manifest_in = os.path.join(root, ""MANIFEST.in"")\n', '-    simple_includes = set()\n', '-    try:\n', '-        with open(manifest_in, ""r"") as f:\n', '-            for line in f:\n', '-                if line.startswith(""include ""):\n', '-                    for include in line.split()[1:]:\n', '-                        simple_includes.add(include)\n', '-    except EnvironmentError:\n', '-        pass\n', ""-    # That doesn't cover everything MANIFEST.in can do\n"", '-    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n', ""-    # it might give some false negatives. Appending redundant 'include'\n"", '-    # lines is safe, though.\n', '-    if ""versioneer.py"" not in simple_includes:\n', '-        print("" appending \'versioneer.py\' to MANIFEST.in"")\n', '-        with open(manifest_in, ""a"") as f:\n', '-            f.write(""include versioneer.py\\n"")\n', '-    else:\n', '-        print("" \'versioneer.py\' already in MANIFEST.in"")\n', '-    if cfg.versionfile_source not in simple_includes:\n', '-        print("" appending versionfile_source (\'%s\') to MANIFEST.in"" %\n', '-              cfg.versionfile_source)\n', '-        with open(manifest_in, ""a"") as f:\n', '-            f.write(""include %s\\n"" % cfg.versionfile_source)\n', '-    else:\n', '-        print("" versionfile_source already in MANIFEST.in"")\n', '-\n', '     # Make VCS-specific changes. For git, this means creating/changing\n', '     # .gitattributes to mark _version.py for export-subst keyword\n', '     # substitution.\n', '-    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n', '     return 0\n', ' \n', ' \n']"
numpy/numpy,v1.23.5,v1.24.0rc1,"['     return errors\n', ' \n', ' \n', '+def setup_command():\n', '+    """"""Set up Versioneer and exit with appropriate error code.""""""\n', '+    errors = do_setup()\n', '+    errors += scan_setup_py()\n', '+    sys.exit(1 if errors else 0)\n', '+\n', '+\n', ' if __name__ == ""__main__"":\n', '     cmd = sys.argv[1]\n', '     if cmd == ""setup"":\n', '+        setup_command()\n']","['     return errors\n', ' \n', ' \n', ' if __name__ == ""__main__"":\n', '     cmd = sys.argv[1]\n', '     if cmd == ""setup"":\n', '-        errors = do_setup()\n', '-        errors += scan_setup_py()\n', '-        if errors:\n', '-            sys.exit(1)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestPrintOptions:\n', '     """"""Test getting and setting global print options.""""""\n', ' \n', '+    def setup_method(self):\n', '         self.oldopts = np.get_printoptions()\n', ' \n', '+    def teardown_method(self):\n', '         np.set_printoptions(**self.oldopts)\n', ' \n', '     def test_basic(self):\n']","[' class TestPrintOptions:\n', '     """"""Test getting and setting global print options.""""""\n', ' \n', '-    def setup(self):\n', '         self.oldopts = np.get_printoptions()\n', ' \n', '-    def teardown(self):\n', '         np.set_printoptions(**self.oldopts)\n', ' \n', '     def test_basic(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestWhitespace:\n', '+    def setup_method(self):\n', ""         self.A = np.array([['abc ', '123  '],\n"", ""                            ['789 ', 'xyz ']]).view(np.chararray)\n"", ""         self.B = np.array([['abc', '123'],\n""]","[' \n', ' \n', ' class TestWhitespace:\n', '-    def setup(self):\n', ""         self.A = np.array([['abc ', '123  '],\n"", ""                            ['789 ', 'xyz ']]).view(np.chararray)\n"", ""         self.B = np.array([['abc', '123'],\n""]"
numpy/numpy,v1.23.4,v1.23.5,"['         assert_(not np.any(self.A != self.B))\n', ' \n', ' class TestChar:\n', '+    def setup_method(self):\n', ""         self.A = np.array('abc1', dtype='c').view(np.chararray)\n"", ' \n', '     def test_it(self):\n']","['         assert_(not np.any(self.A != self.B))\n', ' \n', ' class TestChar:\n', '-    def setup(self):\n', ""         self.A = np.array('abc1', dtype='c').view(np.chararray)\n"", ' \n', '     def test_it(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[""         assert_equal(self.A.upper()[:2].tobytes(), b'AB')\n"", ' \n', ' class TestComparisons:\n', '+    def setup_method(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '123  '],\n""]","[""         assert_equal(self.A.upper()[:2].tobytes(), b'AB')\n"", ' \n', ' class TestComparisons:\n', '-    def setup(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '123  '],\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestComparisonsMixed1(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '+    def setup_method(self):\n', '+        TestComparisons.setup_method(self)\n', ""         self.B = np.array([['efg', '123  '],\n"", ""                            ['051', 'tuv']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestComparisonsMixed2(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '+    def setup_method(self):\n', '+        TestComparisons.setup_method(self)\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestInformation:\n', '+    def setup_method(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']]).view(np.chararray)\n""]","[' class TestComparisonsMixed1(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '-    def setup(self):\n', '-        TestComparisons.setup(self)\n', ""         self.B = np.array([['efg', '123  '],\n"", ""                            ['051', 'tuv']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestComparisonsMixed2(TestComparisons):\n', '     """"""Ticket #1276""""""\n', ' \n', '-    def setup(self):\n', '-        TestComparisons.setup(self)\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']], np.unicode_).view(np.chararray)\n"", ' \n', ' class TestInformation:\n', '-    def setup(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']]).view(np.chararray)\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestMethods:\n', '+    def setup_method(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']],\n""]","[' \n', ' \n', ' class TestMethods:\n', '-    def setup(self):\n', ""         self.A = np.array([[' abc ', ''],\n"", ""                            ['12345', 'MixedCase'],\n"", ""                            ['123 \\t 345 \\0 ', 'UPPER']],\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestOperations:\n', '+    def setup_method(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '456'],\n""]","[' \n', ' \n', ' class TestOperations:\n', '-    def setup(self):\n', ""         self.A = np.array([['abc', '123'],\n"", ""                            ['789', 'xyz']]).view(np.chararray)\n"", ""         self.B = np.array([['efg', '456'],\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[""     message = ''\n"", '     warning_cls = DeprecationWarning\n', ' \n', '+    def setup_method(self):\n', '         self.warn_ctx = warnings.catch_warnings(record=True)\n', '         self.log = self.warn_ctx.__enter__()\n', ' \n']","[""     message = ''\n"", '     warning_cls = DeprecationWarning\n', ' \n', '-    def setup(self):\n', '         self.warn_ctx = warnings.catch_warnings(record=True)\n', '         self.log = self.warn_ctx.__enter__()\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['         warnings.filterwarnings(""always"", message=self.message,\n', '                                 category=self.warning_cls)\n', ' \n', '+    def teardown_method(self):\n', '         self.warn_ctx.__exit__()\n', ' \n', '     def assert_deprecated(self, function, num=1, ignore_others=False,\n']","['         warnings.filterwarnings(""always"", message=self.message,\n', '                                 category=self.warning_cls)\n', ' \n', '-    def teardown(self):\n', '         self.warn_ctx.__exit__()\n', ' \n', '     def assert_deprecated(self, function, num=1, ignore_others=False,\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestTestDeprecated:\n', '     def test_assert_deprecated(self):\n', '         test_case_instance = _DeprecationTestCase()\n', '+        test_case_instance.setup_method()\n', '         assert_raises(AssertionError,\n', '                       test_case_instance.assert_deprecated,\n', '                       lambda: None)\n']","[' class TestTestDeprecated:\n', '     def test_assert_deprecated(self):\n', '         test_case_instance = _DeprecationTestCase()\n', '-        test_case_instance.setup()\n', '         assert_raises(AssertionError,\n', '                       test_case_instance.assert_deprecated,\n', '                       lambda: None)\n']"
numpy/numpy,v1.23.4,v1.23.5,"['             warnings.warn(""foo"", category=DeprecationWarning, stacklevel=2)\n', ' \n', '         test_case_instance.assert_deprecated(foo)\n', '+        test_case_instance.teardown_method()\n', ' \n', ' \n', ' class TestNonNumericConjugate(_DeprecationTestCase):\n']","['             warnings.warn(""foo"", category=DeprecationWarning, stacklevel=2)\n', ' \n', '         test_case_instance.assert_deprecated(foo)\n', '-        test_case_instance.teardown()\n', ' \n', ' \n', ' class TestNonNumericConjugate(_DeprecationTestCase):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['                 ""Did not raise floating point %s error"" % strmatch)\n', ' \n', ' class TestHalf:\n', '+    def setup_method(self):\n', '         # An array of all possible float16 values\n', '         self.all_f16 = np.arange(0x10000, dtype=uint16)\n', '         self.all_f16.dtype = float16\n']","['                 ""Did not raise floating point %s error"" % strmatch)\n', ' \n', ' class TestHalf:\n', '-    def setup(self):\n', '         # An array of all possible float16 values\n', '         self.all_f16 = np.arange(0x10000, dtype=uint16)\n', '         self.all_f16.dtype = float16\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', '     """"""\n', ' \n', '+    def setup_method(self):\n', '         self.a = np.arange(np.prod([3, 1, 5, 6])).reshape(3, 1, 5, 6)\n', '         self.b = np.empty((3, 0, 5, 6))\n', ""         self.complex_indices = ['skip', Ellipsis,\n""]","[' \n', '     """"""\n', ' \n', '-    def setup(self):\n', '         self.a = np.arange(np.prod([3, 1, 5, 6])).reshape(3, 1, 5, 6)\n', '         self.b = np.empty((3, 0, 5, 6))\n', ""         self.complex_indices = ['skip', Ellipsis,\n""]"
numpy/numpy,v1.23.4,v1.23.5,"['     )\n', ' \n', ' class TestMemmap:\n', '+    def setup_method(self):\n', ""         self.tmpfp = NamedTemporaryFile(prefix='mmap')\n"", '         self.shape = (3, 4)\n', ""         self.dtype = 'float32'\n"", '         self.data = arange(12, dtype=self.dtype)\n', '         self.data.resize(self.shape)\n', ' \n', '+    def teardown_method(self):\n', '         self.tmpfp.close()\n', '         self.data = None\n', '         if IS_PYPY:\n']","['     )\n', ' \n', ' class TestMemmap:\n', '-    def setup(self):\n', ""         self.tmpfp = NamedTemporaryFile(prefix='mmap')\n"", '         self.shape = (3, 4)\n', ""         self.dtype = 'float32'\n"", '         self.data = arange(12, dtype=self.dtype)\n', '         self.data.resize(self.shape)\n', ' \n', '-    def teardown(self):\n', '         self.tmpfp.close()\n', '         self.data = None\n', '         if IS_PYPY:\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestFlags:\n', '+    def setup_method(self):\n', '         self.a = np.arange(10)\n', ' \n', '     def test_writeable(self):\n']","[' \n', ' \n', ' class TestFlags:\n', '-    def setup(self):\n', '         self.a = np.arange(10)\n', ' \n', '     def test_writeable(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestAttributes:\n', '+    def setup_method(self):\n', '         self.one = np.arange(10)\n', '         self.two = np.arange(20).reshape(4, 5)\n', '         self.three = np.arange(60, dtype=np.float64).reshape(2, 5, 6)\n']","[' \n', ' \n', ' class TestAttributes:\n', '-    def setup(self):\n', '         self.one = np.arange(10)\n', '         self.two = np.arange(20).reshape(4, 5)\n', '         self.three = np.arange(60, dtype=np.float64).reshape(2, 5, 6)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestZeroRank:\n', '+    def setup_method(self):\n', ""         self.d = np.array(0), np.array('x', object)\n"", ' \n', '     def test_ellipsis_subscript(self):\n']","[' \n', ' \n', ' class TestZeroRank:\n', '-    def setup(self):\n', ""         self.d = np.array(0), np.array('x', object)\n"", ' \n', '     def test_ellipsis_subscript(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestScalarIndexing:\n', '+    def setup_method(self):\n', '         self.d = np.array([0, 1])[0]\n', ' \n', '     def test_ellipsis_subscript(self):\n']","[' \n', ' \n', ' class TestScalarIndexing:\n', '-    def setup(self):\n', '         self.d = np.array([0, 1])[0]\n', ' \n', '     def test_ellipsis_subscript(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['             mm.close()\n', ' \n', ' class TestFlat:\n', '+    def setup_method(self):\n', '         a0 = np.arange(20.0)\n', '         a = a0.reshape(4, 5)\n', '         a0.shape = (4, 5)\n']","['             mm.close()\n', ' \n', ' class TestFlat:\n', '-    def setup(self):\n', '         a0 = np.arange(20.0)\n', '         a = a0.reshape(4, 5)\n', '         a0.shape = (4, 5)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', '     funcs = [_mean, _var, _std]\n', ' \n', '+    def setup_method(self):\n', '         np.random.seed(range(3))\n', '         self.rmat = np.random.random((4, 5))\n', '         self.cmat = self.rmat + 1j * self.rmat\n']","[' \n', '     funcs = [_mean, _var, _std]\n', ' \n', '-    def setup(self):\n', '         np.random.seed(range(3))\n', '         self.rmat = np.random.random((4, 5))\n', '         self.cmat = self.rmat + 1j * self.rmat\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestDot:\n', '+    def setup_method(self):\n', '         np.random.seed(128)\n', '         self.A = np.random.rand(4, 2)\n', '         self.b1 = np.random.rand(2, 1)\n']","[' \n', ' \n', ' class TestDot:\n', '-    def setup(self):\n', '         np.random.seed(128)\n', '         self.A = np.random.rand(4, 2)\n', '         self.b1 = np.random.rand(2, 1)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestChoose:\n', '+    def setup_method(self):\n', '         self.x = 2*np.ones((3,), dtype=int)\n', '         self.y = 3*np.ones((3,), dtype=int)\n', '         self.x2 = 2*np.ones((2, 3), dtype=int)\n']","[' \n', ' \n', ' class TestChoose:\n', '-    def setup(self):\n', '         self.x = 2*np.ones((3,), dtype=int)\n', '         self.y = 3*np.ones((3,), dtype=int)\n', '         self.x2 = 2*np.ones((2, 3), dtype=int)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestRepeat:\n', '+    def setup_method(self):\n', '         self.m = np.array([1, 2, 3, 4, 5, 6])\n', '         self.m_rect = self.m.reshape((2, 3))\n', ' \n']","[' \n', ' \n', ' class TestRepeat:\n', '-    def setup(self):\n', '         self.m = np.array([1, 2, 3, 4, 5, 6])\n', '         self.m_rect = self.m.reshape((2, 3))\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' @pytest.mark.skipif(sys.version_info[:2] == (3, 9) and sys.platform == ""win32"",\n', '                     reason=""Errors with Python 3.9 on Windows"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n', '         [(""i"", ""O""), (""O"", ""i""),  # most simple cases\n', '          (""i,O"", ""O,O""),  # structured partially only copying O\n']","[' \n', ' @pytest.mark.skipif(sys.version_info[:2] == (3, 9) and sys.platform == ""win32"",\n', '                     reason=""Errors with Python 3.9 on Windows"")\n', '-@pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n', '         [(""i"", ""O""), (""O"", ""i""),  # most simple cases\n', '          (""i,O"", ""O,O""),  # structured partially only copying O\n']"
numpy/numpy,v1.23.4,v1.23.5,"['          ])\n', ' @pytest.mark.parametrize(""steps"", [1, 2, 3])\n', ' def test_partial_iteration_cleanup(in_dtype, buf_dtype, steps):\n', '+    """"""\n', '+    Checks for reference counting leaks during cleanup.  Using explicit\n', '+    reference counts lead to occasional false positives (at least in parallel\n', '+    test setups).  This test now should still test leaks correctly when\n', '+    run e.g. with pytest-valgrind or pytest-leaks\n', '+    """"""\n', ""+    value = 2**30 + 1  # just a random value that Python won't intern\n"", '     arr = np.full(int(np.BUFSIZE * 2.5), value).astype(in_dtype)\n', ' \n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n', '             flags=[""buffered"", ""external_loop"", ""refs_ok""], casting=""unsafe"")\n']","['          ])\n', ' @pytest.mark.parametrize(""steps"", [1, 2, 3])\n', ' def test_partial_iteration_cleanup(in_dtype, buf_dtype, steps):\n', '-    value = 123  # relies on python cache (leak-check will still find it)\n', '     arr = np.full(int(np.BUFSIZE * 2.5), value).astype(in_dtype)\n', '-    count = sys.getrefcount(value)\n', ' \n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n', '             flags=[""buffered"", ""external_loop"", ""refs_ok""], casting=""unsafe"")\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         # The iteration finishes in 3 steps, the first two are partial\n', '         next(it)\n', ' \n', '+    del it  # not necessary, but we test the cleanup\n', ' \n', '     # Repeat the test with `iternext`\n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n']","['         # The iteration finishes in 3 steps, the first two are partial\n', '         next(it)\n', ' \n', '-    # Note that resetting does not free references\n', '-    del it\n', '-    break_cycles()\n', '-    break_cycles()\n', '-    assert count == sys.getrefcount(value)\n', ' \n', '     # Repeat the test with `iternext`\n', '     it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     for step in range(steps):\n', '         it.iternext()\n', ' \n', '+    del it  # not necessary, but we test the cleanup\n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n']","['     for step in range(steps):\n', '         it.iternext()\n', ' \n', '-    del it  # should ensure cleanup\n', '-    break_cycles()\n', '-    break_cycles()\n', '-    assert count == sys.getrefcount(value)\n', '-\n', ' \n', ' @pytest.mark.skipif(not HAS_REFCOUNT, reason=""Python lacks refcounts"")\n', ' @pytest.mark.parametrize([""in_dtype"", ""buf_dtype""],\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestBoolArray:\n', '+    def setup_method(self):\n', '         # offset for simd tests\n', '         self.t = np.array([True] * 41, dtype=bool)[1::]\n', '         self.f = np.array([False] * 41, dtype=bool)[1::]\n']","[' \n', ' \n', ' class TestBoolArray:\n', '-    def setup(self):\n', '         # offset for simd tests\n', '         self.t = np.array([True] * 41, dtype=bool)[1::]\n', '         self.f = np.array([False] * 41, dtype=bool)[1::]\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestBoolCmp:\n', '+    def setup_method(self):\n', '         self.f = np.ones(256, dtype=np.float32)\n', '         self.ef = np.ones(self.f.size, dtype=bool)\n', '         self.d = np.ones(128, dtype=np.float64)\n']","[' \n', ' \n', ' class TestBoolCmp:\n', '-    def setup(self):\n', '         self.f = np.ones(256, dtype=np.float32)\n', '         self.ef = np.ones(self.f.size, dtype=bool)\n', '         self.d = np.ones(128, dtype=np.float64)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestClip:\n', '+    def setup_method(self):\n', '         self.nr = 5\n', '         self.nc = 3\n', ' \n']","[' \n', ' \n', ' class TestClip:\n', '-    def setup(self):\n', '         self.nr = 5\n', '         self.nc = 3\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def tst_allclose(self, x, y):\n']","['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def tst_allclose(self, x, y):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '+    def _setup(self):\n', '         atol = self.atol\n', '         rtol = self.rtol\n', '         arr = np.array([100, 1000])\n']","['     rtol = 1e-5\n', '     atol = 1e-8\n', ' \n', '-    def setup(self):\n', '         atol = self.atol\n', '         rtol = self.rtol\n', '         arr = np.array([100, 1000])\n']"
numpy/numpy,v1.23.4,v1.23.5,"['                 ]\n', ' \n', '     def test_ip_isclose(self):\n', '+        self._setup()\n', '         tests = self.some_close_tests\n', '         results = self.some_close_results\n', '         for (x, y), result in zip(tests, results):\n']","['                 ]\n', ' \n', '     def test_ip_isclose(self):\n', '-        self.setup()\n', '         tests = self.some_close_tests\n', '         results = self.some_close_results\n', '         for (x, y), result in zip(tests, results):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['             assert_array_equal(np.isclose(x, y).all(), np.allclose(x, y), msg % (x, y))\n', ' \n', '     def test_ip_all_isclose(self):\n', '+        self._setup()\n', '         for (x, y) in self.all_close_tests:\n', '             self.tst_all_isclose(x, y)\n', ' \n', '     def test_ip_none_isclose(self):\n', '+        self._setup()\n', '         for (x, y) in self.none_close_tests:\n', '             self.tst_none_isclose(x, y)\n', ' \n', '     def test_ip_isclose_allclose(self):\n', '+        self._setup()\n', '         tests = (self.all_close_tests + self.none_close_tests +\n', '                  self.some_close_tests)\n', '         for (x, y) in tests:\n']","['             assert_array_equal(np.isclose(x, y).all(), np.allclose(x, y), msg % (x, y))\n', ' \n', '     def test_ip_all_isclose(self):\n', '-        self.setup()\n', '         for (x, y) in self.all_close_tests:\n', '             self.tst_all_isclose(x, y)\n', ' \n', '     def test_ip_none_isclose(self):\n', '-        self.setup()\n', '         for (x, y) in self.none_close_tests:\n', '             self.tst_none_isclose(x, y)\n', ' \n', '     def test_ip_isclose_allclose(self):\n', '-        self.setup()\n', '         tests = (self.all_close_tests + self.none_close_tests +\n', '                  self.some_close_tests)\n', '         for (x, y) in tests:\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestStdVar:\n', '+    def setup_method(self):\n', '         self.A = np.array([1, -1, 1, -1])\n', '         self.real_var = 1\n', ' \n']","[' \n', ' \n', ' class TestStdVar:\n', '-    def setup(self):\n', '         self.A = np.array([1, -1, 1, -1])\n', '         self.real_var = 1\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestCreationFuncs:\n', '     # Test ones, zeros, empty and full.\n', ' \n', '+    def setup_method(self):\n', '         dtypes = {np.dtype(tp) for tp in itertools.chain(*np.sctypes.values())}\n', '         # void, bytes, str\n', ""         variable_sized = {tp for tp in dtypes if tp.str.endswith('0')}\n""]","[' class TestCreationFuncs:\n', '     # Test ones, zeros, empty and full.\n', ' \n', '-    def setup(self):\n', '         dtypes = {np.dtype(tp) for tp in itertools.chain(*np.sctypes.values())}\n', '         # void, bytes, str\n', ""         variable_sized = {tp for tp in dtypes if tp.str.endswith('0')}\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestLikeFuncs:\n', ""     '''Test ones_like, zeros_like, empty_like and full_like'''\n"", ' \n', '+    def setup_method(self):\n', '         self.data = [\n', '                 # Array scalars\n', '                 (np.array(3.), None),\n']","[' class TestLikeFuncs:\n', ""     '''Test ones_like, zeros_like, empty_like and full_like'''\n"", ' \n', '-    def setup(self):\n', '         self.data = [\n', '                 # Array scalars\n', '                 (np.array(3.), None),\n']"
numpy/numpy,v1.23.4,v1.23.5,"[""         assert_(res == 'f8')\n"", ' \n', ' class TestMultipleFields:\n', '+    def setup_method(self):\n', ""         self.ary = np.array([(1, 2, 3, 4), (5, 6, 7, 8)], dtype='i4,f4,i2,c8')\n"", ' \n', '     def _bad_call(self):\n']","[""         assert_(res == 'f8')\n"", ' \n', ' class TestMultipleFields:\n', '-    def setup(self):\n', ""         self.ary = np.array([(1, 2, 3, 4), (5, 6, 7, 8)], dtype='i4,f4,i2,c8')\n"", ' \n', '     def _bad_call(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestArrayLike:\n', '+    def setup_method(self):\n', '         class MyArray():\n', '             def __init__(self, function=None):\n', '                 self.function = function\n']","[' \n', ' \n', ' class TestArrayLike:\n', '-    def setup(self):\n', '         class MyArray():\n', '             def __init__(self, function=None):\n', '                 self.function = function\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestRecord:\n', '+    def setup_method(self):\n', '         self.data = np.rec.fromrecords([(1, 2, 3), (4, 5, 6)],\n', '                             dtype=[(""col1"", ""<i4""),\n', '                                    (""col2"", ""<i4""),\n']","[' \n', ' \n', ' class TestRecord:\n', '-    def setup(self):\n', '         self.data = np.rec.fromrecords([(1, 2, 3), (4, 5, 6)],\n', '                             dtype=[(""col1"", ""<i4""),\n', '                                    (""col2"", ""<i4""),\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class _FilterInvalids:\n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', ' \n']","[' \n', ' \n', ' class _FilterInvalids:\n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['         # cuts first)\n', ' \n', ' class TestCpow:\n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']","['         # cuts first)\n', ' \n', ' class TestCpow:\n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[""             assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)\n"", ' \n', ' class TestCabs:\n', '+    def setup_method(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']","[""             assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)\n"", ' \n', ' class TestCabs:\n', '-    def setup(self):\n', ""         self.olderr = np.seterr(invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.olderr)\n', ' \n', '     def test_simple(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     arch = None # x86_64\n', '     cc   = None # gcc\n', ' \n', '+    def setup_class(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', '         self._opt = None\n', ' \n']","['     arch = None # x86_64\n', '     cc   = None # gcc\n', ' \n', '-    def setup(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', '         self._opt = None\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[""         cc   = '{cc}'\n"", '         def __init__(self, methodName=""runTest""):\n', '             unittest.TestCase.__init__(self, methodName)\n', '+            self.setup_class()\n', '     """""").format(\n', ""         class_name=arch + '_' + cc, arch=arch, cc=cc\n"", '     )\n']","[""         cc   = '{cc}'\n"", '         def __init__(self, methodName=""runTest""):\n', '             unittest.TestCase.__init__(self, methodName)\n', '-            self.setup()\n', '     """""").format(\n', ""         class_name=arch + '_' + cc, arch=arch, cc=cc\n"", '     )\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestConfFeatures(unittest.TestCase):\n', '     def __init__(self, methodName=""runTest""):\n', '         unittest.TestCase.__init__(self, methodName)\n', '+        self._setup()\n', ' \n', '+    def _setup(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', ' \n', '     def test_features(self):\n']","[' class TestConfFeatures(unittest.TestCase):\n', '     def __init__(self, methodName=""runTest""):\n', '         unittest.TestCase.__init__(self, methodName)\n', '-        self.setup()\n', ' \n', '-    def setup(self):\n', '         FakeCCompilerOpt.conf_nocache = True\n', ' \n', '     def test_features(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestExecCommand:\n', '+    def setup_method(self):\n', '         self.pyexe = get_pythonexe()\n', ' \n', '     def check_nt(self, **kws):\n']","[' \n', ' \n', ' class TestExecCommand:\n', '-    def setup(self):\n', '         self.pyexe = get_pythonexe()\n', ' \n', '     def check_nt(self, **kws):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestSystemInfoReading:\n', ' \n', '+    def setup_method(self):\n', '         """""" Create the libraries """"""\n', '         # Create 2 sources and 2 libraries\n', '         self._dir1 = mkdtemp()\n']","[' \n', ' class TestSystemInfoReading:\n', ' \n', '-    def setup(self):\n', '         """""" Create the libraries """"""\n', '         # Create 2 sources and 2 libraries\n', '         self._dir1 = mkdtemp()\n']"
numpy/numpy,v1.23.4,v1.23.5,"[""         self.c_dup_options = site_and_parse(get_class('duplicate_options'),\n"", '                                             self._sitecfg)\n', ' \n', '+    def teardown_method(self):\n', '         # Do each removal separately\n', '         try:\n', '             shutil.rmtree(self._dir1)\n']","[""         self.c_dup_options = site_and_parse(get_class('duplicate_options'),\n"", '                                             self._sitecfg)\n', ' \n', '-\n', '-    def teardown(self):\n', '         # Do each removal separately\n', '         try:\n', '             shutil.rmtree(self._dir1)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestF2cmapOption(TestAssumedShapeSumExample):\n', '+    def setup_method(self):\n', '         # Use a custom file name for .f2py_f2cmap\n', '         self.sources = list(self.sources)\n', '         f2cmap_src = self.sources.pop(-1)\n']","[' \n', ' \n', ' class TestF2cmapOption(TestAssumedShapeSumExample):\n', '-    def setup(self):\n', '         # Use a custom file name for .f2py_f2cmap\n', '         self.sources = list(self.sources)\n', '         f2cmap_src = self.sources.pop(-1)\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         self.sources.append(self.f2cmap_file.name)\n', '         self.options = [""--f2cmap"", self.f2cmap_file.name]\n', ' \n', '+        super().setup_method()\n', ' \n', '+    def teardown_method(self):\n', '         os.unlink(self.f2cmap_file.name)\n']","['         self.sources.append(self.f2cmap_file.name)\n', '         self.options = [""--f2cmap"", self.f2cmap_file.name]\n', ' \n', '-        super().setup()\n', ' \n', '-    def teardown(self):\n', '         os.unlink(self.f2cmap_file.name)\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     module = None\n', '     module_name = None\n', ' \n', '+    def setup_method(self):\n', '         if sys.platform == ""win32"":\n', '             pytest.skip(""Fails with MinGW64 Gfortran (Issue #9673)"")\n', ' \n']","['     module = None\n', '     module_name = None\n', ' \n', '-    def setup(self):\n', '         if sys.platform == ""win32"":\n', '             pytest.skip(""Fails with MinGW64 Gfortran (Issue #9673)"")\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[""     (3, 0): ('<I', 'utf8'),\n"", ' }\n', ' \n', ""+# Python's literal_eval is not actually safe for large inputs, since parsing\n"", '+# may become slow or even cause interpreter crashes.\n', '+# This is an arbitrary, low limit which should make it safe in practice.\n', '+_MAX_HEADER_SIZE = 10000\n', ' \n', ' def _check_version(version):\n', '     if version not in [(1, 0), (2, 0), (3, 0), None]:\n']","[""     (3, 0): ('<I', 'utf8'),\n"", ' }\n', ' \n', ' \n', ' def _check_version(version):\n', '     if version not in [(1, 0), (2, 0), (3, 0), None]:\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     """"""\n', '     _write_array_header(fp, d, (2, 0))\n', ' \n', '+def read_array_header_1_0(fp, max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Read an array header from a filelike object using the 1.0 file format\n', '     version.\n']","['     """"""\n', '     _write_array_header(fp, d, (2, 0))\n', ' \n', '-def read_array_header_1_0(fp):\n', '     """"""\n', '     Read an array header from a filelike object using the 1.0 file format\n', '     version.\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         contiguous before writing it out.\n', '     dtype : dtype\n', ""         The dtype of the file's data.\n"", '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', ' \n', '     Raises\n', '     ------\n']","['         contiguous before writing it out.\n', '     dtype : dtype\n', ""         The dtype of the file's data.\n"", ' \n', '     Raises\n', '     ------\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         If the data is invalid.\n', ' \n', '     """"""\n', '+    return _read_array_header(\n', '+            fp, version=(1, 0), max_header_size=max_header_size)\n', ' \n', '+def read_array_header_2_0(fp, max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Read an array header from a filelike object using the 2.0 file format\n', '     version.\n']","['         If the data is invalid.\n', ' \n', '     """"""\n', '-    return _read_array_header(fp, version=(1, 0))\n', ' \n', '-def read_array_header_2_0(fp):\n', '     """"""\n', '     Read an array header from a filelike object using the 2.0 file format\n', '     version.\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     ----------\n', '     fp : filelike object\n', '         A file object or something with a `.read()` method like a file.\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', ' \n', '     Returns\n', '     -------\n']","['     ----------\n', '     fp : filelike object\n', '         A file object or something with a `.read()` method like a file.\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         If the data is invalid.\n', ' \n', '     """"""\n', '+    return _read_array_header(\n', '+            fp, version=(2, 0), max_header_size=max_header_size)\n', ' \n', ' \n', ' def _filter_header(s):\n']","['         If the data is invalid.\n', ' \n', '     """"""\n', '-    return _read_array_header(fp, version=(2, 0))\n', ' \n', ' \n', ' def _filter_header(s):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     return tokenize.untokenize(tokens)\n', ' \n', ' \n', '+def _read_array_header(fp, version, max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     see read_array_header_1_0\n', '     """"""\n']","['     return tokenize.untokenize(tokens)\n', ' \n', ' \n', '-def _read_array_header(fp, version):\n', '     """"""\n', '     see read_array_header_1_0\n', '     """"""\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     header_length = struct.unpack(hlength_type, hlength_str)[0]\n', '     header = _read_bytes(fp, header_length, ""array header"")\n', '     header = header.decode(encoding)\n', '+    if len(header) > max_header_size:\n', '+        raise ValueError(\n', '+            f""Header info length ({len(header)}) is large and may not be safe ""\n', '+            ""to load securely.\\n""\n', '+            ""To allow loading, adjust `max_header_size` or fully trust ""\n', '+            ""the `.npy` file using `allow_pickle=True`.\\n""\n', '+            ""For safety against large resource use or crashes, sandboxing ""\n', '+            ""may be necessary."")\n', ' \n', '     # The header is a pretty-printed string representation of a literal\n', '     # Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\n']","['     header_length = struct.unpack(hlength_type, hlength_str)[0]\n', '     header = _read_bytes(fp, header_length, ""array header"")\n', '     header = header.decode(encoding)\n', ' \n', '     # The header is a pretty-printed string representation of a literal\n', '     # Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\n']"
numpy/numpy,v1.23.4,v1.23.5,"[""                 fp.write(chunk.tobytes('C'))\n"", ' \n', ' \n', '+def read_array(fp, allow_pickle=False, pickle_kwargs=None, *,\n', '+               max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Read an array from an NPY file.\n', ' \n']","[""                 fp.write(chunk.tobytes('C'))\n"", ' \n', ' \n', '-def read_array(fp, allow_pickle=False, pickle_kwargs=None):\n', '     """"""\n', '     Read an array from an NPY file.\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['         Additional keyword arguments to pass to pickle.load. These are only\n', '         useful when loading object arrays saved on Python 2 when using\n', '         Python 3.\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', '+        This option is ignored when `allow_pickle` is passed.  In that case\n', '+        the file is by definition trusted and the limit is unnecessary.\n', ' \n', '     Returns\n', '     -------\n']","['         Additional keyword arguments to pass to pickle.load. These are only\n', '         useful when loading object arrays saved on Python 2 when using\n', '         Python 3.\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         an object array.\n', ' \n', '     """"""\n', '+    if allow_pickle:\n', '+        # Effectively ignore max_header_size, since `allow_pickle` indicates\n', '+        # that the input is fully trusted.\n', '+        max_header_size = 2**64\n', '+\n', '     version = read_magic(fp)\n', '     _check_version(version)\n', '+    shape, fortran_order, dtype = _read_array_header(\n', '+            fp, version, max_header_size=max_header_size)\n', '     if len(shape) == 0:\n', '         count = 1\n', '     else:\n']","['         an object array.\n', ' \n', '     """"""\n', '     version = read_magic(fp)\n', '     _check_version(version)\n', '-    shape, fortran_order, dtype = _read_array_header(fp, version)\n', '     if len(shape) == 0:\n', '         count = 1\n', '     else:\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', "" def open_memmap(filename, mode='r+', dtype=None, shape=None,\n"", '+                fortran_order=False, version=None, *,\n', '+                max_header_size=_MAX_HEADER_SIZE):\n', '     """"""\n', '     Open a .npy file as a memory-mapped array.\n', ' \n']","[' \n', ' \n', "" def open_memmap(filename, mode='r+', dtype=None, shape=None,\n"", '-                fortran_order=False, version=None):\n', '     """"""\n', '     Open a .npy file as a memory-mapped array.\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['         If the mode is a ""write"" mode, then this is the version of the file\n', '         format used to create the file.  None means use the oldest\n', '         supported version that is able to store the data.  Default: None\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', ' \n', '     Returns\n', '     -------\n']","['         If the mode is a ""write"" mode, then this is the version of the file\n', '         format used to create the file.  None means use the oldest\n', '         supported version that is able to store the data.  Default: None\n', ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.4,v1.23.5,"['             version = read_magic(fp)\n', '             _check_version(version)\n', ' \n', '+            shape, fortran_order, dtype = _read_array_header(\n', '+                    fp, version, max_header_size=max_header_size)\n', '             if dtype.hasobject:\n', '                 msg = ""Array can\'t be memory-mapped: Python objects in dtype.""\n', '                 raise ValueError(msg)\n']","['             version = read_magic(fp)\n', '             _check_version(version)\n', ' \n', '-            shape, fortran_order, dtype = _read_array_header(fp, version)\n', '             if dtype.hasobject:\n', '                 msg = ""Array can\'t be memory-mapped: Python objects in dtype.""\n', '                 raise ValueError(msg)\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         sample = np.atleast_2d(sample).T\n', '         N, D = sample.shape\n', ' \n', '+    nbin = np.empty(D, np.intp)\n', '     edges = D*[None]\n', '     dedges = D*[None]\n', '     if weights is not None:\n']","['         sample = np.atleast_2d(sample).T\n', '         N, D = sample.shape\n', ' \n', '-    nbin = np.empty(D, int)\n', '     edges = D*[None]\n', '     dedges = D*[None]\n', '     if weights is not None:\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         Additional keyword arguments to pass on to pickle.load.\n', '         These are only useful when loading object arrays saved on\n', '         Python 2 when using Python 3.\n', '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', '+        This option is ignored when `allow_pickle` is passed.  In that case\n', '+        the file is by definition trusted and the limit is unnecessary.\n', ' \n', '     Parameters\n', '     ----------\n']","['         Additional keyword arguments to pass on to pickle.load.\n', '         These are only useful when loading object arrays saved on\n', '         Python 2 when using Python 3.\n', ' \n', '     Parameters\n', '     ----------\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     fid = None\n', ' \n', '     def __init__(self, fid, own_fid=False, allow_pickle=False,\n', '+                 pickle_kwargs=None, *,\n', '+                 max_header_size=format._MAX_HEADER_SIZE):\n', '         # Import is postponed to here since zipfile depends on gzip, an\n', '         # optional component of the so-called standard library.\n', '         _zip = zipfile_factory(fid)\n', '         self._files = _zip.namelist()\n', '         self.files = []\n', '         self.allow_pickle = allow_pickle\n', '+        self.max_header_size = max_header_size\n', '         self.pickle_kwargs = pickle_kwargs\n', '         for x in self._files:\n', ""             if x.endswith('.npy'):\n""]","['     fid = None\n', ' \n', '     def __init__(self, fid, own_fid=False, allow_pickle=False,\n', '-                 pickle_kwargs=None):\n', '         # Import is postponed to here since zipfile depends on gzip, an\n', '         # optional component of the so-called standard library.\n', '         _zip = zipfile_factory(fid)\n', '         self._files = _zip.namelist()\n', '         self.files = []\n', '         self.allow_pickle = allow_pickle\n', '         self.pickle_kwargs = pickle_kwargs\n', '         for x in self._files:\n', ""             if x.endswith('.npy'):\n""]"
numpy/numpy,v1.23.4,v1.23.5,"['                 bytes = self.zip.open(key)\n', '                 return format.read_array(bytes,\n', '                                          allow_pickle=self.allow_pickle,\n', '+                                         pickle_kwargs=self.pickle_kwargs,\n', '+                                         max_header_size=self.max_header_size)\n', '             else:\n', '                 return self.zip.read(key)\n', '         else:\n']","['                 bytes = self.zip.open(key)\n', '                 return format.read_array(bytes,\n', '                                          allow_pickle=self.allow_pickle,\n', '-                                         pickle_kwargs=self.pickle_kwargs)\n', '             else:\n', '                 return self.zip.read(key)\n', '         else:\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', "" @set_module('numpy')\n"", ' def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n', ""+         encoding='ASCII', *, max_header_size=format._MAX_HEADER_SIZE):\n"", '     """"""\n', '     Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n', ' \n']","[' \n', "" @set_module('numpy')\n"", ' def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n', ""-         encoding='ASCII'):\n"", '     """"""\n', '     Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[""         npy/npz files containing object arrays. Values other than 'latin1',\n"", ""         'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n"", ""         data. Default: 'ASCII'\n"", '+    max_header_size : int, optional\n', '+        Maximum allowed size of the header.  Large headers may not be safe\n', '+        to load securely and thus require explicitly passing a larger value.\n', '+        See :py:meth:`ast.literal_eval()` for details.\n', '+        This option is ignored when `allow_pickle` is passed.  In that case\n', '+        the file is by definition trusted and the limit is unnecessary.\n', ' \n', '     Returns\n', '     -------\n']","[""         npy/npz files containing object arrays. Values other than 'latin1',\n"", ""         'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n"", ""         data. Default: 'ASCII'\n"", ' \n', '     Returns\n', '     -------\n']"
numpy/numpy,v1.23.4,v1.23.5,"['             # Potentially transfer file ownership to NpzFile\n', '             stack.pop_all()\n', '             ret = NpzFile(fid, own_fid=own_fid, allow_pickle=allow_pickle,\n', '+                          pickle_kwargs=pickle_kwargs,\n', '+                          max_header_size=max_header_size)\n', '             return ret\n', '         elif magic == format.MAGIC_PREFIX:\n', '             # .npy file\n', '             if mmap_mode:\n', '+                if allow_pickle:\n', '+                    max_header_size = 2**64\n', '+                return format.open_memmap(file, mode=mmap_mode,\n', '+                                          max_header_size=max_header_size)\n', '             else:\n', '                 return format.read_array(fid, allow_pickle=allow_pickle,\n', '+                                         pickle_kwargs=pickle_kwargs,\n', '+                                         max_header_size=max_header_size)\n', '         else:\n', '             # Try a pickle\n', '             if not allow_pickle:\n']","['             # Potentially transfer file ownership to NpzFile\n', '             stack.pop_all()\n', '             ret = NpzFile(fid, own_fid=own_fid, allow_pickle=allow_pickle,\n', '-                          pickle_kwargs=pickle_kwargs)\n', '             return ret\n', '         elif magic == format.MAGIC_PREFIX:\n', '             # .npy file\n', '             if mmap_mode:\n', '-                return format.open_memmap(file, mode=mmap_mode)\n', '             else:\n', '                 return format.read_array(fid, allow_pickle=allow_pickle,\n', '-                                         pickle_kwargs=pickle_kwargs)\n', '         else:\n', '             # Try a pickle\n', '             if not allow_pickle:\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestDataSourceOpen:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']","[' \n', ' \n', ' class TestDataSourceOpen:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestDataSourceExists:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']","[' \n', ' \n', ' class TestDataSourceExists:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestDataSourceAbspath:\n', '+    def setup_method(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']","[' \n', ' \n', ' class TestDataSourceAbspath:\n', '-    def setup(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.ds = datasource.DataSource(self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.ds\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestRepositoryAbspath:\n', '+    def setup_method(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']","[' \n', ' \n', ' class TestRepositoryAbspath:\n', '-    def setup(self):\n', '         self.tmpdir = os.path.abspath(mkdtemp())\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestRepositoryExists:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']","[' \n', ' \n', ' class TestRepositoryExists:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', '         self.repos = datasource.Repository(valid_baseurl(), self.tmpdir)\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', '         del self.repos\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestOpenFunc:\n', '+    def setup_method(self):\n', '         self.tmpdir = mkdtemp()\n', ' \n', '+    def teardown_method(self):\n', '         rmtree(self.tmpdir)\n', ' \n', '     def test_DataSourceOpen(self):\n']","[' \n', ' \n', ' class TestOpenFunc:\n', '-    def setup(self):\n', '         self.tmpdir = mkdtemp()\n', ' \n', '-    def teardown(self):\n', '         rmtree(self.tmpdir)\n', ' \n', '     def test_DataSourceOpen(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     assert_array_equal(long_str_arr, long_str_arr2)\n', ' \n', ' \n', '+@pytest.mark.slow\n', ' def test_memmap_roundtrip(tmpdir):\n', '     for i, arr in enumerate(basic_arrays + record_arrays):\n', '         if arr.dtype.hasobject:\n']","['     assert_array_equal(long_str_arr, long_str_arr2)\n', ' \n', ' \n', ' def test_memmap_roundtrip(tmpdir):\n', '     for i, arr in enumerate(basic_arrays + record_arrays):\n', '         if arr.dtype.hasobject:\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     assert_(len(header) % format.ARRAY_ALIGN == 0)\n', ' \n', '     f.seek(0)\n', '+    n = format.read_array(f, max_header_size=200000)\n', '     assert_array_equal(d, n)\n', ' \n', '     # 1.0 requested but data cannot be saved this way\n']","['     assert_(len(header) % format.ARRAY_ALIGN == 0)\n', ' \n', '     f.seek(0)\n', '-    n = format.read_array(f)\n', '     assert_array_equal(d, n)\n', ' \n', '     # 1.0 requested but data cannot be saved this way\n']"
numpy/numpy,v1.23.4,v1.23.5,"['                             shape=d.shape, version=(2, 0))\n', '     ma[...] = d\n', '     ma.flush()\n', ""+    ma = format.open_memmap(tf1, mode='r', max_header_size=200000)\n"", '     assert_array_equal(ma, d)\n', ' \n', '     with warnings.catch_warnings(record=True) as w:\n']","['                             shape=d.shape, version=(2, 0))\n', '     ma[...] = d\n', '     ma.flush()\n', ""-    ma = format.open_memmap(tf1, mode='r')\n"", '     assert_array_equal(ma, d)\n', ' \n', '     with warnings.catch_warnings(record=True) as w:\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         ma[...] = d\n', '         ma.flush()\n', ' \n', ""+    ma = format.open_memmap(tf2, mode='r', max_header_size=200000)\n"", '+\n', '     assert_array_equal(ma, d)\n', ' \n', '+@pytest.mark.parametrize(""mmap_mode"", [""r"", None])\n', '+def test_huge_header(tmpdir, mmap_mode):\n', ""+    f = os.path.join(tmpdir, f'large_header.npy')\n"", '+    arr = np.array(1, dtype=""i,""*10000+""i"")\n', '+\n', '+    with pytest.warns(UserWarning, match="".*format 2.0""):\n', '+        np.save(f, arr)\n', '+    \n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f, mmap_mode=mmap_mode)\n', '+\n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f, mmap_mode=mmap_mode, max_header_size=20000)\n', '+\n', '+    res = np.load(f, mmap_mode=mmap_mode, allow_pickle=True)\n', '+    assert_array_equal(res, arr)\n', '+\n', '+    res = np.load(f, mmap_mode=mmap_mode, max_header_size=180000)\n', '+    assert_array_equal(res, arr)\n', '+\n', '+def test_huge_header_npz(tmpdir):\n', ""+    f = os.path.join(tmpdir, f'large_header.npz')\n"", '+    arr = np.array(1, dtype=""i,""*10000+""i"")\n', '+\n', '+    with pytest.warns(UserWarning, match="".*format 2.0""):\n', '+        np.savez(f, arr=arr)\n', '+    \n', '+    # Only getting the array from the file actually reads it\n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f)[""arr""]\n', '+\n', '+    with pytest.raises(ValueError, match=""Header.*large""):\n', '+        np.load(f, max_header_size=20000)[""arr""]\n', '+\n', '+    res = np.load(f, allow_pickle=True)[""arr""]\n', '+    assert_array_equal(res, arr)\n', '+\n', '+    res = np.load(f, max_header_size=180000)[""arr""]\n', '+    assert_array_equal(res, arr)\n', ' \n', ' def test_write_version():\n', '     f = BytesIO()\n']","['         ma[...] = d\n', '         ma.flush()\n', ' \n', ""-    ma = format.open_memmap(tf2, mode='r')\n"", '     assert_array_equal(ma, d)\n', ' \n', ' \n', ' def test_write_version():\n', '     f = BytesIO()\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestDelete:\n', ' \n', '+    def setup_method(self):\n', '         self.a = np.arange(5)\n', '         self.nd_a = np.arange(5).repeat(2).reshape(1, 5, 2)\n', ' \n']","[' \n', ' class TestDelete:\n', ' \n', '-    def setup(self):\n', '         self.a = np.arange(5)\n', '         self.nd_a = np.arange(5).repeat(2).reshape(1, 5, 2)\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['     assert_array_almost_equal, assert_raises, assert_allclose,\n', '     assert_array_max_ulp, assert_raises_regex, suppress_warnings,\n', '     )\n', '+from numpy.testing._private.utils import requires_memory\n', ' import pytest\n', ' \n', ' \n', ' class TestHistogram:\n', ' \n', '+    def setup_method(self):\n', '         pass\n', ' \n', '+    def teardown_method(self):\n', '         pass\n', ' \n', '     def test_simple(self):\n']","['     assert_array_almost_equal, assert_raises, assert_allclose,\n', '     assert_array_max_ulp, assert_raises_regex, suppress_warnings,\n', '     )\n', ' import pytest\n', ' \n', ' \n', ' class TestHistogram:\n', ' \n', '-    def setup(self):\n', '         pass\n', ' \n', '-    def teardown(self):\n', '         pass\n', ' \n', '     def test_simple(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[""         edges = histogram_bin_edges(arr, bins='auto', range=(0, 1))\n"", '         assert_array_equal(edges, e)\n', ' \n', '+    @requires_memory(free_bytes=1e10)\n', '+    @pytest.mark.slow\n', '+    def test_big_arrays(self):\n', '+        sample = np.zeros([100000000, 3])\n', '+        xbins = 400\n', '+        ybins = 400\n', '+        zbins = np.arange(16000)\n', '+        hist = np.histogramdd(sample=sample, bins=(xbins, ybins, zbins))\n', '+        assert_equal(type(hist), type((1, 2)))\n', '+\n', ' \n', ' class TestHistogramOptimBinNums:\n', '     """"""\n']","[""         edges = histogram_bin_edges(arr, bins='auto', range=(0, 1))\n"", '         assert_array_equal(edges, e)\n', ' \n', ' \n', ' class TestHistogramOptimBinNums:\n', '     """"""\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestLoadTxt(LoadTxtBase):\n', '     loadfunc = staticmethod(np.loadtxt)\n', ' \n', '+    def setup_method(self):\n', '         # lower chunksize for testing\n', '         self.orig_chunk = np.lib.npyio._loadtxt_chunksize\n', '         np.lib.npyio._loadtxt_chunksize = 1\n', '+\n', '+    def teardown_method(self):\n', '         np.lib.npyio._loadtxt_chunksize = self.orig_chunk\n', ' \n', '     def test_record(self):\n']","[' class TestLoadTxt(LoadTxtBase):\n', '     loadfunc = staticmethod(np.loadtxt)\n', ' \n', '-    def setup(self):\n', '         # lower chunksize for testing\n', '         self.orig_chunk = np.lib.npyio._loadtxt_chunksize\n', '         np.lib.npyio._loadtxt_chunksize = 1\n', '-    def teardown(self):\n', '         np.lib.npyio._loadtxt_chunksize = self.orig_chunk\n', ' \n', '     def test_record(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestRecFunctions:\n', '     # Misc tests\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', ""         z = np.array([('A', 1.), ('B', 2.)],\n""]","[' class TestRecFunctions:\n', '     # Misc tests\n', ' \n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', ""         z = np.array([('A', 1.), ('B', 2.)],\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestMergeArrays:\n', '     # Test merge_arrays\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']","[' class TestMergeArrays:\n', '     # Test merge_arrays\n', ' \n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestAppendFields:\n', '     # Test append_fields\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']","[' class TestAppendFields:\n', '     # Test append_fields\n', ' \n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestStackArrays:\n', '     # Test stack_arrays\n', '+    def setup_method(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']","[' \n', ' class TestStackArrays:\n', '     # Test stack_arrays\n', '-    def setup(self):\n', '         x = np.array([1, 2, ])\n', '         y = np.array([10, 20, 30])\n', '         z = np.array(\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestJoinBy:\n', '+    def setup_method(self):\n', '         self.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                    np.arange(100, 110))),\n', ""                           dtype=[('a', int), ('b', int), ('c', int)])\n""]","[' \n', ' \n', ' class TestJoinBy:\n', '-    def setup(self):\n', '         self.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                    np.arange(100, 110))),\n', ""                           dtype=[('a', int), ('b', int), ('c', int)])\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestJoinBy2:\n', '     @classmethod\n', '+    def setup_method(cls):\n', '         cls.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                   np.arange(100, 110))),\n', ""                          dtype=[('a', int), ('b', int), ('c', int)])\n""]","[' \n', ' class TestJoinBy2:\n', '     @classmethod\n', '-    def setup(cls):\n', '         cls.a = np.array(list(zip(np.arange(10), np.arange(50, 60),\n', '                                   np.arange(100, 110))),\n', ""                          dtype=[('a', int), ('b', int), ('c', int)])\n""]"
numpy/numpy,v1.23.4,v1.23.5,"['     """"""\n', '     # https://github.com/numpy/numpy/issues/2346\n', ' \n', '+    def setup_method(self):\n', '         from datetime import date\n', '         self.data = dict(obj=date(2000, 1, 1))\n', ' \n']","['     """"""\n', '     # https://github.com/numpy/numpy/issues/2346\n', ' \n', '-    def setup(self):\n', '         from datetime import date\n', '         self.data = dict(obj=date(2000, 1, 1))\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"['     Evaluate a string containing a Python literal expression without\n', '     allowing the execution of arbitrary non-literal code.\n', ' \n', '+    .. warning::\n', '+\n', '+        This function is identical to :py:meth:`ast.literal_eval` and\n', '+        has the same security implications.  It may not always be safe\n', '+        to evaluate large input strings.\n', '+\n', '     Parameters\n', '     ----------\n', '     source : str\n']","['     Evaluate a string containing a Python literal expression without\n', '     allowing the execution of arbitrary non-literal code.\n', ' \n', '     Parameters\n', '     ----------\n', '     source : str\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestMaskedArray:\n', '     # Base test class for MaskedArrays.\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']","[' class TestMaskedArray:\n', '     # Base test class for MaskedArrays.\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestMaskedArrayArithmetic:\n', '     # Base test class for MaskedArrays.\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']","[' class TestMaskedArrayArithmetic:\n', '     # Base test class for MaskedArrays.\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_basic_arithmetic(self):\n']","['         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_basic_arithmetic(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestUfuncs:\n', '     # Test class for the application of ufuncs on MaskedArrays.\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', '         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '+    def teardown_method(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_testUfuncRegression(self):\n']","[' class TestUfuncs:\n', '     # Test class for the application of ufuncs on MaskedArrays.\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', '         self.err_status = np.geterr()\n', ""         np.seterr(divide='ignore', invalid='ignore')\n"", ' \n', '-    def teardown(self):\n', '         np.seterr(**self.err_status)\n', ' \n', '     def test_testUfuncRegression(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestMaskedArrayInPlaceArithmetic:\n', '     # Test MaskedArray Arithmetic\n', ' \n', '+    def setup_method(self):\n', '         x = arange(10)\n', '         y = arange(10)\n', '         xm = arange(10)\n']","[' class TestMaskedArrayInPlaceArithmetic:\n', '     # Test MaskedArray Arithmetic\n', ' \n', '-    def setup(self):\n', '         x = arange(10)\n', '         y = arange(10)\n', '         xm = arange(10)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMaskedArrayMethods:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']","[' \n', ' class TestMaskedArrayMethods:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMaskedArrayMathMethods:\n', ' \n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']","[' \n', ' class TestMaskedArrayMathMethods:\n', ' \n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMaskedArrayMathMethodsComplex:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '+    def setup_method(self):\n', '         # Base data definition.\n', '         x = np.array([8.375j, 7.545j, 8.828j, 8.5j, 1.757j, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']","[' \n', ' class TestMaskedArrayMathMethodsComplex:\n', '     # Test class for miscellaneous MaskedArrays methods.\n', '-    def setup(self):\n', '         # Base data definition.\n', '         x = np.array([8.375j, 7.545j, 8.828j, 8.5j, 1.757j, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestMaskedArrayFunctions:\n', '     # Test class for miscellaneous functions.\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         m1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n']","[' class TestMaskedArrayFunctions:\n', '     # Test class for miscellaneous functions.\n', ' \n', '-    def setup(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         m1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMaskedFields:\n', ' \n', '+    def setup_method(self):\n', '         ilist = [1, 2, 3, 4, 5]\n', '         flist = [1.1, 2.2, 3.3, 4.4, 5.5]\n', ""         slist = ['one', 'two', 'three', 'four', 'five']\n""]","[' \n', ' class TestMaskedFields:\n', ' \n', '-    def setup(self):\n', '         ilist = [1, 2, 3, 4, 5]\n', '         flist = [1.1, 2.2, 3.3, 4.4, 5.5]\n', ""         slist = ['one', 'two', 'three', 'four', 'five']\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMaskedView:\n', ' \n', '+    def setup_method(self):\n', '         iterator = list(zip(np.arange(10), np.random.rand(10)))\n', '         data = np.array(iterator)\n', ""         a = array(iterator, dtype=[('a', float), ('b', float)])\n""]","[' \n', ' class TestMaskedView:\n', ' \n', '-    def setup(self):\n', '         iterator = list(zip(np.arange(10), np.random.rand(10)))\n', '         data = np.array(iterator)\n', ""         a = array(iterator, dtype=[('a', float), ('b', float)])\n""]"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestCov:\n', ' \n', '+    def setup_method(self):\n', '         self.data = array(np.random.rand(12))\n', ' \n', '     def test_1d_without_missing(self):\n']","[' \n', ' class TestCov:\n', ' \n', '-    def setup(self):\n', '         self.data = array(np.random.rand(12))\n', ' \n', '     def test_1d_without_missing(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestCorrcoef:\n', ' \n', '+    def setup_method(self):\n', '         self.data = array(np.random.rand(12))\n', '         self.data2 = array(np.random.rand(12))\n', ' \n']","[' \n', ' class TestCorrcoef:\n', ' \n', '-    def setup(self):\n', '         self.data = array(np.random.rand(12))\n', '         self.data2 = array(np.random.rand(12))\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestView:\n', ' \n', '+    def setup_method(self):\n', '         (a, b) = (np.arange(10), np.random.rand(10))\n', ""         ndtype = [('a', float), ('b', float)]\n"", '         arr = np.array(list(zip(a, b)), dtype=ndtype)\n']","[' \n', ' class TestView:\n', ' \n', '-    def setup(self):\n', '         (a, b) = (np.arange(10), np.random.rand(10))\n', ""         ndtype = [('a', float), ('b', float)]\n"", '         arr = np.array(list(zip(a, b)), dtype=ndtype)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' from functools import reduce\n', ' \n', '+import pytest\n', '+\n', ' import numpy as np\n', ' import numpy.core.umath as umath\n', ' import numpy.core.fromnumeric as fromnumeric\n']","[' from functools import reduce\n', ' \n', ' import numpy as np\n', ' import numpy.core.umath as umath\n', ' import numpy.core.fromnumeric as fromnumeric\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMa:\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         a10 = 10.\n']","[' \n', ' class TestMa:\n', ' \n', '-    def setup(self):\n', '         x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n', '         y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n', '         a10 = 10.\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         assert_(eq(filled(xm, 1.e20), xf))\n', '         assert_(eq(x, xm))\n', ' \n', '+    @pytest.mark.parametrize(""s"", [(4, 3), (6, 2)])\n', '+    def test_testBasic2d(self, s):\n', '         # Test of basic array creation and properties in 2 dimensions.\n', '+        (x, y, a10, m1, m2, xm, ym, z, zm, xf, s) = self.d\n', '+        x.shape = s\n', '+        y.shape = s\n', '+        xm.shape = s\n', '+        ym.shape = s\n', '+        xf.shape = s\n', '+\n', '+        assert_(not isMaskedArray(x))\n', '+        assert_(isMaskedArray(xm))\n', '+        assert_equal(shape(xm), s)\n', '+        assert_equal(xm.shape, s)\n', '+        assert_equal(xm.size, reduce(lambda x, y: x * y, s))\n', '+        assert_equal(count(xm), len(m1) - reduce(lambda x, y: x + y, m1))\n', '+        assert_(eq(xm, xf))\n', '+        assert_(eq(filled(xm, 1.e20), xf))\n', '+        assert_(eq(x, xm))\n', ' \n', '     def test_testArithmetic(self):\n', '         # Test of basic arithmetic.\n']","['         assert_(eq(filled(xm, 1.e20), xf))\n', '         assert_(eq(x, xm))\n', ' \n', '-    def test_testBasic2d(self):\n', '         # Test of basic array creation and properties in 2 dimensions.\n', '-        for s in [(4, 3), (6, 2)]:\n', '-            (x, y, a10, m1, m2, xm, ym, z, zm, xf, s) = self.d\n', '-            x.shape = s\n', '-            y.shape = s\n', '-            xm.shape = s\n', '-            ym.shape = s\n', '-            xf.shape = s\n', '-\n', '-            assert_(not isMaskedArray(x))\n', '-            assert_(isMaskedArray(xm))\n', '-            assert_equal(shape(xm), s)\n', '-            assert_equal(xm.shape, s)\n', '-            assert_equal(xm.size, reduce(lambda x, y:x * y, s))\n', '-            assert_equal(count(xm),\n', '-                             len(m1) - reduce(lambda x, y:x + y, m1))\n', '-            assert_(eq(xm, xf))\n', '-            assert_(eq(filled(xm, 1.e20), xf))\n', '-            assert_(eq(x, xm))\n', '-            self.setup()\n', ' \n', '     def test_testArithmetic(self):\n', '         # Test of basic arithmetic.\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestUfuncs:\n', '+    def setup_method(self):\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', ' \n']","[' \n', ' \n', ' class TestUfuncs:\n', '-    def setup(self):\n', '         self.d = (array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),\n', '                   array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestArrayMethods:\n', ' \n', '+    def setup_method(self):\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n', '                       3.012, 6.022, 5.095, 3.116, 5.238, 3.957,\n']","[' \n', ' class TestArrayMethods:\n', ' \n', '-    def setup(self):\n', '         x = np.array([8.375, 7.545, 8.828, 8.5, 1.757, 5.928,\n', '                       8.43, 7.78, 9.865, 5.878, 8.979, 4.732,\n', '                       3.012, 6.022, 5.095, 3.116, 5.238, 3.957,\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' """"""\n', ' import numpy as np\n', '+from numpy.lib.mixins import NDArrayOperatorsMixin\n', ' from numpy.testing import assert_, assert_raises\n', ' from numpy.ma.testutils import assert_equal\n', ' from numpy.ma.core import (\n']","[' \n', ' """"""\n', ' import numpy as np\n', ' from numpy.testing import assert_, assert_raises\n', ' from numpy.ma.testutils import assert_equal\n', ' from numpy.ma.core import (\n']"
numpy/numpy,v1.23.4,v1.23.5,"['         return obj\n', ' \n', ' \n', '+class WrappedArray(NDArrayOperatorsMixin):\n', '+    """"""\n', '+    Wrapping a MaskedArray rather than subclassing to test that\n', '+    ufunc deferrals are commutative.\n', '+    See: https://github.com/numpy/numpy/issues/15200)\n', '+    """"""\n', '+    __array_priority__ = 20\n', '+\n', '+    def __init__(self, array, **attrs):\n', '+        self._array = array\n', '+        self.attrs = attrs\n', '+\n', '+    def __repr__(self):\n', '+        return f""{self.__class__.__name__}(\\n{self._array}\\n{self.attrs}\\n)""\n', '+\n', '+    def __array__(self):\n', '+        return np.asarray(self._array)\n', '+\n', '+    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n', ""+        if method == '__call__':\n"", '+            inputs = [arg._array if isinstance(arg, self.__class__) else arg\n', '+                      for arg in inputs]\n', '+            return self.__class__(ufunc(*inputs, **kwargs), **self.attrs)\n', '+        else:\n', '+            return NotImplemented\n', '+\n', '+\n', ' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '+    def setup_method(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = msubarray(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']","['         return obj\n', ' \n', ' \n', ' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '-    def setup(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = msubarray(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     # Test that the mask is False and not shared when keep_mask=False\n', '     assert_(not new_array.mask)\n', '     assert_(not new_array.sharedmask)\n', '+\n', '+\n', '+class TestClassWrapping:\n', '+    # Test suite for classes that wrap MaskedArrays\n', '+\n', '+    def setup_method(self):\n', '+        m = np.ma.masked_array([1, 3, 5], mask=[False, True, False])\n', '+        wm = WrappedArray(m)\n', '+        self.data = (m, wm)\n', '+\n', '+    def test_masked_unary_operations(self):\n', '+        # Tests masked_unary_operation\n', '+        (m, wm) = self.data\n', ""+        with np.errstate(divide='ignore'):\n"", '+            assert_(isinstance(np.log(wm), WrappedArray))\n', '+\n', '+    def test_masked_binary_operations(self):\n', '+        # Tests masked_binary_operation\n', '+        (m, wm) = self.data\n', '+        # Result should be a WrappedArray\n', '+        assert_(isinstance(np.add(wm, wm), WrappedArray))\n', '+        assert_(isinstance(np.add(m, wm), WrappedArray))\n', '+        assert_(isinstance(np.add(wm, m), WrappedArray))\n', ""+        # add and '+' should call the same ufunc\n"", '+        assert_equal(np.add(m, wm), m + wm)\n', '+        assert_(isinstance(np.hypot(m, wm), WrappedArray))\n', '+        assert_(isinstance(np.hypot(wm, m), WrappedArray))\n', '+        # Test domained binary operations\n', '+        assert_(isinstance(np.divide(wm, m), WrappedArray))\n', '+        assert_(isinstance(np.divide(m, wm), WrappedArray))\n', '+        assert_equal(np.divide(wm, m) * m, np.divide(m, m) * wm)\n', '+        # Test broadcasting\n', '+        m2 = np.stack([m, m])\n', '+        assert_(isinstance(np.divide(wm, m2), WrappedArray))\n', '+        assert_(isinstance(np.divide(m2, wm), WrappedArray))\n', '+        assert_equal(np.divide(m2, wm), np.divide(wm, m2))\n']","['     # Test that the mask is False and not shared when keep_mask=False\n', '     assert_(not new_array.mask)\n', '     assert_(not new_array.sharedmask)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '+    def setup_method(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = MMatrix(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']","[' class TestSubclassing:\n', '     # Test suite for masked subclasses of ndarray.\n', ' \n', '-    def setup(self):\n', ""         x = np.arange(5, dtype='float')\n"", '         mx = MMatrix(x, mask=[0, 1, 0, 0, 0])\n', '         self.data = (x, mx)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestMultivariateHypergeometric:\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 8675309\n', ' \n', '     def test_argument_validation(self):\n']","[' \n', ' class TestMultivariateHypergeometric:\n', ' \n', '-    def setup(self):\n', '         self.seed = 8675309\n', ' \n', '     def test_argument_validation(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestSetState:\n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', '         self.rg = Generator(MT19937(self.seed))\n', '         self.bit_generator = self.rg.bit_generator\n']","[' \n', ' \n', ' class TestSetState:\n', '-    def setup(self):\n', '         self.seed = 1234567890\n', '         self.rg = Generator(MT19937(self.seed))\n', '         self.bit_generator = self.rg.bit_generator\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_integers(self):\n']","['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '-    def setup(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_integers(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['                             [5, 1]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '+    def test_logseries_zero(self):\n', '+        random = Generator(MT19937(self.seed))\n', '+        assert random.logseries(0) == 1\n', '+\n', '+    @pytest.mark.parametrize(""value"", [np.nextafter(0., -1), 1., np.nan, 5.])\n', '+    def test_logseries_exceptions(self, value):\n', '+        random = Generator(MT19937(self.seed))\n', '+        with np.errstate(invalid=""ignore""):\n', '+            with pytest.raises(ValueError):\n', '+                random.logseries(value)\n', '+            with pytest.raises(ValueError):\n', '+                # contiguous path:\n', '+                random.logseries(np.array([value] * 10))\n', '+            with pytest.raises(ValueError):\n', '+                # non-contiguous path:\n', '+                random.logseries(np.array([value] * 10)[::2])\n', ' \n', '     def test_multinomial(self):\n', '         random = Generator(MT19937(self.seed))\n']","['                             [5, 1]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '-    def test_logseries_exceptions(self):\n', ""-        with np.errstate(invalid='ignore'):\n"", '-            assert_raises(ValueError, random.logseries, np.nan)\n', '-            assert_raises(ValueError, random.logseries, [np.nan] * 10)\n', ' \n', '     def test_multinomial(self):\n', '         random = Generator(MT19937(self.seed))\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '+    def setup_method(self):\n', '         self.seed = 123456789\n', ' \n', ' \n']","[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '-    def setup(self):\n', '         self.seed = 123456789\n', ' \n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '+    def setup_method(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']","[' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '-    def setup(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '+    def setup_method(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']","[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '-    def setup(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestSetState:\n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', '         self.prng = random.RandomState(self.seed)\n', '         self.state = self.prng.get_state()\n']","[' \n', ' \n', ' class TestSetState:\n', '-    def setup(self):\n', '         self.seed = 1234567890\n', '         self.prng = random.RandomState(self.seed)\n', '         self.state = self.prng.get_state()\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']","['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '-    def setup(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '+    def setup_method(self):\n', '         self.seed = 123456789\n', ' \n', '     def setSeed(self):\n']","[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '-    def setup(self):\n', '         self.seed = 123456789\n', ' \n', '     def setSeed(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '+    def setup_method(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']","[' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '-    def setup(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '+    def setup_method(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']","[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '-    def setup(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' \n', ' class TestSetState:\n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', '         self.random_state = random.RandomState(self.seed)\n', '         self.state = self.random_state.get_state()\n']","[' \n', ' \n', ' class TestSetState:\n', '-    def setup(self):\n', '         self.seed = 1234567890\n', '         self.random_state = random.RandomState(self.seed)\n', '         self.state = self.random_state.get_state()\n']"
numpy/numpy,v1.23.4,v1.23.5,"['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '+    def setup_method(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']","['     # Make sure the random distribution returns the correct value for a\n', '     # given seed\n', ' \n', '-    def setup(self):\n', '         self.seed = 1234567890\n', ' \n', '     def test_rand(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"['                             [3, 6]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '+    def test_logseries_zero(self):\n', '+        assert random.logseries(0) == 1\n', '+\n', '+    @pytest.mark.parametrize(""value"", [np.nextafter(0., -1), 1., np.nan, 5.])\n', '+    def test_logseries_exceptions(self, value):\n', '+        with np.errstate(invalid=""ignore""):\n', '+            with pytest.raises(ValueError):\n', '+                random.logseries(value)\n', '+            with pytest.raises(ValueError):\n', '+                # contiguous path:\n', '+                random.logseries(np.array([value] * 10))\n', '+            with pytest.raises(ValueError):\n', '+                # non-contiguous path:\n', '+                random.logseries(np.array([value] * 10)[::2])\n', ' \n', '     def test_multinomial(self):\n', '         random.seed(self.seed)\n']","['                             [3, 6]])\n', '         assert_array_equal(actual, desired)\n', ' \n', '-    def test_logseries_exceptions(self):\n', '-        with suppress_warnings() as sup:\n', '-            sup.record(RuntimeWarning)\n', '-            assert_raises(ValueError, random.logseries, np.nan)\n', '-            assert_raises(ValueError, random.logseries, [np.nan] * 10)\n', ' \n', '     def test_multinomial(self):\n', '         random.seed(self.seed)\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '+    def setup_method(self):\n', '         self.seed = 123456789\n', ' \n', '     def set_seed(self):\n']","[' class TestBroadcast:\n', '     # tests that functions that broadcast behave\n', '     # correctly when presented with non-scalar arguments\n', '-    def setup(self):\n', '         self.seed = 123456789\n', ' \n', '     def set_seed(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '+    def setup_method(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']","[' \n', ' class TestThread:\n', '     # make sure each state produces the same sequence even in threads\n', '-    def setup(self):\n', '         self.seeds = range(4)\n', ' \n', '     def check_function(self, function, sz):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '+    def setup_method(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']","[' \n', ' # See Issue #4263\n', ' class TestSingleEltArrayInput:\n', '-    def setup(self):\n', '         self.argOne = np.array([2])\n', '         self.argTwo = np.array([3])\n', '         self.argThree = np.array([4])\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestArrayEqual(_GenericTest):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_array_equal\n', ' \n', '     def test_generic_rank1(self):\n']","[' \n', ' class TestArrayEqual(_GenericTest):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_array_equal\n', ' \n', '     def test_generic_rank1(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestEqual(TestArrayEqual):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_equal\n', ' \n', '     def test_nan_items(self):\n']","[' \n', ' class TestEqual(TestArrayEqual):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_equal\n', ' \n', '     def test_nan_items(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestArrayAlmostEqual(_GenericTest):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_array_almost_equal\n', ' \n', '     def test_closeness(self):\n']","[' \n', ' class TestArrayAlmostEqual(_GenericTest):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_array_almost_equal\n', ' \n', '     def test_closeness(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestAlmostEqual(_GenericTest):\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_almost_equal\n', ' \n', '     def test_closeness(self):\n']","[' \n', ' class TestAlmostEqual(_GenericTest):\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_almost_equal\n', ' \n', '     def test_closeness(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestApproxEqual:\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_approx_equal\n', ' \n', '     def test_simple_0d_arrays(self):\n']","[' \n', ' class TestApproxEqual:\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_approx_equal\n', ' \n', '     def test_simple_0d_arrays(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' \n', ' class TestArrayAssertLess:\n', ' \n', '+    def setup_method(self):\n', '         self._assert_func = assert_array_less\n', ' \n', '     def test_simple_arrays(self):\n']","[' \n', ' class TestArrayAssertLess:\n', ' \n', '-    def setup(self):\n', '         self._assert_func = assert_array_less\n', ' \n', '     def test_simple_arrays(self):\n']"
numpy/numpy,v1.23.4,v1.23.5,"[' @pytest.mark.skip(reason=""The raises decorator depends on Nose"")\n', ' class TestRaises:\n', ' \n', '+    def setup_method(self):\n', '         class MyException(Exception):\n', '             pass\n', ' \n']","[' @pytest.mark.skip(reason=""The raises decorator depends on Nose"")\n', ' class TestRaises:\n', ' \n', '-    def setup(self):\n', '         class MyException(Exception):\n', '             pass\n', ' \n']"
numpy/numpy,v1.23.4,v1.23.5,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.23.5-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.23.4-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' # NOTE: Import `Sequence` from `typing` as we it is needed for a type-alias,\n', ' # not an annotation\n', ' from collections.abc import Collection, Callable\n', '+from typing import Any, Sequence, Protocol, Union, TypeVar, runtime_checkable\n', ' from numpy import (\n', '     ndarray,\n', '     dtype,\n']","[' # NOTE: Import `Sequence` from `typing` as we it is needed for a type-alias,\n', ' # not an annotation\n', ' from collections.abc import Collection, Callable\n', '-from typing import Any, Sequence, Protocol, Union, TypeVar\n', ' from numpy import (\n', '     ndarray,\n', '     dtype,\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' # array.\n', ' # Concrete implementations of the protocol are responsible for adding\n', ' # any and all remaining overloads\n', '+@runtime_checkable\n', ' class _SupportsArray(Protocol[_DType_co]):\n', '     def __array__(self) -> ndarray[Any, _DType_co]: ...\n', ' \n', ' \n', '+@runtime_checkable\n', ' class _SupportsArrayFunc(Protocol):\n', '     """"""A protocol class representing `~class.__array_function__`.""""""\n', '     def __array_function__(\n']","[' # array.\n', ' # Concrete implementations of the protocol are responsible for adding\n', ' # any and all remaining overloads\n', ' class _SupportsArray(Protocol[_DType_co]):\n', '     def __array__(self) -> ndarray[Any, _DType_co]: ...\n', ' \n', ' \n', ' class _SupportsArrayFunc(Protocol):\n', '     """"""A protocol class representing `~class.__array_function__`.""""""\n', '     def __array_function__(\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' # Used as the first overload, should only match NDArray[Any],\n', ' # not any actual types.\n', ' # https://github.com/numpy/numpy/pull/22193\n', '+class _UnknownType:\n', '     ...\n', ' \n', ' \n']","[' # Used as the first overload, should only match NDArray[Any],\n', ' # not any actual types.\n', ' # https://github.com/numpy/numpy/pull/22193\n', '-class _UnknownType: \n', '     ...\n', ' \n', ' \n']"
numpy/numpy,v1.23.3,v1.23.4,"['     TypeVar,\n', '     Protocol,\n', '     TypedDict,\n', '+    runtime_checkable,\n', ' )\n', ' \n', ' import numpy as np\n']","['     TypeVar,\n', '     Protocol,\n', '     TypedDict,\n', ' )\n', ' \n', ' import numpy as np\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' \n', ' \n', ' # A protocol for anything with the dtype attribute\n', '+@runtime_checkable\n', ' class _SupportsDType(Protocol[_DType_co]):\n', '     @property\n', '     def dtype(self) -> _DType_co: ...\n']","[' \n', ' \n', ' # A protocol for anything with the dtype attribute\n', ' class _SupportsDType(Protocol[_DType_co]):\n', '     @property\n', '     def dtype(self) -> _DType_co: ...\n']"
numpy/numpy,v1.23.3,v1.23.4,"['     overload,\n', '     TypeVar,\n', '     Protocol,\n', '+    runtime_checkable,\n', ' )\n', ' \n', ' __all__ = [""_NestedSequence""]\n']","['     overload,\n', '     TypeVar,\n', '     Protocol,\n', ' )\n', ' \n', ' __all__ = [""_NestedSequence""]\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' _T_co = TypeVar(""_T_co"", covariant=True)\n', ' \n', ' \n', '+@runtime_checkable\n', ' class _NestedSequence(Protocol[_T_co]):\n', '     """"""A protocol for representing nested sequences.\n', ' \n']","[' _T_co = TypeVar(""_T_co"", covariant=True)\n', ' \n', ' \n', ' class _NestedSequence(Protocol[_T_co]):\n', '     """"""A protocol for representing nested sequences.\n', ' \n']"
numpy/numpy,v1.23.3,v1.23.4,"['     assert_allclose, IS_PYPY, IS_PYSTON, HAS_REFCOUNT, assert_array_less,\n', '     runstring, temppath, suppress_warnings, break_cycles,\n', '     )\n', '+from numpy.testing._private.utils import requires_memory, _no_tracing\n', ' from numpy.core.tests._locales import CommaDecimalPointLocale\n', ' from numpy.lib.recfunctions import repack_fields\n', ' \n']","['     assert_allclose, IS_PYPY, IS_PYSTON, HAS_REFCOUNT, assert_array_less,\n', '     runstring, temppath, suppress_warnings, break_cycles,\n', '     )\n', '-from numpy.testing._private.utils import _no_tracing\n', ' from numpy.core.tests._locales import CommaDecimalPointLocale\n', ' from numpy.lib.recfunctions import repack_fields\n', ' \n']"
numpy/numpy,v1.23.3,v1.23.4,"['             # Strides in A cols and X\n', '             assert_dot_close(A_f_12, X_f_2, desired)\n', ' \n', '+    @pytest.mark.slow\n', '+    @pytest.mark.parametrize(""dtype"", [np.float64, np.complex128])\n', '+    @requires_memory(free_bytes=18e9)  # complex case needs 18GiB+\n', '+    def test_huge_vectordot(self, dtype):\n', '+        # Large vector multiplications are chunked with 32bit BLAS\n', '+        # Test that the chunking does the right thing, see also gh-22262\n', '+        data = np.ones(2**30+100, dtype=dtype)\n', '+        res = np.dot(data, data)\n', '+        assert res == 2**30+100\n', ' \n', ' \n', ' class MatmulCommon:\n']","['             # Strides in A cols and X\n', '             assert_dot_close(A_f_12, X_f_2, desired)\n', ' \n', ' \n', ' \n', ' class MatmulCommon:\n']"
numpy/numpy,v1.23.3,v1.23.4,"['         comment. None implies no comments. For backwards compatibility, byte\n', ""         strings will be decoded as 'latin1'. The default is '#'.\n"", '     delimiter : str, optional\n', '+        The character used to separate the values. For backwards compatibility,\n', ""+        byte strings will be decoded as 'latin1'. The default is whitespace.\n"", '+\n', '+        .. versionchanged:: 1.23.0\n', '+           Only single character delimiters are supported. Newline characters\n', '+           cannot be used as the delimiter.\n', '+\n', '     converters : dict or callable, optional\n', '         A function to parse all columns strings into the desired value, or\n', '         a dictionary mapping column number to a parser function.\n']","['         comment. None implies no comments. For backwards compatibility, byte\n', ""         strings will be decoded as 'latin1'. The default is '#'.\n"", '     delimiter : str, optional\n', '-        The string used to separate values. For backwards compatibility, byte\n', ""-        strings will be decoded as 'latin1'. The default is whitespace.\n"", '     converters : dict or callable, optional\n', '         A function to parse all columns strings into the desired value, or\n', '         a dictionary mapping column number to a parser function.\n']"
numpy/numpy,v1.23.3,v1.23.4,"['                             finally:\n', '                                 sys.stdout = old_stdout\n', '                                 sys.stderr = old_stderr\n', '+                        except KeyboardInterrupt:\n', '+                            # Assume keyboard interrupt came from a user\n', '+                            raise\n', '+                        except BaseException:\n', '+                            # Ignore also SystemExit and pytests.importorskip\n', '+                            # `Skipped` (these are BaseExceptions; gh-22345)\n', '                             continue\n', ' \n', '             for n, v in _getmembers(item):\n']","['                             finally:\n', '                                 sys.stdout = old_stdout\n', '                                 sys.stderr = old_stderr\n', '-                        # Catch SystemExit, too\n', '-                        except (Exception, SystemExit):\n', '                             continue\n', ' \n', '             for n, v in _getmembers(item):\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' from __future__ import annotations\n', ' \n', ' import sys\n', '+from typing import (\n', '+    get_type_hints,\n', '+    Union,\n', '+    NamedTuple,\n', '+    get_args,\n', '+    get_origin,\n', '+    Any,\n', '+)\n', ' \n', ' import pytest\n', ' import numpy as np\n', ' import numpy.typing as npt\n', '+import numpy._typing as _npt\n', ' \n', ' \n', ' class TypeTup(NamedTuple):\n']","[' from __future__ import annotations\n', ' \n', ' import sys\n', '-from typing import get_type_hints, Union, NamedTuple, get_args, get_origin\n', ' \n', ' import pytest\n', ' import numpy as np\n', ' import numpy.typing as npt\n', ' \n', ' \n', ' class TypeTup(NamedTuple):\n']"
numpy/numpy,v1.23.3,v1.23.4,"['     keys = TYPES.keys()\n', '     ref = set(npt.__all__)\n', '     assert keys == ref\n', '+\n', '+\n', '+PROTOCOLS: dict[str, tuple[type[Any], object]] = {\n', '+    ""_SupportsDType"": (_npt._SupportsDType, np.int64(1)),\n', '+    ""_SupportsArray"": (_npt._SupportsArray, np.arange(10)),\n', '+    ""_SupportsArrayFunc"": (_npt._SupportsArrayFunc, np.arange(10)),\n', '+    ""_NestedSequence"": (_npt._NestedSequence, [1]),\n', '+}\n', '+\n', '+\n', '+@pytest.mark.parametrize(""cls,obj"", PROTOCOLS.values(), ids=PROTOCOLS.keys())\n', '+class TestRuntimeProtocol:\n', '+    def test_isinstance(self, cls: type[Any], obj: object) -> None:\n', '+        assert isinstance(obj, cls)\n', '+        assert not isinstance(None, cls)\n', '+\n', '+    def test_issubclass(self, cls: type[Any], obj: object) -> None:\n', '+        if cls is _npt._SupportsDType:\n', '+            pytest.xfail(\n', '+                ""Protocols with non-method members don\'t support issubclass()""\n', '+            )\n', '+        assert issubclass(type(obj), cls)\n', '+        assert not issubclass(type(None), cls)\n']","['     keys = TYPES.keys()\n', '     ref = set(npt.__all__)\n', '     assert keys == ref\n']"
numpy/numpy,v1.23.3,v1.23.4,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.23.4-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.23.3-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.23.2,v1.23.3,"['     ""dtype[integer[Any]]"",\n', '     int,\n', ' ]\n', '+\n', '+# Extra ArrayLike type so that pyright can deal with NDArray[Any]\n', '+# Used as the first overload, should only match NDArray[Any],\n', '+# not any actual types.\n', '+# https://github.com/numpy/numpy/pull/22193\n', '+class _UnknownType: \n', '+    ...\n', '+\n', '+\n', '+_ArrayLikeUnknown = _DualArrayLike[\n', '+    ""dtype[_UnknownType]"",\n', '+    _UnknownType,\n', '+]\n']","['     ""dtype[integer[Any]]"",\n', '     int,\n', ' ]\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' def vecdot(x1: Array, x2: Array, /, *, axis: int = -1) -> Array:\n', '     if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:\n', ""         raise TypeError('Only numeric dtypes are allowed in vecdot')\n"", '+    ndim = max(x1.ndim, x2.ndim)\n', '+    x1_shape = (1,)*(ndim - x1.ndim) + tuple(x1.shape)\n', '+    x2_shape = (1,)*(ndim - x2.ndim) + tuple(x2.shape)\n', '+    if x1_shape[axis] != x2_shape[axis]:\n', '+        raise ValueError(""x1 and x2 must have the same size along the given axis"")\n', '+\n', '+    x1_, x2_ = np.broadcast_arrays(x1._array, x2._array)\n', '+    x1_ = np.moveaxis(x1_, axis, -1)\n', '+    x2_ = np.moveaxis(x2_, axis, -1)\n', '+\n', '+    res = x1_[..., None, :] @ x2_[..., None]\n', '+    return Array._new(res[..., 0, 0])\n', ' \n', ' \n', ' # Note: the name here is different from norm(). The array API norm is split\n']","[' def vecdot(x1: Array, x2: Array, /, *, axis: int = -1) -> Array:\n', '     if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:\n', ""         raise TypeError('Only numeric dtypes are allowed in vecdot')\n"", '-    return tensordot(x1, x2, axes=((axis,), (axis,)))\n', ' \n', ' \n', ' # Note: the name here is different from norm(). The array API norm is split\n']"
numpy/numpy,v1.23.2,v1.23.3,"['                 ""immintrin.h"",  # AVX\n', '                 ""features.h"",  # for glibc version linux\n', '                 ""xlocale.h"",  # see GH#8367\n', '+                ""dlfcn.h"",  # dladdr\n', '+                ""execinfo.h"",  # backtrace\n', '+                ""libunwind.h"",  # backtrace for LLVM/Clang using libunwind\n', '                 ""sys/mman.h"", #madvise\n', ' ]\n', ' \n']","['                 ""immintrin.h"",  # AVX\n', '                 ""features.h"",  # for glibc version linux\n', '                 ""xlocale.h"",  # see GH#8367\n', '-                ""dlfcn.h"", # dladdr\n', '                 ""sys/mman.h"", #madvise\n', ' ]\n', ' \n']"
numpy/numpy,v1.23.2,v1.23.3,"[' this is private API, but when added, public API may be added here.\n', ' """"""\n', ' \n', '+from __future__ import annotations\n', '+\n', ' import sys\n', ' import types\n', '+from typing import Any\n', ' \n', ' import pytest\n', ' \n']","[' this is private API, but when added, public API may be added here.\n', ' """"""\n', ' \n', ' import sys\n', ' import types\n', '-from typing import Any, Type\n', ' \n', ' import pytest\n', ' \n']"
numpy/numpy,v1.23.2,v1.23.3,"[' \n', ' \n', ' @pytest.mark.skipif(sys.version_info < (3, 9), reason=""Requires python 3.9"")\n', '+@pytest.mark.parametrize(\n', '+    ""cls"", [np.ndarray, np.recarray, np.chararray, np.matrix, np.memmap]\n', '+)\n', ' class TestClassGetItem:\n', '+    def test_class_getitem(self, cls: type[np.ndarray]) -> None:\n', '         """"""Test `ndarray.__class_getitem__`.""""""\n', '         alias = cls[Any, Any]\n', '         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is cls\n', ' \n', '     @pytest.mark.parametrize(""arg_len"", range(4))\n', '+    def test_subscript_tup(self, cls: type[np.ndarray], arg_len: int) -> None:\n', '         arg_tup = (Any,) * arg_len\n', '+        if arg_len in (1, 2):\n', '+            assert cls[arg_tup]\n', '         else:\n', '+            match = f""Too {\'few\' if arg_len == 0 else \'many\'} arguments""\n', '+            with pytest.raises(TypeError, match=match):\n', '+                cls[arg_tup]\n', ' \n', ' \n', ' @pytest.mark.skipif(sys.version_info >= (3, 9), reason=""Requires python 3.8"")\n']","[' \n', ' \n', ' @pytest.mark.skipif(sys.version_info < (3, 9), reason=""Requires python 3.9"")\n', ' class TestClassGetItem:\n', '-    @pytest.mark.parametrize(\n', '-        ""cls"", [np.ndarray, np.recarray, np.chararray, np.matrix, np.memmap]\n', '-    )\n', '-    def test_class_getitem(self, cls: Type[np.ndarray]) -> None:\n', '         """"""Test `ndarray.__class_getitem__`.""""""\n', '         alias = cls[Any, Any]\n', '         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is cls\n', ' \n', '     @pytest.mark.parametrize(""arg_len"", range(4))\n', '-    def test_subscript_tuple(self, arg_len: int) -> None:\n', '         arg_tup = (Any,) * arg_len\n', '-        if arg_len == 2:\n', '-            assert np.ndarray[arg_tup]\n', '         else:\n', '-            with pytest.raises(TypeError):\n', '-                np.ndarray[arg_tup]\n', '-\n', '-    def test_subscript_scalar(self) -> None:\n', '-        with pytest.raises(TypeError):\n', '-            np.ndarray[Any]\n', ' \n', ' \n', ' @pytest.mark.skipif(sys.version_info >= (3, 9), reason=""Requires python 3.8"")\n']"
numpy/numpy,v1.23.2,v1.23.3,"['             min = np.array([np.iinfo(t).min])\n', '             min //= -1\n', ' \n', '+        with np.errstate(over=""ignore""):\n', '             for t in (np.int8, np.int16, np.int32, np.int64, int):\n', '                 test_type(t)\n', ' \n']","['             min = np.array([np.iinfo(t).min])\n', '             min //= -1\n', ' \n', '-        with np.errstate(divide=""ignore""):\n', '             for t in (np.int8, np.int16, np.int32, np.int64, int):\n', '                 test_type(t)\n', ' \n']"
numpy/numpy,v1.23.2,v1.23.3,"['         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is np.complexfloating\n', ' \n', '+    @pytest.mark.parametrize(""arg_len"", range(4))\n', '+    def test_abc_complexfloating_subscript_tuple(self, arg_len: int) -> None:\n', '+        arg_tup = (Any,) * arg_len\n', '+        if arg_len in (1, 2):\n', '+            assert np.complexfloating[arg_tup]\n', '+        else:\n', '+            match = f""Too {\'few\' if arg_len == 0 else \'many\'} arguments""\n', '+            with pytest.raises(TypeError, match=match):\n', '+                np.complexfloating[arg_tup]\n', '+\n', '     @pytest.mark.parametrize(""cls"", [np.generic, np.flexible, np.character])\n', '     def test_abc_non_numeric(self, cls: Type[np.generic]) -> None:\n', '         with pytest.raises(TypeError):\n']","['         assert isinstance(alias, types.GenericAlias)\n', '         assert alias.__origin__ is np.complexfloating\n', ' \n', '     @pytest.mark.parametrize(""cls"", [np.generic, np.flexible, np.character])\n', '     def test_abc_non_numeric(self, cls: Type[np.generic]) -> None:\n', '         with pytest.raises(TypeError):\n']"
numpy/numpy,v1.23.2,v1.23.3,"['         with pytest.raises(TypeError):\n', '             np.ldexp(1., np.uint64(3), signature=(None, None, ""d""))\n', ' \n', '+    def test_partial_signature_mismatch_with_cache(self):\n', '+        with pytest.raises(TypeError):\n', '+            np.add(np.float16(1), np.uint64(2), sig=(""e"", ""d"", None))\n', '+        # Ensure e,d->None is in the dispatching cache (double loop)\n', '+        np.add(np.float16(1), np.float64(2))\n', '+        # The error must still be raised:\n', '+        with pytest.raises(TypeError):\n', '+            np.add(np.float16(1), np.uint64(2), sig=(""e"", ""d"", None))\n', '+\n', '     def test_use_output_signature_for_all_arguments(self):\n', '         # Test that providing only `dtype=` or `signature=(None, None, dtype)`\n', '         # is sufficient if falling back to a homogeneous signature works.\n']","['         with pytest.raises(TypeError):\n', '             np.ldexp(1., np.uint64(3), signature=(None, None, ""d""))\n', ' \n', '     def test_use_output_signature_for_all_arguments(self):\n', '         # Test that providing only `dtype=` or `signature=(None, None, dtype)`\n', '         # is sufficient if falling back to a homogeneous signature works.\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' import pytest\n', ' import sys\n', ' import os\n', '+import operator\n', ' from fractions import Fraction\n', ' from functools import reduce\n', '+from collections import namedtuple\n', ' \n', ' import numpy.core.umath as ncu\n', ' from numpy.core import _umath_tests as ncu_tests\n']","[' import pytest\n', ' import sys\n', ' import os\n', ' from fractions import Fraction\n', ' from functools import reduce\n', ' \n', ' import numpy.core.umath as ncu\n', ' from numpy.core import _umath_tests as ncu_tests\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' from numpy.testing._private.utils import _glibc_older_than\n', ' \n', ' \n', '+def interesting_binop_operands(val1, val2, dtype):\n', '+    """"""\n', '+    Helper to create ""interesting"" operands to cover common code paths:\n', '+    * scalar inputs\n', '+    * only first ""values"" is an array (e.g. scalar division fast-paths)\n', '+    * Longer array (SIMD) placing the value of interest at different positions\n', '+    * Oddly strided arrays which may not be SIMD compatible\n', '+\n', '+    It does not attempt to cover unaligned access or mixed dtypes.\n', '+    These are normally handled by the casting/buffering machinery.\n', '+\n', '+    This is not a fixture (currently), since I believe a fixture normally\n', '+    only yields once?\n', '+    """"""\n', '+    fill_value = 1  # could be a parameter, but maybe not an optional one?\n', '+\n', '+    arr1 = np.full(10003, dtype=dtype, fill_value=fill_value)\n', '+    arr2 = np.full(10003, dtype=dtype, fill_value=fill_value)\n', '+\n', '+    arr1[0] = val1\n', '+    arr2[0] = val2\n', '+\n', '+    extractor = lambda res: res\n', '+    yield arr1[0], arr2[0], extractor, ""scalars""\n', '+\n', '+    extractor = lambda res: res\n', '+    yield arr1[0, ...], arr2[0, ...], extractor, ""scalar-arrays""\n', '+\n', '+    # reset array values to fill_value:\n', '+    arr1[0] = fill_value\n', '+    arr2[0] = fill_value\n', '+\n', '+    for pos in [0, 1, 2, 3, 4, 5, -1, -2, -3, -4]:\n', '+        arr1[pos] = val1\n', '+        arr2[pos] = val2\n', '+\n', '+        extractor = lambda res: res[pos]\n', '+        yield arr1, arr2, extractor, f""off-{pos}""\n', '+        yield arr1, arr2[pos], extractor, f""off-{pos}-with-scalar""\n', '+\n', '+        arr1[pos] = fill_value\n', '+        arr2[pos] = fill_value\n', '+\n', '+    for stride in [-1, 113]:\n', '+        op1 = arr1[::stride]\n', '+        op2 = arr2[::stride]\n', '+        op1[10] = val1\n', '+        op2[10] = val2\n', '+\n', '+        extractor = lambda res: res[10]\n', '+        yield op1, op2, extractor, f""stride-{stride}""\n', '+\n', '+        op1[10] = fill_value\n', '+        op2[10] = fill_value\n', '+\n', '+\n', ' def on_powerpc():\n', '     """""" True if we are running on a Power PC platform.""""""\n', ""     return platform.processor() == 'powerpc' or \\\n""]","[' from numpy.testing._private.utils import _glibc_older_than\n', ' \n', ' \n', ' def on_powerpc():\n', '     """""" True if we are running on a Power PC platform.""""""\n', ""     return platform.processor() == 'powerpc' or \\\n""]"
numpy/numpy,v1.23.2,v1.23.3,"['         a = np.array([np.nan], dtype=object)\n', '         assert_equal(np.not_equal(a, a), [True])\n', ' \n', '+    def test_error_in_equal_reduce(self):\n', '+        # gh-20929\n', '+        # make sure np.equal.reduce raises a TypeError if an array is passed\n', '+        # without specifying the dtype\n', '+        a = np.array([0, 0])\n', '+        assert_equal(np.equal.reduce(a, dtype=bool), True)\n', '+        assert_raises(TypeError, np.equal.reduce, a)\n', '+\n', ' \n', ' class TestAdd:\n', '     def test_reduce_alignment(self):\n']","['         a = np.array([np.nan], dtype=object)\n', '         assert_equal(np.not_equal(a, a), [True])\n', ' \n', ' \n', ' class TestAdd:\n', '     def test_reduce_alignment(self):\n']"
numpy/numpy,v1.23.2,v1.23.3,"['         a_lst, b_lst = a.tolist(), b.tolist()\n', ' \n', '         c_div = lambda n, d: (\n', '+            0 if d == 0 else (\n', '+                fo.min if (n and n == fo.min and d == -1) else n//d\n', '+            )\n', '         )\n', ""         with np.errstate(divide='ignore'):\n"", '             ac = a.copy()\n']","['         a_lst, b_lst = a.tolist(), b.tolist()\n', ' \n', '         c_div = lambda n, d: (\n', '-            0 if d == 0 or (n and n == fo.min and d == -1) else n//d\n', '         )\n', ""         with np.errstate(divide='ignore'):\n"", '             ac = a.copy()\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' \n', '         for divisor in divisors:\n', '             ac = a.copy()\n', ""+            with np.errstate(divide='ignore', over='ignore'):\n"", '                 div_a = a // divisor\n', '                 ac //= divisor\n', '             div_lst = [c_div(i, divisor) for i in a_lst]\n']","[' \n', '         for divisor in divisors:\n', '             ac = a.copy()\n', ""-            with np.errstate(divide='ignore'):\n"", '                 div_a = a // divisor\n', '                 ac //= divisor\n', '             div_lst = [c_div(i, divisor) for i in a_lst]\n']"
numpy/numpy,v1.23.2,v1.23.3,"['             assert all(div_a == div_lst), msg\n', '             assert all(ac == div_lst), msg_eq\n', ' \n', ""+        with np.errstate(divide='raise', over='raise'):\n"", '+            if 0 in b:\n', '                 # Verify overflow case\n', '+                with pytest.raises(FloatingPointError,\n', '+                        match=""divide by zero encountered in floor_divide""):\n', '                     a // b\n', '             else:\n', '                 a // b\n', '             if fo.min and fo.min in a:\n', '+                with pytest.raises(FloatingPointError,\n', ""+                        match='overflow encountered in floor_divide'):\n"", '                     a // -1\n', '             elif fo.min:\n', '                 a // -1\n', '+            with pytest.raises(FloatingPointError,\n', '+                    match=""divide by zero encountered in floor_divide""):\n', '                 a // 0\n', '+            with pytest.raises(FloatingPointError,\n', '+                    match=""divide by zero encountered in floor_divide""):\n', '                 ac = a.copy()\n', '                 ac //= 0\n', ' \n']","['             assert all(div_a == div_lst), msg\n', '             assert all(ac == div_lst), msg_eq\n', ' \n', ""-        with np.errstate(divide='raise'):\n"", '-            if 0 in b or (fo.min and -1 in b and fo.min in a):\n', '                 # Verify overflow case\n', '-                with pytest.raises(FloatingPointError):\n', '                     a // b\n', '             else:\n', '                 a // b\n', '             if fo.min and fo.min in a:\n', '-                with pytest.raises(FloatingPointError):\n', '                     a // -1\n', '             elif fo.min:\n', '                 a // -1\n', '-            with pytest.raises(FloatingPointError):\n', '                 a // 0\n', '-            with pytest.raises(FloatingPointError):\n', '                 ac = a.copy()\n', '                 ac //= 0\n', ' \n']"
numpy/numpy,v1.23.2,v1.23.3,"['         msg = ""Reduce floor integer division check""\n', '         assert div_a == div_lst, msg\n', ' \n', ""+        with np.errstate(divide='raise', over='raise'):\n"", '+            with pytest.raises(FloatingPointError,\n', '+                    match=""divide by zero encountered in reduce""):\n', '                 np.floor_divide.reduce(np.arange(-100, 100, dtype=dtype))\n', '             if fo.min:\n', '+                with pytest.raises(FloatingPointError,\n', ""+                        match='overflow encountered in reduce'):\n"", '                     np.floor_divide.reduce(\n', '                         np.array([fo.min, 1, -1], dtype=dtype)\n', '                     )\n']","['         msg = ""Reduce floor integer division check""\n', '         assert div_a == div_lst, msg\n', ' \n', ""-        with np.errstate(divide='raise'):\n"", '-            with pytest.raises(FloatingPointError):\n', '                 np.floor_divide.reduce(np.arange(-100, 100, dtype=dtype))\n', '             if fo.min:\n', '-                with pytest.raises(FloatingPointError):\n', '                     np.floor_divide.reduce(\n', '                         np.array([fo.min, 1, -1], dtype=dtype)\n', '                     )\n']"
numpy/numpy,v1.23.2,v1.23.3,"[""                 assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, rem))\n"", ' \n', ' \n', '+class TestDivisionIntegerOverflowsAndDivideByZero:\n', ""+    result_type = namedtuple('result_type',\n"", ""+            ['nocast', 'casted'])\n"", '+    helper_lambdas = {\n', ""+        'zero': lambda dtype: 0,\n"", ""+        'min': lambda dtype: np.iinfo(dtype).min,\n"", ""+        'neg_min': lambda dtype: -np.iinfo(dtype).min,\n"", ""+        'min-zero': lambda dtype: (np.iinfo(dtype).min, 0),\n"", ""+        'neg_min-zero': lambda dtype: (-np.iinfo(dtype).min, 0),\n"", '+    }\n', '+    overflow_results = {\n', '+        np.remainder: result_type(\n', ""+            helper_lambdas['zero'], helper_lambdas['zero']),\n"", '+        np.fmod: result_type(\n', ""+            helper_lambdas['zero'], helper_lambdas['zero']),\n"", '+        operator.mod: result_type(\n', ""+            helper_lambdas['zero'], helper_lambdas['zero']),\n"", '+        operator.floordiv: result_type(\n', ""+            helper_lambdas['min'], helper_lambdas['neg_min']),\n"", '+        np.floor_divide: result_type(\n', ""+            helper_lambdas['min'], helper_lambdas['neg_min']),\n"", '+        np.divmod: result_type(\n', ""+            helper_lambdas['min-zero'], helper_lambdas['neg_min-zero'])\n"", '+    }\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""Integer""])\n', '+    def test_signed_division_overflow(self, dtype):\n', '+        to_check = interesting_binop_operands(np.iinfo(dtype).min, -1, dtype)\n', '+        for op1, op2, extractor, operand_identifier in to_check:\n', '+            with pytest.warns(RuntimeWarning, match=""overflow encountered""):\n', '+                res = op1 // op2\n', '+\n', '+            assert res.dtype == op1.dtype\n', '+            assert extractor(res) == np.iinfo(op1.dtype).min\n', '+\n', '+            # Remainder is well defined though, and does not warn:\n', '+            res = op1 % op2\n', '+            assert res.dtype == op1.dtype\n', '+            assert extractor(res) == 0\n', '+            # Check fmod as well:\n', '+            res = np.fmod(op1, op2)\n', '+            assert extractor(res) == 0\n', '+\n', '+            # Divmod warns for the division part:\n', '+            with pytest.warns(RuntimeWarning, match=""overflow encountered""):\n', '+                res1, res2 = np.divmod(op1, op2)\n', '+\n', '+            assert res1.dtype == res2.dtype == op1.dtype\n', '+            assert extractor(res1) == np.iinfo(op1.dtype).min\n', '+            assert extractor(res2) == 0\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_divide_by_zero(self, dtype):\n', '+        # Note that the return value cannot be well defined here, but NumPy\n', '+        # currently uses 0 consistently.  This could be changed.\n', '+        to_check = interesting_binop_operands(1, 0, dtype)\n', '+        for op1, op2, extractor, operand_identifier in to_check:\n', '+            with pytest.warns(RuntimeWarning, match=""divide by zero""):\n', '+                res = op1 // op2\n', '+\n', '+            assert res.dtype == op1.dtype\n', '+            assert extractor(res) == 0\n', '+\n', '+            with pytest.warns(RuntimeWarning, match=""divide by zero""):\n', '+                res1, res2 = np.divmod(op1, op2)\n', '+\n', '+            assert res1.dtype == res2.dtype == op1.dtype\n', '+            assert extractor(res1) == 0\n', '+            assert extractor(res2) == 0\n', '+\n', '+    @pytest.mark.parametrize(""dividend_dtype"",\n', ""+            np.sctypes['int'])\n"", '+    @pytest.mark.parametrize(""divisor_dtype"",\n', ""+            np.sctypes['int'])\n"", '+    @pytest.mark.parametrize(""operation"",\n', '+            [np.remainder, np.fmod, np.divmod, np.floor_divide,\n', '+             operator.mod, operator.floordiv])\n', ""+    @np.errstate(divide='warn', over='warn')\n"", '+    def test_overflows(self, dividend_dtype, divisor_dtype, operation):\n', '+        # SIMD tries to perform the operation on as many elements as possible\n', ""+        # that is a multiple of the register's size. We resort to the\n"", '+        # default implementation for the leftover elements.\n', '+        # We try to cover all paths here.\n', '+        arrays = [np.array([np.iinfo(dividend_dtype).min]*i,\n', '+                           dtype=dividend_dtype) for i in range(1, 129)]\n', '+        divisor = np.array([-1], dtype=divisor_dtype)\n', '+        # If dividend is a larger type than the divisor (`else` case),\n', '+        # then, result will be a larger type than dividend and will not\n', '+        # result in an overflow for `divmod` and `floor_divide`.\n', '+        if np.dtype(dividend_dtype).itemsize >= np.dtype(\n', '+                divisor_dtype).itemsize and operation in (\n', '+                        np.divmod, np.floor_divide, operator.floordiv):\n', '+            with pytest.warns(\n', '+                    RuntimeWarning,\n', '+                    match=""overflow encountered in""):\n', '+                result = operation(\n', '+                            dividend_dtype(np.iinfo(dividend_dtype).min),\n', '+                            divisor_dtype(-1)\n', '+                        )\n', '+                assert result == self.overflow_results[operation].nocast(\n', '+                        dividend_dtype)\n', '+\n', '+            # Arrays\n', '+            for a in arrays:\n', '+                # In case of divmod, we need to flatten the result\n', '+                # column first as we get a column vector of quotient and\n', '+                # remainder and a normal flatten of the expected result.\n', '+                with pytest.warns(\n', '+                        RuntimeWarning,\n', '+                        match=""overflow encountered in""):\n', ""+                    result = np.array(operation(a, divisor)).flatten('f')\n"", '+                    expected_array = np.array(\n', '+                            [self.overflow_results[operation].nocast(\n', '+                                dividend_dtype)]*len(a)).flatten()\n', '+                    assert_array_equal(result, expected_array)\n', '+        else:\n', '+            # Scalars\n', '+            result = operation(\n', '+                        dividend_dtype(np.iinfo(dividend_dtype).min),\n', '+                        divisor_dtype(-1)\n', '+                    )\n', '+            assert result == self.overflow_results[operation].casted(\n', '+                    dividend_dtype)\n', '+\n', '+            # Arrays\n', '+            for a in arrays:\n', '+                # See above comment on flatten\n', ""+                result = np.array(operation(a, divisor)).flatten('f')\n"", '+                expected_array = np.array(\n', '+                        [self.overflow_results[operation].casted(\n', '+                            dividend_dtype)]*len(a)).flatten()\n', '+                assert_array_equal(result, expected_array)\n', '+\n', '+\n', ' class TestCbrt:\n', '     def test_cbrt_scalar(self):\n', '         assert_almost_equal((np.cbrt(np.float32(-2.5)**3)), -2.5)\n']","[""                 assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, rem))\n"", ' \n', ' \n', ' class TestCbrt:\n', '     def test_cbrt_scalar(self):\n', '         assert_almost_equal((np.cbrt(np.float32(-2.5)**3)), -2.5)\n']"
numpy/numpy,v1.23.2,v1.23.3,"['     cxx.compiler_cxx = cxx.compiler_cxx\n', '     cxx.compiler_so = [cxx.compiler_cxx[0]] + \\\n', '                       sanitize_cxx_flags(cxx.compiler_so[1:])\n', ""+    if (sys.platform.startswith(('aix', 'os400')) and\n"", ""+            'ld_so_aix' in cxx.linker_so[0]):\n"", '         # AIX needs the ld_so_aix script included with Python\n', '         cxx.linker_so = [cxx.linker_so[0], cxx.compiler_cxx[0]] \\\n', '                         + cxx.linker_so[2:]\n', ""+    if sys.platform.startswith('os400'):\n"", '+        #This is required by i 7.4 and prievous for PRId64 in printf() call.\n', ""+        cxx.compiler_so.append('-D__STDC_FORMAT_MACROS')\n"", '+        #This a bug of gcc10.3, which failed to handle the TLS init.\n', ""+        cxx.compiler_so.append('-fno-extern-tls-init')\n"", ""+        cxx.linker_so.append('-fno-extern-tls-init')\n"", '     else:\n', '         cxx.linker_so = [cxx.compiler_cxx[0]] + cxx.linker_so[1:]\n', '     return cxx\n']","['     cxx.compiler_cxx = cxx.compiler_cxx\n', '     cxx.compiler_so = [cxx.compiler_cxx[0]] + \\\n', '                       sanitize_cxx_flags(cxx.compiler_so[1:])\n', ""-    if sys.platform.startswith('aix') and 'ld_so_aix' in cxx.linker_so[0]:\n"", '         # AIX needs the ld_so_aix script included with Python\n', '         cxx.linker_so = [cxx.linker_so[0], cxx.compiler_cxx[0]] \\\n', '                         + cxx.linker_so[2:]\n', '     else:\n', '         cxx.linker_so = [cxx.compiler_cxx[0]] + cxx.linker_so[1:]\n', '     return cxx\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' \n', ""         if sys.platform == 'darwin':\n"", ""             return f'-Wl,-rpath,{dir}'\n"", ""+        elif sys.platform.startswith(('aix', 'os400')):\n"", '             # AIX RPATH is called LIBPATH\n', ""             return f'-Wl,-blibpath:{dir}'\n"", '         else:\n']","[' \n', ""         if sys.platform == 'darwin':\n"", ""             return f'-Wl,-rpath,{dir}'\n"", ""-        elif sys.platform[:3] == 'aix':\n"", '             # AIX RPATH is called LIBPATH\n', ""             return f'-Wl,-blibpath:{dir}'\n"", '         else:\n']"
numpy/numpy,v1.23.2,v1.23.3,"[""     module_dir_switch = '-J'\n"", ""     module_include_switch = '-I'\n"", ' \n', ""+    if sys.platform.startswith(('aix', 'os400')):\n"", ""         executables['linker_so'].append('-lpthread')\n"", ""         if platform.architecture()[0][:2] == '64':\n"", ""             for key in ['compiler_f77', 'compiler_f90','compiler_fix','linker_so', 'linker_exe']:\n""]","[""     module_dir_switch = '-J'\n"", ""     module_include_switch = '-I'\n"", ' \n', ""-    if sys.platform[:3] == 'aix':\n"", ""         executables['linker_so'].append('-lpthread')\n"", ""         if platform.architecture()[0][:2] == '64':\n"", ""             for key in ['compiler_f77', 'compiler_f90','compiler_fix','linker_so', 'linker_exe']:\n""]"
numpy/numpy,v1.23.2,v1.23.3,"['         return 1;\n', '     }\n', '     if (PyArray_CheckScalar(obj)) { /* 0-dim array or still array scalar */\n', '+        PyArrayObject *arr;\n', '         if (PyArray_Check(obj)) {\n', '+            arr = (PyArrayObject *)PyArray_Cast((PyArrayObject *)obj, NPY_CDOUBLE);\n', '         }\n', '         else {\n', '+            arr = (PyArrayObject *)PyArray_FromScalar(obj, PyArray_DescrFromType(NPY_CDOUBLE));\n', '         }\n', '         if (arr == NULL) {\n', '             return 0;\n']","['         return 1;\n', '     }\n', '     if (PyArray_CheckScalar(obj)) { /* 0-dim array or still array scalar */\n', '-        PyObject *arr;\n', '         if (PyArray_Check(obj)) {\n', '-            arr = PyArray_Cast((PyArrayObject *)obj, NPY_CDOUBLE);\n', '         }\n', '         else {\n', '-            arr = PyArray_FromScalar(obj, PyArray_DescrFromType(NPY_CDOUBLE));\n', '         }\n', '         if (arr == NULL) {\n', '             return 0;\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' from io import BytesIO, StringIO\n', ' from datetime import datetime\n', ' import locale\n', '+from multiprocessing import Value, get_context\n', ' from ctypes import c_bool\n', ' \n', ' import numpy as np\n']","[' from io import BytesIO, StringIO\n', ' from datetime import datetime\n', ' import locale\n', '-from multiprocessing import Process, Value\n', ' from ctypes import c_bool\n', ' \n', ' import numpy as np\n']"
numpy/numpy,v1.23.2,v1.23.3,"['         # Use an object in shared memory to re-raise the MemoryError exception\n', '         # in our process if needed, see gh-16889\n', '         memoryerror_raised = Value(c_bool)\n', '+\n', '+        # Since Python 3.8, the default start method for multiprocessing has \n', ""+        # been changed from 'fork' to 'spawn' on macOS, causing inconsistency \n"", '+        # on memory sharing model, lead to failed test for check_large_zip\n', ""+        ctx = get_context('fork')\n"", '+        p = ctx.Process(target=check_large_zip, args=(memoryerror_raised,))\n', '         p.start()\n', '         p.join()\n', '         if memoryerror_raised.value:\n']","['         # Use an object in shared memory to re-raise the MemoryError exception\n', '         # in our process if needed, see gh-16889\n', '         memoryerror_raised = Value(c_bool)\n', '-        p = Process(target=check_large_zip, args=(memoryerror_raised,))\n', '         p.start()\n', '         p.join()\n', '         if memoryerror_raised.value:\n']"
numpy/numpy,v1.23.2,v1.23.3,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.23.3-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.23.2-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.23.1,v1.23.2,"['         ""__deepcopy__"",\n', '         ""__unpacked__"",\n', '         ""__typing_unpacked_tuple_args__"",\n', '+        ""__class__"",\n', '     })\n', ' \n', '     def __getattribute__(self, name: str) -> Any:\n']","['         ""__deepcopy__"",\n', '         ""__unpacked__"",\n', '         ""__typing_unpacked_tuple_args__"",\n', '     })\n', ' \n', '     def __getattribute__(self, name: str) -> Any:\n']"
numpy/numpy,v1.23.1,v1.23.2,"['         dt = np.dtype({""names"": [], ""formats"": [], ""itemsize"": 0}, align=True)\n', '         assert dt == np.dtype([])\n', ' \n', '+    def test_subarray_base_item(self):\n', '+        arr = np.ones(3, dtype=[(""f"", ""i"", 3)])\n', '+        # Extracting the field ""absorbs"" the subarray into a view:\n', '+        assert arr[""f""].base is arr\n', '+        # Extract the structured item, and then check the tuple component:\n', '+        item = arr.item(0)\n', '+        assert type(item) is tuple and len(item) == 1\n', '+        assert item[0].base is arr\n', '+\n', '+    def test_subarray_cast_copies(self):\n', '+        # Older versions of NumPy did NOT copy, but they got the ownership\n', '+        # wrong (not actually knowing the correct base!).  Versions since 1.21\n', '+        # (I think) crashed fairly reliable.  This defines the correct behavior\n', '+        # as a copy.  Keeping the ownership would be possible (but harder)\n', '+        arr = np.ones(3, dtype=[(""f"", ""i"", 3)])\n', '+        cast = arr.astype(object)\n', '+        for fields in cast:\n', '+            assert type(fields) == tuple and len(fields) == 1\n', '+            subarr = fields[0]\n', '+            assert subarr.base is None\n', '+            assert subarr.flags.owndata\n', '+\n', '+\n', ' def iter_struct_object_dtypes():\n', '     """"""\n', '     Iterates over a few complex dtypes and object pattern which\n']","['         dt = np.dtype({""names"": [], ""formats"": [], ""itemsize"": 0}, align=True)\n', '         assert dt == np.dtype([])\n', ' \n', ' def iter_struct_object_dtypes():\n', '     """"""\n', '     Iterates over a few complex dtypes and object pattern which\n']"
numpy/numpy,v1.23.1,v1.23.2,"[""         assert_c(a.copy('C'))\n"", ""         assert_fortran(a.copy('F'))\n"", ""         assert_c(a.copy('A'))\n"", '+    \n', '+    @pytest.mark.parametrize(""dtype"", [\'O\', np.int32, \'i,O\'])\n', '+    def test__deepcopy__(self, dtype):\n', '+        # Force the entry of NULLs into array\n', '+        a = np.empty(4, dtype=dtype)\n', '+        ctypes.memset(a.ctypes.data, 0, a.nbytes)\n', '+\n', '+        # Ensure no error is raised, see gh-21833\n', '+        b = a.__deepcopy__({})\n', '+\n', '+        a[0] = 42\n', '+        with pytest.raises(AssertionError):\n', '+            assert_array_equal(a, b)\n', '+\n', '+    def test__deepcopy__catches_failure(self):\n', '+        class MyObj:\n', '+            def __deepcopy__(self, *args, **kwargs):\n', '+                raise RuntimeError\n', '+\n', ""+        arr = np.array([1, MyObj(), 3], dtype='O')\n"", '+        with pytest.raises(RuntimeError):\n', '+            arr.__deepcopy__({})\n', ' \n', '     def test_sort_order(self):\n', '         # Test sorting an array with fields\n']","[""         assert_c(a.copy('C'))\n"", ""         assert_fortran(a.copy('F'))\n"", ""         assert_c(a.copy('A'))\n"", ' \n', '     def test_sort_order(self):\n', '         # Test sorting an array with fields\n']"
numpy/numpy,v1.23.1,v1.23.2,"[' \n', ' \n', ' def bad_arcsinh():\n', '+    """"""The blocklisted trig functions are not accurate on aarch64/PPC for\n', '     complex256. Rather than dig through the actual problem skip the\n', '     test. This should be fixed when we can move past glibc2.17\n', '     which is the version in manylinux2014\n', '     """"""\n', ""+    if platform.machine() == 'aarch64':\n"", '+        x = 1.78e-10\n', '+    elif on_powerpc():\n', '+        x = 2.16e-10\n', '+    else:\n', '+        return False\n', '     v1 = np.arcsinh(np.float128(x))\n', '     v2 = np.arcsinh(np.complex256(x)).real\n', '     # The eps for float128 is 1-e33, so this is way bigger\n']","[' \n', ' \n', ' def bad_arcsinh():\n', '-    """"""The blocklisted trig functions are not accurate on aarch64 for\n', '     complex256. Rather than dig through the actual problem skip the\n', '     test. This should be fixed when we can move past glibc2.17\n', '     which is the version in manylinux2014\n', '     """"""\n', '-    x = 1.78e-10\n', '     v1 = np.arcsinh(np.float128(x))\n', '     v2 = np.arcsinh(np.complex256(x)).real\n', '     # The eps for float128 is 1-e33, so this is way bigger\n']"
numpy/numpy,v1.23.1,v1.23.2,"['         x_basic = np.logspace(-2.999, 0, 10, endpoint=False)\n', ' \n', '         if dtype is np.longcomplex:\n', '+            if bad_arcsinh():\n', '                 pytest.skip(""Trig functions of np.longcomplex values known ""\n', '+                            ""to be inaccurate on aarch64 and PPC for some ""\n', '+                            ""compilation configurations."")\n', ""             # It's not guaranteed that the system-provided arc functions\n"", '             # are accurate down to a few epsilons. (Eg. on Linux 64-bit)\n', '             # So, give more leeway for long complex tests here:\n']","['         x_basic = np.logspace(-2.999, 0, 10, endpoint=False)\n', ' \n', '         if dtype is np.longcomplex:\n', ""-            if (platform.machine() == 'aarch64' and bad_arcsinh()):\n"", '                 pytest.skip(""Trig functions of np.longcomplex values known ""\n', '-                            ""to be inaccurate on aarch64 for some compilation ""\n', '-                            ""configurations."")\n', ""             # It's not guaranteed that the system-provided arc functions\n"", '             # are accurate down to a few epsilons. (Eg. on Linux 64-bit)\n', '             # So, give more leeway for long complex tests here:\n']"
numpy/numpy,v1.23.1,v1.23.2,"[' \n', '     def get_target(self):\n', '         try:\n', '+            p = subprocess.Popen(\n', ""+                self.compiler_f77 + ['-v'],\n"", '+                stdin=subprocess.PIPE,\n', '+                stderr=subprocess.PIPE,\n', '+            )\n', '+            stdout, stderr = p.communicate()\n', '+            output = (stdout or b"""") + (stderr or b"""")\n', '         except (OSError, subprocess.CalledProcessError):\n', '             pass\n', '         else:\n']","[' \n', '     def get_target(self):\n', '         try:\n', ""-            output = subprocess.check_output(self.compiler_f77 + ['-v'])\n"", '         except (OSError, subprocess.CalledProcessError):\n', '             pass\n', '         else:\n']"
numpy/numpy,v1.23.1,v1.23.2,"['         data, e.g. ``converters = lambda s: float(s.strip() or 0)`` will\n', '         convert empty fields to 0.\n', '         Default: None.\n', '+\n', '+        .. versionchanged:: 1.23.0\n', '+           The ability to pass a single callable to be applied to all columns\n', '+           was added.\n', '+\n', '     skiprows : int, optional\n', '         Skip the first `skiprows` lines, including comments; default: 0.\n', '     usecols : int or sequence, optional\n']","['         data, e.g. ``converters = lambda s: float(s.strip() or 0)`` will\n', '         convert empty fields to 0.\n', '         Default: None.\n', '     skiprows : int, optional\n', '         Skip the first `skiprows` lines, including comments; default: 0.\n', '     usecols : int or sequence, optional\n']"
numpy/numpy,v1.23.1,v1.23.2,"['         # double subtraction is needed to remove the extra precision of t < 0.5\n', '         left = nfb._lerp(a, b, 1 - (1 - t))\n', '         right = nfb._lerp(b, a, 1 - t)\n', '+        assert_allclose(left, right)\n', ' \n', '     def test_linear_interpolation_formula_0d_inputs(self):\n', '         a = np.array(2)\n']","['         # double subtraction is needed to remove the extra precision of t < 0.5\n', '         left = nfb._lerp(a, b, 1 - (1 - t))\n', '         right = nfb._lerp(b, a, 1 - t)\n', '-        assert left == right\n', ' \n', '     def test_linear_interpolation_formula_0d_inputs(self):\n', '         a = np.array(2)\n']"
numpy/numpy,v1.23.1,v1.23.2,"['     dirname = builddir / name\n', '     dirname.mkdir(exist_ok=True)\n', '     cfile = _convert_str_to_file(source_string, dirname)\n', ""+    include_dirs = include_dirs + [sysconfig.get_config_var('INCLUDEPY')]\n"", ' \n', '     return _c_compile(\n', '         cfile, outputfilename=dirname / modname,\n']","['     dirname = builddir / name\n', '     dirname.mkdir(exist_ok=True)\n', '     cfile = _convert_str_to_file(source_string, dirname)\n', ""-    include_dirs = [sysconfig.get_config_var('INCLUDEPY')] + include_dirs\n"", ' \n', '     return _c_compile(\n', '         cfile, outputfilename=dirname / modname,\n']"
numpy/numpy,v1.23.1,v1.23.2,"['         # and they are thus now longer equivalent\n', '         (""__ne__"", lambda n: n != next(iter(n)), (""beta"", 1)),\n', ' \n', '+        # >= beta3\n', '         (""__typing_unpacked_tuple_args__"",\n', '          lambda n: n.__typing_unpacked_tuple_args__, (""beta"", 3)),\n', '+\n', '+        # >= beta4\n', '+        (""__class__"", lambda n: n.__class__ == type(n), (""beta"", 4)),\n', '     ])\n', '     def test_py311_features(\n', '         self,\n']","['         # and they are thus now longer equivalent\n', '         (""__ne__"", lambda n: n != next(iter(n)), (""beta"", 1)),\n', ' \n', '-        # >= beta3 stuff\n', '         (""__typing_unpacked_tuple_args__"",\n', '          lambda n: n.__typing_unpacked_tuple_args__, (""beta"", 3)),\n', '     ])\n', '     def test_py311_features(\n', '         self,\n']"
numpy/numpy,v1.23.1,v1.23.2,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.23.2-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.23.1-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.23.0,v1.23.1,"['         self.tiny = self.xmin\n', '         self.huge = self.xmax\n', '         self.smallest_normal = self.xmin\n', '+        self._str_smallest_normal = float_to_str(self.xmin)\n', '         self.smallest_subnormal = float_to_float(smallest_subnormal)\n', '+        self._str_smallest_subnormal = float_to_str(smallest_subnormal)\n', ' \n', '         import math\n', '         self.precision = int(-math.log10(float_to_float(self.eps)))\n']","['         self.tiny = self.xmin\n', '         self.huge = self.xmax\n', '         self.smallest_normal = self.xmin\n', '         self.smallest_subnormal = float_to_float(smallest_subnormal)\n', ' \n', '         import math\n', '         self.precision = int(-math.log10(float_to_float(self.eps)))\n']"
numpy/numpy,v1.23.0,v1.23.1,"['         return ma_like\n', '     # Fall back to parameter discovery\n', '     warnings.warn(\n', ""+        f'Signature {key} for {ftype} does not match any known type: '\n"", ""+        'falling back to type probe function.\\n'\n"", ""+        'This warnings indicates broken support for the dtype!',\n"", '         UserWarning, stacklevel=2)\n', '     return _discovered_machar(ftype)\n', ' \n']","['         return ma_like\n', '     # Fall back to parameter discovery\n', '     warnings.warn(\n', ""-        'Signature {} for {} does not match any known type: '\n"", ""-        'falling back to type probe function'.format(key, ftype),\n"", '         UserWarning, stacklevel=2)\n', '     return _discovered_machar(ftype)\n', ' \n']"
numpy/numpy,v1.23.0,v1.23.1,"['         assert_raises(ValueError, d.sort, kind=k)\n', '         assert_raises(ValueError, d.argsort, kind=k)\n', ' \n', ""+    @pytest.mark.parametrize('a', [\n"", '+        np.array([0, 1, np.nan], dtype=np.float16),\n', '+        np.array([0, 1, np.nan], dtype=np.float32),\n', '+        np.array([0, 1, np.nan]),\n', '+    ])\n', '+    def test_searchsorted_floats(self, a):\n', '+        # test for floats arrays containing nans. Explicitly test \n', '+        # half, single, and double precision floats to verify that\n', '+        # the NaN-handling is correct.\n', '+        msg = ""Test real (%s) searchsorted with nans, side=\'l\'"" % a.dtype\n', ""         b = a.searchsorted(a, side='left')\n"", '         assert_equal(b, np.arange(3), msg)\n', '+        msg = ""Test real (%s) searchsorted with nans, side=\'r\'"" % a.dtype\n', ""         b = a.searchsorted(a, side='right')\n"", '         assert_equal(b, np.arange(1, 4), msg)\n', '         # check keyword arguments\n', '         a.searchsorted(v=1)\n', ""+        x = np.array([0, 1, np.nan], dtype='float32')\n"", '+        y = np.searchsorted(x, x[-1])\n', '+        assert_equal(y, 2)\n', '+\n', '+    def test_searchsorted_complex(self):\n', '+        # test for complex arrays containing nans. \n', '+        # The search sorted routines use the compare functions for the\n', '+        # array type, so this checks if that is consistent with the sort\n', '+        # order.\n', '         # check double complex\n', '         a = np.zeros(9, dtype=np.complex128)\n', '         a.real += [0, 0, 1, 1, 0, 1, np.nan, np.nan, np.nan]\n']","['         assert_raises(ValueError, d.sort, kind=k)\n', '         assert_raises(ValueError, d.argsort, kind=k)\n', ' \n', '-    def test_searchsorted(self):\n', '-        # test for floats and complex containing nans. The logic is the\n', '-        # same for all float types so only test double types for now.\n', '-        # The search sorted routines use the compare functions for the\n', '-        # array type, so this checks if that is consistent with the sort\n', '-        # order.\n', '-\n', '-        # check double\n', '-        a = np.array([0, 1, np.nan])\n', '-        msg = ""Test real searchsorted with nans, side=\'l\'""\n', ""         b = a.searchsorted(a, side='left')\n"", '         assert_equal(b, np.arange(3), msg)\n', '-        msg = ""Test real searchsorted with nans, side=\'r\'""\n', ""         b = a.searchsorted(a, side='right')\n"", '         assert_equal(b, np.arange(1, 4), msg)\n', '         # check keyword arguments\n', '         a.searchsorted(v=1)\n', '         # check double complex\n', '         a = np.zeros(9, dtype=np.complex128)\n', '         a.real += [0, 0, 1, 1, 0, 1, np.nan, np.nan, np.nan]\n']"
numpy/numpy,v1.23.0,v1.23.1,"[""         a = np.array([0, 128], dtype='>i4')\n"", ""         b = a.searchsorted(np.array(128, dtype='>i4'))\n"", '         assert_equal(b, 1, msg)\n', '+        \n', '+    def test_searchsorted_n_elements(self):\n', '         # Check 0 elements\n', '         a = np.ones(0)\n', ""         b = a.searchsorted([0, 1, 2], 'left')\n""]","[""         a = np.array([0, 128], dtype='>i4')\n"", ""         b = a.searchsorted(np.array(128, dtype='>i4'))\n"", '         assert_equal(b, 1, msg)\n', '-\n', '         # Check 0 elements\n', '         a = np.ones(0)\n', ""         b = a.searchsorted([0, 1, 2], 'left')\n""]"
numpy/numpy,v1.23.0,v1.23.1,"[""         b = a.searchsorted([0, 1, 2], 'right')\n"", '         assert_equal(b, [0, 2, 2])\n', ' \n', '+    def test_searchsorted_unaligned_array(self):\n', '         # Test searching unaligned array\n', '         a = np.arange(10)\n', ""         aligned = np.empty(a.itemsize * a.size + 1, 'uint8')\n""]","[""         b = a.searchsorted([0, 1, 2], 'right')\n"", '         assert_equal(b, [0, 2, 2])\n', ' \n', '         # Test searching unaligned array\n', '         a = np.arange(10)\n', ""         aligned = np.empty(a.itemsize * a.size + 1, 'uint8')\n""]"
numpy/numpy,v1.23.0,v1.23.1,"[""         b = a.searchsorted(unaligned, 'right')\n"", '         assert_equal(b, a + 1)\n', ' \n', '+    def test_searchsorted_resetting(self):\n', '         # Test smart resetting of binsearch indices\n', '         a = np.arange(5)\n', ""         b = a.searchsorted([6, 5, 4], 'left')\n""]","[""         b = a.searchsorted(unaligned, 'right')\n"", '         assert_equal(b, a + 1)\n', ' \n', '         # Test smart resetting of binsearch indices\n', '         a = np.arange(5)\n', ""         b = a.searchsorted([6, 5, 4], 'left')\n""]"
numpy/numpy,v1.23.0,v1.23.1,"[""         b = a.searchsorted([6, 5, 4], 'right')\n"", '         assert_equal(b, [5, 5, 5])\n', ' \n', '+    def test_searchsorted_type_specific(self):\n', '         # Test all type specific binary search functions\n', ""         types = ''.join((np.typecodes['AllInteger'], np.typecodes['AllFloat'],\n"", ""                          np.typecodes['Datetime'], '?O'))\n""]","[""         b = a.searchsorted([6, 5, 4], 'right')\n"", '         assert_equal(b, [5, 5, 5])\n', ' \n', '         # Test all type specific binary search functions\n', ""         types = ''.join((np.typecodes['AllInteger'], np.typecodes['AllFloat'],\n"", ""                          np.typecodes['Datetime'], '?O'))\n""]"
numpy/numpy,v1.23.0,v1.23.1,"['             as_ = args\n', ""         b = postcrack(b, as_, tab=tab + '\\t')\n"", ""         if b['block'] in ['interface', 'abstract interface'] and \\\n"", ""+           not b['body'] and not b.get('implementedby'):\n"", ""             if 'f2pyenhancements' not in b:\n"", '                 continue\n', ""         if b['block'].replace(' ', '') == 'pythonmodule':\n""]","['             as_ = args\n', ""         b = postcrack(b, as_, tab=tab + '\\t')\n"", ""         if b['block'] in ['interface', 'abstract interface'] and \\\n"", ""-           not b['body'] and not b['implementedby']:\n"", ""             if 'f2pyenhancements' not in b:\n"", '                 continue\n', ""         if b['block'].replace(' ', '') == 'pythonmodule':\n""]"
numpy/numpy,v1.23.0,v1.23.1,"['             wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n', '             wgt = wgt.swapaxes(-1, axis)\n', ' \n', '+        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n', '         if np.any(scl == 0.0):\n', '             raise ZeroDivisionError(\n', '                 ""Weights sum to zero, can\'t be normalized"")\n']","['             wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n', '             wgt = wgt.swapaxes(-1, axis)\n', ' \n', '-        scl = wgt.sum(axis=axis, dtype=result_dtype)\n', '         if np.any(scl == 0.0):\n', '             raise ZeroDivisionError(\n', '                 ""Weights sum to zero, can\'t be normalized"")\n']"
numpy/numpy,v1.23.0,v1.23.1,"['         single_value = False\n', '         _obj = obj\n', '         obj = np.asarray(obj)\n', '+        # `size == 0` to allow empty lists similar to indexing, but (as there)\n', '+        # is really too generic:\n', '         if obj.size == 0 and not isinstance(_obj, np.ndarray):\n', '             obj = obj.astype(intp)\n', '+        elif obj.size == 1 and obj.dtype.kind in ""ui"":\n', '+            # For a size 1 integer array we can use the single-value path\n', '+            # (most dtypes, except boolean, should just fail later).\n', '+            obj = obj.item()\n', '             single_value = True\n', ' \n', '     if single_value:\n']","['         single_value = False\n', '         _obj = obj\n', '         obj = np.asarray(obj)\n', '         if obj.size == 0 and not isinstance(_obj, np.ndarray):\n', '             obj = obj.astype(intp)\n', '-        elif obj.size == 1 and not isinstance(_obj, bool):\n', '-            obj = obj.astype(intp).reshape(())\n', '             single_value = True\n', ' \n', '     if single_value:\n']"
numpy/numpy,v1.23.0,v1.23.1,"[' \n', '         .. versionadded:: 1.14.0\n', '     max_rows : int, optional\n', '+        Read `max_rows` rows of content after `skiprows` lines. The default is\n', '+        to read all the rows. Note that empty rows containing no data such as\n', '+        empty lines and comment lines are not counted towards `max_rows`,\n', '+        while such lines are counted in `skiprows`.\n', ' \n', '         .. versionadded:: 1.16.0\n', '+        \n', '+        .. versionchanged:: 1.23.0\n', '+            Lines containing no data, including comment lines (e.g., lines \n', ""+            starting with '#' or as specified via `comments`) are not counted \n"", '+            towards `max_rows`.\n', '     quotechar : unicode character or None, optional\n', '         The character used to denote the start and end of a quoted item.\n', '         Occurrences of the delimiter or comment characters are ignored within\n']","[' \n', '         .. versionadded:: 1.14.0\n', '     max_rows : int, optional\n', '-        Read `max_rows` lines of content after `skiprows` lines. The default\n', '-        is to read all the lines.\n', ' \n', '         .. versionadded:: 1.16.0\n', '     quotechar : unicode character or None, optional\n', '         The character used to denote the start and end of a quoted item.\n', '         Occurrences of the delimiter or comment characters are ignored within\n']"
numpy/numpy,v1.23.0,v1.23.1,"[' \n', '         assert_(np.average(y3, weights=w3).dtype == np.result_type(y3, w3))\n', ' \n', '+        # test weights with `keepdims=False` and `keepdims=True`\n', '+        x = np.array([2, 3, 4]).reshape(3, 1)\n', '+        w = np.array([4, 5, 6]).reshape(3, 1)\n', '+\n', '+        actual = np.average(x, weights=w, axis=1, keepdims=False)\n', '+        desired = np.array([2., 3., 4.])\n', '+        assert_array_equal(actual, desired)\n', '+\n', '+        actual = np.average(x, weights=w, axis=1, keepdims=True)\n', '+        desired = np.array([[2.], [3.], [4.]])\n', '+        assert_array_equal(actual, desired)\n', '+\n', '     def test_returned(self):\n', '         y = np.array([[1, 2, 3], [4, 5, 6]])\n', ' \n']","[' \n', '         assert_(np.average(y3, weights=w3).dtype == np.result_type(y3, w3))\n', ' \n', '     def test_returned(self):\n', '         y = np.array([[1, 2, 3], [4, 5, 6]])\n', ' \n']"
numpy/numpy,v1.23.0,v1.23.1,"['         with pytest.raises(IndexError):\n', '             np.delete([0, 1, 2], np.array([], dtype=float))\n', ' \n', '+    @pytest.mark.parametrize(""indexer"", [np.array([1]), [1]])\n', '+    def test_single_item_array(self, indexer):\n', '+        a_del_int = delete(self.a, 1)\n', '+        a_del = delete(self.a, indexer)\n', '+        assert_equal(a_del_int, a_del)\n', '+\n', '+        nd_a_del_int = delete(self.nd_a, 1, axis=1)\n', '+        nd_a_del = delete(self.nd_a, np.array([1]), axis=1)\n', '+        assert_equal(nd_a_del_int, nd_a_del)\n', '+\n', '+    def test_single_item_array_non_int(self):\n', '+        # Special handling for integer arrays must not affect non-integer ones.\n', '+        # If `False` was cast to `0` it would delete the element:\n', '+        res = delete(np.ones(1), np.array([False]))\n', '+        assert_array_equal(res, np.ones(1))\n', '+\n', '+        # Test the more complicated (with axis) case from gh-21840\n', '+        x = np.ones((3, 1))\n', '+        false_mask = np.array([False], dtype=bool)\n', '+        true_mask = np.array([True], dtype=bool)\n', '+\n', '+        res = delete(x, false_mask, axis=-1)\n', '+        assert_array_equal(res, x)\n', '+        res = delete(x, true_mask, axis=-1)\n', '+        assert_array_equal(res, x[:, :0])\n', '+\n', '+        # Object or e.g. timedeltas should *not* be allowed\n', '+        with pytest.raises(IndexError):\n', '+            delete(np.ones(2), np.array([0], dtype=object))\n', '+\n', '+        with pytest.raises(IndexError):\n', '+            # timedeltas are sometimes ""integral, but clearly not allowed:\n', '+            delete(np.ones(2), np.array([0], dtype=""m8[ns]""))\n', ' \n', ' \n', ' class TestGradient:\n']","['         with pytest.raises(IndexError):\n', '             np.delete([0, 1, 2], np.array([], dtype=float))\n', ' \n', '-    def test_single_item_array(self):\n', '-        a_del = delete(self.a, 1)\n', '-        a_del_arr = delete(self.a, np.array([1]))\n', '-        a_del_lst = delete(self.a, [1])\n', '-        a_del_obj = delete(self.a, np.array([1], dtype=object))\n', '-        assert_equal(a_del, a_del_arr, a_del_lst, a_del_obj)\n', '-\n', '-        nd_a_del = delete(self.nd_a, 1, axis=1)\n', '-        nd_a_del_arr = delete(self.nd_a, np.array([1]), axis=1)\n', '-        nd_a_del_lst = delete(self.nd_a, [1], axis=1)\n', '-        nd_a_del_obj = delete(self.nd_a, np.array([1], dtype=object), axis=1)\n', '-        assert_equal(nd_a_del, nd_a_del_arr, nd_a_del_lst, nd_a_del_obj)\n', ' \n', ' \n', ' class TestGradient:\n']"
numpy/numpy,v1.23.0,v1.23.1,"['             wgt = wgt*(~a.mask)\n', '             wgt.mask |= a.mask\n', ' \n', '+        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n', '         avg = np.multiply(a, wgt,\n', '                           dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n', ' \n']","['             wgt = wgt*(~a.mask)\n', '             wgt.mask |= a.mask\n', ' \n', '-        scl = wgt.sum(axis=axis, dtype=result_dtype)\n', '         avg = np.multiply(a, wgt,\n', '                           dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n', ' \n']"
numpy/numpy,v1.23.0,v1.23.1,"['         a2dma = average(a2dm, axis=1)\n', '         assert_equal(a2dma, [1.5, 4.0])\n', ' \n', '+    def test_testAverage4(self):\n', '+        # Test that `keepdims` works with average\n', '+        x = np.array([2, 3, 4]).reshape(3, 1)\n', '+        b = np.ma.array(x, mask=[[False], [False], [True]])\n', '+        w = np.array([4, 5, 6]).reshape(3, 1)\n', '+        actual = average(b, weights=w, axis=1, keepdims=True)\n', '+        desired = masked_array([[2.], [3.], [4.]], [[False], [False], [True]])\n', '+        assert_equal(actual, desired)\n', '+\n', '     def test_onintegers_with_mask(self):\n', '         # Test average on integers with mask\n', '         a = average(array([1, 2]))\n']","['         a2dma = average(a2dm, axis=1)\n', '         assert_equal(a2dma, [1.5, 4.0])\n', ' \n', '     def test_onintegers_with_mask(self):\n', '         # Test average on integers with mask\n', '         a = average(array([1, 2]))\n']"
numpy/numpy,v1.23.0,v1.23.1,"[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""+RELEASE_NOTES = 'doc/source/release/1.23.1-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']","[' #-----------------------------------\n', ' \n', ' # Path to the release notes\n', ""-RELEASE_NOTES = 'doc/source/release/1.23.0-notes.rst'\n"", ' \n', ' \n', ' #-------------------------------------------------------\n']"
numpy/numpy,v1.23.0rc3,v1.23.0,[],"['-from __future__ import absolute_import, division, print_function\n', '-\n', '-from .common import Benchmark\n', '-\n', '-import numpy as np\n', '-import operator\n', '-\n', '-\n', '-_OPERATORS = {\n', ""-    '==': operator.eq,\n"", ""-    '!=': operator.ne,\n"", ""-    '<': operator.lt,\n"", ""-    '<=': operator.le,\n"", ""-    '>': operator.gt,\n"", ""-    '>=': operator.ge,\n"", '-}\n', '-\n', '-\n', '-class StringComparisons(Benchmark):\n', '-    # Basic string comparison speed tests\n', '-    params = [\n', '-        [100, 10000, (1000, 20)],\n', ""-        ['U', 'S'],\n"", '-        [True, False],\n', ""-        ['==', '!=', '<', '<=', '>', '>=']]\n"", ""-    param_names = ['shape', 'dtype', 'contig', 'operator']\n"", '-    int64 = np.dtype(np.int64)\n', '-\n', '-    def setup(self, shape, dtype, contig, operator):\n', '-        self.arr = np.arange(np.prod(shape)).astype(dtype).reshape(shape)\n', '-        self.arr_identical = self.arr.copy()\n', '-        self.arr_different = self.arr[::-1].copy()\n', '-\n', '-        if not contig:\n', '-            self.arr = self.arr[..., ::2]\n', '-            self.arr_identical = self.arr_identical[..., ::2]\n', '-            self.arr_different = self.arr_different[..., ::2]\n', '-\n', '-        self.operator = _OPERATORS[operator]\n', '-\n', '-    def time_compare_identical(self, shape, dtype, contig, operator):\n', '-        self.operator(self.arr, self.arr_identical)\n', '-\n', '-    def time_compare_different(self, shape, dtype, contig, operator):\n', '-        self.operator(self.arr, self.arr_different)\n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"['         # For two string arrays, strings always raised the broadcasting error:\n', ""         a = np.array(['a', 'b'])\n"", ""         b = np.array(['a', 'b', 'c'])\n"", '+        assert_raises(ValueError, lambda x, y: x == y, a, b)\n', ' \n', '         # The empty list is not cast to string, and this used to pass due\n', '         # to dtype mismatch; now (2018-06-21) it correctly leads to a\n']","['         # For two string arrays, strings always raised the broadcasting error:\n', ""         a = np.array(['a', 'b'])\n"", ""         b = np.array(['a', 'b', 'c'])\n"", '-        assert_warns(FutureWarning, lambda x, y: x == y, a, b)\n', ' \n', '         # The empty list is not cast to string, and this used to pass due\n', '         # to dtype mismatch; now (2018-06-21) it correctly leads to a\n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"['                 match=r"".* no common DType exists for the given inputs""):\n', '             np.result_type(1j, rational(1, 2))\n', ' \n', '+    @pytest.mark.parametrize(""val"", [2, 2**32, 2**63, 2**64, 2*100])\n', '+    def test_python_integer_promotion(self, val):\n', '+        # If we only path scalars (mainly python ones!), the result must take\n', '+        # into account that the integer may be considered int32, int64, uint64,\n', '+        # or object depending on the input value.  So test those paths!\n', '+        expected_dtype = np.result_type(np.array(val).dtype, np.array(0).dtype)\n', '+        assert np.result_type(val, 0) == expected_dtype\n', '+        # For completeness sake, also check with a NumPy scalar as second arg:\n', '+        assert np.result_type(val, np.int8(0)) == expected_dtype\n', '+\n', '     @pytest.mark.parametrize([""other"", ""expected""],\n', '             [(1, rational), (1., np.float64)])\n', '     def test_float_int_pyscalar_promote_rational(self, other, expected):\n']","['                 match=r"".* no common DType exists for the given inputs""):\n', '             np.result_type(1j, rational(1, 2))\n', ' \n', '     @pytest.mark.parametrize([""other"", ""expected""],\n', '             [(1, rational), (1., np.float64)])\n', '     def test_float_int_pyscalar_promote_rational(self, other, expected):\n']"
numpy/numpy,v1.23.0rc3,v1.23.0,[],"['-import pytest\n', '-\n', '-import operator\n', '-import numpy as np\n', '-\n', '-from numpy.testing import assert_array_equal\n', '-\n', '-\n', '-COMPARISONS = [\n', '-    (operator.eq, np.equal, ""==""),\n', '-    (operator.ne, np.not_equal, ""!=""),\n', '-    (operator.lt, np.less, ""<""),\n', '-    (operator.le, np.less_equal, ""<=""),\n', '-    (operator.gt, np.greater, "">""),\n', '-    (operator.ge, np.greater_equal, "">=""),\n', '-]\n', '-\n', '-\n', '-@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '-def test_mixed_string_comparison_ufuncs_fail(op, ufunc, sym):\n', '-    arr_string = np.array([""a"", ""b""], dtype=""S"")\n', '-    arr_unicode = np.array([""a"", ""c""], dtype=""U"")\n', '-\n', '-    with pytest.raises(TypeError, match=""did not contain a loop""):\n', '-        ufunc(arr_string, arr_unicode)\n', '-\n', '-    with pytest.raises(TypeError, match=""did not contain a loop""):\n', '-        ufunc(arr_unicode, arr_string)\n', '-\n', '-@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '-def test_mixed_string_comparisons_ufuncs_with_cast(op, ufunc, sym):\n', '-    arr_string = np.array([""a"", ""b""], dtype=""S"")\n', '-    arr_unicode = np.array([""a"", ""c""], dtype=""U"")\n', '-\n', '-    # While there is no loop, manual casting is acceptable:\n', '-    res1 = ufunc(arr_string, arr_unicode, signature=""UU->?"", casting=""unsafe"")\n', '-    res2 = ufunc(arr_string, arr_unicode, signature=""SS->?"", casting=""unsafe"")\n', '-\n', ""-    expected = op(arr_string.astype('U'), arr_unicode)\n"", '-    assert_array_equal(res1, expected)\n', '-    assert_array_equal(res2, expected)\n', '-\n', '-\n', '-@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '-@pytest.mark.parametrize(""dtypes"", [\n', '-        (""S2"", ""S2""), (""S2"", ""S10""),\n', '-        (""<U1"", ""<U1""), (""<U1"", "">U1""), ("">U1"", "">U1""),\n', '-        (""<U1"", ""<U10""), (""<U1"", "">U10"")])\n', '-@pytest.mark.parametrize(""aligned"", [True, False])\n', '-def test_string_comparisons(op, ufunc, sym, dtypes, aligned):\n', '-    # ensure native byte-order for the first view to stay within unicode range\n', '-    native_dt = np.dtype(dtypes[0]).newbyteorder(""="")\n', '-    arr = np.arange(2**15).view(native_dt).astype(dtypes[0])\n', '-    if not aligned:\n', '-        # Make `arr` unaligned:\n', '-        new = np.zeros(arr.nbytes + 1, dtype=np.uint8)[1:].view(dtypes[0])\n', '-        new[...] = arr\n', '-        arr = new\n', '-\n', '-    arr2 = arr.astype(dtypes[1], copy=True)\n', '-    np.random.shuffle(arr2)\n', '-    arr[0] = arr2[0]  # make sure one matches\n', '-\n', '-    expected = [op(d1, d2) for d1, d2 in zip(arr.tolist(), arr2.tolist())]\n', '-    assert_array_equal(op(arr, arr2), expected)\n', '-    assert_array_equal(ufunc(arr, arr2), expected)\n', '-    assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n', '-\n', '-    expected = [op(d2, d1) for d1, d2 in zip(arr.tolist(), arr2.tolist())]\n', '-    assert_array_equal(op(arr2, arr), expected)\n', '-    assert_array_equal(ufunc(arr2, arr), expected)\n', '-    assert_array_equal(np.compare_chararrays(arr2, arr, sym, False), expected)\n', '-\n', '-\n', '-@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '-@pytest.mark.parametrize(""dtypes"", [\n', '-        (""S2"", ""S2""), (""S2"", ""S10""), (""<U1"", ""<U1""), (""<U1"", "">U10"")])\n', '-def test_string_comparisons_empty(op, ufunc, sym, dtypes):\n', '-    arr = np.empty((1, 0, 1, 5), dtype=dtypes[0])\n', '-    arr2 = np.empty((100, 1, 0, 1), dtype=dtypes[1])\n', '-\n', '-    expected = np.empty(np.broadcast_shapes(arr.shape, arr2.shape), dtype=bool)\n', '-    assert_array_equal(op(arr, arr2), expected)\n', '-    assert_array_equal(ufunc(arr, arr2), expected)\n', '-    assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"[' import numpy as np\n', ' from numpy.testing import assert_, assert_equal, assert_array_equal\n', ' \n']","['-import pytest\n', '-\n', ' import numpy as np\n', ' from numpy.testing import assert_, assert_equal, assert_array_equal\n', ' \n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"[""     uni_arr1 = str_arr.astype('>U')\n"", ""     uni_arr2 = str_arr.astype('<U')\n"", ' \n', '+    assert_(str_arr != uni_arr1)\n', '+    assert_(str_arr != uni_arr2)\n', '     assert_array_equal(uni_arr1, uni_arr2)\n', ' \n', ' \n']","[""     uni_arr1 = str_arr.astype('>U')\n"", ""     uni_arr2 = str_arr.astype('<U')\n"", ' \n', '-    with pytest.warns(FutureWarning):\n', '-        assert str_arr != uni_arr1\n', '-    with pytest.warns(FutureWarning):\n', '-        assert str_arr != uni_arr2\n', '-\n', '     assert_array_equal(uni_arr1, uni_arr2)\n', ' \n', ' \n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"[' """"""\n', ' \n', ' import sys\n', '+import os\n', ' import pytest\n', ' from tempfile import NamedTemporaryFile, mkstemp\n', ' from io import StringIO\n']","[' """"""\n', ' \n', ' import sys\n', ' import pytest\n', ' from tempfile import NamedTemporaryFile, mkstemp\n', ' from io import StringIO\n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"[' \n', '     txt = StringIO(""0,0,XXX\\n0\\n0,XXX,XXX,0,XXX\\n"")\n', '     with pytest.raises(ValueError,\n', '+                match=""invalid column index -2 at row 2 with 1 columns""):\n', '         # There is no -2 column in the second row:\n', '         np.loadtxt(txt, dtype=float, delimiter="","", usecols=[0, -2])\n', ' \n']","[' \n', '     txt = StringIO(""0,0,XXX\\n0\\n0,XXX,XXX,0,XXX\\n"")\n', '     with pytest.raises(ValueError,\n', '-                match=""invalid column index -2 at row 1 with 2 columns""):\n', '         # There is no -2 column in the second row:\n', '         np.loadtxt(txt, dtype=float, delimiter="","", usecols=[0, -2])\n', ' \n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '+    os.close(fd)\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=unitless_dtype)\n', '+    os.remove(fname)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']","[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=unitless_dtype)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']"
numpy/numpy,v1.23.0rc3,v1.23.0,"[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '+    os.close(fd)\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=""U"", converters=conv, encoding=None)\n', '+    os.remove(fname)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']","[' \n', '     # file-obj path\n', '     fd, fname = mkstemp()\n', '     with open(fname, ""w"") as fh:\n', '         fh.write(""\\n"".join(data))\n', '     a = np.loadtxt(fname, dtype=""U"", converters=conv, encoding=None)\n', '     assert a.dtype == expected.dtype\n', '     assert_equal(a, expected)\n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['+from __future__ import absolute_import, division, print_function\n', '+\n', '+from .common import Benchmark\n', '+\n', '+import numpy as np\n', '+import operator\n', '+\n', '+\n', '+_OPERATORS = {\n', ""+    '==': operator.eq,\n"", ""+    '!=': operator.ne,\n"", ""+    '<': operator.lt,\n"", ""+    '<=': operator.le,\n"", ""+    '>': operator.gt,\n"", ""+    '>=': operator.ge,\n"", '+}\n', '+\n', '+\n', '+class StringComparisons(Benchmark):\n', '+    # Basic string comparison speed tests\n', '+    params = [\n', '+        [100, 10000, (1000, 20)],\n', ""+        ['U', 'S'],\n"", '+        [True, False],\n', ""+        ['==', '!=', '<', '<=', '>', '>=']]\n"", ""+    param_names = ['shape', 'dtype', 'contig', 'operator']\n"", '+    int64 = np.dtype(np.int64)\n', '+\n', '+    def setup(self, shape, dtype, contig, operator):\n', '+        self.arr = np.arange(np.prod(shape)).astype(dtype).reshape(shape)\n', '+        self.arr_identical = self.arr.copy()\n', '+        self.arr_different = self.arr[::-1].copy()\n', '+\n', '+        if not contig:\n', '+            self.arr = self.arr[..., ::2]\n', '+            self.arr_identical = self.arr_identical[..., ::2]\n', '+            self.arr_different = self.arr_different[..., ::2]\n', '+\n', '+        self.operator = _OPERATORS[operator]\n', '+\n', '+    def time_compare_identical(self, shape, dtype, contig, operator):\n', '+        self.operator(self.arr, self.arr_identical)\n', '+\n', '+    def time_compare_different(self, shape, dtype, contig, operator):\n', '+        self.operator(self.arr, self.arr_different)\n']",[]
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', "" html_favicon = '_static/favicon/favicon.ico'\n"", ' \n', '+# Set up the version switcher.  The versions.json is stored in the doc repo.\n', "" if os.environ.get('CIRCLE_JOB', False) and \\\n"", ""         os.environ.get('CIRCLE_BRANCH', '') != 'main':\n"", '     # For PR, name is set to its ref\n']","[' \n', "" html_favicon = '_static/favicon/favicon.ico'\n"", ' \n', '-# Set up the version switcher.  The versions.json is stored in the devdocs.\n', "" if os.environ.get('CIRCLE_JOB', False) and \\\n"", ""         os.environ.get('CIRCLE_BRANCH', '') != 'main':\n"", '     # For PR, name is set to its ref\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['   ""navbar_end"": [""version-switcher"", ""navbar-icon-links""],\n', '   ""switcher"": {\n', '       ""version_match"": switcher_version,\n', '+      ""json_url"": ""https://numpy.org/doc/_static/versions.json"",\n', '   },\n', ' }\n', ' \n']","['   ""navbar_end"": [""version-switcher"", ""navbar-icon-links""],\n', '   ""switcher"": {\n', '       ""version_match"": switcher_version,\n', '-      ""json_url"": ""https://numpy.org/devdocs/_static/versions.json"",\n', '   },\n', ' }\n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         args.append(value)\n', ' \n', '     cls = type(alias)\n', '+    return cls(alias.__origin__, tuple(args), alias.__unpacked__)\n', ' \n', ' \n', ' class _GenericAlias:\n']","['         args.append(value)\n', ' \n', '     cls = type(alias)\n', '-    return cls(alias.__origin__, tuple(args))\n', ' \n', ' \n', ' class _GenericAlias:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', '     """"""\n', ' \n', '+    __slots__ = (\n', '+        ""__weakref__"",\n', '+        ""_origin"",\n', '+        ""_args"",\n', '+        ""_parameters"",\n', '+        ""_hash"",\n', '+        ""_starred"",\n', '+    )\n', ' \n', '     @property\n', '     def __origin__(self) -> type:\n']","[' \n', '     """"""\n', ' \n', '-    __slots__ = (""__weakref__"", ""_origin"", ""_args"", ""_parameters"", ""_hash"")\n', ' \n', '     @property\n', '     def __origin__(self) -> type:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         """"""Type variables in the ``GenericAlias``.""""""\n', '         return super().__getattribute__(""_parameters"")\n', ' \n', '+    @property\n', '+    def __unpacked__(self) -> bool:\n', '+        return super().__getattribute__(""_starred"")\n', '+\n', '+    @property\n', '+    def __typing_unpacked_tuple_args__(self) -> tuple[object, ...] | None:\n', '+        # NOTE: This should return `__args__` if `__origin__` is a tuple,\n', '+        # which should never be the case with how `_GenericAlias` is used\n', '+        # within numpy\n', '+        return None\n', '+\n', '     def __init__(\n', '         self,\n', '         origin: type,\n', '         args: object | tuple[object, ...],\n', '+        starred: bool = False,\n', '     ) -> None:\n', '         self._origin = origin\n', '         self._args = args if isinstance(args, tuple) else (args,)\n', '         self._parameters = tuple(_parse_parameters(self.__args__))\n', '+        self._starred = starred\n', ' \n', '     @property\n', '     def __call__(self) -> type[Any]:\n']","['         """"""Type variables in the ``GenericAlias``.""""""\n', '         return super().__getattribute__(""_parameters"")\n', ' \n', '     def __init__(\n', '         self,\n', '         origin: type,\n', '         args: object | tuple[object, ...],\n', '     ) -> None:\n', '         self._origin = origin\n', '         self._args = args if isinstance(args, tuple) else (args,)\n', '         self._parameters = tuple(_parse_parameters(self.__args__))\n', ' \n', '     @property\n', '     def __call__(self) -> type[Any]:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', '     def __reduce__(self: _T) -> tuple[\n', '         type[_T],\n', '+        tuple[type[Any], tuple[object, ...], bool],\n', '     ]:\n', '         cls = type(self)\n', '+        return cls, (self.__origin__, self.__args__, self.__unpacked__)\n', ' \n', '     def __mro_entries__(self, bases: Iterable[object]) -> tuple[type[Any]]:\n', '         return (self.__origin__,)\n']","[' \n', '     def __reduce__(self: _T) -> tuple[\n', '         type[_T],\n', '-        tuple[type[Any], tuple[object, ...]],\n', '     ]:\n', '         cls = type(self)\n', '-        return cls, (self.__origin__, self.__args__)\n', ' \n', '     def __mro_entries__(self, bases: Iterable[object]) -> tuple[type[Any]]:\n', '         return (self.__origin__,)\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         try:\n', '             return super().__getattribute__(""_hash"")\n', '         except AttributeError:\n', '+            self._hash: int = (\n', '+                hash(self.__origin__) ^\n', '+                hash(self.__args__) ^\n', '+                hash(self.__unpacked__)\n', '+            )\n', '             return super().__getattribute__(""_hash"")\n', ' \n', '     def __instancecheck__(self, obj: object) -> NoReturn:\n']","['         try:\n', '             return super().__getattribute__(""_hash"")\n', '         except AttributeError:\n', '-            self._hash: int = hash(self.__origin__) ^ hash(self.__args__)\n', '             return super().__getattribute__(""_hash"")\n', ' \n', '     def __instancecheck__(self, obj: object) -> NoReturn:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         """"""Return ``repr(self)``.""""""\n', '         args = "", "".join(_to_str(i) for i in self.__args__)\n', '         origin = _to_str(self.__origin__)\n', '+        prefix = ""*"" if self.__unpacked__ else """"\n', '+        return f""{prefix}{origin}[{args}]""\n', ' \n', '     def __getitem__(self: _T, key: object | tuple[object, ...]) -> _T:\n', '         """"""Return ``self[key]``.""""""\n']","['         """"""Return ``repr(self)``.""""""\n', '         args = "", "".join(_to_str(i) for i in self.__args__)\n', '         origin = _to_str(self.__origin__)\n', '-        return f""{origin}[{args}]""\n', ' \n', '     def __getitem__(self: _T, key: object | tuple[object, ...]) -> _T:\n', '         """"""Return ``self[key]``.""""""\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['             return NotImplemented\n', '         return (\n', '             self.__origin__ == value.__origin__ and\n', '+            self.__args__ == value.__args__ and\n', '+            self.__unpacked__ == getattr(\n', '+                value, ""__unpacked__"", self.__unpacked__\n', '+            )\n', '         )\n', ' \n', '+    def __iter__(self: _T) -> Generator[_T, None, None]:\n', '+        """"""Return ``iter(self)``.""""""\n', '+        cls = type(self)\n', '+        yield cls(self.__origin__, self.__args__, True)\n', '+\n', '     _ATTR_EXCEPTIONS: ClassVar[frozenset[str]] = frozenset({\n', '         ""__origin__"",\n', '         ""__args__"",\n']","['             return NotImplemented\n', '         return (\n', '             self.__origin__ == value.__origin__ and\n', '-            self.__args__ == value.__args__\n', '         )\n', ' \n', '     _ATTR_EXCEPTIONS: ClassVar[frozenset[str]] = frozenset({\n', '         ""__origin__"",\n', '         ""__args__"",\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         ""__reduce_ex__"",\n', '         ""__copy__"",\n', '         ""__deepcopy__"",\n', '+        ""__unpacked__"",\n', '+        ""__typing_unpacked_tuple_args__"",\n', '     })\n', ' \n', '     def __getattribute__(self, name: str) -> Any:\n']","['         ""__reduce_ex__"",\n', '         ""__copy__"",\n', '         ""__deepcopy__"",\n', '     })\n', ' \n', '     def __getattribute__(self, name: str) -> Any:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['     if path_type is None:\n', '         path_type = False\n', ' \n', '+    explicit_einsum_path = False\n', '     memory_limit = None\n', ' \n', '     # No optimization or a named path algorithm\n']","['     if path_type is None:\n', '         path_type = False\n', ' \n', '     memory_limit = None\n', ' \n', '     # No optimization or a named path algorithm\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', '     # Given an explicit path\n', ""     elif len(path_type) and (path_type[0] == 'einsum_path'):\n"", '+        explicit_einsum_path = True\n', ' \n', '     # Path tuple with memory limit\n', '     elif ((len(path_type) == 2) and isinstance(path_type[0], str) and\n']","[' \n', '     # Given an explicit path\n', ""     elif len(path_type) and (path_type[0] == 'einsum_path'):\n"", '-        pass\n', ' \n', '     # Path tuple with memory limit\n', '     elif ((len(path_type) == 2) and isinstance(path_type[0], str) and\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['     naive_cost = _flop_count(indices, inner_product, len(input_list), dimension_dict)\n', ' \n', '     # Compute the path\n', '+    if explicit_einsum_path:\n', '+        path = path_type[1:]\n', '+    elif (\n', '+        (path_type is False)\n', '+        or (len(input_list) in [1, 2])\n', '+        or (indices == output_set)\n', '+    ):\n', '         # Nothing to be optimized, leave it to einsum\n', '         path = [tuple(range(len(input_list)))]\n', '     elif path_type == ""greedy"":\n', '         path = _greedy_path(input_sets, output_set, dimension_dict, memory_arg)\n', '     elif path_type == ""optimal"":\n', '         path = _optimal_path(input_sets, output_set, dimension_dict, memory_arg)\n', '     else:\n', '         raise KeyError(""Path name %s not found"", path_type)\n', ' \n']","['     naive_cost = _flop_count(indices, inner_product, len(input_list), dimension_dict)\n', ' \n', '     # Compute the path\n', '-    if (path_type is False) or (len(input_list) in [1, 2]) or (indices == output_set):\n', '         # Nothing to be optimized, leave it to einsum\n', '         path = [tuple(range(len(input_list)))]\n', '     elif path_type == ""greedy"":\n', '         path = _greedy_path(input_sets, output_set, dimension_dict, memory_arg)\n', '     elif path_type == ""optimal"":\n', '         path = _optimal_path(input_sets, output_set, dimension_dict, memory_arg)\n', ""-    elif path_type[0] == 'einsum_path':\n"", '-        path = path_type[1:]\n', '     else:\n', '         raise KeyError(""Path name %s not found"", path_type)\n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', '     opt_cost = sum(cost_list) + 1\n', ' \n', '+    if len(input_list) != 1:\n', '+        # Explicit ""einsum_path"" is usually trusted, but we detect this kind of\n', '+        # mistake in order to prevent from returning an intermediate value.\n', '+        raise RuntimeError(\n', '+            ""Invalid einsum_path is specified: {} more operands has to be ""\n', '+            ""contracted."".format(len(input_list) - 1))\n', '+\n', '     if einsum_call_arg:\n', '         return (operands, contraction_list)\n', ' \n']","[' \n', '     opt_cost = sum(cost_list) + 1\n', ' \n', '     if einsum_call_arg:\n', '         return (operands, contraction_list)\n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         # For two string arrays, strings always raised the broadcasting error:\n', ""         a = np.array(['a', 'b'])\n"", ""         b = np.array(['a', 'b', 'c'])\n"", '+        assert_warns(FutureWarning, lambda x, y: x == y, a, b)\n', ' \n', '         # The empty list is not cast to string, and this used to pass due\n', '         # to dtype mismatch; now (2018-06-21) it correctly leads to a\n']","['         # For two string arrays, strings always raised the broadcasting error:\n', ""         a = np.array(['a', 'b'])\n"", ""         b = np.array(['a', 'b', 'c'])\n"", '-        assert_raises(ValueError, lambda x, y: x == y, a, b)\n', ' \n', '         # The empty list is not cast to string, and this used to pass due\n', '         # to dtype mismatch; now (2018-06-21) it correctly leads to a\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['     def test_deprecated(self):\n', '         a = np.zeros((1,)*32)\n', '         self.assert_deprecated(lambda: np.repeat(a, 1, axis=np.MAXDIMS))\n', '+\n', '+\n', '+class TestLoadtxtParseIntsViaFloat(_DeprecationTestCase):\n', '+    # Deprecated 2022-07-03, NumPy 1.23\n', '+    # This test can be removed without replacement after the deprecation.\n', '+    # The tests:\n', '+    #   * numpy/lib/tests/test_loadtxt.py::test_integer_signs\n', '+    #   * lib/tests/test_loadtxt.py::test_implicit_cast_float_to_int_fails\n', '+    # Have a warning filter that needs to be removed.\n', '+    message = r""loadtxt\\(\\): Parsing an integer via a float is deprecated.*""\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_deprecated_warning(self, dtype):\n', '+        with pytest.warns(DeprecationWarning, match=self.message):\n', '+            np.loadtxt([""10.5""], dtype=dtype)\n', '+\n', '+    @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+    def test_deprecated_raised(self, dtype):\n', '+        # The DeprecationWarning is chained when raised, so test manually:\n', '+        with warnings.catch_warnings():\n', '+            warnings.simplefilter(""error"", DeprecationWarning)\n', '+            try:\n', '+                np.loadtxt([""10.5""], dtype=dtype)\n', '+            except ValueError as e:\n', '+                assert isinstance(e.__cause__, DeprecationWarning)\n']","['     def test_deprecated(self):\n', '         a = np.zeros((1,)*32)\n', '         self.assert_deprecated(lambda: np.repeat(a, 1, axis=np.MAXDIMS))\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         opt = np.einsum(*path_test, optimize=exp_path)\n', '         assert_almost_equal(noopt, opt)\n', ' \n', '+    def test_path_type_input_internal_trace(self):\n', '+        #gh-20962\n', ""+        path_test = self.build_operands('cab,cdd->ab')\n"", ""+        exp_path = ['einsum_path', (1,), (0, 1)]\n"", '+\n', '+        path, path_str = np.einsum_path(*path_test, optimize=exp_path)\n', '+        self.assert_path_equal(path, exp_path)\n', '+\n', '+        # Double check einsum works on the input path\n', '+        noopt = np.einsum(*path_test, optimize=False)\n', '+        opt = np.einsum(*path_test, optimize=exp_path)\n', '+        assert_almost_equal(noopt, opt)\n', '+\n', '+    def test_path_type_input_invalid(self):\n', ""+        path_test = self.build_operands('ab,bc,cd,de->ae')\n"", ""+        exp_path = ['einsum_path', (2, 3), (0, 1)]\n"", '+        assert_raises(RuntimeError, np.einsum, *path_test, optimize=exp_path)\n', '+        assert_raises(\n', '+            RuntimeError, np.einsum_path, *path_test, optimize=exp_path)\n', '+\n', ""+        path_test = self.build_operands('a,a,a->a')\n"", ""+        exp_path = ['einsum_path', (1,), (0, 1)]\n"", '+        assert_raises(RuntimeError, np.einsum, *path_test, optimize=exp_path)\n', '+        assert_raises(\n', '+            RuntimeError, np.einsum_path, *path_test, optimize=exp_path)\n', '+\n', '     def test_spaces(self):\n', '         #gh-10794\n', '         arr = np.array([[1]])\n']","['         opt = np.einsum(*path_test, optimize=exp_path)\n', '         assert_almost_equal(noopt, opt)\n', ' \n', '     def test_spaces(self):\n', '         #gh-10794\n', '         arr = np.array([[1]])\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[""             assert_equal(5, int_func(np.bytes_(b'5')))\n"", ""             assert_equal(6, int_func(np.unicode_(u'6')))\n"", ' \n', '+            # The delegation of int() to __trunc__ was deprecated in\n', '+            # Python 3.11.\n', '+            if sys.version_info < (3, 11):\n', '+                class HasTrunc:\n', '+                    def __trunc__(self):\n', '+                        return 3\n', '+                assert_equal(3, int_func(np.array(HasTrunc())))\n', '+                assert_equal(3, int_func(np.array([HasTrunc()])))\n', '+            else:\n', '+                pass\n', ' \n', '             class NotConvertible:\n', '                 def __int__(self):\n']","[""             assert_equal(5, int_func(np.bytes_(b'5')))\n"", ""             assert_equal(6, int_func(np.unicode_(u'6')))\n"", ' \n', '-            class HasTrunc:\n', '-                def __trunc__(self):\n', '-                    return 3\n', '-            assert_equal(3, int_func(np.array(HasTrunc())))\n', '-            assert_equal(3, int_func(np.array([HasTrunc()])))\n', ' \n', '             class NotConvertible:\n', '                 def __int__(self):\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['+import pytest\n', '+\n', '+import operator\n', '+import numpy as np\n', '+\n', '+from numpy.testing import assert_array_equal\n', '+\n', '+\n', '+COMPARISONS = [\n', '+    (operator.eq, np.equal, ""==""),\n', '+    (operator.ne, np.not_equal, ""!=""),\n', '+    (operator.lt, np.less, ""<""),\n', '+    (operator.le, np.less_equal, ""<=""),\n', '+    (operator.gt, np.greater, "">""),\n', '+    (operator.ge, np.greater_equal, "">=""),\n', '+]\n', '+\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+def test_mixed_string_comparison_ufuncs_fail(op, ufunc, sym):\n', '+    arr_string = np.array([""a"", ""b""], dtype=""S"")\n', '+    arr_unicode = np.array([""a"", ""c""], dtype=""U"")\n', '+\n', '+    with pytest.raises(TypeError, match=""did not contain a loop""):\n', '+        ufunc(arr_string, arr_unicode)\n', '+\n', '+    with pytest.raises(TypeError, match=""did not contain a loop""):\n', '+        ufunc(arr_unicode, arr_string)\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+def test_mixed_string_comparisons_ufuncs_with_cast(op, ufunc, sym):\n', '+    arr_string = np.array([""a"", ""b""], dtype=""S"")\n', '+    arr_unicode = np.array([""a"", ""c""], dtype=""U"")\n', '+\n', '+    # While there is no loop, manual casting is acceptable:\n', '+    res1 = ufunc(arr_string, arr_unicode, signature=""UU->?"", casting=""unsafe"")\n', '+    res2 = ufunc(arr_string, arr_unicode, signature=""SS->?"", casting=""unsafe"")\n', '+\n', ""+    expected = op(arr_string.astype('U'), arr_unicode)\n"", '+    assert_array_equal(res1, expected)\n', '+    assert_array_equal(res2, expected)\n', '+\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+@pytest.mark.parametrize(""dtypes"", [\n', '+        (""S2"", ""S2""), (""S2"", ""S10""),\n', '+        (""<U1"", ""<U1""), (""<U1"", "">U1""), ("">U1"", "">U1""),\n', '+        (""<U1"", ""<U10""), (""<U1"", "">U10"")])\n', '+@pytest.mark.parametrize(""aligned"", [True, False])\n', '+def test_string_comparisons(op, ufunc, sym, dtypes, aligned):\n', '+    # ensure native byte-order for the first view to stay within unicode range\n', '+    native_dt = np.dtype(dtypes[0]).newbyteorder(""="")\n', '+    arr = np.arange(2**15).view(native_dt).astype(dtypes[0])\n', '+    if not aligned:\n', '+        # Make `arr` unaligned:\n', '+        new = np.zeros(arr.nbytes + 1, dtype=np.uint8)[1:].view(dtypes[0])\n', '+        new[...] = arr\n', '+        arr = new\n', '+\n', '+    arr2 = arr.astype(dtypes[1], copy=True)\n', '+    np.random.shuffle(arr2)\n', '+    arr[0] = arr2[0]  # make sure one matches\n', '+\n', '+    expected = [op(d1, d2) for d1, d2 in zip(arr.tolist(), arr2.tolist())]\n', '+    assert_array_equal(op(arr, arr2), expected)\n', '+    assert_array_equal(ufunc(arr, arr2), expected)\n', '+    assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n', '+\n', '+    expected = [op(d2, d1) for d1, d2 in zip(arr.tolist(), arr2.tolist())]\n', '+    assert_array_equal(op(arr2, arr), expected)\n', '+    assert_array_equal(ufunc(arr2, arr), expected)\n', '+    assert_array_equal(np.compare_chararrays(arr2, arr, sym, False), expected)\n', '+\n', '+\n', '+@pytest.mark.parametrize([""op"", ""ufunc"", ""sym""], COMPARISONS)\n', '+@pytest.mark.parametrize(""dtypes"", [\n', '+        (""S2"", ""S2""), (""S2"", ""S10""), (""<U1"", ""<U1""), (""<U1"", "">U10"")])\n', '+def test_string_comparisons_empty(op, ufunc, sym, dtypes):\n', '+    arr = np.empty((1, 0, 1, 5), dtype=dtypes[0])\n', '+    arr2 = np.empty((100, 1, 0, 1), dtype=dtypes[1])\n', '+\n', '+    expected = np.empty(np.broadcast_shapes(arr.shape, arr2.shape), dtype=bool)\n', '+    assert_array_equal(op(arr, arr2), expected)\n', '+    assert_array_equal(ufunc(arr, arr2), expected)\n', '+    assert_array_equal(np.compare_chararrays(arr, arr2, sym, False), expected)\n']",[]
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         # the result would be just a scalar `5`, but is broadcast fully:\n', '         assert (out == 5).all()\n', ' \n', '+    @pytest.mark.parametrize([""arr"", ""out""], [\n', '+                ([2], np.empty(())),\n', '+                ([1, 2], np.empty(1)),\n', '+                (np.ones((4, 3)), np.empty((4, 1)))],\n', '+            ids=[""(1,)->()"", ""(2,)->(1,)"", ""(4, 3)->(4, 1)""])\n', '+    def test_out_broadcast_errors(self, arr, out):\n', '+        # Output is (currently) allowed to broadcast inputs, but it cannot be\n', '+        # smaller than the actual result.\n', '+        with pytest.raises(ValueError, match=""non-broadcastable""):\n', '+            np.positive(arr, out=out)\n', '+\n', '+        with pytest.raises(ValueError, match=""non-broadcastable""):\n', '+            np.add(np.ones(()), arr, out=out)\n', '+\n', '     def test_type_cast(self):\n', '         msg = ""type cast""\n', ""         a = np.arange(6, dtype='short').reshape((2, 3))\n""]","['         # the result would be just a scalar `5`, but is broadcast fully:\n', '         assert (out == 5).all()\n', ' \n', '     def test_type_cast(self):\n', '         msg = ""type cast""\n', ""         a = np.arange(6, dtype='short').reshape((2, 3))\n""]"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['+import pytest\n', '+\n', ' import numpy as np\n', ' from numpy.testing import assert_, assert_equal, assert_array_equal\n', ' \n']","[' import numpy as np\n', ' from numpy.testing import assert_, assert_equal, assert_array_equal\n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[""     uni_arr1 = str_arr.astype('>U')\n"", ""     uni_arr2 = str_arr.astype('<U')\n"", ' \n', '+    with pytest.warns(FutureWarning):\n', '+        assert str_arr != uni_arr1\n', '+    with pytest.warns(FutureWarning):\n', '+        assert str_arr != uni_arr2\n', '+\n', '     assert_array_equal(uni_arr1, uni_arr2)\n', ' \n', ' \n']","[""     uni_arr1 = str_arr.astype('>U')\n"", ""     uni_arr2 = str_arr.astype('<U')\n"", ' \n', '-    assert_(str_arr != uni_arr1)\n', '-    assert_(str_arr != uni_arr2)\n', '     assert_array_equal(uni_arr1, uni_arr2)\n', ' \n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['     def __init__(self):\n', '         if hasattr(self, ""cc_is_cached""):\n', '             return\n', '+        #      attr            regex        compiler-expression\n', '         detect_arch = (\n', '+            (""cc_on_x64"",      "".*(x|x86_|amd)64.*"", """"),\n', '+            (""cc_on_x86"",      "".*(win32|x86|i386|i686).*"", """"),\n', '+            (""cc_on_ppc64le"",  "".*(powerpc|ppc)64(el|le).*"", """"),\n', '+            (""cc_on_ppc64"",    "".*(powerpc|ppc)64.*"", """"),\n', '+            (""cc_on_aarch64"",  "".*(aarch64|arm64).*"", """"),\n', '+            (""cc_on_armhf"",    "".*arm.*"", ""defined(__ARM_ARCH_7__) || ""\n', '+                                          ""defined(__ARM_ARCH_7A__)""),\n', '+            (""cc_on_s390x"",    "".*s390x.*"", """"),\n', '             # undefined platform\n', '+            (""cc_on_noarch"",   """", """"),\n', '         )\n', '         detect_compiler = (\n', '+            (""cc_is_gcc"",     r"".*(gcc|gnu\\-g).*"", """"),\n', '+            (""cc_is_clang"",    "".*clang.*"", """"),\n', '+            # intel msvc like\n', '+            (""cc_is_iccw"",     "".*(intelw|intelemw|iccw).*"", """"),\n', '+            (""cc_is_icc"",      "".*(intel|icc).*"", """"),  # intel unix like\n', '+            (""cc_is_msvc"",     "".*msvc.*"", """"),\n', '             # undefined compiler will be treat it as gcc\n', '+            (""cc_is_nocc"",     """", """"),\n', '         )\n', '         detect_args = (\n', '+           (""cc_has_debug"",  "".*(O0|Od|ggdb|coverage|debug:full).*"", """"),\n', '+           (""cc_has_native"", "".*(-march=native|-xHost|/QxHost).*"", """"),\n', '            # in case if the class run with -DNPY_DISABLE_OPTIMIZATION\n', '+           (""cc_noopt"", "".*DISABLE_OPT.*"", """"),\n', '         )\n', ' \n', '         dist_info = self.dist_info()\n', '         platform, compiler_info, extra_args = dist_info\n', '         # set False to all attrs\n', '         for section in (detect_arch, detect_compiler, detect_args):\n', '+            for attr, rgex, cexpr in section:\n', '                 setattr(self, attr, False)\n', ' \n', '         for detect, searchin in ((detect_arch, platform), (detect_compiler, compiler_info)):\n', '+            for attr, rgex, cexpr in detect:\n', '                 if rgex and not re.match(rgex, searchin, re.IGNORECASE):\n', '                     continue\n', '+                if cexpr and not self.cc_test_cexpr(cexpr):\n', '+                    continue\n', '                 setattr(self, attr, True)\n', '                 break\n', ' \n', '+        for attr, rgex, cexpr in detect_args:\n', '             if rgex and not re.match(rgex, extra_args, re.IGNORECASE):\n', '                 continue\n', '+            if cexpr and not self.cc_test_cexpr(cexpr):\n', '+                continue\n', '             setattr(self, attr, True)\n', ' \n', '         if self.cc_on_noarch:\n']","['     def __init__(self):\n', '         if hasattr(self, ""cc_is_cached""):\n', '             return\n', '-        #      attr                regex\n', '         detect_arch = (\n', '-            (""cc_on_x64"",      "".*(x|x86_|amd)64.*""),\n', '-            (""cc_on_x86"",      "".*(win32|x86|i386|i686).*""),\n', '-            (""cc_on_ppc64le"",  "".*(powerpc|ppc)64(el|le).*""),\n', '-            (""cc_on_ppc64"",    "".*(powerpc|ppc)64.*""),\n', '-            (""cc_on_aarch64"",  "".*(aarch64|arm64).*""),\n', '-            (""cc_on_armhf"",    "".*arm.*""),\n', '-            (""cc_on_s390x"",    "".*s390x.*""),\n', '             # undefined platform\n', '-            (""cc_on_noarch"",    """"),\n', '         )\n', '         detect_compiler = (\n', '-            (""cc_is_gcc"",     r"".*(gcc|gnu\\-g).*""),\n', '-            (""cc_is_clang"",    "".*clang.*""),\n', '-            (""cc_is_iccw"",     "".*(intelw|intelemw|iccw).*""), # intel msvc like\n', '-            (""cc_is_icc"",      "".*(intel|icc).*""), # intel unix like\n', '-            (""cc_is_msvc"",     "".*msvc.*""),\n', '             # undefined compiler will be treat it as gcc\n', '-            (""cc_is_nocc"",     """"),\n', '         )\n', '         detect_args = (\n', '-           (""cc_has_debug"",  "".*(O0|Od|ggdb|coverage|debug:full).*""),\n', '-           (""cc_has_native"", "".*(-march=native|-xHost|/QxHost).*""),\n', '            # in case if the class run with -DNPY_DISABLE_OPTIMIZATION\n', '-           (""cc_noopt"", "".*DISABLE_OPT.*""),\n', '         )\n', ' \n', '         dist_info = self.dist_info()\n', '         platform, compiler_info, extra_args = dist_info\n', '         # set False to all attrs\n', '         for section in (detect_arch, detect_compiler, detect_args):\n', '-            for attr, rgex in section:\n', '                 setattr(self, attr, False)\n', ' \n', '         for detect, searchin in ((detect_arch, platform), (detect_compiler, compiler_info)):\n', '-            for attr, rgex in detect:\n', '                 if rgex and not re.match(rgex, searchin, re.IGNORECASE):\n', '                     continue\n', '                 setattr(self, attr, True)\n', '                 break\n', ' \n', '-        for attr, rgex in detect_args:\n', '             if rgex and not re.match(rgex, extra_args, re.IGNORECASE):\n', '                 continue\n', '             setattr(self, attr, True)\n', ' \n', '         if self.cc_on_noarch:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['             self.dist_log(""testing failed"", stderr=True)\n', '         return test\n', ' \n', '+    @_Cache.me\n', '+    def cc_test_cexpr(self, cexpr, flags=[]):\n', '+        """"""\n', '+        Same as the above but supports compile-time expressions.\n', '+        """"""\n', '+        self.dist_log(""testing compiler expression"", cexpr)\n', '+        test_path = os.path.join(self.conf_tmp_path, ""npy_dist_test_cexpr.c"")\n', '+        with open(test_path, ""w"") as fd:\n', '+            fd.write(textwrap.dedent(f""""""\\\n', '+               #if !({cexpr})\n', '+                   #error ""unsupported expression""\n', '+               #endif\n', '+               int dummy;\n', '+            """"""))\n', '+        test = self.dist_test(test_path, flags)\n', '+        if not test:\n', '+            self.dist_log(""testing failed"", stderr=True)\n', '+        return test\n', '+\n', '     def cc_normalize_flags(self, flags):\n', '         """"""\n', '         Remove the conflicts that caused due gathering implied features flags.\n']","['             self.dist_log(""testing failed"", stderr=True)\n', '         return test\n', ' \n', '     def cc_normalize_flags(self, flags):\n', '         """"""\n', '         Remove the conflicts that caused due gathering implied features flags.\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[""     module_include_switch = '/I'\n"", ' \n', '     def get_flags(self):\n', ""+        opt = ['/nologo', '/MD', '/nbs', '/names:lowercase', \n"", ""+               '/assume:underscore', '/fpp']\n"", '         return opt\n', ' \n', '     def get_flags_free(self):\n']","[""     module_include_switch = '/I'\n"", ' \n', '     def get_flags(self):\n', ""-        opt = ['/nologo', '/MD', '/nbs', '/names:lowercase', '/assume:underscore']\n"", '         return opt\n', ' \n', '     def get_flags_free(self):\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', ' f2cmap_default = copy.deepcopy(f2cmap_all)\n', ' \n', '+f2cmap_mapped = []\n', ' \n', ' def load_f2cmap_file(f2cmap_file):\n', '     global f2cmap_all\n']","[' \n', ' f2cmap_default = copy.deepcopy(f2cmap_all)\n', ' \n', ' \n', ' def load_f2cmap_file(f2cmap_file):\n', '     global f2cmap_all\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['                     f2cmap_all[k][k1] = d[k][k1]\n', '                     outmess(\'\\tMapping ""%s(kind=%s)"" to ""%s""\\n\' %\n', '                             (k, k1, d[k][k1]))\n', '+                    f2cmap_mapped.append(d[k][k1])\n', '                 else:\n', '                     errmess(""\\tIgnoring map {\'%s\':{\'%s\':\'%s\'}}: \'%s\' must be in %s\\n"" % (\n', '                         k, k1, d[k][k1], d[k][k1], list(c2py_map.keys())))\n']","['                     f2cmap_all[k][k1] = d[k][k1]\n', '                     outmess(\'\\tMapping ""%s(kind=%s)"" to ""%s""\\n\' %\n', '                             (k, k1, d[k][k1]))\n', '                 else:\n', '                     errmess(""\\tIgnoring map {\'%s\':{\'%s\':\'%s\'}}: \'%s\' must be in %s\\n"" % (\n', '                         k, k1, d[k][k1], d[k][k1], list(c2py_map.keys())))\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['                 errmess(\n', ""                     'Tip: If your original code is Fortran source then you must use -m option.\\n')\n"", ""             raise TypeError('All blocks must be python module blocks but got %s' % (\n"", ""+                repr(plist['block'])))\n"", ""     auxfuncs.debugoptions = options['debug']\n"", '     f90mod_rules.options = options\n', ""     auxfuncs.wrapfuncs = options['wrapfuncs']\n""]","['                 errmess(\n', ""                     'Tip: If your original code is Fortran source then you must use -m option.\\n')\n"", ""             raise TypeError('All blocks must be python module blocks but got %s' % (\n"", ""-                repr(postlist[i]['block'])))\n"", ""     auxfuncs.debugoptions = options['debug']\n"", '     f90mod_rules.options = options\n', ""     auxfuncs.wrapfuncs = options['wrapfuncs']\n""]"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         rd = dictappend(rd, ar)\n', ' \n', '     needs = cfuncs.get_needs()\n', '+    # Add mapped definitions\n', ""+    needs['typedefs'] += [cvar for cvar in capi_maps.f2cmap_mapped #\n"", '+                          if cvar in typedef_need_dict.values()]\n', '     code = {}\n', '     for n in needs.keys():\n', '         code[n] = []\n']","['         rd = dictappend(rd, ar)\n', ' \n', '     needs = cfuncs.get_needs()\n', '     code = {}\n', '     for n in needs.keys():\n', '         code[n] = []\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['+from . import util\n', '+import numpy as np\n', '+\n', '+class TestF2Cmap(util.F2PyTest):\n', '+    sources = [\n', '+        util.getpath(""tests"", ""src"", ""f2cmap"", ""isoFortranEnvMap.f90""),\n', '+        util.getpath(""tests"", ""src"", ""f2cmap"", "".f2py_f2cmap"")\n', '+    ]\n', '+\n', '+    # gh-15095\n', '+    def test_long_long_map(self):\n', '+        inp = np.ones(3)\n', '+        out = self.module.func1(inp)\n', '+        exp_out = 3\n', '+        assert out == exp_out\n']",[]
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', ' \n', ' def _unique_dispatcher(ar, return_index=None, return_inverse=None,\n', '+                       return_counts=None, axis=None, *, equal_nan=None):\n', '     return (ar,)\n', ' \n', ' \n', ' @array_function_dispatch(_unique_dispatcher)\n', ' def unique(ar, return_index=False, return_inverse=False,\n', '+           return_counts=False, axis=None, *, equal_nan=True):\n', '     """"""\n', '     Find the unique elements of an array.\n', ' \n']","[' \n', ' \n', ' def _unique_dispatcher(ar, return_index=None, return_inverse=None,\n', '-                       return_counts=None, axis=None):\n', '     return (ar,)\n', ' \n', ' \n', ' @array_function_dispatch(_unique_dispatcher)\n', ' def unique(ar, return_index=False, return_inverse=False,\n', '-           return_counts=False, axis=None):\n', '     """"""\n', '     Find the unique elements of an array.\n', ' \n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['     return_counts : bool, optional\n', '         If True, also return the number of times each unique item appears\n', '         in `ar`.\n', '     axis : int or None, optional\n', '         The axis to operate on. If None, `ar` will be flattened. If an integer,\n', '         the subarrays indexed by the given axis will be flattened and treated\n']","['     return_counts : bool, optional\n', '         If True, also return the number of times each unique item appears\n', '         in `ar`.\n', '-\n', '-        .. versionadded:: 1.9.0\n', '-\n', '     axis : int or None, optional\n', '         The axis to operate on. If None, `ar` will be flattened. If an integer,\n', '         the subarrays indexed by the given axis will be flattened and treated\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' \n', '         .. versionadded:: 1.13.0\n', ' \n', '+    equal_nan : bool, optional\n', '+        If True, collapses multiple NaN values in the return array into one.\n', '+\n', '+        .. versionadded:: 1.24\n', '+\n', '     Returns\n', '     -------\n', '     unique : ndarray\n']","[' \n', '         .. versionadded:: 1.13.0\n', ' \n', '     Returns\n', '     -------\n', '     unique : ndarray\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['     """"""\n', '     ar = np.asanyarray(ar)\n', '     if axis is None:\n', '+        ret = _unique1d(ar, return_index, return_inverse, return_counts, \n', '+                        equal_nan=equal_nan)\n', '         return _unpack_tuple(ret)\n', ' \n', '     # axis was specified and not None\n']","['     """"""\n', '     ar = np.asanyarray(ar)\n', '     if axis is None:\n', '-        ret = _unique1d(ar, return_index, return_inverse, return_counts)\n', '         return _unpack_tuple(ret)\n', ' \n', '     # axis was specified and not None\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         return uniq\n', ' \n', '     output = _unique1d(consolidated, return_index,\n', '+                       return_inverse, return_counts, equal_nan=equal_nan)\n', '     output = (reshape_uniq(output[0]),) + output[1:]\n', '     return _unpack_tuple(output)\n', ' \n', ' \n', ' def _unique1d(ar, return_index=False, return_inverse=False,\n', '+              return_counts=False, *, equal_nan=True):\n', '     """"""\n', '     Find the unique elements of an array, ignoring shape.\n', '     """"""\n']","['         return uniq\n', ' \n', '     output = _unique1d(consolidated, return_index,\n', '-                       return_inverse, return_counts)\n', '     output = (reshape_uniq(output[0]),) + output[1:]\n', '     return _unpack_tuple(output)\n', ' \n', ' \n', ' def _unique1d(ar, return_index=False, return_inverse=False,\n', '-              return_counts=False):\n', '     """"""\n', '     Find the unique elements of an array, ignoring shape.\n', '     """"""\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         aux = ar\n', '     mask = np.empty(aux.shape, dtype=np.bool_)\n', '     mask[:1] = True\n', '+    if (equal_nan and aux.shape[0] > 0 and aux.dtype.kind in ""cfmM"" and\n', '+            np.isnan(aux[-1])):\n', '         if aux.dtype.kind == ""c"":  # for complex all NaNs are considered equivalent\n', ""             aux_firstnan = np.searchsorted(np.isnan(aux), True, side='left')\n"", '         else:\n']","['         aux = ar\n', '     mask = np.empty(aux.shape, dtype=np.bool_)\n', '     mask[:1] = True\n', '-    if aux.shape[0] > 0 and aux.dtype.kind in ""cfmM"" and np.isnan(aux[-1]):\n', '         if aux.dtype.kind == ""c"":  # for complex all NaNs are considered equivalent\n', ""             aux_firstnan = np.searchsorted(np.isnan(aux), True, side='left')\n"", '         else:\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         assert_array_equal(uniq[:, inv], data)\n', '         msg = ""Unique\'s return_counts=True failed with axis=1""\n', '         assert_array_equal(cnt, np.array([2, 1, 1]), msg)\n', '+\n', '+    def test_unique_nanequals(self):\n', '+        # issue 20326\n', '+        a = np.array([1, 1, np.nan, np.nan, np.nan])\n', '+        unq = np.unique(a)\n', '+        not_unq = np.unique(a, equal_nan=False)\n', '+        assert_array_equal(unq, np.array([1, np.nan]))\n', '+        assert_array_equal(not_unq, np.array([1, np.nan, np.nan, np.nan]))\n']","['         assert_array_equal(uniq[:, inv], data)\n', '         msg = ""Unique\'s return_counts=True failed with axis=1""\n', '         assert_array_equal(cnt, np.array([2, 1, 1]), msg)\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+@pytest.mark.filterwarnings(""error:.*integer via a float.*:DeprecationWarning"")\n', ' def test_integer_signs(dtype):\n', '     dtype = np.dtype(dtype)\n', '     assert np.loadtxt([""+2""], dtype=dtype) == 2\n']","[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', ' def test_integer_signs(dtype):\n', '     dtype = np.dtype(dtype)\n', '     assert np.loadtxt([""+2""], dtype=dtype) == 2\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', '+@pytest.mark.filterwarnings(""error:.*integer via a float.*:DeprecationWarning"")\n', ' def test_implicit_cast_float_to_int_fails(dtype):\n', '     txt = StringIO(""1.0, 2.1, 3.7\\n4, 5, 6"")\n', '     with pytest.raises(ValueError):\n']","[' @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),\n', '                     reason=""PyPy bug in error formatting"")\n', ' @pytest.mark.parametrize(""dtype"", np.typecodes[""AllInteger""])\n', ' def test_implicit_cast_float_to_int_fails(dtype):\n', '     txt = StringIO(""1.0, 2.1, 3.7\\n4, 5, 6"")\n', '     with pytest.raises(ValueError):\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"[' import pytest\n', ' import numpy as np\n', ' from numpy._typing._generic_alias import _GenericAlias\n', '+from typing_extensions import Unpack\n', ' \n', ' ScalarType = TypeVar(""ScalarType"", bound=np.generic, covariant=True)\n', ' T1 = TypeVar(""T1"")\n']","[' import pytest\n', ' import numpy as np\n', ' from numpy._typing._generic_alias import _GenericAlias\n', ' \n', ' ScalarType = TypeVar(""ScalarType"", bound=np.generic, covariant=True)\n', ' T1 = TypeVar(""T1"")\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         (""__origin__"", lambda n: n.__origin__),\n', '         (""__args__"", lambda n: n.__args__),\n', '         (""__parameters__"", lambda n: n.__parameters__),\n', '         (""__mro_entries__"", lambda n: n.__mro_entries__([object])),\n', '         (""__hash__"", lambda n: hash(n)),\n', '         (""__repr__"", lambda n: repr(n)),\n']","['         (""__origin__"", lambda n: n.__origin__),\n', '         (""__args__"", lambda n: n.__args__),\n', '         (""__parameters__"", lambda n: n.__parameters__),\n', '-        (""__reduce__"", lambda n: n.__reduce__()[1:]),\n', '-        (""__reduce_ex__"", lambda n: n.__reduce_ex__(1)[1:]),\n', '         (""__mro_entries__"", lambda n: n.__mro_entries__([object])),\n', '         (""__hash__"", lambda n: hash(n)),\n', '         (""__repr__"", lambda n: repr(n)),\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['         (""__getitem__"", lambda n: n[Union[T1, T2]][np.float32, np.float64]),\n', '         (""__eq__"", lambda n: n == n),\n', '         (""__ne__"", lambda n: n != np.ndarray),\n', '         (""__call__"", lambda n: n((1,), np.int64, BUFFER)),\n', '         (""__call__"", lambda n: n(shape=(1,), dtype=np.int64, buffer=BUFFER)),\n', '         (""subclassing"", lambda n: _get_subclass_mro(n)),\n']","['         (""__getitem__"", lambda n: n[Union[T1, T2]][np.float32, np.float64]),\n', '         (""__eq__"", lambda n: n == n),\n', '         (""__ne__"", lambda n: n != np.ndarray),\n', '-        (""__dir__"", lambda n: dir(n)),\n', '         (""__call__"", lambda n: n((1,), np.int64, BUFFER)),\n', '         (""__call__"", lambda n: n(shape=(1,), dtype=np.int64, buffer=BUFFER)),\n', '         (""subclassing"", lambda n: _get_subclass_mro(n)),\n']"
numpy/numpy,v1.23.0rc2,v1.23.0rc3,"['             value_ref = func(NDArray_ref)\n', '             assert value == value_ref\n', ' \n', '+    def test_dir(self) -> None:\n', '+        value = dir(NDArray)\n', '+        if sys.version_info < (3, 9):\n', '+            return\n', '+\n', '+        # A number attributes only exist in `types.GenericAlias` in >= 3.11\n', '+        if sys.version_info < (3, 11, 0, ""beta"", 3):\n', '+            value.remove(""__typing_unpacked_tuple_args__"")\n', '+        if sys.version_info < (3, 11, 0, ""beta"", 1):\n', '+            value.remove(""__unpacked__"")\n', '+        assert value == dir(NDArray_ref)\n', '+\n', '+    @pytest.mark.parametrize(""name,func,dev_version"", [\n', '+        (""__iter__"", lambda n: len(list(n)), (""beta"", 1)),\n', '+        (""__iter__"", lambda n: next(iter(n)), (""beta"", 1)),\n', '+        (""__unpacked__"", lambda n: n.__unpacked__, (""beta"", 1)),\n', '+        (""Unpack"", lambda n: Unpack[n], (""beta"", 1)),\n', '+\n', '+        # The right operand should now have `__unpacked__ = True`,\n', '+        # and they are thus now longer equivalent\n', '+        (""__ne__"", lambda n: n != next(iter(n)), (""beta"", 1)),\n', '+\n', '+        # >= beta3 stuff\n', '+        (""__typing_unpacked_tuple_args__"",\n', '+         lambda n: n.__typing_unpacked_tuple_args__, (""beta"", 3)),\n', '+    ])\n', '+    def test_py311_features(\n', '+        self,\n', '+        name: str,\n', '+        func: FuncType,\n', '+        dev_version: tuple[str, int],\n', '+    ) -> None:\n', '+        """"""Test Python 3.11 features.""""""\n', '+        value = func(NDArray)\n', '+\n', '+        if sys.version_info >= (3, 11, 0, *dev_version):\n', '+            value_ref = func(NDArray_ref)\n', '+            assert value == value_ref\n', '+\n', '     def test_weakref(self) -> None:\n', '         """"""Test ``__weakref__``.""""""\n', '         value = weakref.ref(NDArray)()\n']","['             value_ref = func(NDArray_ref)\n', '             assert value == value_ref\n', ' \n', '     def test_weakref(self) -> None:\n', '         """"""Test ``__weakref__``.""""""\n', '         value = weakref.ref(NDArray)()\n']"
numpy/numpy,v1.23.0rc1,v1.23.0rc2,"['         buf = x.tobytes()\n', '         assert_array_equal(np.frombuffer(buf, dtype=dt), x.flat)\n', ' \n', '+    @pytest.mark.parametrize(""obj"", [np.arange(10), b""12345678""])\n', '+    def test_array_base(self, obj):\n', '+        # Objects (including NumPy arrays), which do not use the\n', '+        # `release_buffer` slot should be directly used as a base object.\n', '+        # See also gh-21612\n', '+        new = np.frombuffer(obj)\n', '+        assert new.base is obj\n', ' \n', '     def test_empty(self):\n', ""         assert_array_equal(np.frombuffer(b''), np.array([]))\n""]","['         buf = x.tobytes()\n', '         assert_array_equal(np.frombuffer(buf, dtype=dt), x.flat)\n', ' \n', '-    def test_array_base(self):\n', '-        arr = np.arange(10)\n', '-        new = np.frombuffer(arr)\n', '-        # We currently special case arrays to ensure they are used as a base.\n', '-        # This could probably be changed (removing the test).\n', '-        assert new.base is arr\n', ' \n', '     def test_empty(self):\n', ""         assert_array_equal(np.frombuffer(b''), np.array([]))\n""]"
numpy/numpy,v1.23.0rc1,v1.23.0rc2,"[' \n', '         needs_f77 = False\n', '         needs_f90 = False\n', '+        needs_pyf = False\n', '         for fn in codes:\n', '             if str(fn).endswith("".f""):\n', '                 needs_f77 = True\n', '             elif str(fn).endswith("".f90""):\n', '                 needs_f90 = True\n', '+            elif str(fn).endswith("".pyf""):\n', '+                needs_pyf = True\n', '         if needs_f77 and not has_f77_compiler():\n', '             pytest.skip(""No Fortran 77 compiler available"")\n', '         if needs_f90 and not has_f90_compiler():\n', '             pytest.skip(""No Fortran 90 compiler available"")\n', '+        if needs_pyf and not (has_f90_compiler() or has_f77_compiler()):\n', '+            pytest.skip(""No Fortran compiler available"")\n', ' \n', '         # Build the module\n', '         if self.code is not None:\n']","[' \n', '         needs_f77 = False\n', '         needs_f90 = False\n', '         for fn in codes:\n', '             if str(fn).endswith("".f""):\n', '                 needs_f77 = True\n', '             elif str(fn).endswith("".f90""):\n', '                 needs_f90 = True\n', '         if needs_f77 and not has_f77_compiler():\n', '             pytest.skip(""No Fortran 77 compiler available"")\n', '         if needs_f90 and not has_f90_compiler():\n', '             pytest.skip(""No Fortran 90 compiler available"")\n', ' \n', '         # Build the module\n', '         if self.code is not None:\n']"
numpy/numpy,v1.23.0rc1,v1.23.0rc2,"[' import urllib3\n', ' from bs4 import BeautifulSoup\n', ' \n', '+__version__ = ""0.1""\n', ' \n', ' # Edit these for other projects.\n', '+STAGING_URL = ""https://anaconda.org/multibuild-wheels-staging/numpy""\n', '+PREFIX = ""numpy""\n', '+\n', '+# Name endings of the files to download.\n', '+WHL = r""-.*\\.whl$""\n', '+ZIP = r""\\.zip$""\n', '+GZIP = r""\\.tar\\.gz$""\n', '+SUFFIX = rf""({WHL}|{GZIP}|{ZIP})""\n', ' \n', ' \n', ' def get_wheel_names(version):\n']","[' import urllib3\n', ' from bs4 import BeautifulSoup\n', ' \n', ""-__version__ = '0.1'\n"", ' \n', ' # Edit these for other projects.\n', ""-STAGING_URL = 'https://anaconda.org/multibuild-wheels-staging/numpy'\n"", ""-PREFIX = 'numpy'\n"", ' \n', ' \n', ' def get_wheel_names(version):\n']"
numpy/numpy,v1.23.0rc1,v1.23.0rc2,"['         The release version. For instance, ""1.18.3"".\n', ' \n', '     """"""\n', '+    http = urllib3.PoolManager(cert_reqs=""CERT_REQUIRED"")\n', '+    tmpl = re.compile(rf""^.*{PREFIX}-{version}{SUFFIX}"")\n', '     index_url = f""{STAGING_URL}/files""\n', '+    index_html = http.request(""GET"", index_url)\n', '+    soup = BeautifulSoup(index_html.data, ""html.parser"")\n', '     return soup.findAll(text=tmpl)\n', ' \n', ' \n']","['         The release version. For instance, ""1.18.3"".\n', ' \n', '     """"""\n', ""-    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED')\n"", '-    tmpl = re.compile(rf""^.*{PREFIX}-{version}-.*\\.whl$"")\n', '     index_url = f""{STAGING_URL}/files""\n', ""-    index_html = http.request('GET', index_url)\n"", ""-    soup = BeautifulSoup(index_html.data, 'html.parser')\n"", '     return soup.findAll(text=tmpl)\n', ' \n', ' \n']"
numpy/numpy,v1.23.0rc1,v1.23.0rc2,"['         Directory in which to download the wheels.\n', ' \n', '     """"""\n', '+    http = urllib3.PoolManager(cert_reqs=""CERT_REQUIRED"")\n', '     wheel_names = get_wheel_names(version)\n', ' \n', '     for i, wheel_name in enumerate(wheel_names):\n', '         wheel_url = f""{STAGING_URL}/{version}/download/{wheel_name}""\n', '         wheel_path = os.path.join(wheelhouse, wheel_name)\n', '+        with open(wheel_path, ""wb"") as f:\n', '+            with http.request(""GET"", wheel_url, preload_content=False,) as r:\n', '                 print(f""{i + 1:<4}{wheel_name}"")\n', '                 shutil.copyfileobj(r, f)\n', '     print(f""\\nTotal files downloaded: {len(wheel_names)}"")\n', ' \n', ' \n', '+if __name__ == ""__main__"":\n', '     parser = argparse.ArgumentParser()\n', '     parser.add_argument(\n', '         ""version"",\n']","['         Directory in which to download the wheels.\n', ' \n', '     """"""\n', ""-    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED')\n"", '     wheel_names = get_wheel_names(version)\n', ' \n', '     for i, wheel_name in enumerate(wheel_names):\n', '         wheel_url = f""{STAGING_URL}/{version}/download/{wheel_name}""\n', '         wheel_path = os.path.join(wheelhouse, wheel_name)\n', ""-        with open(wheel_path, 'wb') as f:\n"", ""-            with http.request('GET', wheel_url, preload_content=False,) as r:\n"", '                 print(f""{i + 1:<4}{wheel_name}"")\n', '                 shutil.copyfileobj(r, f)\n', '     print(f""\\nTotal files downloaded: {len(wheel_names)}"")\n', ' \n', ' \n', ""-if __name__ == '__main__':\n"", '     parser = argparse.ArgumentParser()\n', '     parser.add_argument(\n', '         ""version"",\n']"
